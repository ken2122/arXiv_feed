{"custom_id": "2511.07441v3", "method": "POST", "url": "/v1/responses", "body": {"model": "gpt-5-mini", "input": "You are a specialist research analyst in Web3, DeFi, cryptography, and distributed systems.\n\n    Your task:\n    From the paper below (Title + Summary + Link), evaluate how useful each paper is for understanding investment opportunities or technological advantages within the Web3 / crypto / DeFi ecosystem.\n    Rate each paper on a five-level scale: Highest / High / Medium / Low / Lowest.\n\n    \"Useful\" means:\n\n    - Improves understanding of new cryptographic primitives relevant to blockchain performance or security\n    - Enhances scalability: distributed systems, P2P networking, consensus mechanisms\n    - Advances in zero knowledge, MPC, PQC that could impact future L1/L2 chains\n    - DeFi modeling, AMMs, MEV, risk models, liquidity dynamics\n    - Smart contract security, attack vectors, economic incentives\n    - Token economics, mechanism design for decentralized systems\n    - Quantum threats to blockchain or cryptography\n    - Any breakthrough that meaningfully improves decentralization, scalability, privacy, or composability\n\n    Output instructions:\n\n    - Output each JSON object in JSON Lines format (one line per paper).\n\n    {\n        \"title\": title of the paper (in Japanese),\n        \"summary\": A concise summary of the paper (in Japanese),\n        \"impact_level\": \"Highest|High|Medium|Low|Lowest\",\n        \"why_matters\": An array (JSON array) containing 2\u20134 bullet points explaining why this paper matters for Web3 investment\n    }\n\n    - Do not output anything except valid JSON object in JSON Lines.\n    - \"title\", \"summary\", \"why_matters\" text in the output must be written in Japanese.\n\n    Paper:\n    title: AudAgent: Automated Auditing of Privacy Policy Compliance in AI Agents\n    summary: AI agents can autonomously perform tasks and, often without explicit user consent, collect or disclose users' sensitive local data, which raises serious privacy concerns. Although AI agents' privacy policies describe their intended data practices, there remains limited transparency and accountability about whether runtime behavior matches those policies. To close this gap, we introduce AudAgent, a visual tool that continuously monitors AI agents' data practices in real time and guards compliance with stated privacy policies.\n  AudAgent consists of four components for automated privacy auditing of AI agents. (i) Policy formalization: a novel cross-LLM voting mechanism to guarantee confidence of the parsed privacy policy model. (ii) Runtime annotation: a lightweight Presidio-based analyzer detects sensitive data and annotates data practices based on the AI agent's context and the privacy policy model. (iii) Compliance auditing: ontology graphs and automata-based checking connect the privacy policy model with runtime annotations, enabling on-the-fly compliance checking. (iv) User interface: an infrastructure-independent implementation visualizes the real-time execution trace of AI agents along with potential privacy policy violations, providing user-friendly transparency and accountability.\n  We evaluate AudAgent with AI agents built using mainstream frameworks, demonstrating its effectiveness in detecting and visualizing privacy policy violations in real time. Using AudAgent, we also find that most privacy policies omit explicit safeguards for highly sensitive data such as SSNs, whose misuse violates legal requirements, and that many agents do not refuse handling such data via third-party tools, including those controlled by Claude, Gemini, and DeepSeek. AudAgent proactively blocks operations on such data, overriding the agents' original privacy policy and behavior.\n    link: https://arxiv.org/abs/2511.07441v3\n    "}}
{"custom_id": "2512.05069v1", "method": "POST", "url": "/v1/responses", "body": {"model": "gpt-5-mini", "input": "You are a specialist research analyst in Web3, DeFi, cryptography, and distributed systems.\n\n    Your task:\n    From the paper below (Title + Summary + Link), evaluate how useful each paper is for understanding investment opportunities or technological advantages within the Web3 / crypto / DeFi ecosystem.\n    Rate each paper on a five-level scale: Highest / High / Medium / Low / Lowest.\n\n    \"Useful\" means:\n\n    - Improves understanding of new cryptographic primitives relevant to blockchain performance or security\n    - Enhances scalability: distributed systems, P2P networking, consensus mechanisms\n    - Advances in zero knowledge, MPC, PQC that could impact future L1/L2 chains\n    - DeFi modeling, AMMs, MEV, risk models, liquidity dynamics\n    - Smart contract security, attack vectors, economic incentives\n    - Token economics, mechanism design for decentralized systems\n    - Quantum threats to blockchain or cryptography\n    - Any breakthrough that meaningfully improves decentralization, scalability, privacy, or composability\n\n    Output instructions:\n\n    - Output each JSON object in JSON Lines format (one line per paper).\n\n    {\n        \"title\": title of the paper (in Japanese),\n        \"summary\": A concise summary of the paper (in Japanese),\n        \"impact_level\": \"Highest|High|Medium|Low|Lowest\",\n        \"why_matters\": An array (JSON array) containing 2\u20134 bullet points explaining why this paper matters for Web3 investment\n    }\n\n    - Do not output anything except valid JSON object in JSON Lines.\n    - \"title\", \"summary\", \"why_matters\" text in the output must be written in Japanese.\n\n    Paper:\n    title: Hybrid Quantum-Classical Autoencoders for Unsupervised Network Intrusion Detection\n    summary: Unsupervised anomaly-based intrusion detection requires models that can generalize to attack patterns not observed during training. This work presents the first large-scale evaluation of hybrid quantum-classical (HQC) autoencoders for this task. We construct a unified experimental framework that iterates over key quantum design choices, including quantum-layer placement, measurement approach, variational and non-variational formulations, and latent-space regularization. Experiments across three benchmark NIDS datasets show that HQC autoencoders can match or exceed classical performance in their best configurations, although they exhibit higher sensitivity to architectural decisions. Under zero-day evaluation, well-configured HQC models provide stronger and more stable generalization than classical and supervised baselines. Simulated gate-noise experiments reveal early performance degradation, indicating the need for noise-aware HQC designs. These results provide the first data-driven characterization of HQC autoencoder behavior for network intrusion detection and outline key factors that govern their practical viability. All experiment code and configurations are available at https://github.com/arasyi/hqcae-network-intrusion-detection.\n    link: https://arxiv.org/abs/2512.05069v1\n    "}}
{"custom_id": "2512.05065v1", "method": "POST", "url": "/v1/responses", "body": {"model": "gpt-5-mini", "input": "You are a specialist research analyst in Web3, DeFi, cryptography, and distributed systems.\n\n    Your task:\n    From the paper below (Title + Summary + Link), evaluate how useful each paper is for understanding investment opportunities or technological advantages within the Web3 / crypto / DeFi ecosystem.\n    Rate each paper on a five-level scale: Highest / High / Medium / Low / Lowest.\n\n    \"Useful\" means:\n\n    - Improves understanding of new cryptographic primitives relevant to blockchain performance or security\n    - Enhances scalability: distributed systems, P2P networking, consensus mechanisms\n    - Advances in zero knowledge, MPC, PQC that could impact future L1/L2 chains\n    - DeFi modeling, AMMs, MEV, risk models, liquidity dynamics\n    - Smart contract security, attack vectors, economic incentives\n    - Token economics, mechanism design for decentralized systems\n    - Quantum threats to blockchain or cryptography\n    - Any breakthrough that meaningfully improves decentralization, scalability, privacy, or composability\n\n    Output instructions:\n\n    - Output each JSON object in JSON Lines format (one line per paper).\n\n    {\n        \"title\": title of the paper (in Japanese),\n        \"summary\": A concise summary of the paper (in Japanese),\n        \"impact_level\": \"Highest|High|Medium|Low|Lowest\",\n        \"why_matters\": An array (JSON array) containing 2\u20134 bullet points explaining why this paper matters for Web3 investment\n    }\n\n    - Do not output anything except valid JSON object in JSON Lines.\n    - \"title\", \"summary\", \"why_matters\" text in the output must be written in Japanese.\n\n    Paper:\n    title: Personalizing Agent Privacy Decisions via Logical Entailment\n    summary: Personal language model-based agents are becoming more widespread for completing tasks on behalf of users; however, this raises serious privacy questions regarding whether these models will appropriately disclose user data. While prior work has evaluated language models on data-sharing scenarios based on general privacy norms, we focus on personalizing language models' privacy decisions, grounding their judgments directly in prior user privacy decisions. Our findings suggest that general privacy norms are insufficient for effective personalization of privacy decisions. Furthermore, we find that eliciting privacy judgments from the model through In-context Learning (ICL) is unreliable to due misalignment with the user's prior privacy judgments and opaque reasoning traces, which make it difficult for the user to interpret the reasoning behind the model's decisions. To address these limitations, we propose ARIEL (Agentic Reasoning with Individualized Entailment Logic), a framework that jointly leverages a language model and rule-based logic for structured data-sharing reasoning. ARIEL is based on formulating personalization of data sharing as an entailment, whether a prior user judgment on a data-sharing request implies the same judgment for an incoming request. Our experimental evaluations on advanced models and publicly-available datasets demonstrate that ARIEL can reduce the F1 score error by $\\textbf{39.1%}$ over language model-based reasoning (ICL), demonstrating that ARIEL is effective at correctly judging requests where the user would approve data sharing. Overall, our findings suggest that combining LLMs with strict logical entailment is a highly effective strategy for enabling personalized privacy judgments for agents.\n    link: https://arxiv.org/abs/2512.05065v1\n    "}}
{"custom_id": "2412.13222v3", "method": "POST", "url": "/v1/responses", "body": {"model": "gpt-5-mini", "input": "You are a specialist research analyst in Web3, DeFi, cryptography, and distributed systems.\n\n    Your task:\n    From the paper below (Title + Summary + Link), evaluate how useful each paper is for understanding investment opportunities or technological advantages within the Web3 / crypto / DeFi ecosystem.\n    Rate each paper on a five-level scale: Highest / High / Medium / Low / Lowest.\n\n    \"Useful\" means:\n\n    - Improves understanding of new cryptographic primitives relevant to blockchain performance or security\n    - Enhances scalability: distributed systems, P2P networking, consensus mechanisms\n    - Advances in zero knowledge, MPC, PQC that could impact future L1/L2 chains\n    - DeFi modeling, AMMs, MEV, risk models, liquidity dynamics\n    - Smart contract security, attack vectors, economic incentives\n    - Token economics, mechanism design for decentralized systems\n    - Quantum threats to blockchain or cryptography\n    - Any breakthrough that meaningfully improves decentralization, scalability, privacy, or composability\n\n    Output instructions:\n\n    - Output each JSON object in JSON Lines format (one line per paper).\n\n    {\n        \"title\": title of the paper (in Japanese),\n        \"summary\": A concise summary of the paper (in Japanese),\n        \"impact_level\": \"Highest|High|Medium|Low|Lowest\",\n        \"why_matters\": An array (JSON array) containing 2\u20134 bullet points explaining why this paper matters for Web3 investment\n    }\n\n    - Do not output anything except valid JSON object in JSON Lines.\n    - \"title\", \"summary\", \"why_matters\" text in the output must be written in Japanese.\n\n    Paper:\n    title: Near Real-time Adaptive Isotropic and Anisotropic Image-to-mesh Conversion for Numerical Simulations Involving Cerebral Aneurysms\n    summary: Presented are two techniques that are designed to help streamline the discretization of complex vascular geometries within the numerical modeling process. The first method integrates multiple software tools into a single pipeline which can generate adaptive anisotropic meshes from segmented medical images. The pipeline is shown to satisfy quality, fidelity, smoothness, and robustness requirements while providing near real-time performance for medical image-to-mesh conversion. The second method approximates a user-defined sizing function to generate adaptive isotropic meshes of good quality and fidelity in real-time. Tested with two brain aneurysm cases and utilizing up to 96 CPU cores within a single, multicore node on Purdue University's Anvil supercomputer, the parallel adaptive anisotropic meshing method utilizes a hierarchical load balancing model (designed for large, cc-NUMA shared memory architectures) and contains an optimized local reconnection operation that performs three times faster than its original implementation from previous studies. The adaptive isotropic method is shown to generate a mesh of up to approximately 50 million elements in less than a minute while the adaptive anisotropic method is shown to generate approximately the same number of elements in about 5 minutes.\n    link: https://arxiv.org/abs/2412.13222v3\n    "}}
{"custom_id": "2504.14005v5", "method": "POST", "url": "/v1/responses", "body": {"model": "gpt-5-mini", "input": "You are a specialist research analyst in Web3, DeFi, cryptography, and distributed systems.\n\n    Your task:\n    From the paper below (Title + Summary + Link), evaluate how useful each paper is for understanding investment opportunities or technological advantages within the Web3 / crypto / DeFi ecosystem.\n    Rate each paper on a five-level scale: Highest / High / Medium / Low / Lowest.\n\n    \"Useful\" means:\n\n    - Improves understanding of new cryptographic primitives relevant to blockchain performance or security\n    - Enhances scalability: distributed systems, P2P networking, consensus mechanisms\n    - Advances in zero knowledge, MPC, PQC that could impact future L1/L2 chains\n    - DeFi modeling, AMMs, MEV, risk models, liquidity dynamics\n    - Smart contract security, attack vectors, economic incentives\n    - Token economics, mechanism design for decentralized systems\n    - Quantum threats to blockchain or cryptography\n    - Any breakthrough that meaningfully improves decentralization, scalability, privacy, or composability\n\n    Output instructions:\n\n    - Output each JSON object in JSON Lines format (one line per paper).\n\n    {\n        \"title\": title of the paper (in Japanese),\n        \"summary\": A concise summary of the paper (in Japanese),\n        \"impact_level\": \"Highest|High|Medium|Low|Lowest\",\n        \"why_matters\": An array (JSON array) containing 2\u20134 bullet points explaining why this paper matters for Web3 investment\n    }\n\n    - Do not output anything except valid JSON object in JSON Lines.\n    - \"title\", \"summary\", \"why_matters\" text in the output must be written in Japanese.\n\n    Paper:\n    title: Short remarks on shallow unitary circuits\n    summary: (i) We point out that every local unitary circuit of depth smaller than the linear system size is easily distinguished from a global Haar random unitary if there is a conserved quantity that is a sum of local operators. This is always the case with a continuous onsite symmetry or with a local energy conservation law. (ii) We explain a simple algorithm for a formulation of the shallow unitary circuit learning problem and relate it to an open question on strictly locality-preserving unitaries (quantum cellular automata). (iii) We show that any translation-invariant quantum cellular automaton in $D$-dimensional lattice of volume $V$ can be implemented using only $O(V)$ local gates in a staircase fashion using invertible subalgebra pumping.\n    link: https://arxiv.org/abs/2504.14005v5\n    "}}
{"custom_id": "2512.05022v1", "method": "POST", "url": "/v1/responses", "body": {"model": "gpt-5-mini", "input": "You are a specialist research analyst in Web3, DeFi, cryptography, and distributed systems.\n\n    Your task:\n    From the paper below (Title + Summary + Link), evaluate how useful each paper is for understanding investment opportunities or technological advantages within the Web3 / crypto / DeFi ecosystem.\n    Rate each paper on a five-level scale: Highest / High / Medium / Low / Lowest.\n\n    \"Useful\" means:\n\n    - Improves understanding of new cryptographic primitives relevant to blockchain performance or security\n    - Enhances scalability: distributed systems, P2P networking, consensus mechanisms\n    - Advances in zero knowledge, MPC, PQC that could impact future L1/L2 chains\n    - DeFi modeling, AMMs, MEV, risk models, liquidity dynamics\n    - Smart contract security, attack vectors, economic incentives\n    - Token economics, mechanism design for decentralized systems\n    - Quantum threats to blockchain or cryptography\n    - Any breakthrough that meaningfully improves decentralization, scalability, privacy, or composability\n\n    Output instructions:\n\n    - Output each JSON object in JSON Lines format (one line per paper).\n\n    {\n        \"title\": title of the paper (in Japanese),\n        \"summary\": A concise summary of the paper (in Japanese),\n        \"impact_level\": \"Highest|High|Medium|Low|Lowest\",\n        \"why_matters\": An array (JSON array) containing 2\u20134 bullet points explaining why this paper matters for Web3 investment\n    }\n\n    - Do not output anything except valid JSON object in JSON Lines.\n    - \"title\", \"summary\", \"why_matters\" text in the output must be written in Japanese.\n\n    Paper:\n    title: Emergence of ER=EPR from non-local gravitational energy\n    summary: We construct a class of wormhole geometries supported by the non-local gravitational self-energy that regularizes the particle and black-hole sectors of spacetime. Using this framework, inspired by T-duality, we show that two entangled particles (or particle-black-hole pairs) naturally source an Einstein-Rosen-type geometry in which the required violation of the strong energy condition arises from intrinsic quantum-gravity effects rather than from ad hoc exotic matter, which is matter that violates the null energy condition. We classify the resulting wormholes, analyze their horizons, throat structure and embedding properties, and we identify the exotic energy needed at the minimal surface. Imposing the ER=EPR requirement of non-traversability and the absence of a macroscopic throat, we find that only the zero-throat geometry is compatible with an entanglement-induced Einstein-Rosen bridge, providing a concrete realization of ER=EPR within a fully regular spacetime. Finally, we briefly discuss possible implications for microscopic ER networks from vacuum fluctuations, replica-wormhole interpretations of Hawking radiation, and possible links to entanglement-driven dark-energy scenarios.\n    link: https://arxiv.org/abs/2512.05022v1\n    "}}
{"custom_id": "2512.05014v1", "method": "POST", "url": "/v1/responses", "body": {"model": "gpt-5-mini", "input": "You are a specialist research analyst in Web3, DeFi, cryptography, and distributed systems.\n\n    Your task:\n    From the paper below (Title + Summary + Link), evaluate how useful each paper is for understanding investment opportunities or technological advantages within the Web3 / crypto / DeFi ecosystem.\n    Rate each paper on a five-level scale: Highest / High / Medium / Low / Lowest.\n\n    \"Useful\" means:\n\n    - Improves understanding of new cryptographic primitives relevant to blockchain performance or security\n    - Enhances scalability: distributed systems, P2P networking, consensus mechanisms\n    - Advances in zero knowledge, MPC, PQC that could impact future L1/L2 chains\n    - DeFi modeling, AMMs, MEV, risk models, liquidity dynamics\n    - Smart contract security, attack vectors, economic incentives\n    - Token economics, mechanism design for decentralized systems\n    - Quantum threats to blockchain or cryptography\n    - Any breakthrough that meaningfully improves decentralization, scalability, privacy, or composability\n\n    Output instructions:\n\n    - Output each JSON object in JSON Lines format (one line per paper).\n\n    {\n        \"title\": title of the paper (in Japanese),\n        \"summary\": A concise summary of the paper (in Japanese),\n        \"impact_level\": \"Highest|High|Medium|Low|Lowest\",\n        \"why_matters\": An array (JSON array) containing 2\u20134 bullet points explaining why this paper matters for Web3 investment\n    }\n\n    - Do not output anything except valid JSON object in JSON Lines.\n    - \"title\", \"summary\", \"why_matters\" text in the output must be written in Japanese.\n\n    Paper:\n    title: Hall-like response from anisotropic Fermi surfaces\n    summary: We demonstrate that an anisotropic and rotated Fermi surface can generate a finite Hall-like transverse response in electron transport, even in the absence of a magnetic field or Berry curvature. Using a two-dimensional continuum model, we show that broken $k_y \\to -k_y$ symmetry inherent to anistropic band structures leads to a nonzero transverse conductivity. We construct a lattice model with direction-dependent nearest- and next-nearest-neighbor hoppings that faithfully reproduces the continuum dispersion and allows controlled rotation of the Fermi contour. Employing a multiterminal geometry and the B\u00fcttiker-probe method, we compute the resulting Hall voltage and establish its direct correspondence with the continuum transverse response. The effect increases with the degree of anisotropy and vanishes at rotation angles where mirror symmetry is restored. Unlike the quantum Hall effect, the Hall response predicted here is not quantized but varies continuously with the band-structure parameters. Our results provide a symmetry-based route to engineer Hall-like signals in low-symmetry materials without magnetic fields or topological effects.\n    link: https://arxiv.org/abs/2512.05014v1\n    "}}
{"custom_id": "2512.05011v1", "method": "POST", "url": "/v1/responses", "body": {"model": "gpt-5-mini", "input": "You are a specialist research analyst in Web3, DeFi, cryptography, and distributed systems.\n\n    Your task:\n    From the paper below (Title + Summary + Link), evaluate how useful each paper is for understanding investment opportunities or technological advantages within the Web3 / crypto / DeFi ecosystem.\n    Rate each paper on a five-level scale: Highest / High / Medium / Low / Lowest.\n\n    \"Useful\" means:\n\n    - Improves understanding of new cryptographic primitives relevant to blockchain performance or security\n    - Enhances scalability: distributed systems, P2P networking, consensus mechanisms\n    - Advances in zero knowledge, MPC, PQC that could impact future L1/L2 chains\n    - DeFi modeling, AMMs, MEV, risk models, liquidity dynamics\n    - Smart contract security, attack vectors, economic incentives\n    - Token economics, mechanism design for decentralized systems\n    - Quantum threats to blockchain or cryptography\n    - Any breakthrough that meaningfully improves decentralization, scalability, privacy, or composability\n\n    Output instructions:\n\n    - Output each JSON object in JSON Lines format (one line per paper).\n\n    {\n        \"title\": title of the paper (in Japanese),\n        \"summary\": A concise summary of the paper (in Japanese),\n        \"impact_level\": \"Highest|High|Medium|Low|Lowest\",\n        \"why_matters\": An array (JSON array) containing 2\u20134 bullet points explaining why this paper matters for Web3 investment\n    }\n\n    - Do not output anything except valid JSON object in JSON Lines.\n    - \"title\", \"summary\", \"why_matters\" text in the output must be written in Japanese.\n\n    Paper:\n    title: Risk aversion of insider and dynamic asymmetric information\n    summary: This paper studies a Kyle-Back model with a risk-averse insider possessing exponential utility and a dynamic stochastic signal about the asset's terminal fundamental value. While the existing literature considers either risk-neutral insiders with dynamic signals or risk-averse insiders with static signals, we establish equilibrium when both features are present. Our approach imposes no restrictions on the magnitude of the risk aversion parameter, extending beyond previous work that requires sufficiently small risk aversion. We employ a weak conditioning methodology to construct a Schr\u00f6dinger bridge between the insider's signal and the asset price process, an approach that naturally accommodates stochastic signal evolution and removes risk aversion constraints.\n  We derive necessary conditions for equilibrium, showing that the optimal insider strategy must be continuous with bounded variation. Under these conditions, we characterize the market-maker pricing rule and insider strategy that achieve equilibrium. We obtain explicit closed-form solutions for important cases including deterministic and quadratic signal volatilities, demonstrating the tractability of our framework.\n    link: https://arxiv.org/abs/2512.05011v1\n    "}}
{"custom_id": "2512.04984v1", "method": "POST", "url": "/v1/responses", "body": {"model": "gpt-5-mini", "input": "You are a specialist research analyst in Web3, DeFi, cryptography, and distributed systems.\n\n    Your task:\n    From the paper below (Title + Summary + Link), evaluate how useful each paper is for understanding investment opportunities or technological advantages within the Web3 / crypto / DeFi ecosystem.\n    Rate each paper on a five-level scale: Highest / High / Medium / Low / Lowest.\n\n    \"Useful\" means:\n\n    - Improves understanding of new cryptographic primitives relevant to blockchain performance or security\n    - Enhances scalability: distributed systems, P2P networking, consensus mechanisms\n    - Advances in zero knowledge, MPC, PQC that could impact future L1/L2 chains\n    - DeFi modeling, AMMs, MEV, risk models, liquidity dynamics\n    - Smart contract security, attack vectors, economic incentives\n    - Token economics, mechanism design for decentralized systems\n    - Quantum threats to blockchain or cryptography\n    - Any breakthrough that meaningfully improves decentralization, scalability, privacy, or composability\n\n    Output instructions:\n\n    - Output each JSON object in JSON Lines format (one line per paper).\n\n    {\n        \"title\": title of the paper (in Japanese),\n        \"summary\": A concise summary of the paper (in Japanese),\n        \"impact_level\": \"Highest|High|Medium|Low|Lowest\",\n        \"why_matters\": An array (JSON array) containing 2\u20134 bullet points explaining why this paper matters for Web3 investment\n    }\n\n    - Do not output anything except valid JSON object in JSON Lines.\n    - \"title\", \"summary\", \"why_matters\" text in the output must be written in Japanese.\n\n    Paper:\n    title: Federated Learning for Terahertz Wireless Communication\n    summary: The convergence of Terahertz (THz) communications and Federated Learning (FL) promises ultra-fast distributed learning, yet the impact of realistic wideband impairments on optimization dynamics remains theoretically uncharacterized. This paper bridges this gap by developing a multicarrier stochastic framework that explicitly couples local gradient updates with frequency-selective THz effects, including beam squint, molecular absorption, and jitter. Our analysis uncovers a critical diversity trap: under standard unbiased aggregation, the convergence error floor is driven by the harmonic mean of subcarrier SNRs. Consequently, a single spectral hole caused by severe beam squint can render the entire bandwidth useless for reliable model updates. We further identify a fundamental bandwidth limit, revealing that expanding the spectrum beyond a critical point degrades convergence due to the integration of thermal noise and gain collapse at band edges. Finally, we demonstrate that an SNR-weighted aggregation strategy is necessary to suppress the variance singularity at these spectral holes, effectively recovering convergence in high-squint regimes where standard averaging fails. Numerical results validate the expected impact of the discussed physical layer parameters' on performance of THz-FL systems.\n    link: https://arxiv.org/abs/2512.04984v1\n    "}}
{"custom_id": "2201.05094v2", "method": "POST", "url": "/v1/responses", "body": {"model": "gpt-5-mini", "input": "You are a specialist research analyst in Web3, DeFi, cryptography, and distributed systems.\n\n    Your task:\n    From the paper below (Title + Summary + Link), evaluate how useful each paper is for understanding investment opportunities or technological advantages within the Web3 / crypto / DeFi ecosystem.\n    Rate each paper on a five-level scale: Highest / High / Medium / Low / Lowest.\n\n    \"Useful\" means:\n\n    - Improves understanding of new cryptographic primitives relevant to blockchain performance or security\n    - Enhances scalability: distributed systems, P2P networking, consensus mechanisms\n    - Advances in zero knowledge, MPC, PQC that could impact future L1/L2 chains\n    - DeFi modeling, AMMs, MEV, risk models, liquidity dynamics\n    - Smart contract security, attack vectors, economic incentives\n    - Token economics, mechanism design for decentralized systems\n    - Quantum threats to blockchain or cryptography\n    - Any breakthrough that meaningfully improves decentralization, scalability, privacy, or composability\n\n    Output instructions:\n\n    - Output each JSON object in JSON Lines format (one line per paper).\n\n    {\n        \"title\": title of the paper (in Japanese),\n        \"summary\": A concise summary of the paper (in Japanese),\n        \"impact_level\": \"Highest|High|Medium|Low|Lowest\",\n        \"why_matters\": An array (JSON array) containing 2\u20134 bullet points explaining why this paper matters for Web3 investment\n    }\n\n    - Do not output anything except valid JSON object in JSON Lines.\n    - \"title\", \"summary\", \"why_matters\" text in the output must be written in Japanese.\n\n    Paper:\n    title: Thermodynamic formalism for continuous-time quantum Markov semigroups: the detailed balance condition, entropy, pressure and equilibrium quantum processes\n    summary: $M_n(\\mathbb{C})$ denotes the set of $n$ by $n$ complex matrices. Consider continuous time quantum semigroups $\\mathcal{P}_t= e^{t\\, \\mathcal{L}}$, $t \\geq 0$, where $\\mathcal{L}:M_n(\\mathbb{C}) \\to M_n(\\mathbb{C})$ is the infinitesimal generator. If we assume that $\\mathcal{L}(I)=0$, we will call $e^{t\\, \\mathcal{L}}$, $t \\geq 0$ a quantum Markov semigroup. Given a stationary density matrix $\u03c1= \u03c1_{\\mathcal{L}}$, for the quantum Markov semigroup $\\mathcal{P}_t$, $t \\geq 0$, we can define a continuous time stationary quantum Markov process, denoted by $X_t$, $t \\geq 0.$ Given an {\\it a priori} Laplacian operator $\\mathcal{L}_0:M_n(\\mathbb{C}) \\to M_n(\\mathbb{C})$, we will present a natural concept of entropy for a class of density matrices on $M_n(\\mathbb{C})$. Given an Hermitian operator $A:\\mathbb{C}^n\\to \\mathbb{C}^n$ (which plays the role of an Hamiltonian), we will study a version of the variational principle of pressure for $A$. A density matrix $\u03c1_A$ maximizing pressure will be called an equilibrium density matrix. From $\u03c1_A$ we will derive a new infinitesimal generator $\\mathcal{L}_A$. Finally, the continuous time quantum Markov process defined by the semigroup $\\mathcal{P}_t= e^{t\\, \\mathcal{L}_A}$, $t \\geq 0$, and an initial stationary density matrix, will be called the continuous time equilibrium quantum Markov process for the Hamiltonian $A$. It corresponds to the quantum thermodynamical equilibrium for the action of the Hamiltonian $A$.\n    link: https://arxiv.org/abs/2201.05094v2\n    "}}
{"custom_id": "2204.09329v2", "method": "POST", "url": "/v1/responses", "body": {"model": "gpt-5-mini", "input": "You are a specialist research analyst in Web3, DeFi, cryptography, and distributed systems.\n\n    Your task:\n    From the paper below (Title + Summary + Link), evaluate how useful each paper is for understanding investment opportunities or technological advantages within the Web3 / crypto / DeFi ecosystem.\n    Rate each paper on a five-level scale: Highest / High / Medium / Low / Lowest.\n\n    \"Useful\" means:\n\n    - Improves understanding of new cryptographic primitives relevant to blockchain performance or security\n    - Enhances scalability: distributed systems, P2P networking, consensus mechanisms\n    - Advances in zero knowledge, MPC, PQC that could impact future L1/L2 chains\n    - DeFi modeling, AMMs, MEV, risk models, liquidity dynamics\n    - Smart contract security, attack vectors, economic incentives\n    - Token economics, mechanism design for decentralized systems\n    - Quantum threats to blockchain or cryptography\n    - Any breakthrough that meaningfully improves decentralization, scalability, privacy, or composability\n\n    Output instructions:\n\n    - Output each JSON object in JSON Lines format (one line per paper).\n\n    {\n        \"title\": title of the paper (in Japanese),\n        \"summary\": A concise summary of the paper (in Japanese),\n        \"impact_level\": \"Highest|High|Medium|Low|Lowest\",\n        \"why_matters\": An array (JSON array) containing 2\u20134 bullet points explaining why this paper matters for Web3 investment\n    }\n\n    - Do not output anything except valid JSON object in JSON Lines.\n    - \"title\", \"summary\", \"why_matters\" text in the output must be written in Japanese.\n\n    Paper:\n    title: Deterministic Distributed Algorithms and Measurable Combinatorics on $\u0394$-Regular Forests\n    summary: We investigate the connections between the fields of distributed computing and measurable combinatorics by considering complexity classes of locally checkable labeling problems on regular forests. We show that the most important deterministic complexity classes from the LOCAL model of distributed computing exactly coincide with well-studied classes in measurable combinatorics. Namely, first we show that a locally checkable labeling problem admits a continuous solution if and only if it can be solved by a deterministic local algorithm with complexity $O(\\log^* n)$. Second, our main result states that, surprisingly, a locally checkable labeling problem admits a Baire measurable solution if and only if it can be solved by a local algorithm with complexity $O(\\log n)$. These theorems suggest the existence of deeper connections between the two frameworks. Furthermore, the latter result relies on a complete combinatorial characterization of the classes in question, and as a by-product, it shows that membership in these classes is decidable.\n    link: https://arxiv.org/abs/2204.09329v2\n    "}}
{"custom_id": "2512.04950v1", "method": "POST", "url": "/v1/responses", "body": {"model": "gpt-5-mini", "input": "You are a specialist research analyst in Web3, DeFi, cryptography, and distributed systems.\n\n    Your task:\n    From the paper below (Title + Summary + Link), evaluate how useful each paper is for understanding investment opportunities or technological advantages within the Web3 / crypto / DeFi ecosystem.\n    Rate each paper on a five-level scale: Highest / High / Medium / Low / Lowest.\n\n    \"Useful\" means:\n\n    - Improves understanding of new cryptographic primitives relevant to blockchain performance or security\n    - Enhances scalability: distributed systems, P2P networking, consensus mechanisms\n    - Advances in zero knowledge, MPC, PQC that could impact future L1/L2 chains\n    - DeFi modeling, AMMs, MEV, risk models, liquidity dynamics\n    - Smart contract security, attack vectors, economic incentives\n    - Token economics, mechanism design for decentralized systems\n    - Quantum threats to blockchain or cryptography\n    - Any breakthrough that meaningfully improves decentralization, scalability, privacy, or composability\n\n    Output instructions:\n\n    - Output each JSON object in JSON Lines format (one line per paper).\n\n    {\n        \"title\": title of the paper (in Japanese),\n        \"summary\": A concise summary of the paper (in Japanese),\n        \"impact_level\": \"Highest|High|Medium|Low|Lowest\",\n        \"why_matters\": An array (JSON array) containing 2\u20134 bullet points explaining why this paper matters for Web3 investment\n    }\n\n    - Do not output anything except valid JSON object in JSON Lines.\n    - \"title\", \"summary\", \"why_matters\" text in the output must be written in Japanese.\n\n    Paper:\n    title: Opacity problems in multi-energy timed automata\n    summary: Cyber-physical systems can be subject to information leakage; in the presence of continuous variables such as time and energy, these leaks can be subtle to detect. We study here the verification of opacity problems over systems with observation over both timing and energy information. We introduce guarded multi-energy timed automata as an extension of timed automata with multiple energy variables and guards over such variables. Despite undecidability of this general formalism, we establish positive results over a number of subclasses, notably when the attacker observes the final energy and/or the execution time, but also when they have access to the value of the energy variables every time unit.\n    link: https://arxiv.org/abs/2512.04950v1\n    "}}
{"custom_id": "2508.08366v2", "method": "POST", "url": "/v1/responses", "body": {"model": "gpt-5-mini", "input": "You are a specialist research analyst in Web3, DeFi, cryptography, and distributed systems.\n\n    Your task:\n    From the paper below (Title + Summary + Link), evaluate how useful each paper is for understanding investment opportunities or technological advantages within the Web3 / crypto / DeFi ecosystem.\n    Rate each paper on a five-level scale: Highest / High / Medium / Low / Lowest.\n\n    \"Useful\" means:\n\n    - Improves understanding of new cryptographic primitives relevant to blockchain performance or security\n    - Enhances scalability: distributed systems, P2P networking, consensus mechanisms\n    - Advances in zero knowledge, MPC, PQC that could impact future L1/L2 chains\n    - DeFi modeling, AMMs, MEV, risk models, liquidity dynamics\n    - Smart contract security, attack vectors, economic incentives\n    - Token economics, mechanism design for decentralized systems\n    - Quantum threats to blockchain or cryptography\n    - Any breakthrough that meaningfully improves decentralization, scalability, privacy, or composability\n\n    Output instructions:\n\n    - Output each JSON object in JSON Lines format (one line per paper).\n\n    {\n        \"title\": title of the paper (in Japanese),\n        \"summary\": A concise summary of the paper (in Japanese),\n        \"impact_level\": \"Highest|High|Medium|Low|Lowest\",\n        \"why_matters\": An array (JSON array) containing 2\u20134 bullet points explaining why this paper matters for Web3 investment\n    }\n\n    - Do not output anything except valid JSON object in JSON Lines.\n    - \"title\", \"summary\", \"why_matters\" text in the output must be written in Japanese.\n\n    Paper:\n    title: Deconfined quantum criticality on a triangular Rydberg array\n    summary: Fluctuations can drive continuous phase transitions between two distinct ordered phases -- so-called deconfined quantum critical points (DQCPs) -- which lie beyond the Landau-Ginzburg-Wilson paradigm. Despite several theoretical predictions over the past decades, experimental evidence of DQCPs remains elusive. We show that a DQCP can be explored in a system of Rydberg atoms arranged on a triangular lattice and coupled through van der Waals interactions. Specifically, we investigate the nature of the phase transition between two ordered phases at 1/3 and 2/3 Rydberg excitation density, which were recently probed experimentally in [P. Scholl et al., Nature 595, 233 (2021)]. Using a field-theoretical analysis, we predict both the critical exponents for infinitely long cylinders of increasing circumference and the emergence of a conformal field theory near criticality showing an enlarged U(1) symmetry -- a signature of DQCPs -- and confirm these predictions numerically. Finally, we extend these results to ladder geometries and show how the emergent U(1) symmetry could be probed experimentally using finite tweezer arrays.\n    link: https://arxiv.org/abs/2508.08366v2\n    "}}
{"custom_id": "2512.04908v1", "method": "POST", "url": "/v1/responses", "body": {"model": "gpt-5-mini", "input": "You are a specialist research analyst in Web3, DeFi, cryptography, and distributed systems.\n\n    Your task:\n    From the paper below (Title + Summary + Link), evaluate how useful each paper is for understanding investment opportunities or technological advantages within the Web3 / crypto / DeFi ecosystem.\n    Rate each paper on a five-level scale: Highest / High / Medium / Low / Lowest.\n\n    \"Useful\" means:\n\n    - Improves understanding of new cryptographic primitives relevant to blockchain performance or security\n    - Enhances scalability: distributed systems, P2P networking, consensus mechanisms\n    - Advances in zero knowledge, MPC, PQC that could impact future L1/L2 chains\n    - DeFi modeling, AMMs, MEV, risk models, liquidity dynamics\n    - Smart contract security, attack vectors, economic incentives\n    - Token economics, mechanism design for decentralized systems\n    - Quantum threats to blockchain or cryptography\n    - Any breakthrough that meaningfully improves decentralization, scalability, privacy, or composability\n\n    Output instructions:\n\n    - Output each JSON object in JSON Lines format (one line per paper).\n\n    {\n        \"title\": title of the paper (in Japanese),\n        \"summary\": A concise summary of the paper (in Japanese),\n        \"impact_level\": \"Highest|High|Medium|Low|Lowest\",\n        \"why_matters\": An array (JSON array) containing 2\u20134 bullet points explaining why this paper matters for Web3 investment\n    }\n\n    - Do not output anything except valid JSON object in JSON Lines.\n    - \"title\", \"summary\", \"why_matters\" text in the output must be written in Japanese.\n\n    Paper:\n    title: Logic-Driven Cybersecurity: A Novel Framework for System Log Anomaly Detection using Answer Set Programming\n    summary: This study explores the application of Answer Set Programming (ASP) for detecting anomalies in system logs, addressing the challenges posed by evolving cyber threats. We propose a novel framework that leverages ASP's declarative nature and logical reasoning capabilities to encode complex security rules as logical predicates. Our ASP-based system was applied to a real-world Linux system log dataset, demonstrating its effectiveness in identifying various anomalies such as potential brute-force attacks, privilege escalations, frequent network connections from specific IPs, and various system-level issues. Key findings highlight ASP's strengths in handling structured log data, rule flexibility, and event correlation. The approach shows promise in providing explainable alerts from real-world data. This research contributes to computer forensics by demonstrating a logic-based paradigm for log analysis on a practical dataset, opening avenues for more nuanced and adaptive cyber intelligence systems.\n    link: https://arxiv.org/abs/2512.04908v1\n    "}}
{"custom_id": "2409.12103v2", "method": "POST", "url": "/v1/responses", "body": {"model": "gpt-5-mini", "input": "You are a specialist research analyst in Web3, DeFi, cryptography, and distributed systems.\n\n    Your task:\n    From the paper below (Title + Summary + Link), evaluate how useful each paper is for understanding investment opportunities or technological advantages within the Web3 / crypto / DeFi ecosystem.\n    Rate each paper on a five-level scale: Highest / High / Medium / Low / Lowest.\n\n    \"Useful\" means:\n\n    - Improves understanding of new cryptographic primitives relevant to blockchain performance or security\n    - Enhances scalability: distributed systems, P2P networking, consensus mechanisms\n    - Advances in zero knowledge, MPC, PQC that could impact future L1/L2 chains\n    - DeFi modeling, AMMs, MEV, risk models, liquidity dynamics\n    - Smart contract security, attack vectors, economic incentives\n    - Token economics, mechanism design for decentralized systems\n    - Quantum threats to blockchain or cryptography\n    - Any breakthrough that meaningfully improves decentralization, scalability, privacy, or composability\n\n    Output instructions:\n\n    - Output each JSON object in JSON Lines format (one line per paper).\n\n    {\n        \"title\": title of the paper (in Japanese),\n        \"summary\": A concise summary of the paper (in Japanese),\n        \"impact_level\": \"Highest|High|Medium|Low|Lowest\",\n        \"why_matters\": An array (JSON array) containing 2\u20134 bullet points explaining why this paper matters for Web3 investment\n    }\n\n    - Do not output anything except valid JSON object in JSON Lines.\n    - \"title\", \"summary\", \"why_matters\" text in the output must be written in Japanese.\n\n    Paper:\n    title: Towards practical secure delegated quantum computing with semi-classical light\n    summary: Secure Delegated Quantum Computation (SDQC) protocols are a vital piece of the future quantum information processing global architecture since they allow end-users to perform their valuable computations on remote quantum servers without fear that a malicious quantum service provider or an eavesdropper might acquire some information about their data or algorithm. They also allow end-users to check that their computation has been performed as they have specified it.\n  However, existing protocols all have drawbacks that limit their usage in the real world. Most require the client to either operate a single-qubit source or perform single-qubit measurements, thus requiring them to still have some quantum technological capabilities albeit restricted, or require the server to perform operations which are hard to implement on real hardware (e.g isolate single photons from laser pulses and polarisation-preserving photon-number quantum non-demolition measurements). Others remove the need for quantum communications entirely but this comes at a cost in terms of security guarantees and memory overhead on the server's side.\n  We present an SDQC protocol which drastically reduces the technological requirements of both the client and the server while providing information-theoretic composable security. More precisely, the client only manipulates an attenuated laser pulse, while the server only handles interacting quantum emitters with a structure capable of generating spin-photon entanglement. The quantum emitter acts as both a converter from coherent laser pulses to polarisation-encoded qubits and an entanglement generator. Such devices have recently been used to demonstrate the largest entangled photonic state to date, thus hinting at the readiness of our protocol for experimental implementations.\n    link: https://arxiv.org/abs/2409.12103v2\n    "}}
{"custom_id": "2512.04855v1", "method": "POST", "url": "/v1/responses", "body": {"model": "gpt-5-mini", "input": "You are a specialist research analyst in Web3, DeFi, cryptography, and distributed systems.\n\n    Your task:\n    From the paper below (Title + Summary + Link), evaluate how useful each paper is for understanding investment opportunities or technological advantages within the Web3 / crypto / DeFi ecosystem.\n    Rate each paper on a five-level scale: Highest / High / Medium / Low / Lowest.\n\n    \"Useful\" means:\n\n    - Improves understanding of new cryptographic primitives relevant to blockchain performance or security\n    - Enhances scalability: distributed systems, P2P networking, consensus mechanisms\n    - Advances in zero knowledge, MPC, PQC that could impact future L1/L2 chains\n    - DeFi modeling, AMMs, MEV, risk models, liquidity dynamics\n    - Smart contract security, attack vectors, economic incentives\n    - Token economics, mechanism design for decentralized systems\n    - Quantum threats to blockchain or cryptography\n    - Any breakthrough that meaningfully improves decentralization, scalability, privacy, or composability\n\n    Output instructions:\n\n    - Output each JSON object in JSON Lines format (one line per paper).\n\n    {\n        \"title\": title of the paper (in Japanese),\n        \"summary\": A concise summary of the paper (in Japanese),\n        \"impact_level\": \"Highest|High|Medium|Low|Lowest\",\n        \"why_matters\": An array (JSON array) containing 2\u20134 bullet points explaining why this paper matters for Web3 investment\n    }\n\n    - Do not output anything except valid JSON object in JSON Lines.\n    - \"title\", \"summary\", \"why_matters\" text in the output must be written in Japanese.\n\n    Paper:\n    title: A Novel Trust-Based DDoS Cyberattack Detection Model for Smart Business Environments\n    summary: As the frequency and complexity of Distributed Denial-of-Service (DDoS) attacks continue to increase, the level of threats posed to Smart Internet of Things (SIoT) business environments have also increased. These environments generally have several interconnected SIoT systems and devices that are integral to daily operations, usually depending on cloud infrastructure and real-time data analytics, which require continuous availability and secure data exchange. Conventional detection mechanisms, while useful in static or traditional network environments, often are inadequate in responding to the needs of these dynamic and diverse SIoT networks. In this paper, we introduce a novel trust-based DDoS detection model tailored to meet the unique requirements of smart business environments. The proposed model incorporates a trust evaluation engine that continuously monitors node behaviour, calculating trust scores based on packet delivery ratio, response time, and anomaly detection. These trust metrics are then aggregated by a central trust-based repository that uses inherent trust values to identify traffic patterns indicative of DDoS attacks. By integrating both trust scores and central trust-based outputs, the trust calculation is enhanced, ensuring that threats are accurately identified and addressed in real-time. The model demonstrated a significant improvement in detection accuracy, and a low false-positive rate with enhanced scalability and adaptability under TCP SYN, Ping Flood, and UDP Flood attacks. The results show that a trust-based approach provides an effective, lightweight alternative for securing resource-constrained business IoT environments.\n    link: https://arxiv.org/abs/2512.04855v1\n    "}}
{"custom_id": "2512.04841v1", "method": "POST", "url": "/v1/responses", "body": {"model": "gpt-5-mini", "input": "You are a specialist research analyst in Web3, DeFi, cryptography, and distributed systems.\n\n    Your task:\n    From the paper below (Title + Summary + Link), evaluate how useful each paper is for understanding investment opportunities or technological advantages within the Web3 / crypto / DeFi ecosystem.\n    Rate each paper on a five-level scale: Highest / High / Medium / Low / Lowest.\n\n    \"Useful\" means:\n\n    - Improves understanding of new cryptographic primitives relevant to blockchain performance or security\n    - Enhances scalability: distributed systems, P2P networking, consensus mechanisms\n    - Advances in zero knowledge, MPC, PQC that could impact future L1/L2 chains\n    - DeFi modeling, AMMs, MEV, risk models, liquidity dynamics\n    - Smart contract security, attack vectors, economic incentives\n    - Token economics, mechanism design for decentralized systems\n    - Quantum threats to blockchain or cryptography\n    - Any breakthrough that meaningfully improves decentralization, scalability, privacy, or composability\n\n    Output instructions:\n\n    - Output each JSON object in JSON Lines format (one line per paper).\n\n    {\n        \"title\": title of the paper (in Japanese),\n        \"summary\": A concise summary of the paper (in Japanese),\n        \"impact_level\": \"Highest|High|Medium|Low|Lowest\",\n        \"why_matters\": An array (JSON array) containing 2\u20134 bullet points explaining why this paper matters for Web3 investment\n    }\n\n    - Do not output anything except valid JSON object in JSON Lines.\n    - \"title\", \"summary\", \"why_matters\" text in the output must be written in Japanese.\n\n    Paper:\n    title: SoK: a Comprehensive Causality Analysis Framework for Large Language Model Security\n    summary: Large Language Models (LLMs) exhibit remarkable capabilities but remain vulnerable to adversarial manipulations such as jailbreaking, where crafted prompts bypass safety mechanisms. Understanding the causal factors behind such vulnerabilities is essential for building reliable defenses.\n  In this work, we introduce a unified causality analysis framework that systematically supports all levels of causal investigation in LLMs, ranging from token-level, neuron-level, and layer-level interventions to representation-level analysis. The framework enables consistent experimentation and comparison across diverse causality-based attack and defense methods. Accompanying this implementation, we provide the first comprehensive survey of causality-driven jailbreak studies and empirically evaluate the framework on multiple open-weight models and safety-critical benchmarks including jailbreaks, hallucination detection, backdoor identification, and fairness evaluation. Our results reveal that: (1) targeted interventions on causally critical components can reliably modify safety behavior; (2) safety-related mechanisms are highly localized (i.e., concentrated in early-to-middle layers with only 1--2\\% of neurons exhibiting causal influence); and (3) causal features extracted from our framework achieve over 95\\% detection accuracy across multiple threat types.\n  By bridging theoretical causality analysis and practical model safety, our framework establishes a reproducible foundation for research on causality-based attacks, interpretability, and robust attack detection and mitigation in LLMs. Code is available at https://github.com/Amadeuszhao/SOK_Casuality.\n    link: https://arxiv.org/abs/2512.04841v1\n    "}}
{"custom_id": "2506.18709v2", "method": "POST", "url": "/v1/responses", "body": {"model": "gpt-5-mini", "input": "You are a specialist research analyst in Web3, DeFi, cryptography, and distributed systems.\n\n    Your task:\n    From the paper below (Title + Summary + Link), evaluate how useful each paper is for understanding investment opportunities or technological advantages within the Web3 / crypto / DeFi ecosystem.\n    Rate each paper on a five-level scale: Highest / High / Medium / Low / Lowest.\n\n    \"Useful\" means:\n\n    - Improves understanding of new cryptographic primitives relevant to blockchain performance or security\n    - Enhances scalability: distributed systems, P2P networking, consensus mechanisms\n    - Advances in zero knowledge, MPC, PQC that could impact future L1/L2 chains\n    - DeFi modeling, AMMs, MEV, risk models, liquidity dynamics\n    - Smart contract security, attack vectors, economic incentives\n    - Token economics, mechanism design for decentralized systems\n    - Quantum threats to blockchain or cryptography\n    - Any breakthrough that meaningfully improves decentralization, scalability, privacy, or composability\n\n    Output instructions:\n\n    - Output each JSON object in JSON Lines format (one line per paper).\n\n    {\n        \"title\": title of the paper (in Japanese),\n        \"summary\": A concise summary of the paper (in Japanese),\n        \"impact_level\": \"Highest|High|Medium|Low|Lowest\",\n        \"why_matters\": An array (JSON array) containing 2\u20134 bullet points explaining why this paper matters for Web3 investment\n    }\n\n    - Do not output anything except valid JSON object in JSON Lines.\n    - \"title\", \"summary\", \"why_matters\" text in the output must be written in Japanese.\n\n    Paper:\n    title: Local classical correlations between physical electrons in Hubbard systems\n    summary: We demonstrate that the local nonfreeness, an unbiased measure of correlation between electrons at a single lattice site, can be computed as the mutual information between local natural spin orbitals. This leads us to prove a general result: local electron correlations in Hubbard-type models are fully classical since the local reduced density matrix is separable in the natural basis and no quantum correlations beyond entanglement are present. Finally, we compare different theoretical descriptions of magnetic and nonmagnetic states, showing that local classical correlations are drastically influenced by nonlocal processes. These results confirm the relation between local classical correlations within an open system and nonlocal entanglement, and they provide a clear path for the study of the relationship between traditional quantum resources and the nonfreeness, in terms of experimentally accessible quantities.\n    link: https://arxiv.org/abs/2506.18709v2\n    "}}
{"custom_id": "2506.09314v2", "method": "POST", "url": "/v1/responses", "body": {"model": "gpt-5-mini", "input": "You are a specialist research analyst in Web3, DeFi, cryptography, and distributed systems.\n\n    Your task:\n    From the paper below (Title + Summary + Link), evaluate how useful each paper is for understanding investment opportunities or technological advantages within the Web3 / crypto / DeFi ecosystem.\n    Rate each paper on a five-level scale: Highest / High / Medium / Low / Lowest.\n\n    \"Useful\" means:\n\n    - Improves understanding of new cryptographic primitives relevant to blockchain performance or security\n    - Enhances scalability: distributed systems, P2P networking, consensus mechanisms\n    - Advances in zero knowledge, MPC, PQC that could impact future L1/L2 chains\n    - DeFi modeling, AMMs, MEV, risk models, liquidity dynamics\n    - Smart contract security, attack vectors, economic incentives\n    - Token economics, mechanism design for decentralized systems\n    - Quantum threats to blockchain or cryptography\n    - Any breakthrough that meaningfully improves decentralization, scalability, privacy, or composability\n\n    Output instructions:\n\n    - Output each JSON object in JSON Lines format (one line per paper).\n\n    {\n        \"title\": title of the paper (in Japanese),\n        \"summary\": A concise summary of the paper (in Japanese),\n        \"impact_level\": \"Highest|High|Medium|Low|Lowest\",\n        \"why_matters\": An array (JSON array) containing 2\u20134 bullet points explaining why this paper matters for Web3 investment\n    }\n\n    - Do not output anything except valid JSON object in JSON Lines.\n    - \"title\", \"summary\", \"why_matters\" text in the output must be written in Japanese.\n\n    Paper:\n    title: Droplet-gas phases and their dynamical formation in particle imbalanced mixtures\n    summary: We explore the ground state phase diagram and nonequilibrium dynamics of genuine two-component particle-imbalanced droplets in both isotropic and anisotropic three-dimensional confinements. A gradual transition from mixed droplet-gas to gas configurations is revealed as the average intercomponent attraction decreases or the transverse confinement becomes tighter. Within the mixed structures, a specific majority fragment binds to the minority droplet, satisfying the density ratio locking condition, while the remaining atoms are in a gas state. Our extended Gross-Pitaevskii numerical results are corroborated by a suitable variational approximation capturing the shape and characteristics of droplet-gas fragments. The tunability of the relatively low gas fraction is showcased through parametric variations of the atom number, the intercomponent imbalance, the trap aspect ratio, or the radius of a box potential. To validate the existence and probe the properties of these exotic phases, we simulate the standard time-of-flight and radio frequency experimental techniques. These allow to dynamically identify the resilience of the droplet fragment and the expansion of the gas fraction. Our results, amenable to current experimental cold atom settings, are expected to guide forthcoming investigations aiming to reveal unseen out-of-equilibrium droplet dynamics.\n    link: https://arxiv.org/abs/2506.09314v2\n    "}}
{"custom_id": "2502.00638v3", "method": "POST", "url": "/v1/responses", "body": {"model": "gpt-5-mini", "input": "You are a specialist research analyst in Web3, DeFi, cryptography, and distributed systems.\n\n    Your task:\n    From the paper below (Title + Summary + Link), evaluate how useful each paper is for understanding investment opportunities or technological advantages within the Web3 / crypto / DeFi ecosystem.\n    Rate each paper on a five-level scale: Highest / High / Medium / Low / Lowest.\n\n    \"Useful\" means:\n\n    - Improves understanding of new cryptographic primitives relevant to blockchain performance or security\n    - Enhances scalability: distributed systems, P2P networking, consensus mechanisms\n    - Advances in zero knowledge, MPC, PQC that could impact future L1/L2 chains\n    - DeFi modeling, AMMs, MEV, risk models, liquidity dynamics\n    - Smart contract security, attack vectors, economic incentives\n    - Token economics, mechanism design for decentralized systems\n    - Quantum threats to blockchain or cryptography\n    - Any breakthrough that meaningfully improves decentralization, scalability, privacy, or composability\n\n    Output instructions:\n\n    - Output each JSON object in JSON Lines format (one line per paper).\n\n    {\n        \"title\": title of the paper (in Japanese),\n        \"summary\": A concise summary of the paper (in Japanese),\n        \"impact_level\": \"Highest|High|Medium|Low|Lowest\",\n        \"why_matters\": An array (JSON array) containing 2\u20134 bullet points explaining why this paper matters for Web3 investment\n    }\n\n    - Do not output anything except valid JSON object in JSON Lines.\n    - \"title\", \"summary\", \"why_matters\" text in the output must be written in Japanese.\n\n    Paper:\n    title: Cycles and Cuts in Supersingular L-Isogeny Graphs\n    summary: Supersingular elliptic curve isogeny graphs underlie isogeny-based cryptography. For isogenies of a single prime degree $\\ell$, their structure has been investigated graph-theoretically. We generalise the notion of $\\ell$-isogeny graphs to $L$-isogeny graphs (studied in the prime field case by Delfs and Galbraith), where $L$ is a set of small primes dictating the allowed isogeny degrees in the graph. We analyse the graph-theoretic structure of $L$-isogeny graphs. Our approaches may be put into two categories: cycles and graph cuts.\n  On the topic of cycles, we provide: a count for the number of cycles in the $L$-isogeny graph with cyclic kernels using traces of Brandt matrices; an efficiently computable estimate based on this approach; and a third ideal-theoretic count for a certain subclass of $L$-isogeny cycles. We provide code to compute each of these three counts.\n  On the topic of graph cuts, we compare several algorithms to compute graph cuts which minimise a measure called the edge expansion, outlining a cryptographic motivation for doing so. Our results show that a greedy neighbour algorithm out-performs standard spectral algorithms for computing optimal graph cuts. We provide code and study explicit examples.\n  Furthermore, we describe several directions of active and future research.\n    link: https://arxiv.org/abs/2502.00638v3\n    "}}
{"custom_id": "2512.04785v1", "method": "POST", "url": "/v1/responses", "body": {"model": "gpt-5-mini", "input": "You are a specialist research analyst in Web3, DeFi, cryptography, and distributed systems.\n\n    Your task:\n    From the paper below (Title + Summary + Link), evaluate how useful each paper is for understanding investment opportunities or technological advantages within the Web3 / crypto / DeFi ecosystem.\n    Rate each paper on a five-level scale: Highest / High / Medium / Low / Lowest.\n\n    \"Useful\" means:\n\n    - Improves understanding of new cryptographic primitives relevant to blockchain performance or security\n    - Enhances scalability: distributed systems, P2P networking, consensus mechanisms\n    - Advances in zero knowledge, MPC, PQC that could impact future L1/L2 chains\n    - DeFi modeling, AMMs, MEV, risk models, liquidity dynamics\n    - Smart contract security, attack vectors, economic incentives\n    - Token economics, mechanism design for decentralized systems\n    - Quantum threats to blockchain or cryptography\n    - Any breakthrough that meaningfully improves decentralization, scalability, privacy, or composability\n\n    Output instructions:\n\n    - Output each JSON object in JSON Lines format (one line per paper).\n\n    {\n        \"title\": title of the paper (in Japanese),\n        \"summary\": A concise summary of the paper (in Japanese),\n        \"impact_level\": \"Highest|High|Medium|Low|Lowest\",\n        \"why_matters\": An array (JSON array) containing 2\u20134 bullet points explaining why this paper matters for Web3 investment\n    }\n\n    - Do not output anything except valid JSON object in JSON Lines.\n    - \"title\", \"summary\", \"why_matters\" text in the output must be written in Japanese.\n\n    Paper:\n    title: ASTRIDE: A Security Threat Modeling Platform for Agentic-AI Applications\n    summary: AI agent-based systems are becoming increasingly integral to modern software architectures, enabling autonomous decision-making, dynamic task execution, and multimodal interactions through large language models (LLMs). However, these systems introduce novel and evolving security challenges, including prompt injection attacks, context poisoning, model manipulation, and opaque agent-to-agent communication, that are not effectively captured by traditional threat modeling frameworks. In this paper, we introduce ASTRIDE, an automated threat modeling platform purpose-built for AI agent-based systems. ASTRIDE extends the classical STRIDE framework by introducing a new threat category, A for AI Agent-Specific Attacks, which encompasses emerging vulnerabilities such as prompt injection, unsafe tool invocation, and reasoning subversion, unique to agent-based applications. To automate threat modeling, ASTRIDE combines a consortium of fine-tuned vision-language models (VLMs) with the OpenAI-gpt-oss reasoning LLM to perform end-to-end analysis directly from visual agent architecture diagrams, such as data flow diagrams(DFDs). LLM agents orchestrate the end-to-end threat modeling automation process by coordinating interactions between the VLM consortium and the reasoning LLM. Our evaluations demonstrate that ASTRIDE provides accurate, scalable, and explainable threat modeling for next-generation intelligent systems. To the best of our knowledge, ASTRIDE is the first framework to both extend STRIDE with AI-specific threats and integrate fine-tuned VLMs with a reasoning LLM to fully automate diagram-driven threat modeling in AI agent-based applications.\n    link: https://arxiv.org/abs/2512.04785v1\n    "}}
{"custom_id": "2411.17461v4", "method": "POST", "url": "/v1/responses", "body": {"model": "gpt-5-mini", "input": "You are a specialist research analyst in Web3, DeFi, cryptography, and distributed systems.\n\n    Your task:\n    From the paper below (Title + Summary + Link), evaluate how useful each paper is for understanding investment opportunities or technological advantages within the Web3 / crypto / DeFi ecosystem.\n    Rate each paper on a five-level scale: Highest / High / Medium / Low / Lowest.\n\n    \"Useful\" means:\n\n    - Improves understanding of new cryptographic primitives relevant to blockchain performance or security\n    - Enhances scalability: distributed systems, P2P networking, consensus mechanisms\n    - Advances in zero knowledge, MPC, PQC that could impact future L1/L2 chains\n    - DeFi modeling, AMMs, MEV, risk models, liquidity dynamics\n    - Smart contract security, attack vectors, economic incentives\n    - Token economics, mechanism design for decentralized systems\n    - Quantum threats to blockchain or cryptography\n    - Any breakthrough that meaningfully improves decentralization, scalability, privacy, or composability\n\n    Output instructions:\n\n    - Output each JSON object in JSON Lines format (one line per paper).\n\n    {\n        \"title\": title of the paper (in Japanese),\n        \"summary\": A concise summary of the paper (in Japanese),\n        \"impact_level\": \"Highest|High|Medium|Low|Lowest\",\n        \"why_matters\": An array (JSON array) containing 2\u20134 bullet points explaining why this paper matters for Web3 investment\n    }\n\n    - Do not output anything except valid JSON object in JSON Lines.\n    - \"title\", \"summary\", \"why_matters\" text in the output must be written in Japanese.\n\n    Paper:\n    title: SoK: Decentralized AI (DeAI)\n    summary: Centralization enhances the efficiency of Artificial Intelligence (AI) but also introduces critical challenges, including single points of failure, inherent biases, data privacy risks, and scalability limitations. To address these issues, blockchain-based Decentralized Artificial Intelligence (DeAI) has emerged as a promising paradigm that leverages decentralization and transparency to improve the trustworthiness of AI systems. Despite rapid adoption in industry, the academic community lacks a systematic analysis of DeAI's technical foundations, opportunities, and challenges. This work presents the first Systematization of Knowledge (SoK) on DeAI, offering a formal definition, a taxonomy of existing solutions based on the AI lifecycle, and an in-depth investigation of the roles of blockchain in enabling secure and incentive-compatible collaboration. We further review security risks across the DeAI lifecycle and empirically evaluate representative mitigation techniques. Finally, we highlight open research challenges and future directions for advancing blockchain-based DeAI.\n    link: https://arxiv.org/abs/2411.17461v4\n    "}}
{"custom_id": "2501.00926v3", "method": "POST", "url": "/v1/responses", "body": {"model": "gpt-5-mini", "input": "You are a specialist research analyst in Web3, DeFi, cryptography, and distributed systems.\n\n    Your task:\n    From the paper below (Title + Summary + Link), evaluate how useful each paper is for understanding investment opportunities or technological advantages within the Web3 / crypto / DeFi ecosystem.\n    Rate each paper on a five-level scale: Highest / High / Medium / Low / Lowest.\n\n    \"Useful\" means:\n\n    - Improves understanding of new cryptographic primitives relevant to blockchain performance or security\n    - Enhances scalability: distributed systems, P2P networking, consensus mechanisms\n    - Advances in zero knowledge, MPC, PQC that could impact future L1/L2 chains\n    - DeFi modeling, AMMs, MEV, risk models, liquidity dynamics\n    - Smart contract security, attack vectors, economic incentives\n    - Token economics, mechanism design for decentralized systems\n    - Quantum threats to blockchain or cryptography\n    - Any breakthrough that meaningfully improves decentralization, scalability, privacy, or composability\n\n    Output instructions:\n\n    - Output each JSON object in JSON Lines format (one line per paper).\n\n    {\n        \"title\": title of the paper (in Japanese),\n        \"summary\": A concise summary of the paper (in Japanese),\n        \"impact_level\": \"Highest|High|Medium|Low|Lowest\",\n        \"why_matters\": An array (JSON array) containing 2\u20134 bullet points explaining why this paper matters for Web3 investment\n    }\n\n    - Do not output anything except valid JSON object in JSON Lines.\n    - \"title\", \"summary\", \"why_matters\" text in the output must be written in Japanese.\n\n    Paper:\n    title: Differentially Private Matchings: Symmetry Lower Bounds, Arboricity Sparsifiers, and Public Vertex Subset Mechanism\n    summary: Computing matchings in graphs is a foundational algorithmic task. Despite extensive interest in differentially private (DP) graph analysis, work on privately computing matching solutions, rather than just their size, has been sparse. The sole prior work in the standard model of pure $\\varepsilon$-differential privacy, by Hsu, Huang, Roth, Roughgarden, and Wu [HHR+14, STOC'14], focused on allocations and was thus restricted to bipartite graphs. This paper presents a comprehensive study of differentially private algorithms for maximum matching and b-matching in general graphs, which also yields techniques that directly improve upon prior work in the bipartite setting. En route to solving these matching problems, we develop a set of novel techniques with broad applicability, including a new symmetry argument for DP lower bounds, the first private arboricity-based sparsifiers for node-DP, and the novel Public Vertex Subset Mechanism. We demonstrate the versatility of these tools by applying them to other DP problems, such as vertex cover [GLM+10, SODA'10], and beyond DP, such as low-sensitivity algorithms [VY23, SODA'21, SICOMP'23]. [...]\n    link: https://arxiv.org/abs/2501.00926v3\n    "}}
{"custom_id": "2512.04679v1", "method": "POST", "url": "/v1/responses", "body": {"model": "gpt-5-mini", "input": "You are a specialist research analyst in Web3, DeFi, cryptography, and distributed systems.\n\n    Your task:\n    From the paper below (Title + Summary + Link), evaluate how useful each paper is for understanding investment opportunities or technological advantages within the Web3 / crypto / DeFi ecosystem.\n    Rate each paper on a five-level scale: Highest / High / Medium / Low / Lowest.\n\n    \"Useful\" means:\n\n    - Improves understanding of new cryptographic primitives relevant to blockchain performance or security\n    - Enhances scalability: distributed systems, P2P networking, consensus mechanisms\n    - Advances in zero knowledge, MPC, PQC that could impact future L1/L2 chains\n    - DeFi modeling, AMMs, MEV, risk models, liquidity dynamics\n    - Smart contract security, attack vectors, economic incentives\n    - Token economics, mechanism design for decentralized systems\n    - Quantum threats to blockchain or cryptography\n    - Any breakthrough that meaningfully improves decentralization, scalability, privacy, or composability\n\n    Output instructions:\n\n    - Output each JSON object in JSON Lines format (one line per paper).\n\n    {\n        \"title\": title of the paper (in Japanese),\n        \"summary\": A concise summary of the paper (in Japanese),\n        \"impact_level\": \"Highest|High|Medium|Low|Lowest\",\n        \"why_matters\": An array (JSON array) containing 2\u20134 bullet points explaining why this paper matters for Web3 investment\n    }\n\n    - Do not output anything except valid JSON object in JSON Lines.\n    - \"title\", \"summary\", \"why_matters\" text in the output must be written in Japanese.\n\n    Paper:\n    title: Timely Information for Strategic Persuasion\n    summary: This work investigates a dynamic variant of Bayesian persuasion, in which a strategic sender seeks to influence a receiver's belief over time through controlling the timing of the information disclosure, under resource constraints. We consider a binary information source (i.e., taking values 0 or 1), where the source's state evolve according to a continuous-time Markov chain (CTMC). In this setting, the receiver aims to estimate the source's state as accurately as possible. In contrast, the sender seeks to persuade the receiver to estimate the state to be 1, regardless of whether this estimate reflects the true state. This misalignment between their objectives naturally leads to a Stackelberg game formulation where the sender, acting as the leader, chooses an information-revelation policy, and the receiver, as the follower, decides whether to follow the sender's messages. As a result, the sender's objective is to maximize the long-term average time that the receiver's estimate equals 1, subject to a total sampling constraint and a constraint for the receiver to follow the sender's messages called incentive compatibility (IC) constraint. We first consider the single-source problem and show that the sender's optimal policy is to allocate a minimal sampling rate to the undesired state 0 (just enough to satisfy the IC constraint) and assign the remaining sampling rate to the desired state 1. Next, we extend the analysis to the multi-source case, where each source has a different minimal sampling rate. Our results show that the sender can leverage the timeliness of the revealed information to influence the receiver, thereby achieving a higher utility.\n    link: https://arxiv.org/abs/2512.04679v1\n    "}}
{"custom_id": "2512.04675v1", "method": "POST", "url": "/v1/responses", "body": {"model": "gpt-5-mini", "input": "You are a specialist research analyst in Web3, DeFi, cryptography, and distributed systems.\n\n    Your task:\n    From the paper below (Title + Summary + Link), evaluate how useful each paper is for understanding investment opportunities or technological advantages within the Web3 / crypto / DeFi ecosystem.\n    Rate each paper on a five-level scale: Highest / High / Medium / Low / Lowest.\n\n    \"Useful\" means:\n\n    - Improves understanding of new cryptographic primitives relevant to blockchain performance or security\n    - Enhances scalability: distributed systems, P2P networking, consensus mechanisms\n    - Advances in zero knowledge, MPC, PQC that could impact future L1/L2 chains\n    - DeFi modeling, AMMs, MEV, risk models, liquidity dynamics\n    - Smart contract security, attack vectors, economic incentives\n    - Token economics, mechanism design for decentralized systems\n    - Quantum threats to blockchain or cryptography\n    - Any breakthrough that meaningfully improves decentralization, scalability, privacy, or composability\n\n    Output instructions:\n\n    - Output each JSON object in JSON Lines format (one line per paper).\n\n    {\n        \"title\": title of the paper (in Japanese),\n        \"summary\": A concise summary of the paper (in Japanese),\n        \"impact_level\": \"Highest|High|Medium|Low|Lowest\",\n        \"why_matters\": An array (JSON array) containing 2\u20134 bullet points explaining why this paper matters for Web3 investment\n    }\n\n    - Do not output anything except valid JSON object in JSON Lines.\n    - \"title\", \"summary\", \"why_matters\" text in the output must be written in Japanese.\n\n    Paper:\n    title: Cryptanalysis of Gleeok-128\n    summary: Gleeok is a family of low latency keyed pseudorandom functions (PRFs) consisting of three parallel SPN based permutations whose outputs are XORed to form the final value. Both Gleeok-128 and Gleeok-256 use a 256 bit key, with block sizes of 128 and 256 bits, respectively. Owing to its multi branch structure, evaluating security margins and mounting effective key recovery attacks present nontrivial challenges. This paper provides the first comprehensive third party cryptanalysis of Gleeok-128. We introduce a two stage MILP based framework for constructing branch wise and full cipher differential linear (DL) distinguishers, together with an integral based key recovery framework tailored to multi branch designs. Our DL analysis yields 7, 7, 8, and 4 round distinguishers for Branch 1, Branch 2, Branch 3, and Gleeok-128, respectively, with squared correlations approximately 2 to the power minus 88.12, 2 to the power minus 88.12, 2 to the power minus 38.73, and 2 to the power minus 49.04, outperforming those in the design document except for the full PRF case. By tightening algebraic degree bounds, we further derive 9, 9, and 7 round integral distinguishers for the three branches and a 7 round distinguisher for the full PRF, extending the designers results by 3, 3, and 2 rounds and by 2 rounds, respectively. These integral properties enable 7 round and 8 round key recovery attacks in the non full codebook and full codebook settings. In addition, we identify a flaw in the original linear security evaluation of Branch 3, showing that it can be distinguished over all 12 rounds with data complexity about 2 to the power 48. We also propose optimized linear layer parameters that significantly improve linear resistance without sacrificing diffusion. Our results advance the understanding of Gleeok-128 and provide general methods for analyzing multi branch symmetric designs.\n    link: https://arxiv.org/abs/2512.04675v1\n    "}}
{"custom_id": "2512.04668v1", "method": "POST", "url": "/v1/responses", "body": {"model": "gpt-5-mini", "input": "You are a specialist research analyst in Web3, DeFi, cryptography, and distributed systems.\n\n    Your task:\n    From the paper below (Title + Summary + Link), evaluate how useful each paper is for understanding investment opportunities or technological advantages within the Web3 / crypto / DeFi ecosystem.\n    Rate each paper on a five-level scale: Highest / High / Medium / Low / Lowest.\n\n    \"Useful\" means:\n\n    - Improves understanding of new cryptographic primitives relevant to blockchain performance or security\n    - Enhances scalability: distributed systems, P2P networking, consensus mechanisms\n    - Advances in zero knowledge, MPC, PQC that could impact future L1/L2 chains\n    - DeFi modeling, AMMs, MEV, risk models, liquidity dynamics\n    - Smart contract security, attack vectors, economic incentives\n    - Token economics, mechanism design for decentralized systems\n    - Quantum threats to blockchain or cryptography\n    - Any breakthrough that meaningfully improves decentralization, scalability, privacy, or composability\n\n    Output instructions:\n\n    - Output each JSON object in JSON Lines format (one line per paper).\n\n    {\n        \"title\": title of the paper (in Japanese),\n        \"summary\": A concise summary of the paper (in Japanese),\n        \"impact_level\": \"Highest|High|Medium|Low|Lowest\",\n        \"why_matters\": An array (JSON array) containing 2\u20134 bullet points explaining why this paper matters for Web3 investment\n    }\n\n    - Do not output anything except valid JSON object in JSON Lines.\n    - \"title\", \"summary\", \"why_matters\" text in the output must be written in Japanese.\n\n    Paper:\n    title: Topology Matters: Measuring Memory Leakage in Multi-Agent LLMs\n    summary: Graph topology is a fundamental determinant of memory leakage in multi-agent LLM systems, yet its effects remain poorly quantified. We introduce MAMA (Multi-Agent Memory Attack), a framework that measures how network structure shapes leakage. MAMA operates on synthetic documents containing labeled Personally Identifiable Information (PII) entities, from which we generate sanitized task instructions. We execute a two-phase protocol: Engram (seeding private information into a target agent's memory) and Resonance (multi-round interaction where an attacker attempts extraction). Over up to 10 interaction rounds, we quantify leakage as the fraction of ground-truth PII recovered from attacking agent outputs via exact matching. We systematically evaluate six common network topologies (fully connected, ring, chain, binary tree, star, and star-ring), varying agent counts $n\\in\\{4,5,6\\}$, attacker-target placements, and base models. Our findings reveal consistent patterns: fully connected graphs exhibit maximum leakage while chains provide strongest protection; shorter attacker-target graph distance and higher target centrality significantly increase vulnerability; leakage rises sharply in early rounds before plateauing; model choice shifts absolute leakage rates but preserves topology rankings; temporal/locational PII attributes leak more readily than identity credentials or regulated identifiers. These results provide the first systematic mapping from architectural choices to measurable privacy risk, yielding actionable guidance: prefer sparse or hierarchical connectivity, maximize attacker-target separation, limit node degree and network radius, avoid shortcuts bypassing hubs, and implement topology-aware access controls.\n    link: https://arxiv.org/abs/2512.04668v1\n    "}}
{"custom_id": "2512.04663v1", "method": "POST", "url": "/v1/responses", "body": {"model": "gpt-5-mini", "input": "You are a specialist research analyst in Web3, DeFi, cryptography, and distributed systems.\n\n    Your task:\n    From the paper below (Title + Summary + Link), evaluate how useful each paper is for understanding investment opportunities or technological advantages within the Web3 / crypto / DeFi ecosystem.\n    Rate each paper on a five-level scale: Highest / High / Medium / Low / Lowest.\n\n    \"Useful\" means:\n\n    - Improves understanding of new cryptographic primitives relevant to blockchain performance or security\n    - Enhances scalability: distributed systems, P2P networking, consensus mechanisms\n    - Advances in zero knowledge, MPC, PQC that could impact future L1/L2 chains\n    - DeFi modeling, AMMs, MEV, risk models, liquidity dynamics\n    - Smart contract security, attack vectors, economic incentives\n    - Token economics, mechanism design for decentralized systems\n    - Quantum threats to blockchain or cryptography\n    - Any breakthrough that meaningfully improves decentralization, scalability, privacy, or composability\n\n    Output instructions:\n\n    - Output each JSON object in JSON Lines format (one line per paper).\n\n    {\n        \"title\": title of the paper (in Japanese),\n        \"summary\": A concise summary of the paper (in Japanese),\n        \"impact_level\": \"Highest|High|Medium|Low|Lowest\",\n        \"why_matters\": An array (JSON array) containing 2\u20134 bullet points explaining why this paper matters for Web3 investment\n    }\n\n    - Do not output anything except valid JSON object in JSON Lines.\n    - \"title\", \"summary\", \"why_matters\" text in the output must be written in Japanese.\n\n    Paper:\n    title: Fermionic neural Gibbs states\n    summary: We introduce fermionic neural Gibbs states (fNGS), a variational framework for modeling finite-temperature properties of strongly interacting fermions. fNGS starts from a reference mean-field thermofield-double state and uses neural-network transformations together with imaginary-time evolution to systematically build strong correlations. Applied to the doped Fermi-Hubbard model, a minimal lattice model capturing essential features of strong electronic correlations, fNGS accurately reproduces thermal energies over a broad range of temperatures, interaction strengths, even at large dopings, for system sizes beyond the reach of exact methods. These results demonstrate a scalable route to studying finite-temperature properties of strongly correlated fermionic systems beyond one dimension with neural-network representations of quantum states.\n    link: https://arxiv.org/abs/2512.04663v1\n    "}}
{"custom_id": "2312.10657v2", "method": "POST", "url": "/v1/responses", "body": {"model": "gpt-5-mini", "input": "You are a specialist research analyst in Web3, DeFi, cryptography, and distributed systems.\n\n    Your task:\n    From the paper below (Title + Summary + Link), evaluate how useful each paper is for understanding investment opportunities or technological advantages within the Web3 / crypto / DeFi ecosystem.\n    Rate each paper on a five-level scale: Highest / High / Medium / Low / Lowest.\n\n    \"Useful\" means:\n\n    - Improves understanding of new cryptographic primitives relevant to blockchain performance or security\n    - Enhances scalability: distributed systems, P2P networking, consensus mechanisms\n    - Advances in zero knowledge, MPC, PQC that could impact future L1/L2 chains\n    - DeFi modeling, AMMs, MEV, risk models, liquidity dynamics\n    - Smart contract security, attack vectors, economic incentives\n    - Token economics, mechanism design for decentralized systems\n    - Quantum threats to blockchain or cryptography\n    - Any breakthrough that meaningfully improves decentralization, scalability, privacy, or composability\n\n    Output instructions:\n\n    - Output each JSON object in JSON Lines format (one line per paper).\n\n    {\n        \"title\": title of the paper (in Japanese),\n        \"summary\": A concise summary of the paper (in Japanese),\n        \"impact_level\": \"Highest|High|Medium|Low|Lowest\",\n        \"why_matters\": An array (JSON array) containing 2\u20134 bullet points explaining why this paper matters for Web3 investment\n    }\n\n    - Do not output anything except valid JSON object in JSON Lines.\n    - \"title\", \"summary\", \"why_matters\" text in the output must be written in Japanese.\n\n    Paper:\n    title: UltraClean: A Simple Framework to Train Robust Neural Networks against Backdoor Attacks\n    summary: Backdoor attacks are emerging threats to deep neural networks, which typically embed malicious behaviors into a victim model by injecting poisoned samples. Adversaries can activate the injected backdoor during inference by presenting the trigger on input images. Prior defensive methods have achieved remarkable success in countering dirty-label backdoor attacks where the labels of poisoned samples are often mislabeled. However, these approaches do not work for a recent new type of backdoor -- clean-label backdoor attacks that imperceptibly modify poisoned data and hold consistent labels. More complex and powerful algorithms are demanded to defend against such stealthy attacks. In this paper, we propose UltraClean, a general framework that simplifies the identification of poisoned samples and defends against both dirty-label and clean-label backdoor attacks. Given the fact that backdoor triggers introduce adversarial noise that intensifies in feed-forward propagation, UltraClean first generates two variants of training samples using off-the-shelf denoising functions. It then measures the susceptibility of training samples leveraging the error amplification effect in DNNs, which dilates the noise difference between the original image and denoised variants. Lastly, it filters out poisoned samples based on the susceptibility to thwart the backdoor implantation. Despite its simplicity, UltraClean achieves a superior detection rate across various datasets and significantly reduces the backdoor attack success rate while maintaining a decent model accuracy on clean data, outperforming existing defensive methods by a large margin. Code is available at https://github.com/bxz9200/UltraClean.\n    link: https://arxiv.org/abs/2312.10657v2\n    "}}
{"custom_id": "2512.04656v1", "method": "POST", "url": "/v1/responses", "body": {"model": "gpt-5-mini", "input": "You are a specialist research analyst in Web3, DeFi, cryptography, and distributed systems.\n\n    Your task:\n    From the paper below (Title + Summary + Link), evaluate how useful each paper is for understanding investment opportunities or technological advantages within the Web3 / crypto / DeFi ecosystem.\n    Rate each paper on a five-level scale: Highest / High / Medium / Low / Lowest.\n\n    \"Useful\" means:\n\n    - Improves understanding of new cryptographic primitives relevant to blockchain performance or security\n    - Enhances scalability: distributed systems, P2P networking, consensus mechanisms\n    - Advances in zero knowledge, MPC, PQC that could impact future L1/L2 chains\n    - DeFi modeling, AMMs, MEV, risk models, liquidity dynamics\n    - Smart contract security, attack vectors, economic incentives\n    - Token economics, mechanism design for decentralized systems\n    - Quantum threats to blockchain or cryptography\n    - Any breakthrough that meaningfully improves decentralization, scalability, privacy, or composability\n\n    Output instructions:\n\n    - Output each JSON object in JSON Lines format (one line per paper).\n\n    {\n        \"title\": title of the paper (in Japanese),\n        \"summary\": A concise summary of the paper (in Japanese),\n        \"impact_level\": \"Highest|High|Medium|Low|Lowest\",\n        \"why_matters\": An array (JSON array) containing 2\u20134 bullet points explaining why this paper matters for Web3 investment\n    }\n\n    - Do not output anything except valid JSON object in JSON Lines.\n    - \"title\", \"summary\", \"why_matters\" text in the output must be written in Japanese.\n\n    Paper:\n    title: Collective cluster nucleation dynamics in 2D Ising quantum magnets\n    summary: Strongly interacting many-body systems often show collective properties that are non-trivially related to the microscopic degrees of freedom. Collectivity is responsible for intriguing ground state properties, for example, in superconductors. However, collective effects may also govern the non-equilibrium response of quantum systems, not only in condensed matter physics but also in quantum field theories modeling the properties of our universe. Understanding emergent collective dynamics from first principles, in particular in non-perturbative regimes, is therefore one of the central challenges in quantum many-body physics. Here we report on the observation of collective cluster nucleation in 2D quantum Ising systems realized in an atomic Rydberg array. We observe a confined regime in which the steady-state cluster size is energy-dependent and a deconfined regime characterized by kinetically constrained dynamics of cluster nucleation. Our results mark a qualitative leap for quantum simulations with Rydberg arrays and shed light on highly collective non-equilibrium processes in one of the most important textbook models of condensed matter physics with relevance from quantum magnets and the kinetics of glass formers to cosmology.\n    link: https://arxiv.org/abs/2512.04656v1\n    "}}
{"custom_id": "2512.03914v2", "method": "POST", "url": "/v1/responses", "body": {"model": "gpt-5-mini", "input": "You are a specialist research analyst in Web3, DeFi, cryptography, and distributed systems.\n\n    Your task:\n    From the paper below (Title + Summary + Link), evaluate how useful each paper is for understanding investment opportunities or technological advantages within the Web3 / crypto / DeFi ecosystem.\n    Rate each paper on a five-level scale: Highest / High / Medium / Low / Lowest.\n\n    \"Useful\" means:\n\n    - Improves understanding of new cryptographic primitives relevant to blockchain performance or security\n    - Enhances scalability: distributed systems, P2P networking, consensus mechanisms\n    - Advances in zero knowledge, MPC, PQC that could impact future L1/L2 chains\n    - DeFi modeling, AMMs, MEV, risk models, liquidity dynamics\n    - Smart contract security, attack vectors, economic incentives\n    - Token economics, mechanism design for decentralized systems\n    - Quantum threats to blockchain or cryptography\n    - Any breakthrough that meaningfully improves decentralization, scalability, privacy, or composability\n\n    Output instructions:\n\n    - Output each JSON object in JSON Lines format (one line per paper).\n\n    {\n        \"title\": title of the paper (in Japanese),\n        \"summary\": A concise summary of the paper (in Japanese),\n        \"impact_level\": \"Highest|High|Medium|Low|Lowest\",\n        \"why_matters\": An array (JSON array) containing 2\u20134 bullet points explaining why this paper matters for Web3 investment\n    }\n\n    - Do not output anything except valid JSON object in JSON Lines.\n    - \"title\", \"summary\", \"why_matters\" text in the output must be written in Japanese.\n\n    Paper:\n    title: Integrating High Performance In-Memory Data Streaming and In-Situ Visualization in Hybrid MPI+OpenMP PIC MC Simulations Towards Exascale\n    summary: Efficient simulation of complex plasma dynamics is crucial for advancing fusion energy research. Particle-in-Cell (PIC) Monte Carlo (MC) simulations provide insights into plasma behavior, including turbulence and confinement, which are essential for optimizing fusion reactor performance. Transitioning to exascale simulations introduces significant challenges, with traditional file input/output (I/O) inefficiencies remaining a key bottleneck. This work advances BIT1, an electrostatic PIC MC code, by improving the particle mover with OpenMP task-based parallelism, integrating the openPMD streaming API, and enabling in-memory data streaming with ADIOS2's Sustainable Staging Transport (SST) engine to enhance I/O performance, computational efficiency, and system storage utilization. We employ profiling tools such as gprof, perf, IPM and Darshan, which provide insights into computation, communication, and I/O operations. We implement time-dependent data checkpointing with the openPMD API enabling seamless data movement and in-situ visualization for real-time analysis without interrupting the simulation. We demonstrate improvements in simulation runtime, data accessibility and real-time insights by comparing traditional file I/O with the ADIOS2 BP4 and SST backends. The proposed hybrid BIT1 openPMD SST enhancement introduces a new paradigm for real-time scientific discovery in plasma simulations, enabling faster insights and more efficient use of exascale computing resources.\n    link: https://arxiv.org/abs/2512.03914v2\n    "}}
{"custom_id": "2409.18530v2", "method": "POST", "url": "/v1/responses", "body": {"model": "gpt-5-mini", "input": "You are a specialist research analyst in Web3, DeFi, cryptography, and distributed systems.\n\n    Your task:\n    From the paper below (Title + Summary + Link), evaluate how useful each paper is for understanding investment opportunities or technological advantages within the Web3 / crypto / DeFi ecosystem.\n    Rate each paper on a five-level scale: Highest / High / Medium / Low / Lowest.\n\n    \"Useful\" means:\n\n    - Improves understanding of new cryptographic primitives relevant to blockchain performance or security\n    - Enhances scalability: distributed systems, P2P networking, consensus mechanisms\n    - Advances in zero knowledge, MPC, PQC that could impact future L1/L2 chains\n    - DeFi modeling, AMMs, MEV, risk models, liquidity dynamics\n    - Smart contract security, attack vectors, economic incentives\n    - Token economics, mechanism design for decentralized systems\n    - Quantum threats to blockchain or cryptography\n    - Any breakthrough that meaningfully improves decentralization, scalability, privacy, or composability\n\n    Output instructions:\n\n    - Output each JSON object in JSON Lines format (one line per paper).\n\n    {\n        \"title\": title of the paper (in Japanese),\n        \"summary\": A concise summary of the paper (in Japanese),\n        \"impact_level\": \"Highest|High|Medium|Low|Lowest\",\n        \"why_matters\": An array (JSON array) containing 2\u20134 bullet points explaining why this paper matters for Web3 investment\n    }\n\n    - Do not output anything except valid JSON object in JSON Lines.\n    - \"title\", \"summary\", \"why_matters\" text in the output must be written in Japanese.\n\n    Paper:\n    title: A Static Analysis of Popular C Packages in Linux\n    summary: Static analysis is a classical technique for improving software security and software quality in general. Fairly recently, a new static analyzer was implemented in the GNU Compiler Collection (GCC). The present paper uses the GCC's analyzer to empirically examine popular Linux packages. The dataset used is based on those packages in the Gentoo Linux distribution that are either written in C or contain C code. In total, 3,538 such packages are covered. According to the results, uninitialized variables and NULL pointer dereference issues are the most common problems according to the analyzer. Classical memory management issues are relatively rare. The warnings also follow a long-tailed probability distribution across the packages; a few packages are highly warning-prone, whereas no warnings are present for as much as 89% of the packages. Furthermore, the warnings do not vary across different application domains. With these results, the paper contributes to the domain of large-scale empirical research on software quality and security. In addition, a discussion is presented about practical implications of the results.\n    link: https://arxiv.org/abs/2409.18530v2\n    "}}
{"custom_id": "2501.16165v3", "method": "POST", "url": "/v1/responses", "body": {"model": "gpt-5-mini", "input": "You are a specialist research analyst in Web3, DeFi, cryptography, and distributed systems.\n\n    Your task:\n    From the paper below (Title + Summary + Link), evaluate how useful each paper is for understanding investment opportunities or technological advantages within the Web3 / crypto / DeFi ecosystem.\n    Rate each paper on a five-level scale: Highest / High / Medium / Low / Lowest.\n\n    \"Useful\" means:\n\n    - Improves understanding of new cryptographic primitives relevant to blockchain performance or security\n    - Enhances scalability: distributed systems, P2P networking, consensus mechanisms\n    - Advances in zero knowledge, MPC, PQC that could impact future L1/L2 chains\n    - DeFi modeling, AMMs, MEV, risk models, liquidity dynamics\n    - Smart contract security, attack vectors, economic incentives\n    - Token economics, mechanism design for decentralized systems\n    - Quantum threats to blockchain or cryptography\n    - Any breakthrough that meaningfully improves decentralization, scalability, privacy, or composability\n\n    Output instructions:\n\n    - Output each JSON object in JSON Lines format (one line per paper).\n\n    {\n        \"title\": title of the paper (in Japanese),\n        \"summary\": A concise summary of the paper (in Japanese),\n        \"impact_level\": \"Highest|High|Medium|Low|Lowest\",\n        \"why_matters\": An array (JSON array) containing 2\u20134 bullet points explaining why this paper matters for Web3 investment\n    }\n\n    - Do not output anything except valid JSON object in JSON Lines.\n    - \"title\", \"summary\", \"why_matters\" text in the output must be written in Japanese.\n\n    Paper:\n    title: A Survey of Operating System Kernel Fuzzing\n    summary: The Operating System (OS) kernel is foundational in modern computing, especially with the proliferation of diverse computing devices. However, its development also comes with vulnerabilities that can lead to severe security breaches. Kernel fuzzing, a technique used to uncover these vulnerabilities, poses distinct challenges when compared to user-space fuzzing. These include the complexity of configuring the testing environment and addressing the statefulness inherent to both the kernel and the fuzzing process. Despite the significant interest from the community, a comprehensive understanding of kernel fuzzing remains lacking, hindering further progress in the field. In this paper, we present the first systematic study focused specifically on OS kernel fuzzing. We begin by outlining the unique challenges of kernel fuzzing, which distinguish it from those in user space. Following this, we summarize the progress of 107 academic studies from top-tier venues between 2017 and 2025. To structure this analysis, we introduce a stage-based fuzzing model and a novel fuzzing taxonomy that highlights nine core functionalities unique to kernel fuzzing. Each of these functionalities is examined in conjunction with the methodological approaches employed to address them. Finally, we identify remaining gaps in addressing challenges and outline promising directions to guide forthcoming research in kernel security.\n    link: https://arxiv.org/abs/2501.16165v3\n    "}}
{"custom_id": "2512.03898v2", "method": "POST", "url": "/v1/responses", "body": {"model": "gpt-5-mini", "input": "You are a specialist research analyst in Web3, DeFi, cryptography, and distributed systems.\n\n    Your task:\n    From the paper below (Title + Summary + Link), evaluate how useful each paper is for understanding investment opportunities or technological advantages within the Web3 / crypto / DeFi ecosystem.\n    Rate each paper on a five-level scale: Highest / High / Medium / Low / Lowest.\n\n    \"Useful\" means:\n\n    - Improves understanding of new cryptographic primitives relevant to blockchain performance or security\n    - Enhances scalability: distributed systems, P2P networking, consensus mechanisms\n    - Advances in zero knowledge, MPC, PQC that could impact future L1/L2 chains\n    - DeFi modeling, AMMs, MEV, risk models, liquidity dynamics\n    - Smart contract security, attack vectors, economic incentives\n    - Token economics, mechanism design for decentralized systems\n    - Quantum threats to blockchain or cryptography\n    - Any breakthrough that meaningfully improves decentralization, scalability, privacy, or composability\n\n    Output instructions:\n\n    - Output each JSON object in JSON Lines format (one line per paper).\n\n    {\n        \"title\": title of the paper (in Japanese),\n        \"summary\": A concise summary of the paper (in Japanese),\n        \"impact_level\": \"Highest|High|Medium|Low|Lowest\",\n        \"why_matters\": An array (JSON array) containing 2\u20134 bullet points explaining why this paper matters for Web3 investment\n    }\n\n    - Do not output anything except valid JSON object in JSON Lines.\n    - \"title\", \"summary\", \"why_matters\" text in the output must be written in Japanese.\n\n    Paper:\n    title: Polylogarithmic-Depth Quantum Algorithm for Simulating the Extended Hubbard Model on a Two-Dimensional Lattice Using the Fast Multipole Method\n    summary: The extended Hubbard model on a two-dimensional lattice captures key physical phenomena, but is challenging to simulate due to the presence of long-range interactions. In this work, we present an efficient quantum algorithm for simulating the time evolution of this model. Our approach, inspired by the fast multipole method, approximates pairwise interactions by interactions between hierarchical levels of coarse-graining boxes. We discuss how to leverage recent advances in two-dimensional neutral atom quantum computing, supporting non-local operations such as long-range gates and shuttling. The resulting circuit depth for a single Trotter step scales polylogarithmically with system size.\n    link: https://arxiv.org/abs/2512.03898v2\n    "}}
{"custom_id": "2512.04611v1", "method": "POST", "url": "/v1/responses", "body": {"model": "gpt-5-mini", "input": "You are a specialist research analyst in Web3, DeFi, cryptography, and distributed systems.\n\n    Your task:\n    From the paper below (Title + Summary + Link), evaluate how useful each paper is for understanding investment opportunities or technological advantages within the Web3 / crypto / DeFi ecosystem.\n    Rate each paper on a five-level scale: Highest / High / Medium / Low / Lowest.\n\n    \"Useful\" means:\n\n    - Improves understanding of new cryptographic primitives relevant to blockchain performance or security\n    - Enhances scalability: distributed systems, P2P networking, consensus mechanisms\n    - Advances in zero knowledge, MPC, PQC that could impact future L1/L2 chains\n    - DeFi modeling, AMMs, MEV, risk models, liquidity dynamics\n    - Smart contract security, attack vectors, economic incentives\n    - Token economics, mechanism design for decentralized systems\n    - Quantum threats to blockchain or cryptography\n    - Any breakthrough that meaningfully improves decentralization, scalability, privacy, or composability\n\n    Output instructions:\n\n    - Output each JSON object in JSON Lines format (one line per paper).\n\n    {\n        \"title\": title of the paper (in Japanese),\n        \"summary\": A concise summary of the paper (in Japanese),\n        \"impact_level\": \"Highest|High|Medium|Low|Lowest\",\n        \"why_matters\": An array (JSON array) containing 2\u20134 bullet points explaining why this paper matters for Web3 investment\n    }\n\n    - Do not output anything except valid JSON object in JSON Lines.\n    - \"title\", \"summary\", \"why_matters\" text in the output must be written in Japanese.\n\n    Paper:\n    title: PBFuzz: Agentic Directed Fuzzing for PoV Generation\n    summary: Proof-of-Vulnerability (PoV) input generation is a critical task in software security and supports downstream applications such as path generation and validation. Generating a PoV input requires solving two sets of constraints: (1) reachability constraints for reaching vulnerable code locations, and (2) triggering constraints for activating the target vulnerability. Existing approaches, including directed greybox fuzzing and LLM-assisted fuzzing, struggle to efficiently satisfy these constraints. This work presents an agentic method that mimics human experts. Human analysts iteratively study code to extract semantic reachability and triggering constraints, form hypotheses about PoV triggering strategies, encode them as test inputs, and refine their understanding using debugging feedback. We automate this process with an agentic directed fuzzing framework called PBFuzz. PBFuzz tackles four challenges in agentic PoV generation: autonomous code reasoning for semantic constraint extraction, custom program-analysis tools for targeted inference, persistent memory to avoid hypothesis drift, and property-based testing for efficient constraint solving while preserving input structure. Experiments on the Magma benchmark show strong results. PBFuzz triggered 57 vulnerabilities, surpassing all baselines, and uniquely triggered 17 vulnerabilities not exposed by existing fuzzers. PBFuzz achieved this within a 30-minute budget per target, while conventional approaches use 24 hours. Median time-to-exposure was 339 seconds for PBFuzz versus 8680 seconds for AFL++ with CmpLog, giving a 25.6x efficiency improvement with an API cost of 1.83 USD per vulnerability.\n    link: https://arxiv.org/abs/2512.04611v1\n    "}}
{"custom_id": "2510.05497v2", "method": "POST", "url": "/v1/responses", "body": {"model": "gpt-5-mini", "input": "You are a specialist research analyst in Web3, DeFi, cryptography, and distributed systems.\n\n    Your task:\n    From the paper below (Title + Summary + Link), evaluate how useful each paper is for understanding investment opportunities or technological advantages within the Web3 / crypto / DeFi ecosystem.\n    Rate each paper on a five-level scale: Highest / High / Medium / Low / Lowest.\n\n    \"Useful\" means:\n\n    - Improves understanding of new cryptographic primitives relevant to blockchain performance or security\n    - Enhances scalability: distributed systems, P2P networking, consensus mechanisms\n    - Advances in zero knowledge, MPC, PQC that could impact future L1/L2 chains\n    - DeFi modeling, AMMs, MEV, risk models, liquidity dynamics\n    - Smart contract security, attack vectors, economic incentives\n    - Token economics, mechanism design for decentralized systems\n    - Quantum threats to blockchain or cryptography\n    - Any breakthrough that meaningfully improves decentralization, scalability, privacy, or composability\n\n    Output instructions:\n\n    - Output each JSON object in JSON Lines format (one line per paper).\n\n    {\n        \"title\": title of the paper (in Japanese),\n        \"summary\": A concise summary of the paper (in Japanese),\n        \"impact_level\": \"Highest|High|Medium|Low|Lowest\",\n        \"why_matters\": An array (JSON array) containing 2\u20134 bullet points explaining why this paper matters for Web3 investment\n    }\n\n    - Do not output anything except valid JSON object in JSON Lines.\n    - \"title\", \"summary\", \"why_matters\" text in the output must be written in Japanese.\n\n    Paper:\n    title: Orders in Chaos: Enhancing Large-Scale MoE LLM Serving with Data Movement Forecasting\n    summary: Large-scale Mixture of Experts (MoE) Large Language Models (LLMs) have recently become the frontier open weight models, achieving remarkable model capability similar to proprietary ones. But their random expert selection mechanism introduces significant data movement overhead that becomes the dominant bottleneck in multi-unit LLM serving systems.\n  To understand the patterns underlying this data movement, we conduct comprehensive data-movement-centric profiling across four state-of-the-art large-scale MoE models released in 2025 (200B-1000B) using over 24,000 requests spanning diverse workloads. We perform systematic analysis from both temporal and spatial perspectives and distill six key insights to guide the design of diverse future serving systems. With our insights, we then demonstrate how to improve wafer-scale GPUs as a case study, and show that minor architectural modifications leveraging the insights achieve substantial performance gains, delivering 5.3x and 3.1x average speedups on DeepSeek V3 and Qwen3, respectively. Our work presents the first comprehensive data-centric analysis of large-scale MoE models and a concrete design study using the learned lessons, with profiling traces and simulation framework already open-sourced with $>$1k downloads. Our traces and results are publicly available at https://huggingface.co/datasets/core12345/MoE_expert_selection_trace\n    link: https://arxiv.org/abs/2510.05497v2\n    "}}
{"custom_id": "2512.04590v1", "method": "POST", "url": "/v1/responses", "body": {"model": "gpt-5-mini", "input": "You are a specialist research analyst in Web3, DeFi, cryptography, and distributed systems.\n\n    Your task:\n    From the paper below (Title + Summary + Link), evaluate how useful each paper is for understanding investment opportunities or technological advantages within the Web3 / crypto / DeFi ecosystem.\n    Rate each paper on a five-level scale: Highest / High / Medium / Low / Lowest.\n\n    \"Useful\" means:\n\n    - Improves understanding of new cryptographic primitives relevant to blockchain performance or security\n    - Enhances scalability: distributed systems, P2P networking, consensus mechanisms\n    - Advances in zero knowledge, MPC, PQC that could impact future L1/L2 chains\n    - DeFi modeling, AMMs, MEV, risk models, liquidity dynamics\n    - Smart contract security, attack vectors, economic incentives\n    - Token economics, mechanism design for decentralized systems\n    - Quantum threats to blockchain or cryptography\n    - Any breakthrough that meaningfully improves decentralization, scalability, privacy, or composability\n\n    Output instructions:\n\n    - Output each JSON object in JSON Lines format (one line per paper).\n\n    {\n        \"title\": title of the paper (in Japanese),\n        \"summary\": A concise summary of the paper (in Japanese),\n        \"impact_level\": \"Highest|High|Medium|Low|Lowest\",\n        \"why_matters\": An array (JSON array) containing 2\u20134 bullet points explaining why this paper matters for Web3 investment\n    }\n\n    - Do not output anything except valid JSON object in JSON Lines.\n    - \"title\", \"summary\", \"why_matters\" text in the output must be written in Japanese.\n\n    Paper:\n    title: Exploiting \\texttt{ftrace}'s \\texttt{function\\_graph} Tracer Features for Machine Learning: A Case Study on Encryption Detection\n    summary: This paper proposes using the Linux kernel ftrace framework, particularly the function graph tracer, to generate informative system level data for machine learning (ML) applications. Experiments on a real world encryption detection task demonstrate the efficacy of the proposed features across several learning algorithms. The learner faces the problem of detecting encryption activities across a large dataset of files, using function call traces and graph based features. Empirical results highlight an outstanding accuracy of 99.28 on the task at hand, underscoring the efficacy of features derived from the function graph tracer. The results were further validated in an additional experiment targeting a multilabel classification problem, in which running programs were identified from trace data. This work provides comprehensive methodologies for preprocessing raw trace data and extracting graph based features, offering significant advancements in applying ML to system behavior analysis, program identification, and anomaly detection. By bridging the gap between system tracing and ML, this paper paves the way for innovative solutions in performance monitoring and security analytics.\n    link: https://arxiv.org/abs/2512.04590v1\n    "}}
{"custom_id": "2512.04580v1", "method": "POST", "url": "/v1/responses", "body": {"model": "gpt-5-mini", "input": "You are a specialist research analyst in Web3, DeFi, cryptography, and distributed systems.\n\n    Your task:\n    From the paper below (Title + Summary + Link), evaluate how useful each paper is for understanding investment opportunities or technological advantages within the Web3 / crypto / DeFi ecosystem.\n    Rate each paper on a five-level scale: Highest / High / Medium / Low / Lowest.\n\n    \"Useful\" means:\n\n    - Improves understanding of new cryptographic primitives relevant to blockchain performance or security\n    - Enhances scalability: distributed systems, P2P networking, consensus mechanisms\n    - Advances in zero knowledge, MPC, PQC that could impact future L1/L2 chains\n    - DeFi modeling, AMMs, MEV, risk models, liquidity dynamics\n    - Smart contract security, attack vectors, economic incentives\n    - Token economics, mechanism design for decentralized systems\n    - Quantum threats to blockchain or cryptography\n    - Any breakthrough that meaningfully improves decentralization, scalability, privacy, or composability\n\n    Output instructions:\n\n    - Output each JSON object in JSON Lines format (one line per paper).\n\n    {\n        \"title\": title of the paper (in Japanese),\n        \"summary\": A concise summary of the paper (in Japanese),\n        \"impact_level\": \"Highest|High|Medium|Low|Lowest\",\n        \"why_matters\": An array (JSON array) containing 2\u20134 bullet points explaining why this paper matters for Web3 investment\n    }\n\n    - Do not output anything except valid JSON object in JSON Lines.\n    - \"title\", \"summary\", \"why_matters\" text in the output must be written in Japanese.\n\n    Paper:\n    title: A Light-Weight Large Language Model File Format for Highly-Secure Model Distribution\n    summary: To enhance the performance of large language models (LLMs) in various domain-specific applications, sensitive data such as healthcare, law, and finance are being used to privately customize or fine-tune these models. Such privately adapted LLMs are regarded as either personal privacy assets or corporate intellectual property. Therefore, protecting model weights and maintaining strict confidentiality during deployment and distribution have become critically important. However, existing model formats and deployment frameworks provide little to no built-in support for confidentiality, access control, or secure integration with trusted hardware. Current methods for securing model deployment either rely on computationally expensive cryptographic techniques or tightly controlled private infrastructure. Although these approaches can be effective in specific scenarios, they are difficult and costly for widespread deployment.\n  In this paper, we introduce CryptoTensors, a secure and format-compatible file structure for confidential LLM distribution. Built as an extension to the widely adopted Safetensors format, CryptoTensors incorporates tensor-level encryption and embedded access control policies, while preserving critical features such as lazy loading and partial deserialization. It enables transparent decryption and automated key management, supporting flexible licensing and secure model execution with minimal overhead. We implement a proof-of-concept library, benchmark its performance across serialization and runtime scenarios, and validate its compatibility with existing inference frameworks, including Hugging Face Transformers and vLLM. Our results highlight CryptoTensors as a light-weight, efficient, and developer-friendly solution for safeguarding LLM weights in real-world and widespread deployments.\n    link: https://arxiv.org/abs/2512.04580v1\n    "}}
{"custom_id": "2511.18723v2", "method": "POST", "url": "/v1/responses", "body": {"model": "gpt-5-mini", "input": "You are a specialist research analyst in Web3, DeFi, cryptography, and distributed systems.\n\n    Your task:\n    From the paper below (Title + Summary + Link), evaluate how useful each paper is for understanding investment opportunities or technological advantages within the Web3 / crypto / DeFi ecosystem.\n    Rate each paper on a five-level scale: Highest / High / Medium / Low / Lowest.\n\n    \"Useful\" means:\n\n    - Improves understanding of new cryptographic primitives relevant to blockchain performance or security\n    - Enhances scalability: distributed systems, P2P networking, consensus mechanisms\n    - Advances in zero knowledge, MPC, PQC that could impact future L1/L2 chains\n    - DeFi modeling, AMMs, MEV, risk models, liquidity dynamics\n    - Smart contract security, attack vectors, economic incentives\n    - Token economics, mechanism design for decentralized systems\n    - Quantum threats to blockchain or cryptography\n    - Any breakthrough that meaningfully improves decentralization, scalability, privacy, or composability\n\n    Output instructions:\n\n    - Output each JSON object in JSON Lines format (one line per paper).\n\n    {\n        \"title\": title of the paper (in Japanese),\n        \"summary\": A concise summary of the paper (in Japanese),\n        \"impact_level\": \"Highest|High|Medium|Low|Lowest\",\n        \"why_matters\": An array (JSON array) containing 2\u20134 bullet points explaining why this paper matters for Web3 investment\n    }\n\n    - Do not output anything except valid JSON object in JSON Lines.\n    - \"title\", \"summary\", \"why_matters\" text in the output must be written in Japanese.\n\n    Paper:\n    title: N2N: A Parallel Framework for Large-Scale MILP under Distributed Memory\n    summary: Parallelization has emerged as a promising approach for accelerating MILP solving. However, the complexity of the branch-and-bound (B&B) framework and the numerous effective algorithm components in MILP solvers make it difficult to parallelize. In this study, a scalable parallel framework, N2N (a node-to-node framework that maps the B&B nodes to distributed computing nodes), was proposed to solve large-scale problems in a distributed memory computing environment. Both deterministic and nondeterministic modes are supported, and the framework is designed to be easily integrated with existing solvers. Regarding the deterministic mode, a novel sliding-window-based algorithm was designed and implemented to ensure that tasks are generated and solved in a deterministic order. Moreover, several advanced techniques, such as the utilization of CP search and general primal heuristics, have been developed to fully utilize distributed computing resources and capabilities of base solvers. Adaptive solving and data communication optimization were also investigated. A popular open-source MILP solver, SCIP, was integrated into N2N as the base solver, yielding N2N-SCIP. Extensive computational experiments were conducted to evaluate the performance of N2N-SCIP compared to ParaSCIP, which is a state-of-the-art distributed parallel MILP solver under the UG framework. The nondeterministic N2N-SCIP achieves speedups of 22.52 and 12.71 with 1,000 MPI processes on the Kunpeng and x86 computing clusters, which is 1.98 and 2.08 times faster than ParaSCIP, respectively. In the deterministic mode, N2N-SCIP also shows significant performance improvements over ParaSCIP across different process numbers and computing clusters. To validate the generality of N2N, HiGHS, another open-source solver, was integrated into N2N. The related results are analyzed, and the requirements of N2N on base solvers are also concluded.\n    link: https://arxiv.org/abs/2511.18723v2\n    "}}
{"custom_id": "2508.08860v3", "method": "POST", "url": "/v1/responses", "body": {"model": "gpt-5-mini", "input": "You are a specialist research analyst in Web3, DeFi, cryptography, and distributed systems.\n\n    Your task:\n    From the paper below (Title + Summary + Link), evaluate how useful each paper is for understanding investment opportunities or technological advantages within the Web3 / crypto / DeFi ecosystem.\n    Rate each paper on a five-level scale: Highest / High / Medium / Low / Lowest.\n\n    \"Useful\" means:\n\n    - Improves understanding of new cryptographic primitives relevant to blockchain performance or security\n    - Enhances scalability: distributed systems, P2P networking, consensus mechanisms\n    - Advances in zero knowledge, MPC, PQC that could impact future L1/L2 chains\n    - DeFi modeling, AMMs, MEV, risk models, liquidity dynamics\n    - Smart contract security, attack vectors, economic incentives\n    - Token economics, mechanism design for decentralized systems\n    - Quantum threats to blockchain or cryptography\n    - Any breakthrough that meaningfully improves decentralization, scalability, privacy, or composability\n\n    Output instructions:\n\n    - Output each JSON object in JSON Lines format (one line per paper).\n\n    {\n        \"title\": title of the paper (in Japanese),\n        \"summary\": A concise summary of the paper (in Japanese),\n        \"impact_level\": \"Highest|High|Medium|Low|Lowest\",\n        \"why_matters\": An array (JSON array) containing 2\u20134 bullet points explaining why this paper matters for Web3 investment\n    }\n\n    - Do not output anything except valid JSON object in JSON Lines.\n    - \"title\", \"summary\", \"why_matters\" text in the output must be written in Japanese.\n\n    Paper:\n    title: Superradiant Phase Transition and Statistical Properties in Dicke-Stark Model\n    summary: In this study, the energy spectrum and thermal equilibrium states of the finite-size Dicke-Stark model were numerically obtained within the extended coherent state space by solving the dressed master equation for strongly coupled light-atom systems. The critical point of the superradiant phase transition in the infinite-size Dicke-Stark model was analytically derived using the mean-field approach and confirmed with numerical calculation. Under thermal equilibrium conditions, analyses of the negativity, zero-time-delay two-photon correlation function, and atom-spin squeezing parameters in the finite-size Dicke-Stark model reveal that as the coupling strength increases, the light field undergoes a transition from photon bunching to anti-bunching and then back to bunching. The Stark field can modulate both the maximum and minimum values of the two-photon correlation function and their corresponding coupling strengths. At low temperatures, the system exhibits entanglement and spin squeezing. As temperature rises, entanglement gradually diminishes, while strong coupling facilitates the preservation of entanglement in the system state. Atom-spin squeezing spin squeezing is highly sensitive to temperature and vanishes rapidly with increasing temperature. This work contributes to the fundamental understanding of quantum phenomena in Dicke-Stark systems.\n    link: https://arxiv.org/abs/2508.08860v3\n    "}}
{"custom_id": "2501.07033v2", "method": "POST", "url": "/v1/responses", "body": {"model": "gpt-5-mini", "input": "You are a specialist research analyst in Web3, DeFi, cryptography, and distributed systems.\n\n    Your task:\n    From the paper below (Title + Summary + Link), evaluate how useful each paper is for understanding investment opportunities or technological advantages within the Web3 / crypto / DeFi ecosystem.\n    Rate each paper on a five-level scale: Highest / High / Medium / Low / Lowest.\n\n    \"Useful\" means:\n\n    - Improves understanding of new cryptographic primitives relevant to blockchain performance or security\n    - Enhances scalability: distributed systems, P2P networking, consensus mechanisms\n    - Advances in zero knowledge, MPC, PQC that could impact future L1/L2 chains\n    - DeFi modeling, AMMs, MEV, risk models, liquidity dynamics\n    - Smart contract security, attack vectors, economic incentives\n    - Token economics, mechanism design for decentralized systems\n    - Quantum threats to blockchain or cryptography\n    - Any breakthrough that meaningfully improves decentralization, scalability, privacy, or composability\n\n    Output instructions:\n\n    - Output each JSON object in JSON Lines format (one line per paper).\n\n    {\n        \"title\": title of the paper (in Japanese),\n        \"summary\": A concise summary of the paper (in Japanese),\n        \"impact_level\": \"Highest|High|Medium|Low|Lowest\",\n        \"why_matters\": An array (JSON array) containing 2\u20134 bullet points explaining why this paper matters for Web3 investment\n    }\n\n    - Do not output anything except valid JSON object in JSON Lines.\n    - \"title\", \"summary\", \"why_matters\" text in the output must be written in Japanese.\n\n    Paper:\n    title: Detection of AI Deepfake and Fraud in Online Payments Using GAN-Based Models\n    summary: This study explores the use of Generative Adversarial Networks (GANs) to detect AI deepfakes and fraudulent activities in online payment systems. With the growing prevalence of deepfake technology, which can manipulate facial features in images and videos, the potential for fraud in online transactions has escalated. Traditional security systems struggle to identify these sophisticated forms of fraud. This research proposes a novel GAN-based model that enhances online payment security by identifying subtle manipulations in payment images. The model is trained on a dataset consisting of real-world online payment images and deepfake images generated using advanced GAN architectures, such as StyleGAN and DeepFake. The results demonstrate that the proposed model can accurately distinguish between legitimate transactions and deepfakes, achieving a high detection rate above 95%. This approach significantly improves the robustness of payment systems against AI-driven fraud. The paper contributes to the growing field of digital security, offering insights into the application of GANs for fraud detection in financial services. Keywords- Payment Security, Image Recognition, Generative Adversarial Networks, AI Deepfake, Fraudulent Activities\n    link: https://arxiv.org/abs/2501.07033v2\n    "}}
{"custom_id": "2512.04527v1", "method": "POST", "url": "/v1/responses", "body": {"model": "gpt-5-mini", "input": "You are a specialist research analyst in Web3, DeFi, cryptography, and distributed systems.\n\n    Your task:\n    From the paper below (Title + Summary + Link), evaluate how useful each paper is for understanding investment opportunities or technological advantages within the Web3 / crypto / DeFi ecosystem.\n    Rate each paper on a five-level scale: Highest / High / Medium / Low / Lowest.\n\n    \"Useful\" means:\n\n    - Improves understanding of new cryptographic primitives relevant to blockchain performance or security\n    - Enhances scalability: distributed systems, P2P networking, consensus mechanisms\n    - Advances in zero knowledge, MPC, PQC that could impact future L1/L2 chains\n    - DeFi modeling, AMMs, MEV, risk models, liquidity dynamics\n    - Smart contract security, attack vectors, economic incentives\n    - Token economics, mechanism design for decentralized systems\n    - Quantum threats to blockchain or cryptography\n    - Any breakthrough that meaningfully improves decentralization, scalability, privacy, or composability\n\n    Output instructions:\n\n    - Output each JSON object in JSON Lines format (one line per paper).\n\n    {\n        \"title\": title of the paper (in Japanese),\n        \"summary\": A concise summary of the paper (in Japanese),\n        \"impact_level\": \"Highest|High|Medium|Low|Lowest\",\n        \"why_matters\": An array (JSON array) containing 2\u20134 bullet points explaining why this paper matters for Web3 investment\n    }\n\n    - Do not output anything except valid JSON object in JSON Lines.\n    - \"title\", \"summary\", \"why_matters\" text in the output must be written in Japanese.\n\n    Paper:\n    title: FLEX: Leveraging FPGA-CPU Synergy for Mixed-Cell-Height Legalization Acceleration\n    summary: In this work, we present FLEX, an FPGA-CPU accelerator for mixed-cell-height legalization tasks. We address challenges from the following perspectives. First, we optimize the task assignment strategy and perform an efficient task partition between FPGA and CPU to exploit their complementary strengths. Second, a multi-granularity pipelining technique is employed to accelerate the most time-consuming step, finding optimal placement position (FOP), in legalization. At last, we particularly target the computationally intensive cell shifting process in FOP, optimizing the design to align it seamlessly with the multi-granularity pipelining framework for further speedup. Experimental results show that FLEX achieves up to 18.3x and 5.4x speedups compared to state-of-the-art CPU-GPU and multi-threaded CPU legalizers with better scalability, while improving legalization quality by 4% and 1%.\n    link: https://arxiv.org/abs/2512.04527v1\n    "}}
{"custom_id": "2512.03771v2", "method": "POST", "url": "/v1/responses", "body": {"model": "gpt-5-mini", "input": "You are a specialist research analyst in Web3, DeFi, cryptography, and distributed systems.\n\n    Your task:\n    From the paper below (Title + Summary + Link), evaluate how useful each paper is for understanding investment opportunities or technological advantages within the Web3 / crypto / DeFi ecosystem.\n    Rate each paper on a five-level scale: Highest / High / Medium / Low / Lowest.\n\n    \"Useful\" means:\n\n    - Improves understanding of new cryptographic primitives relevant to blockchain performance or security\n    - Enhances scalability: distributed systems, P2P networking, consensus mechanisms\n    - Advances in zero knowledge, MPC, PQC that could impact future L1/L2 chains\n    - DeFi modeling, AMMs, MEV, risk models, liquidity dynamics\n    - Smart contract security, attack vectors, economic incentives\n    - Token economics, mechanism design for decentralized systems\n    - Quantum threats to blockchain or cryptography\n    - Any breakthrough that meaningfully improves decentralization, scalability, privacy, or composability\n\n    Output instructions:\n\n    - Output each JSON object in JSON Lines format (one line per paper).\n\n    {\n        \"title\": title of the paper (in Japanese),\n        \"summary\": A concise summary of the paper (in Japanese),\n        \"impact_level\": \"Highest|High|Medium|Low|Lowest\",\n        \"why_matters\": An array (JSON array) containing 2\u20134 bullet points explaining why this paper matters for Web3 investment\n    }\n\n    - Do not output anything except valid JSON object in JSON Lines.\n    - \"title\", \"summary\", \"why_matters\" text in the output must be written in Japanese.\n\n    Paper:\n    title: In-Context Representation Hijacking\n    summary: We introduce $\\textbf{Doublespeak}$, a simple in-context representation hijacking attack against large language models (LLMs). The attack works by systematically replacing a harmful keyword (e.g., bomb) with a benign token (e.g., carrot) across multiple in-context examples, provided a prefix to a harmful request. We demonstrate that this substitution leads to the internal representation of the benign token converging toward that of the harmful one, effectively embedding the harmful semantics under a euphemism. As a result, superficially innocuous prompts (e.g., \"How to build a carrot?\") are internally interpreted as disallowed instructions (e.g., \"How to build a bomb?\"), thereby bypassing the model's safety alignment. We use interpretability tools to show that this semantic overwrite emerges layer by layer, with benign meanings in early layers converging into harmful semantics in later ones. Doublespeak is optimization-free, broadly transferable across model families, and achieves strong success rates on closed-source and open-source systems, reaching 74% ASR on Llama-3.3-70B-Instruct with a single-sentence context override. Our findings highlight a new attack surface in the latent space of LLMs, revealing that current alignment strategies are insufficient and should instead operate at the representation level.\n    link: https://arxiv.org/abs/2512.03771v2\n    "}}
{"custom_id": "2511.22421v2", "method": "POST", "url": "/v1/responses", "body": {"model": "gpt-5-mini", "input": "You are a specialist research analyst in Web3, DeFi, cryptography, and distributed systems.\n\n    Your task:\n    From the paper below (Title + Summary + Link), evaluate how useful each paper is for understanding investment opportunities or technological advantages within the Web3 / crypto / DeFi ecosystem.\n    Rate each paper on a five-level scale: Highest / High / Medium / Low / Lowest.\n\n    \"Useful\" means:\n\n    - Improves understanding of new cryptographic primitives relevant to blockchain performance or security\n    - Enhances scalability: distributed systems, P2P networking, consensus mechanisms\n    - Advances in zero knowledge, MPC, PQC that could impact future L1/L2 chains\n    - DeFi modeling, AMMs, MEV, risk models, liquidity dynamics\n    - Smart contract security, attack vectors, economic incentives\n    - Token economics, mechanism design for decentralized systems\n    - Quantum threats to blockchain or cryptography\n    - Any breakthrough that meaningfully improves decentralization, scalability, privacy, or composability\n\n    Output instructions:\n\n    - Output each JSON object in JSON Lines format (one line per paper).\n\n    {\n        \"title\": title of the paper (in Japanese),\n        \"summary\": A concise summary of the paper (in Japanese),\n        \"impact_level\": \"Highest|High|Medium|Low|Lowest\",\n        \"why_matters\": An array (JSON array) containing 2\u20134 bullet points explaining why this paper matters for Web3 investment\n    }\n\n    - Do not output anything except valid JSON object in JSON Lines.\n    - \"title\", \"summary\", \"why_matters\" text in the output must be written in Japanese.\n\n    Paper:\n    title: Semantic-Aware Caching for Efficient Image Generation in Edge Computing\n    summary: Text-to-image generation employing diffusion models has attained significant popularity due to its capability to produce high-quality images that adhere to textual prompts. However, the integration of diffusion models faces critical challenges into resource-constrained mobile and edge environments because it requires multiple denoising steps from the original random noise. A practical way to speed up denoising is to initialize the process with a noised reference image that is similar to the target, since both images share similar layouts, structures, and details, allowing for fewer denoising steps. Based on this idea, we present CacheGenius, a hybrid image generation system in edge computing that accelerates generation by combining text-toimage and image-to-image workflows. It generates images from user text prompts using cached reference images. CacheGenius introduces a semantic-aware classified storage scheme and a request-scheduling algorithm that ensures semantic alignment between references and targets. To ensure sustained performance, it employs a cache maintenance policy that proactively evicts obsolete entries via correlation analysis. Evaluated in a distributed edge computing system, CacheGenius reduces generation latency by 41% and computational costs by 48% relative to baselines, while maintaining competitive evaluation metrics.\n    link: https://arxiv.org/abs/2511.22421v2\n    "}}
{"custom_id": "2412.00387v2", "method": "POST", "url": "/v1/responses", "body": {"model": "gpt-5-mini", "input": "You are a specialist research analyst in Web3, DeFi, cryptography, and distributed systems.\n\n    Your task:\n    From the paper below (Title + Summary + Link), evaluate how useful each paper is for understanding investment opportunities or technological advantages within the Web3 / crypto / DeFi ecosystem.\n    Rate each paper on a five-level scale: Highest / High / Medium / Low / Lowest.\n\n    \"Useful\" means:\n\n    - Improves understanding of new cryptographic primitives relevant to blockchain performance or security\n    - Enhances scalability: distributed systems, P2P networking, consensus mechanisms\n    - Advances in zero knowledge, MPC, PQC that could impact future L1/L2 chains\n    - DeFi modeling, AMMs, MEV, risk models, liquidity dynamics\n    - Smart contract security, attack vectors, economic incentives\n    - Token economics, mechanism design for decentralized systems\n    - Quantum threats to blockchain or cryptography\n    - Any breakthrough that meaningfully improves decentralization, scalability, privacy, or composability\n\n    Output instructions:\n\n    - Output each JSON object in JSON Lines format (one line per paper).\n\n    {\n        \"title\": title of the paper (in Japanese),\n        \"summary\": A concise summary of the paper (in Japanese),\n        \"impact_level\": \"Highest|High|Medium|Low|Lowest\",\n        \"why_matters\": An array (JSON array) containing 2\u20134 bullet points explaining why this paper matters for Web3 investment\n    }\n\n    - Do not output anything except valid JSON object in JSON Lines.\n    - \"title\", \"summary\", \"why_matters\" text in the output must be written in Japanese.\n\n    Paper:\n    title: A generalization of Burmester-Desmedt GKE based on a non-abelian finite group action\n    summary: The advent of large-scale quantum computers implies that our existing public-key cryptography infrastructure has become insecure. That means that the privacy of many mobile applications involving dynamic peer groups, such as multicast messaging or pay-per-view, could be compromised. In this work we propose a generalization of the well known group key exchange protocol proposed by Burmester and Desmedt to the non-abelian case by the use of finite group actions and we prove that the presented protocol is secure in Katz and Yung's model.\n    link: https://arxiv.org/abs/2412.00387v2\n    "}}
{"custom_id": "2412.17704v3", "method": "POST", "url": "/v1/responses", "body": {"model": "gpt-5-mini", "input": "You are a specialist research analyst in Web3, DeFi, cryptography, and distributed systems.\n\n    Your task:\n    From the paper below (Title + Summary + Link), evaluate how useful each paper is for understanding investment opportunities or technological advantages within the Web3 / crypto / DeFi ecosystem.\n    Rate each paper on a five-level scale: Highest / High / Medium / Low / Lowest.\n\n    \"Useful\" means:\n\n    - Improves understanding of new cryptographic primitives relevant to blockchain performance or security\n    - Enhances scalability: distributed systems, P2P networking, consensus mechanisms\n    - Advances in zero knowledge, MPC, PQC that could impact future L1/L2 chains\n    - DeFi modeling, AMMs, MEV, risk models, liquidity dynamics\n    - Smart contract security, attack vectors, economic incentives\n    - Token economics, mechanism design for decentralized systems\n    - Quantum threats to blockchain or cryptography\n    - Any breakthrough that meaningfully improves decentralization, scalability, privacy, or composability\n\n    Output instructions:\n\n    - Output each JSON object in JSON Lines format (one line per paper).\n\n    {\n        \"title\": title of the paper (in Japanese),\n        \"summary\": A concise summary of the paper (in Japanese),\n        \"impact_level\": \"Highest|High|Medium|Low|Lowest\",\n        \"why_matters\": An array (JSON array) containing 2\u20134 bullet points explaining why this paper matters for Web3 investment\n    }\n\n    - Do not output anything except valid JSON object in JSON Lines.\n    - \"title\", \"summary\", \"why_matters\" text in the output must be written in Japanese.\n\n    Paper:\n    title: Enhanced Quantum Circuit Cutting Framework for Sampling Overhead Reduction\n    summary: The recently developed quantum circuit cutting technique greatly extends the capabilities of current noisy intermediate-scale quantum (NISQ) hardware. However, it introduces substantial overhead in both classical postprocessing and quantum resources, as the postprocessing complexity and sampling cost scale exponentially with the number of circuit cuts. In this work, we propose an enhanced circuit cutting framework, ShotQC, which effectively reduces the sampling overhead through two key optimizations: shot distribution and cut parameterization. The former employs an adaptive Monte Carlo strategy to dynamically allocate more quantum resources to subcircuit configurations that contribute more to the variance in the final outcome. The latter exploits additional degrees of freedom in postprocessing to further suppress variance. Integrating these optimizations, ShotQC significantly reduces the sampling overhead without increasing classical postprocessing complexity, as demonstrated across a range of benchmark circuits.\n    link: https://arxiv.org/abs/2412.17704v3\n    "}}
{"custom_id": "2511.13725v2", "method": "POST", "url": "/v1/responses", "body": {"model": "gpt-5-mini", "input": "You are a specialist research analyst in Web3, DeFi, cryptography, and distributed systems.\n\n    Your task:\n    From the paper below (Title + Summary + Link), evaluate how useful each paper is for understanding investment opportunities or technological advantages within the Web3 / crypto / DeFi ecosystem.\n    Rate each paper on a five-level scale: Highest / High / Medium / Low / Lowest.\n\n    \"Useful\" means:\n\n    - Improves understanding of new cryptographic primitives relevant to blockchain performance or security\n    - Enhances scalability: distributed systems, P2P networking, consensus mechanisms\n    - Advances in zero knowledge, MPC, PQC that could impact future L1/L2 chains\n    - DeFi modeling, AMMs, MEV, risk models, liquidity dynamics\n    - Smart contract security, attack vectors, economic incentives\n    - Token economics, mechanism design for decentralized systems\n    - Quantum threats to blockchain or cryptography\n    - Any breakthrough that meaningfully improves decentralization, scalability, privacy, or composability\n\n    Output instructions:\n\n    - Output each JSON object in JSON Lines format (one line per paper).\n\n    {\n        \"title\": title of the paper (in Japanese),\n        \"summary\": A concise summary of the paper (in Japanese),\n        \"impact_level\": \"Highest|High|Medium|Low|Lowest\",\n        \"why_matters\": An array (JSON array) containing 2\u20134 bullet points explaining why this paper matters for Web3 investment\n    }\n\n    - Do not output anything except valid JSON object in JSON Lines.\n    - \"title\", \"summary\", \"why_matters\" text in the output must be written in Japanese.\n\n    Paper:\n    title: AI Kill Switch for malicious web-based LLM agent\n    summary: Recently, web-based Large Language Model (LLM) agents autonomously perform increasingly complex tasks, thereby bringing significant convenience. However, they also amplify the risks of malicious misuse cases such as unauthorized collection of personally identifiable information (PII), generation of socially divisive content, and even automated web hacking. To address these threats, we propose an AI Kill Switch technique that can immediately halt the operation of malicious web-based LLM agents. To achieve this, we introduce AutoGuard - the key idea is generating defensive prompts that trigger the safety mechanisms of malicious LLM agents. In particular, generated defense prompts are transparently embedded into the website's DOM so that they remain invisible to human users but can be detected by the crawling process of malicious agents, triggering its internal safety mechanisms to abort malicious actions once read. To evaluate our approach, we constructed a dedicated benchmark consisting of three representative malicious scenarios. Experimental results show that AutoGuard achieves over 80% Defense Success Rate (DSR) across diverse malicious agents, including GPT-4o, Claude-4.5-Sonnet and generalizes well to advanced models like GPT-5.1, Gemini-2.5-flash, and Gemini-3-pro. Also, our approach demonstrates robust defense performance in real-world website environments without significant performance degradation for benign agents. Through this research, we demonstrate the controllability of web-based LLM agents, thereby contributing to the broader effort of AI control and safety.\n    link: https://arxiv.org/abs/2511.13725v2\n    "}}
{"custom_id": "2512.04449v1", "method": "POST", "url": "/v1/responses", "body": {"model": "gpt-5-mini", "input": "You are a specialist research analyst in Web3, DeFi, cryptography, and distributed systems.\n\n    Your task:\n    From the paper below (Title + Summary + Link), evaluate how useful each paper is for understanding investment opportunities or technological advantages within the Web3 / crypto / DeFi ecosystem.\n    Rate each paper on a five-level scale: Highest / High / Medium / Low / Lowest.\n\n    \"Useful\" means:\n\n    - Improves understanding of new cryptographic primitives relevant to blockchain performance or security\n    - Enhances scalability: distributed systems, P2P networking, consensus mechanisms\n    - Advances in zero knowledge, MPC, PQC that could impact future L1/L2 chains\n    - DeFi modeling, AMMs, MEV, risk models, liquidity dynamics\n    - Smart contract security, attack vectors, economic incentives\n    - Token economics, mechanism design for decentralized systems\n    - Quantum threats to blockchain or cryptography\n    - Any breakthrough that meaningfully improves decentralization, scalability, privacy, or composability\n\n    Output instructions:\n\n    - Output each JSON object in JSON Lines format (one line per paper).\n\n    {\n        \"title\": title of the paper (in Japanese),\n        \"summary\": A concise summary of the paper (in Japanese),\n        \"impact_level\": \"Highest|High|Medium|Low|Lowest\",\n        \"why_matters\": An array (JSON array) containing 2\u20134 bullet points explaining why this paper matters for Web3 investment\n    }\n\n    - Do not output anything except valid JSON object in JSON Lines.\n    - \"title\", \"summary\", \"why_matters\" text in the output must be written in Japanese.\n\n    Paper:\n    title: Offloading to CXL-based Computational Memory\n    summary: CXL-based Computational Memory (CCM) enables near-memory processing within expanded remote memory, presenting opportunities to address data movement costs associated with disaggregated memory systems and to accelerate overall performance. However, existing operation offloading mechanisms are not capable of leveraging the trade-offs of different models based on different CXL protocols. This work first examines these tradeoffs and demonstrates their impact on end-to-end performance and system efficiency for workloads with diverse data and processing requirements. We propose a novel 'Asynchronous Back-Streaming' protocol by carefully layering data and control transfer operations on top of the underlying CXL protocols. We design KAI, a system that realizes the asynchronous back-streaming model that supports asynchronous data movement and lightweight pipelining in host-CCM interactions. Overall, KAI reduces end-to-end runtime by up to 50.4%, and CCM and host idle times by average 22.11x and 3.85x, respectively.\n    link: https://arxiv.org/abs/2512.04449v1\n    "}}
{"custom_id": "2512.04436v1", "method": "POST", "url": "/v1/responses", "body": {"model": "gpt-5-mini", "input": "You are a specialist research analyst in Web3, DeFi, cryptography, and distributed systems.\n\n    Your task:\n    From the paper below (Title + Summary + Link), evaluate how useful each paper is for understanding investment opportunities or technological advantages within the Web3 / crypto / DeFi ecosystem.\n    Rate each paper on a five-level scale: Highest / High / Medium / Low / Lowest.\n\n    \"Useful\" means:\n\n    - Improves understanding of new cryptographic primitives relevant to blockchain performance or security\n    - Enhances scalability: distributed systems, P2P networking, consensus mechanisms\n    - Advances in zero knowledge, MPC, PQC that could impact future L1/L2 chains\n    - DeFi modeling, AMMs, MEV, risk models, liquidity dynamics\n    - Smart contract security, attack vectors, economic incentives\n    - Token economics, mechanism design for decentralized systems\n    - Quantum threats to blockchain or cryptography\n    - Any breakthrough that meaningfully improves decentralization, scalability, privacy, or composability\n\n    Output instructions:\n\n    - Output each JSON object in JSON Lines format (one line per paper).\n\n    {\n        \"title\": title of the paper (in Japanese),\n        \"summary\": A concise summary of the paper (in Japanese),\n        \"impact_level\": \"Highest|High|Medium|Low|Lowest\",\n        \"why_matters\": An array (JSON array) containing 2\u20134 bullet points explaining why this paper matters for Web3 investment\n    }\n\n    - Do not output anything except valid JSON object in JSON Lines.\n    - \"title\", \"summary\", \"why_matters\" text in the output must be written in Japanese.\n\n    Paper:\n    title: ReFuzz: Reusing Tests for Processor Fuzzing with Contextual Bandits\n    summary: Processor designs rely on iterative modifications and reuse well-established designs. However, this reuse of prior designs also leads to similar vulnerabilities across multiple processors. As processors grow increasingly complex with iterative modifications, efficiently detecting vulnerabilities from modern processors is critical. Inspired by software fuzzing, hardware fuzzing has recently demonstrated its effectiveness in detecting processor vulnerabilities. Yet, to our best knowledge, existing processor fuzzers fuzz each design individually, lacking the capability to understand known vulnerabilities in prior processors to fine-tune fuzzing to identify similar or new variants of vulnerabilities.\n  To address this gap, we present ReFuzz, an adaptive fuzzing framework that leverages contextual bandit to reuse highly effective tests from prior processors to fuzz a processor-under-test (PUT) within a given ISA. By intelligently mutating tests that trigger vulnerabilities in prior processors, ReFuzz effectively detects similar and new variants of vulnerabilities in PUTs. ReFuzz uncovered three new security vulnerabilities and two new functional bugs. ReFuzz detected one vulnerability by reusing a test that triggers a known vulnerability in a prior processor. One functional bug exists across three processors that share design modules. The second bug has two variants. Additionally, ReFuzz reuses highly effective tests to enhance efficiency in coverage, achieving an average 511.23x coverage speedup and up to 9.33% more total coverage, compared to existing fuzzers.\n    link: https://arxiv.org/abs/2512.04436v1\n    "}}
{"custom_id": "2512.04429v1", "method": "POST", "url": "/v1/responses", "body": {"model": "gpt-5-mini", "input": "You are a specialist research analyst in Web3, DeFi, cryptography, and distributed systems.\n\n    Your task:\n    From the paper below (Title + Summary + Link), evaluate how useful each paper is for understanding investment opportunities or technological advantages within the Web3 / crypto / DeFi ecosystem.\n    Rate each paper on a five-level scale: Highest / High / Medium / Low / Lowest.\n\n    \"Useful\" means:\n\n    - Improves understanding of new cryptographic primitives relevant to blockchain performance or security\n    - Enhances scalability: distributed systems, P2P networking, consensus mechanisms\n    - Advances in zero knowledge, MPC, PQC that could impact future L1/L2 chains\n    - DeFi modeling, AMMs, MEV, risk models, liquidity dynamics\n    - Smart contract security, attack vectors, economic incentives\n    - Token economics, mechanism design for decentralized systems\n    - Quantum threats to blockchain or cryptography\n    - Any breakthrough that meaningfully improves decentralization, scalability, privacy, or composability\n\n    Output instructions:\n\n    - Output each JSON object in JSON Lines format (one line per paper).\n\n    {\n        \"title\": title of the paper (in Japanese),\n        \"summary\": A concise summary of the paper (in Japanese),\n        \"impact_level\": \"Highest|High|Medium|Low|Lowest\",\n        \"why_matters\": An array (JSON array) containing 2\u20134 bullet points explaining why this paper matters for Web3 investment\n    }\n\n    - Do not output anything except valid JSON object in JSON Lines.\n    - \"title\", \"summary\", \"why_matters\" text in the output must be written in Japanese.\n\n    Paper:\n    title: Combined Quantum and Post-Quantum Security Performance Under Finite Keys\n    summary: Recent advances in quantum-secure communication have highlighted the value of hybrid schemes that combine Quantum Key Distribution (QKD) with Post-Quantum Cryptography (PQC). Yet most existing hybrid designs omit realistic finite-key effects on QKD key rates and do not specify how to maintain security when both QKD and PQC primitives leak information through side-channels. These gaps limit the applicability of hybrid systems in practical, deployed networks. In this work, we advance a recently proposed hybrid QKD-PQC system by integrating tight finite-key security to the QKD primitive and improving the design for better scalability. This hybrid system employs an information-theoretically secure instruction sequence that determines the configurations of different primitives and thus ensures message confidentiality even when both the QKD and the PQC primitives are compromised. The novelty in our work lies in the implementation of the tightest finite-key security to date for the BBM92 protocol and the design improvements in the primitives of the hybrid system that ensure the processing time scales linearly with the size of secret instructions.\n    link: https://arxiv.org/abs/2512.04429v1\n    "}}
{"custom_id": "2512.04389v1", "method": "POST", "url": "/v1/responses", "body": {"model": "gpt-5-mini", "input": "You are a specialist research analyst in Web3, DeFi, cryptography, and distributed systems.\n\n    Your task:\n    From the paper below (Title + Summary + Link), evaluate how useful each paper is for understanding investment opportunities or technological advantages within the Web3 / crypto / DeFi ecosystem.\n    Rate each paper on a five-level scale: Highest / High / Medium / Low / Lowest.\n\n    \"Useful\" means:\n\n    - Improves understanding of new cryptographic primitives relevant to blockchain performance or security\n    - Enhances scalability: distributed systems, P2P networking, consensus mechanisms\n    - Advances in zero knowledge, MPC, PQC that could impact future L1/L2 chains\n    - DeFi modeling, AMMs, MEV, risk models, liquidity dynamics\n    - Smart contract security, attack vectors, economic incentives\n    - Token economics, mechanism design for decentralized systems\n    - Quantum threats to blockchain or cryptography\n    - Any breakthrough that meaningfully improves decentralization, scalability, privacy, or composability\n\n    Output instructions:\n\n    - Output each JSON object in JSON Lines format (one line per paper).\n\n    {\n        \"title\": title of the paper (in Japanese),\n        \"summary\": A concise summary of the paper (in Japanese),\n        \"impact_level\": \"Highest|High|Medium|Low|Lowest\",\n        \"why_matters\": An array (JSON array) containing 2\u20134 bullet points explaining why this paper matters for Web3 investment\n    }\n\n    - Do not output anything except valid JSON object in JSON Lines.\n    - \"title\", \"summary\", \"why_matters\" text in the output must be written in Japanese.\n\n    Paper:\n    title: A Structure-Aware Irregular Blocking Method for Sparse LU Factorization\n    summary: In sparse LU factorization, nonzero elements after symbolic factorization tend to distribute in diagonal and right-bottom region of sparse matrices. However, regular 2D blocking on this non-uniform distribution structure may lead to workload imbalance across blocks. Besides, existing matrix features fail to guide us effectively in blocking. In this paper, we propose a structure-aware irregular blocking method for numerical factorization. A novel diagonal block-based feature is introduced to effectively characterize the local nonzero distribution of sparse matrices. Based on this, we further propose an irregular blocking method that adjusts block sizes according to the local distribution of nonzeros. The strategy utilizes fine-grained blocks in dense regions and coarse-grained blocks in sparse regions, adequately balancing the nonzeros of blocks both within the same level and across levels in the dependency tree. Experiments demonstrate that, on a single NVIDIA A100 GPU, our proposed irregular blocking method achieves average speedups of 1.50x and 3.32x over PanguLU and the latest SuperLU_DIST, respectively. In addition, it achieves speedups of 1.40x and 3.84x over PanguLU and SuperLU_DIST on 4 NVIDIA A100 GPUs.\n    link: https://arxiv.org/abs/2512.04389v1\n    "}}
{"custom_id": "2512.04380v1", "method": "POST", "url": "/v1/responses", "body": {"model": "gpt-5-mini", "input": "You are a specialist research analyst in Web3, DeFi, cryptography, and distributed systems.\n\n    Your task:\n    From the paper below (Title + Summary + Link), evaluate how useful each paper is for understanding investment opportunities or technological advantages within the Web3 / crypto / DeFi ecosystem.\n    Rate each paper on a five-level scale: Highest / High / Medium / Low / Lowest.\n\n    \"Useful\" means:\n\n    - Improves understanding of new cryptographic primitives relevant to blockchain performance or security\n    - Enhances scalability: distributed systems, P2P networking, consensus mechanisms\n    - Advances in zero knowledge, MPC, PQC that could impact future L1/L2 chains\n    - DeFi modeling, AMMs, MEV, risk models, liquidity dynamics\n    - Smart contract security, attack vectors, economic incentives\n    - Token economics, mechanism design for decentralized systems\n    - Quantum threats to blockchain or cryptography\n    - Any breakthrough that meaningfully improves decentralization, scalability, privacy, or composability\n\n    Output instructions:\n\n    - Output each JSON object in JSON Lines format (one line per paper).\n\n    {\n        \"title\": title of the paper (in Japanese),\n        \"summary\": A concise summary of the paper (in Japanese),\n        \"impact_level\": \"Highest|High|Medium|Low|Lowest\",\n        \"why_matters\": An array (JSON array) containing 2\u20134 bullet points explaining why this paper matters for Web3 investment\n    }\n\n    - Do not output anything except valid JSON object in JSON Lines.\n    - \"title\", \"summary\", \"why_matters\" text in the output must be written in Japanese.\n\n    Paper:\n    title: Vision and Causal Learning Based Channel Estimation for THz Communications\n    summary: The use of terahertz (THz) communications with massive multiple input multiple output (MIMO) systems in 6G can potentially provide high data rates and low latency communications. However, accurate channel estimation in THz frequencies presents significant challenges due to factors such as high propagation losses, sensitivity to environmental obstructions, and strong atmospheric absorption. These challenges are par- ticularly pronounced in urban environments, where traditional channel estimation methods often fail to deliver reliable results, particularly in complex non-line-of-sight (NLoS) scenarios. This paper introduces a novel vision-based channel estimation tech- nique that integrates causal reasoning into urban THz communi- cation systems. The proposed method combines computer vision algorithms with variational causal dynamics (VCD) to analyze real-time images of the urban environment, allowing for a deeper understanding of the physical factors that influence THz signal propagation. By capturing the complex, dynamic interactions between physical objects (such as buildings, trees, and vehicles) and the transmitted signals, the model can predict the channel with up to twice the accuracy of conventional methods. This model improves estimation accuracy and demonstrates supe- rior generalization performance. Hence, it can provide reliable predictions even in previously unseen urban environments. The effectiveness of the proposed method is particularly evident in NLoS conditions, where it significantly outperforms traditional methods such as by accounting for indirect signal paths, such as reflections and diffractions. Simulation results confirm that the proposed vision-based approach surpasses conventional artificial intelligence (AI)-based estimation techniques in accuracy and robustness, showing a substantial improvement across various dynamic urban scenarios.\n    link: https://arxiv.org/abs/2512.04380v1\n    "}}
{"custom_id": "2512.04368v1", "method": "POST", "url": "/v1/responses", "body": {"model": "gpt-5-mini", "input": "You are a specialist research analyst in Web3, DeFi, cryptography, and distributed systems.\n\n    Your task:\n    From the paper below (Title + Summary + Link), evaluate how useful each paper is for understanding investment opportunities or technological advantages within the Web3 / crypto / DeFi ecosystem.\n    Rate each paper on a five-level scale: Highest / High / Medium / Low / Lowest.\n\n    \"Useful\" means:\n\n    - Improves understanding of new cryptographic primitives relevant to blockchain performance or security\n    - Enhances scalability: distributed systems, P2P networking, consensus mechanisms\n    - Advances in zero knowledge, MPC, PQC that could impact future L1/L2 chains\n    - DeFi modeling, AMMs, MEV, risk models, liquidity dynamics\n    - Smart contract security, attack vectors, economic incentives\n    - Token economics, mechanism design for decentralized systems\n    - Quantum threats to blockchain or cryptography\n    - Any breakthrough that meaningfully improves decentralization, scalability, privacy, or composability\n\n    Output instructions:\n\n    - Output each JSON object in JSON Lines format (one line per paper).\n\n    {\n        \"title\": title of the paper (in Japanese),\n        \"summary\": A concise summary of the paper (in Japanese),\n        \"impact_level\": \"Highest|High|Medium|Low|Lowest\",\n        \"why_matters\": An array (JSON array) containing 2\u20134 bullet points explaining why this paper matters for Web3 investment\n    }\n\n    - Do not output anything except valid JSON object in JSON Lines.\n    - \"title\", \"summary\", \"why_matters\" text in the output must be written in Japanese.\n\n    Paper:\n    title: AutoGuard: A Self-Healing Proactive Security Layer for DevSecOps Pipelines Using Reinforcement Learning\n    summary: Contemporary DevSecOps pipelines have to deal with the evolution of security in an ever-continuously integrated and deployed environment. Existing methods,such as rule-based intrusion detection and static vulnerability scanning, are inadequate and unreceptive to changes in the system, causing longer response times and organization needs exposure to emerging attack vectors. In light of the previous constraints, we introduce AutoGuard to the DevSecOps ecosystem, a reinforcement learning (RL)-powered self-healing security framework built to pre-emptively protect DevSecOps environments. AutoGuard is a self-securing security environment that continuously observes pipeline activities for potential anomalies while preemptively remediating the environment. The model observes and reacts based on a policy that is continually learned dynamically over time. The RL agent improves each action over time through reward-based learning aimed at improving the agent's ability to prevent, detect and respond to a security incident in real-time. Testing using simulated ContinuousIntegration / Continuous Deployment (CI/CD) environments showed AutoGuard to successfully improve threat detection accuracy by 22%, reduce mean time torecovery (MTTR) for incidents by 38% and increase overall resilience to incidents as compared to traditional methods.\n  Keywords- DevSecOps, Reinforcement Learning, Self- Healing Security, Continuous Integration, Automated Threat Mitigation\n    link: https://arxiv.org/abs/2512.04368v1\n    "}}
{"custom_id": "2509.04084v2", "method": "POST", "url": "/v1/responses", "body": {"model": "gpt-5-mini", "input": "You are a specialist research analyst in Web3, DeFi, cryptography, and distributed systems.\n\n    Your task:\n    From the paper below (Title + Summary + Link), evaluate how useful each paper is for understanding investment opportunities or technological advantages within the Web3 / crypto / DeFi ecosystem.\n    Rate each paper on a five-level scale: Highest / High / Medium / Low / Lowest.\n\n    \"Useful\" means:\n\n    - Improves understanding of new cryptographic primitives relevant to blockchain performance or security\n    - Enhances scalability: distributed systems, P2P networking, consensus mechanisms\n    - Advances in zero knowledge, MPC, PQC that could impact future L1/L2 chains\n    - DeFi modeling, AMMs, MEV, risk models, liquidity dynamics\n    - Smart contract security, attack vectors, economic incentives\n    - Token economics, mechanism design for decentralized systems\n    - Quantum threats to blockchain or cryptography\n    - Any breakthrough that meaningfully improves decentralization, scalability, privacy, or composability\n\n    Output instructions:\n\n    - Output each JSON object in JSON Lines format (one line per paper).\n\n    {\n        \"title\": title of the paper (in Japanese),\n        \"summary\": A concise summary of the paper (in Japanese),\n        \"impact_level\": \"Highest|High|Medium|Low|Lowest\",\n        \"why_matters\": An array (JSON array) containing 2\u20134 bullet points explaining why this paper matters for Web3 investment\n    }\n\n    - Do not output anything except valid JSON object in JSON Lines.\n    - \"title\", \"summary\", \"why_matters\" text in the output must be written in Japanese.\n\n    Paper:\n    title: Optimizing Frequent Checkpointing via Low-Cost Differential for Distributed Training Systems\n    summary: Distributed training of large deep-learning models often leads to failures, so checkpointing is commonly employed for recovery. State-of-the-art studies focus on frequent checkpointing for fast recovery from failures. However, it generates numerous checkpoints, incurring substantial costs and thus degrading training performance. Recently, differential checkpointing has been proposed to reduce costs, but it is limited to recommendation systems, so its application to general distributed training systems remains unexplored.\n  We proposes \\sysname, an efficient frequent checkpointing framework that \\textit{reuses} compressed gradients, serving as differential checkpoints to reduce cost. Furthermore, \\sysname incorporates a batched gradient write optimization to persist these differentials to storage efficiently. It also dynamically tunes both the checkpoint frequency and the batching size to maximize performance. In non-compression scenario, We further proposes \\sysnameplus with a layer-wise gradient reusing and snapshotting approach and a CPU-based asynchronous persistence strategy, enabling frequent checkpointing without gradient compression. Experiments on various workloads show that \\sysname can achieve checkpointing frequency up to per iteration with less than 3.1\\% runtime overhead.\n    link: https://arxiv.org/abs/2509.04084v2\n    "}}
{"custom_id": "2512.04355v1", "method": "POST", "url": "/v1/responses", "body": {"model": "gpt-5-mini", "input": "You are a specialist research analyst in Web3, DeFi, cryptography, and distributed systems.\n\n    Your task:\n    From the paper below (Title + Summary + Link), evaluate how useful each paper is for understanding investment opportunities or technological advantages within the Web3 / crypto / DeFi ecosystem.\n    Rate each paper on a five-level scale: Highest / High / Medium / Low / Lowest.\n\n    \"Useful\" means:\n\n    - Improves understanding of new cryptographic primitives relevant to blockchain performance or security\n    - Enhances scalability: distributed systems, P2P networking, consensus mechanisms\n    - Advances in zero knowledge, MPC, PQC that could impact future L1/L2 chains\n    - DeFi modeling, AMMs, MEV, risk models, liquidity dynamics\n    - Smart contract security, attack vectors, economic incentives\n    - Token economics, mechanism design for decentralized systems\n    - Quantum threats to blockchain or cryptography\n    - Any breakthrough that meaningfully improves decentralization, scalability, privacy, or composability\n\n    Output instructions:\n\n    - Output each JSON object in JSON Lines format (one line per paper).\n\n    {\n        \"title\": title of the paper (in Japanese),\n        \"summary\": A concise summary of the paper (in Japanese),\n        \"impact_level\": \"Highest|High|Medium|Low|Lowest\",\n        \"why_matters\": An array (JSON array) containing 2\u20134 bullet points explaining why this paper matters for Web3 investment\n    }\n\n    - Do not output anything except valid JSON object in JSON Lines.\n    - \"title\", \"summary\", \"why_matters\" text in the output must be written in Japanese.\n\n    Paper:\n    title: Counting Without Running: Evaluating LLMs' Reasoning About Code Complexity\n    summary: Modern GPU software stacks demand developers who can anticipate performance bottlenecks before ever launching a kernel; misjudging floating-point workloads upstream can derail tuning, scheduling, and even hardware procurement. Yet despite rapid progress in code generation, today's Large Language Models (LLMs) are rarely tested on this kind of forward-looking reasoning. We close that gap with gpuFLOPBench, a benchmark that asks models to \"count without running\" by predicting single and double-precision FLOP counts for 577 CUDA kernels drawn from HeCBench, annotated with ground-truth profiles and eight execution attributes that distinguish trivially analyzable code from kernels whose FLOPs depend on hidden compiler or runtime behavior. Evaluating current closed-source reasoning models shows clear but uneven progress: the newest LLMs achieve perfect classification on straightforward kernels but still incur multiple order-of-magnitude errors whenever implicit FLOPs arise from division, intrinsic math functions, or common subexpressions. These results surface a core limitation of existing code assistants -- the inability to internalize hardware-specific microcode effects -- and position gpuFLOPBench as a focused testbed for developing LLM tooling that can reason about performance with the same rigor as experienced GPU developers. Sources are available at our repository: https://github.com/Scientific-Computing-Lab/gpuFLOPBench\n    link: https://arxiv.org/abs/2512.04355v1\n    "}}
{"custom_id": "2512.04346v1", "method": "POST", "url": "/v1/responses", "body": {"model": "gpt-5-mini", "input": "You are a specialist research analyst in Web3, DeFi, cryptography, and distributed systems.\n\n    Your task:\n    From the paper below (Title + Summary + Link), evaluate how useful each paper is for understanding investment opportunities or technological advantages within the Web3 / crypto / DeFi ecosystem.\n    Rate each paper on a five-level scale: Highest / High / Medium / Low / Lowest.\n\n    \"Useful\" means:\n\n    - Improves understanding of new cryptographic primitives relevant to blockchain performance or security\n    - Enhances scalability: distributed systems, P2P networking, consensus mechanisms\n    - Advances in zero knowledge, MPC, PQC that could impact future L1/L2 chains\n    - DeFi modeling, AMMs, MEV, risk models, liquidity dynamics\n    - Smart contract security, attack vectors, economic incentives\n    - Token economics, mechanism design for decentralized systems\n    - Quantum threats to blockchain or cryptography\n    - Any breakthrough that meaningfully improves decentralization, scalability, privacy, or composability\n\n    Output instructions:\n\n    - Output each JSON object in JSON Lines format (one line per paper).\n\n    {\n        \"title\": title of the paper (in Japanese),\n        \"summary\": A concise summary of the paper (in Japanese),\n        \"impact_level\": \"Highest|High|Medium|Low|Lowest\",\n        \"why_matters\": An array (JSON array) containing 2\u20134 bullet points explaining why this paper matters for Web3 investment\n    }\n\n    - Do not output anything except valid JSON object in JSON Lines.\n    - \"title\", \"summary\", \"why_matters\" text in the output must be written in Japanese.\n\n    Paper:\n    title: Making Cellular Networks Crisis-Proof: Towards Island-Ready, Resilient-By-Design 6G Communication Network\n    summary: 5G and 5G-Advanced cellular networks are vulnerable to regional outages resulting from disasters or targeted attacks. This fragility stems from the reliance on the central core network involved for most 5G connectivity use cases. Crisis-struck regions isolated from the cellular core network form islands, where crisis response is hindered by the unavailability of recovery-relevant services, such as emergency calls, cell broadcasts, messengers, and news apps. Our concept of island-ready, resilient-by-design 6G communication networks envisions local cellular connectivity allowing users to connect to regional application servers, which is currently impossible. In our conceptualization, we follow an all-society approach, as realizing island connectivity requires the cooperation of multiple actors, including users, operators, developers, providers, and authorities. We evaluate how island-ready 5G and 5G-Advanced systems are and outline the open challenges stakeholders must address for full island readiness, such as decentralizing the 6G core network and designing local-first application architectures.\n    link: https://arxiv.org/abs/2512.04346v1\n    "}}
{"custom_id": "2512.04338v1", "method": "POST", "url": "/v1/responses", "body": {"model": "gpt-5-mini", "input": "You are a specialist research analyst in Web3, DeFi, cryptography, and distributed systems.\n\n    Your task:\n    From the paper below (Title + Summary + Link), evaluate how useful each paper is for understanding investment opportunities or technological advantages within the Web3 / crypto / DeFi ecosystem.\n    Rate each paper on a five-level scale: Highest / High / Medium / Low / Lowest.\n\n    \"Useful\" means:\n\n    - Improves understanding of new cryptographic primitives relevant to blockchain performance or security\n    - Enhances scalability: distributed systems, P2P networking, consensus mechanisms\n    - Advances in zero knowledge, MPC, PQC that could impact future L1/L2 chains\n    - DeFi modeling, AMMs, MEV, risk models, liquidity dynamics\n    - Smart contract security, attack vectors, economic incentives\n    - Token economics, mechanism design for decentralized systems\n    - Quantum threats to blockchain or cryptography\n    - Any breakthrough that meaningfully improves decentralization, scalability, privacy, or composability\n\n    Output instructions:\n\n    - Output each JSON object in JSON Lines format (one line per paper).\n\n    {\n        \"title\": title of the paper (in Japanese),\n        \"summary\": A concise summary of the paper (in Japanese),\n        \"impact_level\": \"Highest|High|Medium|Low|Lowest\",\n        \"why_matters\": An array (JSON array) containing 2\u20134 bullet points explaining why this paper matters for Web3 investment\n    }\n\n    - Do not output anything except valid JSON object in JSON Lines.\n    - \"title\", \"summary\", \"why_matters\" text in the output must be written in Japanese.\n\n    Paper:\n    title: One Detector Fits All: Robust and Adaptive Detection of Malicious Packages from PyPI to Enterprises\n    summary: The rise of supply chain attacks via malicious Python packages demands robust detection solutions. Current approaches, however, overlook two critical challenges: robustness against adversarial source code transformations and adaptability to the varying false positive rate (FPR) requirements of different actors, from repository maintainers (requiring low FPR) to enterprise security teams (higher FPR tolerance).\n  We introduce a robust detector capable of seamless integration into both public repositories like PyPI and enterprise ecosystems. To ensure robustness, we propose a novel methodology for generating adversarial packages using fine-grained code obfuscation. Combining these with adversarial training (AT) enhances detector robustness by 2.5x. We comprehensively evaluate AT effectiveness by testing our detector against 122,398 packages collected daily from PyPI over 80 days, showing that AT needs careful application: it makes the detector more robust to obfuscations and allows finding 10% more obfuscated packages, but slightly decreases performance on non-obfuscated packages.\n  We demonstrate production adaptability of our detector via two case studies: (i) one for PyPI maintainers (tuned at 0.1% FPR) and (ii) one for enterprise teams (tuned at 10% FPR). In the former, we analyze 91,949 packages collected from PyPI over 37 days, achieving a daily detection rate of 2.48 malicious packages with only 2.18 false positives. In the latter, we analyze 1,596 packages adopted by a multinational software company, obtaining only 1.24 false positives daily. These results show that our detector can be seamlessly integrated into both public repositories like PyPI and enterprise ecosystems, ensuring a very low time budget of a few minutes to review the false positives.\n  Overall, we uncovered 346 malicious packages, now reported to the community.\n    link: https://arxiv.org/abs/2512.04338v1\n    "}}
{"custom_id": "2512.04320v1", "method": "POST", "url": "/v1/responses", "body": {"model": "gpt-5-mini", "input": "You are a specialist research analyst in Web3, DeFi, cryptography, and distributed systems.\n\n    Your task:\n    From the paper below (Title + Summary + Link), evaluate how useful each paper is for understanding investment opportunities or technological advantages within the Web3 / crypto / DeFi ecosystem.\n    Rate each paper on a five-level scale: Highest / High / Medium / Low / Lowest.\n\n    \"Useful\" means:\n\n    - Improves understanding of new cryptographic primitives relevant to blockchain performance or security\n    - Enhances scalability: distributed systems, P2P networking, consensus mechanisms\n    - Advances in zero knowledge, MPC, PQC that could impact future L1/L2 chains\n    - DeFi modeling, AMMs, MEV, risk models, liquidity dynamics\n    - Smart contract security, attack vectors, economic incentives\n    - Token economics, mechanism design for decentralized systems\n    - Quantum threats to blockchain or cryptography\n    - Any breakthrough that meaningfully improves decentralization, scalability, privacy, or composability\n\n    Output instructions:\n\n    - Output each JSON object in JSON Lines format (one line per paper).\n\n    {\n        \"title\": title of the paper (in Japanese),\n        \"summary\": A concise summary of the paper (in Japanese),\n        \"impact_level\": \"Highest|High|Medium|Low|Lowest\",\n        \"why_matters\": An array (JSON array) containing 2\u20134 bullet points explaining why this paper matters for Web3 investment\n    }\n\n    - Do not output anything except valid JSON object in JSON Lines.\n    - \"title\", \"summary\", \"why_matters\" text in the output must be written in Japanese.\n\n    Paper:\n    title: VLCs: Managing Parallelism with Virtualized Libraries\n    summary: As the complexity and scale of modern parallel machines continue to grow, programmers increasingly rely on composition of software libraries to encapsulate and exploit parallelism. However, many libraries are not designed with composition in mind and assume they have exclusive access to all resources. Using such libraries concurrently can result in contention and degraded performance. Prior solutions involve modifying the libraries or the OS, which is often infeasible.\n  We propose Virtual Library Contexts (VLCs), which are process subunits that encapsulate sets of libraries and associated resource allocations. VLCs control the resource utilization of these libraries without modifying library code. This enables the user to partition resources between libraries to prevent contention, or load multiple copies of the same library to allow parallel execution of otherwise thread-unsafe code within the same process.\n  In this paper, we describe and evaluate C++ and Python prototypes of VLCs. Experiments show VLCs enable a speedup up to 2.85x on benchmarks including applications using OpenMP, OpenBLAS, and LibTorch.\n    link: https://arxiv.org/abs/2512.04320v1\n    "}}
{"custom_id": "2512.04291v1", "method": "POST", "url": "/v1/responses", "body": {"model": "gpt-5-mini", "input": "You are a specialist research analyst in Web3, DeFi, cryptography, and distributed systems.\n\n    Your task:\n    From the paper below (Title + Summary + Link), evaluate how useful each paper is for understanding investment opportunities or technological advantages within the Web3 / crypto / DeFi ecosystem.\n    Rate each paper on a five-level scale: Highest / High / Medium / Low / Lowest.\n\n    \"Useful\" means:\n\n    - Improves understanding of new cryptographic primitives relevant to blockchain performance or security\n    - Enhances scalability: distributed systems, P2P networking, consensus mechanisms\n    - Advances in zero knowledge, MPC, PQC that could impact future L1/L2 chains\n    - DeFi modeling, AMMs, MEV, risk models, liquidity dynamics\n    - Smart contract security, attack vectors, economic incentives\n    - Token economics, mechanism design for decentralized systems\n    - Quantum threats to blockchain or cryptography\n    - Any breakthrough that meaningfully improves decentralization, scalability, privacy, or composability\n\n    Output instructions:\n\n    - Output each JSON object in JSON Lines format (one line per paper).\n\n    {\n        \"title\": title of the paper (in Japanese),\n        \"summary\": A concise summary of the paper (in Japanese),\n        \"impact_level\": \"Highest|High|Medium|Low|Lowest\",\n        \"why_matters\": An array (JSON array) containing 2\u20134 bullet points explaining why this paper matters for Web3 investment\n    }\n\n    - Do not output anything except valid JSON object in JSON Lines.\n    - \"title\", \"summary\", \"why_matters\" text in the output must be written in Japanese.\n\n    Paper:\n    title: Scaling MPI Applications on Aurora\n    summary: The Aurora supercomputer, which was deployed at Argonne National Laboratory in 2024, is currently one of three Exascale machines in the world on the Top500 list. The Aurora system is composed of over ten thousand nodes each of which contains six Intel Data Center Max Series GPUs, Intel's first data center-focused discrete GPU, and two Intel Xeon Max Series CPUs, Intel's first Xeon processor to contain HBM memory. To achieve Exascale performance the system utilizes the HPE Slingshot high-performance fabric interconnect to connect the nodes. Aurora is currently the largest deployment of the Slingshot fabric to date with nearly 85,000 Cassini NICs and 5,600 Rosetta switches connected in a dragonfly topology. The combination of the Intel powered nodes and the Slingshot network enabled Aurora to become the second fastest system on the Top500 list in June of 2024 and the fastest system on the HPL MxP benchmark. The system is one of the most powerful systems in the world dedicated to AI and HPC simulations for open science. This paper presents details of the Aurora system design with a particular focus on the network fabric and the approach taken to validating it. The performance of the systems is demonstrated through the presentation of the results of MPI benchmarks as well as performance benchmarks including HPL, HPL-MxP, Graph500, and HPCG run on a large fraction of the system. Additionally results are presented for a diverse set of applications including HACC, AMR-Wind, LAMMPS, and FMM demonstrating that Aurora provides the throughput, latency, and bandwidth across system needed to allow applications to perform and scale to large node counts and providing new levels of capability and enabling breakthrough science.\n    link: https://arxiv.org/abs/2512.04291v1\n    "}}
{"custom_id": "2512.04260v1", "method": "POST", "url": "/v1/responses", "body": {"model": "gpt-5-mini", "input": "You are a specialist research analyst in Web3, DeFi, cryptography, and distributed systems.\n\n    Your task:\n    From the paper below (Title + Summary + Link), evaluate how useful each paper is for understanding investment opportunities or technological advantages within the Web3 / crypto / DeFi ecosystem.\n    Rate each paper on a five-level scale: Highest / High / Medium / Low / Lowest.\n\n    \"Useful\" means:\n\n    - Improves understanding of new cryptographic primitives relevant to blockchain performance or security\n    - Enhances scalability: distributed systems, P2P networking, consensus mechanisms\n    - Advances in zero knowledge, MPC, PQC that could impact future L1/L2 chains\n    - DeFi modeling, AMMs, MEV, risk models, liquidity dynamics\n    - Smart contract security, attack vectors, economic incentives\n    - Token economics, mechanism design for decentralized systems\n    - Quantum threats to blockchain or cryptography\n    - Any breakthrough that meaningfully improves decentralization, scalability, privacy, or composability\n\n    Output instructions:\n\n    - Output each JSON object in JSON Lines format (one line per paper).\n\n    {\n        \"title\": title of the paper (in Japanese),\n        \"summary\": A concise summary of the paper (in Japanese),\n        \"impact_level\": \"Highest|High|Medium|Low|Lowest\",\n        \"why_matters\": An array (JSON array) containing 2\u20134 bullet points explaining why this paper matters for Web3 investment\n    }\n\n    - Do not output anything except valid JSON object in JSON Lines.\n    - \"title\", \"summary\", \"why_matters\" text in the output must be written in Japanese.\n\n    Paper:\n    title: Breaking Isolation: A New Perspective on Hypervisor Exploitation via Cross-Domain Attacks\n    summary: Hypervisors are under threat by critical memory safety vulnerabilities, with pointer corruption being one of the most prevalent and severe forms. Existing exploitation frameworks depend on identifying highly-constrained structures in the host machine and accurately determining their runtime addresses, which is ineffective in hypervisor environments where such structures are rare and further obfuscated by Address Space Layout Randomization (ASLR). We instead observe that modern virtualization environments exhibit weak memory isolation -- guest memory is fully attacker-controlled yet accessible from the host, providing a reliable primitive for exploitation. Based on this observation, we present the first systematic characterization and taxonomy of Cross-Domain Attacks (CDA), a class of exploitation techniques that enable capability escalation through guest memory reuse. To automate this process, we develop a system that identifies cross-domain gadgets, matches them with corrupted pointers, synthesizes triggering inputs, and assembles complete exploit chains. Our evaluation on 15 real-world vulnerabilities across QEMU and VirtualBox shows that CDA is widely applicable and effective.\n    link: https://arxiv.org/abs/2512.04260v1\n    "}}
{"custom_id": "2512.04259v1", "method": "POST", "url": "/v1/responses", "body": {"model": "gpt-5-mini", "input": "You are a specialist research analyst in Web3, DeFi, cryptography, and distributed systems.\n\n    Your task:\n    From the paper below (Title + Summary + Link), evaluate how useful each paper is for understanding investment opportunities or technological advantages within the Web3 / crypto / DeFi ecosystem.\n    Rate each paper on a five-level scale: Highest / High / Medium / Low / Lowest.\n\n    \"Useful\" means:\n\n    - Improves understanding of new cryptographic primitives relevant to blockchain performance or security\n    - Enhances scalability: distributed systems, P2P networking, consensus mechanisms\n    - Advances in zero knowledge, MPC, PQC that could impact future L1/L2 chains\n    - DeFi modeling, AMMs, MEV, risk models, liquidity dynamics\n    - Smart contract security, attack vectors, economic incentives\n    - Token economics, mechanism design for decentralized systems\n    - Quantum threats to blockchain or cryptography\n    - Any breakthrough that meaningfully improves decentralization, scalability, privacy, or composability\n\n    Output instructions:\n\n    - Output each JSON object in JSON Lines format (one line per paper).\n\n    {\n        \"title\": title of the paper (in Japanese),\n        \"summary\": A concise summary of the paper (in Japanese),\n        \"impact_level\": \"Highest|High|Medium|Low|Lowest\",\n        \"why_matters\": An array (JSON array) containing 2\u20134 bullet points explaining why this paper matters for Web3 investment\n    }\n\n    - Do not output anything except valid JSON object in JSON Lines.\n    - \"title\", \"summary\", \"why_matters\" text in the output must be written in Japanese.\n\n    Paper:\n    title: WildCode: An Empirical Analysis of Code Generated by ChatGPT\n    summary: LLM models are increasingly used to generate code, but the quality and security of this code are often uncertain. Several recent studies have raised alarm bells, indicating that such AI-generated code may be particularly vulnerable to cyberattacks. However, most of these studies rely on code that is generated specifically for the study, which raises questions about the realism of such experiments. In this study, we perform a large-scale empirical analysis of real-life code generated by ChatGPT. We evaluate code generated by ChatGPT both with respect to correctness and security and delve into the intentions of users who request code from the model. Our research confirms previous studies that used synthetic queries and yielded evidence that LLM-generated code is often inadequate with respect to security. We also find that users exhibit little curiosity about the security features of the code they ask LLMs to generate, as evidenced by their lack of queries on this topic.\n    link: https://arxiv.org/abs/2512.04259v1\n    "}}
{"custom_id": "2512.04254v1", "method": "POST", "url": "/v1/responses", "body": {"model": "gpt-5-mini", "input": "You are a specialist research analyst in Web3, DeFi, cryptography, and distributed systems.\n\n    Your task:\n    From the paper below (Title + Summary + Link), evaluate how useful each paper is for understanding investment opportunities or technological advantages within the Web3 / crypto / DeFi ecosystem.\n    Rate each paper on a five-level scale: Highest / High / Medium / Low / Lowest.\n\n    \"Useful\" means:\n\n    - Improves understanding of new cryptographic primitives relevant to blockchain performance or security\n    - Enhances scalability: distributed systems, P2P networking, consensus mechanisms\n    - Advances in zero knowledge, MPC, PQC that could impact future L1/L2 chains\n    - DeFi modeling, AMMs, MEV, risk models, liquidity dynamics\n    - Smart contract security, attack vectors, economic incentives\n    - Token economics, mechanism design for decentralized systems\n    - Quantum threats to blockchain or cryptography\n    - Any breakthrough that meaningfully improves decentralization, scalability, privacy, or composability\n\n    Output instructions:\n\n    - Output each JSON object in JSON Lines format (one line per paper).\n\n    {\n        \"title\": title of the paper (in Japanese),\n        \"summary\": A concise summary of the paper (in Japanese),\n        \"impact_level\": \"Highest|High|Medium|Low|Lowest\",\n        \"why_matters\": An array (JSON array) containing 2\u20134 bullet points explaining why this paper matters for Web3 investment\n    }\n\n    - Do not output anything except valid JSON object in JSON Lines.\n    - \"title\", \"summary\", \"why_matters\" text in the output must be written in Japanese.\n\n    Paper:\n    title: Hey GPT-OSS, Looks Like You Got It - Now Walk Me Through It! An Assessment of the Reasoning Language Models Chain of Thought Mechanism for Digital Forensics\n    summary: The use of large language models in digital forensics has been widely explored. Beyond identifying potential applications, research has also focused on optimizing model performance for forensic tasks through fine-tuning. However, limited result explainability reduces their operational and legal usability. Recently, a new class of reasoning language models has emerged, designed to handle logic-based tasks through an `internal reasoning' mechanism. Yet, users typically see only the final answer, not the underlying reasoning. One of these reasoning models is gpt-oss, which can be deployed locally, providing full access to its underlying reasoning process. This article presents the first investigation into the potential of reasoning language models for digital forensics. Four test use cases are examined to assess the usability of the reasoning component in supporting result explainability. The evaluation combines a new quantitative metric with qualitative analysis. Findings show that the reasoning component aids in explaining and validating language model outputs in digital forensics at medium reasoning levels, but this support is often limited, and higher reasoning levels do not enhance response quality.\n    link: https://arxiv.org/abs/2512.04254v1\n    "}}
{"custom_id": "2512.04237v1", "method": "POST", "url": "/v1/responses", "body": {"model": "gpt-5-mini", "input": "You are a specialist research analyst in Web3, DeFi, cryptography, and distributed systems.\n\n    Your task:\n    From the paper below (Title + Summary + Link), evaluate how useful each paper is for understanding investment opportunities or technological advantages within the Web3 / crypto / DeFi ecosystem.\n    Rate each paper on a five-level scale: Highest / High / Medium / Low / Lowest.\n\n    \"Useful\" means:\n\n    - Improves understanding of new cryptographic primitives relevant to blockchain performance or security\n    - Enhances scalability: distributed systems, P2P networking, consensus mechanisms\n    - Advances in zero knowledge, MPC, PQC that could impact future L1/L2 chains\n    - DeFi modeling, AMMs, MEV, risk models, liquidity dynamics\n    - Smart contract security, attack vectors, economic incentives\n    - Token economics, mechanism design for decentralized systems\n    - Quantum threats to blockchain or cryptography\n    - Any breakthrough that meaningfully improves decentralization, scalability, privacy, or composability\n\n    Output instructions:\n\n    - Output each JSON object in JSON Lines format (one line per paper).\n\n    {\n        \"title\": title of the paper (in Japanese),\n        \"summary\": A concise summary of the paper (in Japanese),\n        \"impact_level\": \"Highest|High|Medium|Low|Lowest\",\n        \"why_matters\": An array (JSON array) containing 2\u20134 bullet points explaining why this paper matters for Web3 investment\n    }\n\n    - Do not output anything except valid JSON object in JSON Lines.\n    - \"title\", \"summary\", \"why_matters\" text in the output must be written in Japanese.\n\n    Paper:\n    title: Primitive Vector Cipher(PVC): A Hybrid Encryption Scheme based on the Vector Computational Diffie-Hellman (V-CDH) Problem\n    summary: This work introduces the Primitive Vector Cipher (PVC), a novel hybrid encryption scheme integrating matrix-based cryptography with advanced Diffie-Hellman key exchange. PVC's security is grounded on the established hardness of the Vector Computational Diffie- Hellman (V-CDH) problem. The two-layered design uses HKDF to mask plaintext via a DH-authenticated shared primitive vector and randomize cipher blocks with a per-block offset. This approach eliminates deterministic repetitions and provides strong resistance against linear and known-plaintext attacks. PVC's block-wise structure allows for massive parallelism and excellent linear scaling. Security is formally analyzed, demonstrating INDCPA security under V-CDH. STS protocol integration elevates security toward IND-CCA guarantees.\n    link: https://arxiv.org/abs/2512.04237v1\n    "}}
{"custom_id": "2512.04226v1", "method": "POST", "url": "/v1/responses", "body": {"model": "gpt-5-mini", "input": "You are a specialist research analyst in Web3, DeFi, cryptography, and distributed systems.\n\n    Your task:\n    From the paper below (Title + Summary + Link), evaluate how useful each paper is for understanding investment opportunities or technological advantages within the Web3 / crypto / DeFi ecosystem.\n    Rate each paper on a five-level scale: Highest / High / Medium / Low / Lowest.\n\n    \"Useful\" means:\n\n    - Improves understanding of new cryptographic primitives relevant to blockchain performance or security\n    - Enhances scalability: distributed systems, P2P networking, consensus mechanisms\n    - Advances in zero knowledge, MPC, PQC that could impact future L1/L2 chains\n    - DeFi modeling, AMMs, MEV, risk models, liquidity dynamics\n    - Smart contract security, attack vectors, economic incentives\n    - Token economics, mechanism design for decentralized systems\n    - Quantum threats to blockchain or cryptography\n    - Any breakthrough that meaningfully improves decentralization, scalability, privacy, or composability\n\n    Output instructions:\n\n    - Output each JSON object in JSON Lines format (one line per paper).\n\n    {\n        \"title\": title of the paper (in Japanese),\n        \"summary\": A concise summary of the paper (in Japanese),\n        \"impact_level\": \"Highest|High|Medium|Low|Lowest\",\n        \"why_matters\": An array (JSON array) containing 2\u20134 bullet points explaining why this paper matters for Web3 investment\n    }\n\n    - Do not output anything except valid JSON object in JSON Lines.\n    - \"title\", \"summary\", \"why_matters\" text in the output must be written in Japanese.\n\n    Paper:\n    title: tritonBLAS: Triton-based Analytical Approach for GEMM Kernel Parameter Selection\n    summary: We present tritonBLAS, a fast and deterministic analytical model that uses architectural parameters like the cache hierarchy, and relative code and data placement to generate performant GPU GEMM kernels. tritonBLAS explicitly models the relationship between architectural topology, matrix shapes, and algorithmic blocking behavior to predict near-optimal configurations without runtime autotuning. Based on this model, we developed and implemented a lightweight GEMM framework entirely within Triton. We evaluate the performance of tritonBLAS across a diverse set of GEMM problem sizes on modern GPUs. tritonBLAS achieves over 95% of the performance of autotuning solutions, while reducing autotuning time to zero. This makes tritonBLAS a practical drop-in replacement for empirical tuning in production HPC and ML workloads.\n    link: https://arxiv.org/abs/2512.04226v1\n    "}}
{"custom_id": "2512.04211v1", "method": "POST", "url": "/v1/responses", "body": {"model": "gpt-5-mini", "input": "You are a specialist research analyst in Web3, DeFi, cryptography, and distributed systems.\n\n    Your task:\n    From the paper below (Title + Summary + Link), evaluate how useful each paper is for understanding investment opportunities or technological advantages within the Web3 / crypto / DeFi ecosystem.\n    Rate each paper on a five-level scale: Highest / High / Medium / Low / Lowest.\n\n    \"Useful\" means:\n\n    - Improves understanding of new cryptographic primitives relevant to blockchain performance or security\n    - Enhances scalability: distributed systems, P2P networking, consensus mechanisms\n    - Advances in zero knowledge, MPC, PQC that could impact future L1/L2 chains\n    - DeFi modeling, AMMs, MEV, risk models, liquidity dynamics\n    - Smart contract security, attack vectors, economic incentives\n    - Token economics, mechanism design for decentralized systems\n    - Quantum threats to blockchain or cryptography\n    - Any breakthrough that meaningfully improves decentralization, scalability, privacy, or composability\n\n    Output instructions:\n\n    - Output each JSON object in JSON Lines format (one line per paper).\n\n    {\n        \"title\": title of the paper (in Japanese),\n        \"summary\": A concise summary of the paper (in Japanese),\n        \"impact_level\": \"Highest|High|Medium|Low|Lowest\",\n        \"why_matters\": An array (JSON array) containing 2\u20134 bullet points explaining why this paper matters for Web3 investment\n    }\n\n    - Do not output anything except valid JSON object in JSON Lines.\n    - \"title\", \"summary\", \"why_matters\" text in the output must be written in Japanese.\n\n    Paper:\n    title: Simulation of a Heterogeneous Quantum Network\n    summary: Quantum networks are expected to be heterogeneous systems, combining distinct qubit platforms, photon wavelengths, and device timescales to achieve scalable, multiuser connectivity. Building and iterating on such systems is costly and slow, motivating hardware-faithful simulations to explore architecture design space and justify implementation decisions. This paper presents a framework for simulating heterogeneous quantum networks based on SeQUeNCe, a discrete-event simulator of quantum networks. We introduce faithful device models for two representative platforms - Ytterbium atoms and superconducting qubits. On top of these models, we implement entanglement generation and entanglement swapping protocols for time-bin encoded photons that account for disparate clock rates and quantum frequency conversion and transducer losses/noise brought by the heterogeneity. Using extensive simulations, we map the rate-fidelity trade space and identify the dominant bottlenecks unique to heterogeneous systems. The models are open source and extensible, enabling reproducible evaluation of future heterogeneous designs and protocols.\n    link: https://arxiv.org/abs/2512.04211v1\n    "}}
{"custom_id": "2511.17127v2", "method": "POST", "url": "/v1/responses", "body": {"model": "gpt-5-mini", "input": "You are a specialist research analyst in Web3, DeFi, cryptography, and distributed systems.\n\n    Your task:\n    From the paper below (Title + Summary + Link), evaluate how useful each paper is for understanding investment opportunities or technological advantages within the Web3 / crypto / DeFi ecosystem.\n    Rate each paper on a five-level scale: Highest / High / Medium / Low / Lowest.\n\n    \"Useful\" means:\n\n    - Improves understanding of new cryptographic primitives relevant to blockchain performance or security\n    - Enhances scalability: distributed systems, P2P networking, consensus mechanisms\n    - Advances in zero knowledge, MPC, PQC that could impact future L1/L2 chains\n    - DeFi modeling, AMMs, MEV, risk models, liquidity dynamics\n    - Smart contract security, attack vectors, economic incentives\n    - Token economics, mechanism design for decentralized systems\n    - Quantum threats to blockchain or cryptography\n    - Any breakthrough that meaningfully improves decentralization, scalability, privacy, or composability\n\n    Output instructions:\n\n    - Output each JSON object in JSON Lines format (one line per paper).\n\n    {\n        \"title\": title of the paper (in Japanese),\n        \"summary\": A concise summary of the paper (in Japanese),\n        \"impact_level\": \"Highest|High|Medium|Low|Lowest\",\n        \"why_matters\": An array (JSON array) containing 2\u20134 bullet points explaining why this paper matters for Web3 investment\n    }\n\n    - Do not output anything except valid JSON object in JSON Lines.\n    - \"title\", \"summary\", \"why_matters\" text in the output must be written in Japanese.\n\n    Paper:\n    title: Training Foundation Models on a Full-Stack AMD Platform: Compute, Networking, and System Design\n    summary: We report on the first large-scale mixture-of-experts (MoE) pretraining study on pure AMD hardware, utilizing both MI300X GPUs and Pollara networking. We distill practical guidance for both systems and model design. On the systems side, we deliver a comprehensive cluster and networking characterization: microbenchmarks for all core collectives (all-reduce, reduce-scatter, all-gather, broadcast) across message sizes and GPU counts over Pollara. To our knowledge, this is the first at this scale. We further provide MI300X microbenchmarks on kernel sizing and memory bandwidth to inform model design. On the modeling side, we introduce and apply MI300X-aware transformer sizing rules for attention and MLP blocks and justify MoE widths that jointly optimize training throughput and inference latency. We describe our training stack in depth, including often-ignored utilities such as fault-tolerance and checkpoint-reshaping, as well as detailed information on our training recipe. We also provide a preview of our model architecture and base model - ZAYA1 (760M active, 8.3B total parameters MoE, available at https://huggingface.co/Zyphra/ZAYA1-base) - which will be further improved upon in forthcoming papers. ZAYA1-base achieves performance comparable to leading base models such as Qwen3-4B and Gemma3-12B at its scale and larger, and outperforms models including Llama-3-8B and OLMoE across reasoning, mathematics, and coding benchmarks. Together, these results demonstrate that the AMD hardware, network, and software stack are mature and optimized enough for competitive large-scale pretraining.\n    link: https://arxiv.org/abs/2511.17127v2\n    "}}
{"custom_id": "2512.04174v1", "method": "POST", "url": "/v1/responses", "body": {"model": "gpt-5-mini", "input": "You are a specialist research analyst in Web3, DeFi, cryptography, and distributed systems.\n\n    Your task:\n    From the paper below (Title + Summary + Link), evaluate how useful each paper is for understanding investment opportunities or technological advantages within the Web3 / crypto / DeFi ecosystem.\n    Rate each paper on a five-level scale: Highest / High / Medium / Low / Lowest.\n\n    \"Useful\" means:\n\n    - Improves understanding of new cryptographic primitives relevant to blockchain performance or security\n    - Enhances scalability: distributed systems, P2P networking, consensus mechanisms\n    - Advances in zero knowledge, MPC, PQC that could impact future L1/L2 chains\n    - DeFi modeling, AMMs, MEV, risk models, liquidity dynamics\n    - Smart contract security, attack vectors, economic incentives\n    - Token economics, mechanism design for decentralized systems\n    - Quantum threats to blockchain or cryptography\n    - Any breakthrough that meaningfully improves decentralization, scalability, privacy, or composability\n\n    Output instructions:\n\n    - Output each JSON object in JSON Lines format (one line per paper).\n\n    {\n        \"title\": title of the paper (in Japanese),\n        \"summary\": A concise summary of the paper (in Japanese),\n        \"impact_level\": \"Highest|High|Medium|Low|Lowest\",\n        \"why_matters\": An array (JSON array) containing 2\u20134 bullet points explaining why this paper matters for Web3 investment\n    }\n\n    - Do not output anything except valid JSON object in JSON Lines.\n    - \"title\", \"summary\", \"why_matters\" text in the output must be written in Japanese.\n\n    Paper:\n    title: Deformed LDPC codes with spontaneously broken non-invertible duality symmetries\n    summary: Low-density parity check (LDPC) codes are a well known class of Pauli stabiliser Hamiltonians that furnish fixed-point realisations of nontrivial gapped phases such as symmetry breaking and topologically ordered (including fracton) phases. In this work, we propose symmetry-preserving deformations of these models, in the presence of a transverse field, and identify special points along the deformations with interesting features: (i) the special point is frustration-free, (ii) its ground states include a product state and the code space of the underlying code, and (iii) it remains gapped in the thermodynamic (infinite volume) limit. So the special point realises a first-order transition between (or the coexistence of) the trivial gapped phase and the nontrivial gapped phase associated with the code. In addition, if the original model has a non-invertible duality symmetry, then so does the deformed model. In this case, the duality symmetry is spontaneously broken at the special point, consistent with the associated anomaly.\n  A key step in proving the gap is a coarse-graining/blocking procedure on the Tanner graph of the code that allows us to apply the martingale method successfully. Our model, therefore, provides the first application of the martingale method to a frustration-free model, that is not commuting projector, defined on an arbitrary Tanner graph.\n  We also discuss several familiar examples on Euclidean spatial lattice. Of particular interest is the 2+1d transverse field Ising model: while there is no non-invertible duality symmetry in this case, our results, together with known numerical results, suggest the existence of a tricritical point in the phase diagram.\n    link: https://arxiv.org/abs/2512.04174v1\n    "}}
{"custom_id": "2512.04169v1", "method": "POST", "url": "/v1/responses", "body": {"model": "gpt-5-mini", "input": "You are a specialist research analyst in Web3, DeFi, cryptography, and distributed systems.\n\n    Your task:\n    From the paper below (Title + Summary + Link), evaluate how useful each paper is for understanding investment opportunities or technological advantages within the Web3 / crypto / DeFi ecosystem.\n    Rate each paper on a five-level scale: Highest / High / Medium / Low / Lowest.\n\n    \"Useful\" means:\n\n    - Improves understanding of new cryptographic primitives relevant to blockchain performance or security\n    - Enhances scalability: distributed systems, P2P networking, consensus mechanisms\n    - Advances in zero knowledge, MPC, PQC that could impact future L1/L2 chains\n    - DeFi modeling, AMMs, MEV, risk models, liquidity dynamics\n    - Smart contract security, attack vectors, economic incentives\n    - Token economics, mechanism design for decentralized systems\n    - Quantum threats to blockchain or cryptography\n    - Any breakthrough that meaningfully improves decentralization, scalability, privacy, or composability\n\n    Output instructions:\n\n    - Output each JSON object in JSON Lines format (one line per paper).\n\n    {\n        \"title\": title of the paper (in Japanese),\n        \"summary\": A concise summary of the paper (in Japanese),\n        \"impact_level\": \"Highest|High|Medium|Low|Lowest\",\n        \"why_matters\": An array (JSON array) containing 2\u20134 bullet points explaining why this paper matters for Web3 investment\n    }\n\n    - Do not output anything except valid JSON object in JSON Lines.\n    - \"title\", \"summary\", \"why_matters\" text in the output must be written in Japanese.\n\n    Paper:\n    title: Exploiting Movable Logical Qubits for Lattice Surgery Compilation\n    summary: Lattice surgery with two-dimensional quantum error correcting codes is among the leading schemes for fault-tolerant quantum computation, motivated by superconducting hardware architectures. In conventional lattice surgery compilation schemes, logical circuits are compiled following a place-and-route paradigm, where logical qubits remain statically fixed in space throughout the computation. In this work, we introduce a paradigm shift by exploiting movable logical qubits via teleportation during the logical lattice surgery CNOT gate. Focusing on lattice surgery with the color code, we propose a proof-of-concept compilation scheme that leverages this capability. Numerical simulations show that the proposed approach can substantially reduce the routed circuit depth compared to standard place-and-route compilation techniques. Our results demonstrate that optimizations based on movable logical qubits are not limited to architectures with physically movable qubits, such as neutral atoms or trapped ions - they are also readily applicable to superconducting quantum hardware. An open-source implementation of our method is available on GitHub https://github.com/munich-quantum-toolkit/qecc.\n    link: https://arxiv.org/abs/2512.04169v1\n    "}}
{"custom_id": "2512.04155v1", "method": "POST", "url": "/v1/responses", "body": {"model": "gpt-5-mini", "input": "You are a specialist research analyst in Web3, DeFi, cryptography, and distributed systems.\n\n    Your task:\n    From the paper below (Title + Summary + Link), evaluate how useful each paper is for understanding investment opportunities or technological advantages within the Web3 / crypto / DeFi ecosystem.\n    Rate each paper on a five-level scale: Highest / High / Medium / Low / Lowest.\n\n    \"Useful\" means:\n\n    - Improves understanding of new cryptographic primitives relevant to blockchain performance or security\n    - Enhances scalability: distributed systems, P2P networking, consensus mechanisms\n    - Advances in zero knowledge, MPC, PQC that could impact future L1/L2 chains\n    - DeFi modeling, AMMs, MEV, risk models, liquidity dynamics\n    - Smart contract security, attack vectors, economic incentives\n    - Token economics, mechanism design for decentralized systems\n    - Quantum threats to blockchain or cryptography\n    - Any breakthrough that meaningfully improves decentralization, scalability, privacy, or composability\n\n    Output instructions:\n\n    - Output each JSON object in JSON Lines format (one line per paper).\n\n    {\n        \"title\": title of the paper (in Japanese),\n        \"summary\": A concise summary of the paper (in Japanese),\n        \"impact_level\": \"Highest|High|Medium|Low|Lowest\",\n        \"why_matters\": An array (JSON array) containing 2\u20134 bullet points explaining why this paper matters for Web3 investment\n    }\n\n    - Do not output anything except valid JSON object in JSON Lines.\n    - \"title\", \"summary\", \"why_matters\" text in the output must be written in Japanese.\n\n    Paper:\n    title: Dissipative Yao-Lee Spin-Orbital Model: Exact Solvability and $\\mathcal{PT}$ Symmetry Breaking\n    summary: Exactly solvable dissipative models provide an analytical tool for studying the relaxation dynamics in open quantum systems. In this work, we study an exactly solvable model based on an anisotropic variant of the Yao-Lee spin-orbital model, with dissipation acting in the spin sector. We map Liouvillian dynamics to fermions hopping in a doubled Hilbert space under a non-Hermitian Hamiltonian and demonstrate the model's exact solvability. We analyze the model's strong and weak symmetries, which protect an exponentially large manifold of non-equilibrium steady states, establishing the system as a physically feasible dissipative spin liquid. Furthermore, we analyze the transient dynamics in a translationally invariant sector and discover that the single-particle Liouvillian spectrum hosts an exceptional ring in momentum space. We map out a characteristic $\\mathcal{PT}$ symmetry breaking transition driven by the dissipation strength, which governs the crossover from oscillatory to decaying relaxation of physical observables. Our work provides a physically motivated, solvable setting for exploring the coexistence of dissipative spin liquid physics and Liouvillian spectral singularities.\n    link: https://arxiv.org/abs/2512.04155v1\n    "}}
