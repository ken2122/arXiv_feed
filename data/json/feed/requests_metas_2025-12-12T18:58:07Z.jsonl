{"custom_id": "2512.11783v1", "method": "POST", "url": "/v1/responses", "body": {"model": "gpt-5-mini", "input": "You are a specialist research analyst in Web3, DeFi, cryptography, and distributed systems.\n\n    Your task:\n    From the paper below (Title + Summary + Link), evaluate how useful each paper is for understanding investment opportunities or technological advantages within the Web3 / crypto / DeFi ecosystem.\n    Rate each paper on a five-level scale: Highest / High / Medium / Low / Lowest.\n\n    \"Useful\" means:\n\n    - Improves understanding of new cryptographic primitives relevant to blockchain performance or security\n    - Enhances scalability: distributed systems, P2P networking, consensus mechanisms\n    - Advances in zero knowledge, MPC, PQC that could impact future L1/L2 chains\n    - DeFi modeling, AMMs, MEV, risk models, liquidity dynamics\n    - Smart contract security, attack vectors, economic incentives\n    - Token economics, mechanism design for decentralized systems\n    - Quantum threats to blockchain or cryptography\n    - Any breakthrough that meaningfully improves decentralization, scalability, privacy, or composability\n\n    Output instructions:\n\n    - Output each JSON object in JSON Lines format (one line per paper).\n\n    {\n        \"title\": title of the paper (in Japanese),\n        \"summary\": A concise summary of the paper (in Japanese),\n        \"impact_level\": \"Highest|High|Medium|Low|Lowest\",\n        \"why_matters\": An array (JSON array) containing 2\u20134 bullet points explaining why this paper matters for Web3 investment\n    }\n\n    - Do not output anything except valid JSON object in JSON Lines.\n    - \"title\", \"summary\", \"why_matters\" text in the output must be written in Japanese.\n\n    Paper:\n    title: Super Suffixes: Bypassing Text Generation Alignment and Guard Models Simultaneously\n    summary: The rapid deployment of Large Language Models (LLMs) has created an urgent need for enhanced security and privacy measures in Machine Learning (ML). LLMs are increasingly being used to process untrusted text inputs and even generate executable code, often while having access to sensitive system controls. To address these security concerns, several companies have introduced guard models, which are smaller, specialized models designed to protect text generation models from adversarial or malicious inputs. In this work, we advance the study of adversarial inputs by introducing Super Suffixes, suffixes capable of overriding multiple alignment objectives across various models with different tokenization schemes. We demonstrate their effectiveness, along with our joint optimization technique, by successfully bypassing the protection mechanisms of Llama Prompt Guard 2 on five different text generation models for malicious text and code generation. To the best of our knowledge, this is the first work to reveal that Llama Prompt Guard 2 can be compromised through joint optimization.\n  Additionally, by analyzing the changing similarity of a model's internal state to specific concept directions during token sequence processing, we propose an effective and lightweight method to detect Super Suffix attacks. We show that the cosine similarity between the residual stream and certain concept directions serves as a distinctive fingerprint of model intent. Our proposed countermeasure, DeltaGuard, significantly improves the detection of malicious prompts generated through Super Suffixes. It increases the non-benign classification rate to nearly 100%, making DeltaGuard a valuable addition to the guard model stack and enhancing robustness against adversarial prompt attacks.\n    link: https://arxiv.org/abs/2512.11783v1\n    "}}
{"custom_id": "2512.11775v1", "method": "POST", "url": "/v1/responses", "body": {"model": "gpt-5-mini", "input": "You are a specialist research analyst in Web3, DeFi, cryptography, and distributed systems.\n\n    Your task:\n    From the paper below (Title + Summary + Link), evaluate how useful each paper is for understanding investment opportunities or technological advantages within the Web3 / crypto / DeFi ecosystem.\n    Rate each paper on a five-level scale: Highest / High / Medium / Low / Lowest.\n\n    \"Useful\" means:\n\n    - Improves understanding of new cryptographic primitives relevant to blockchain performance or security\n    - Enhances scalability: distributed systems, P2P networking, consensus mechanisms\n    - Advances in zero knowledge, MPC, PQC that could impact future L1/L2 chains\n    - DeFi modeling, AMMs, MEV, risk models, liquidity dynamics\n    - Smart contract security, attack vectors, economic incentives\n    - Token economics, mechanism design for decentralized systems\n    - Quantum threats to blockchain or cryptography\n    - Any breakthrough that meaningfully improves decentralization, scalability, privacy, or composability\n\n    Output instructions:\n\n    - Output each JSON object in JSON Lines format (one line per paper).\n\n    {\n        \"title\": title of the paper (in Japanese),\n        \"summary\": A concise summary of the paper (in Japanese),\n        \"impact_level\": \"Highest|High|Medium|Low|Lowest\",\n        \"why_matters\": An array (JSON array) containing 2\u20134 bullet points explaining why this paper matters for Web3 investment\n    }\n\n    - Do not output anything except valid JSON object in JSON Lines.\n    - \"title\", \"summary\", \"why_matters\" text in the output must be written in Japanese.\n\n    Paper:\n    title: Hypergraph based Multi-Party Payment Channel\n    summary: Public blockchains inherently offer low throughput and high latency, motivating off-chain scalability solutions such as Payment Channel Networks (PCNs). However, existing PCNs suffer from liquidity fragmentation-funds locked in one channel cannot be reused elsewhere-and channel depletion, both of which limit routing efficiency and reduce transaction success rates. Multi-party channel (MPC) constructions mitigate these issues, but they typically rely on leaders or coordinators, creating single points of failure and providing only limited flexibility for inter-channel payments.\n  We introduce Hypergraph-based Multi-Party Payment Channels (H-MPCs), a new off-chain construction that replaces bilateral channels with collectively funded hyperedges. These hyperedges enable fully concurrent, leaderless intra- and inter-hyperedge payments through verifiable, proposer-ordered DAG updates, offering significantly greater flexibility and concurrency than prior designs.\n  Our implementation on a 150-node network demonstrates a transaction success rate of approximately 94% without HTLC expiry or routing failures, highlighting the robustness of H-MPCs.\n    link: https://arxiv.org/abs/2512.11775v1\n    "}}
{"custom_id": "2512.11765v1", "method": "POST", "url": "/v1/responses", "body": {"model": "gpt-5-mini", "input": "You are a specialist research analyst in Web3, DeFi, cryptography, and distributed systems.\n\n    Your task:\n    From the paper below (Title + Summary + Link), evaluate how useful each paper is for understanding investment opportunities or technological advantages within the Web3 / crypto / DeFi ecosystem.\n    Rate each paper on a five-level scale: Highest / High / Medium / Low / Lowest.\n\n    \"Useful\" means:\n\n    - Improves understanding of new cryptographic primitives relevant to blockchain performance or security\n    - Enhances scalability: distributed systems, P2P networking, consensus mechanisms\n    - Advances in zero knowledge, MPC, PQC that could impact future L1/L2 chains\n    - DeFi modeling, AMMs, MEV, risk models, liquidity dynamics\n    - Smart contract security, attack vectors, economic incentives\n    - Token economics, mechanism design for decentralized systems\n    - Quantum threats to blockchain or cryptography\n    - Any breakthrough that meaningfully improves decentralization, scalability, privacy, or composability\n\n    Output instructions:\n\n    - Output each JSON object in JSON Lines format (one line per paper).\n\n    {\n        \"title\": title of the paper (in Japanese),\n        \"summary\": A concise summary of the paper (in Japanese),\n        \"impact_level\": \"Highest|High|Medium|Low|Lowest\",\n        \"why_matters\": An array (JSON array) containing 2\u20134 bullet points explaining why this paper matters for Web3 investment\n    }\n\n    - Do not output anything except valid JSON object in JSON Lines.\n    - \"title\", \"summary\", \"why_matters\" text in the output must be written in Japanese.\n\n    Paper:\n    title: High-Frequency Analysis of a Trading Game with Transient Price Impact\n    summary: We study the high-frequency limit of an $n$-trader optimal execution game in discrete time. Traders face transient price impact of Obizhaeva--Wang type in addition to quadratic instantaneous trading costs $\u03b8(\u0394X_t)^2$ on each transaction $\u0394X_t$. There is a unique Nash equilibrium in which traders choose liquidation strategies minimizing expected execution costs. In the high-frequency limit where the grid of trading dates converges to the continuous interval $[0,T]$, the discrete equilibrium inventories converge at rate $1/N$ to the continuous-time equilibrium of an Obizhaeva--Wang model with additional quadratic costs $\\vartheta_0(\u0394X_0)^2$ and $\\vartheta_T(\u0394X_T)^2$ on initial and terminal block trades, where $\\vartheta_0=(n-1)/2$ and $\\vartheta_T=1/2$. The latter model was introduced by Campbell and Nutz as the limit of continuous-time equilibria with vanishing instantaneous costs. Our results extend and refine previous results of Schied, Strehle, and Zhang for the particular case $n=2$ where $\\vartheta_0=\\vartheta_T=1/2$. In particular, we show how the coefficients $\\vartheta_0=(n-1)/2$ and $\\vartheta_T=1/2$ arise endogenously in the high-frequency limit: the initial and terminal block costs of the continuous-time model are identified as the limits of the cumulative discrete instantaneous costs incurred over small neighborhoods of $0$ and $T$, respectively, and these limits are independent of $\u03b8>0$. By contrast, when $\u03b8=0$ the discrete-time equilibrium strategies and costs exhibit persistent oscillations and admit no high-frequency limit, mirroring the non-existence of continuous-time equilibria without boundary block costs. Our results show that two different types of trading frictions -- a fine time discretization and small instantaneous costs in continuous time -- have similar regularizing effects and select a canonical model in the limit.\n    link: https://arxiv.org/abs/2512.11765v1\n    "}}
{"custom_id": "2312.11533v3", "method": "POST", "url": "/v1/responses", "body": {"model": "gpt-5-mini", "input": "You are a specialist research analyst in Web3, DeFi, cryptography, and distributed systems.\n\n    Your task:\n    From the paper below (Title + Summary + Link), evaluate how useful each paper is for understanding investment opportunities or technological advantages within the Web3 / crypto / DeFi ecosystem.\n    Rate each paper on a five-level scale: Highest / High / Medium / Low / Lowest.\n\n    \"Useful\" means:\n\n    - Improves understanding of new cryptographic primitives relevant to blockchain performance or security\n    - Enhances scalability: distributed systems, P2P networking, consensus mechanisms\n    - Advances in zero knowledge, MPC, PQC that could impact future L1/L2 chains\n    - DeFi modeling, AMMs, MEV, risk models, liquidity dynamics\n    - Smart contract security, attack vectors, economic incentives\n    - Token economics, mechanism design for decentralized systems\n    - Quantum threats to blockchain or cryptography\n    - Any breakthrough that meaningfully improves decentralization, scalability, privacy, or composability\n\n    Output instructions:\n\n    - Output each JSON object in JSON Lines format (one line per paper).\n\n    {\n        \"title\": title of the paper (in Japanese),\n        \"summary\": A concise summary of the paper (in Japanese),\n        \"impact_level\": \"Highest|High|Medium|Low|Lowest\",\n        \"why_matters\": An array (JSON array) containing 2\u20134 bullet points explaining why this paper matters for Web3 investment\n    }\n\n    - Do not output anything except valid JSON object in JSON Lines.\n    - \"title\", \"summary\", \"why_matters\" text in the output must be written in Japanese.\n\n    Paper:\n    title: Cryptanalysis of PLWE based on zero-trace quadratic roots\n    summary: We extend two of the attacks on the PLWE problem presented in (Y. Elias, K. E. Lauter, E. Ozman, and K. E. Stange, Ring-LWE Cryptography for the Number Theorist, in Directions in Number Theory, E. E. Eischen, L. Long, R. Pries, and K. E. Stange, eds., vol. 3 of Association for Women in Mathematics Series, Cham, 2016, Springer International Publishing, pp. 271-290) to a ring $R_q=\\mathbb{F}_q[x]/(f(x))$ where the irreducible monic polynomial $f(x)\\in\\mathbb{Z}[x]$ has an irreducible quadratic factor over $\\mathbb{F}_q[x]$ of the form $x^2+\u03c1$ with $\u03c1$ of suitable multiplicative order in $\\mathbb{F}_q$. Our attack exploits the fact that the trace of the root is zero, and has overwhelming success probability as a function of the number of samples taken as input. An implementation in Maple and some examples of our attack are also provided.\n    link: https://arxiv.org/abs/2312.11533v3\n    "}}
{"custom_id": "2511.11843v2", "method": "POST", "url": "/v1/responses", "body": {"model": "gpt-5-mini", "input": "You are a specialist research analyst in Web3, DeFi, cryptography, and distributed systems.\n\n    Your task:\n    From the paper below (Title + Summary + Link), evaluate how useful each paper is for understanding investment opportunities or technological advantages within the Web3 / crypto / DeFi ecosystem.\n    Rate each paper on a five-level scale: Highest / High / Medium / Low / Lowest.\n\n    \"Useful\" means:\n\n    - Improves understanding of new cryptographic primitives relevant to blockchain performance or security\n    - Enhances scalability: distributed systems, P2P networking, consensus mechanisms\n    - Advances in zero knowledge, MPC, PQC that could impact future L1/L2 chains\n    - DeFi modeling, AMMs, MEV, risk models, liquidity dynamics\n    - Smart contract security, attack vectors, economic incentives\n    - Token economics, mechanism design for decentralized systems\n    - Quantum threats to blockchain or cryptography\n    - Any breakthrough that meaningfully improves decentralization, scalability, privacy, or composability\n\n    Output instructions:\n\n    - Output each JSON object in JSON Lines format (one line per paper).\n\n    {\n        \"title\": title of the paper (in Japanese),\n        \"summary\": A concise summary of the paper (in Japanese),\n        \"impact_level\": \"Highest|High|Medium|Low|Lowest\",\n        \"why_matters\": An array (JSON array) containing 2\u20134 bullet points explaining why this paper matters for Web3 investment\n    }\n\n    - Do not output anything except valid JSON object in JSON Lines.\n    - \"title\", \"summary\", \"why_matters\" text in the output must be written in Japanese.\n\n    Paper:\n    title: TD-Orch: Scalable Load-Balancing for Distributed Systems with Applications to Graph Processing\n    summary: In this paper, we introduce a task-data orchestration abstraction that supports a range of distributed applications, including graph processing and key-value stores. Given a batch of lambda tasks each requesting one or more data items, where both tasks and data are distributed across multiple machines, each task must be co-located with its target data (by moving tasks and/or data) and then executed. We present TD-Orch, an efficient and scalable orchestration framework featuring a simple application developer interface. TD-Orch employs a distributed push-pull technique, leveraging the bidirectional flow of both tasks and data to achieve scalable load balance across machines even under highly skewed data requests (data hot spots), with minimal communication overhead. Experimental results show that TD-Orch achieves up to 2.8x speedup over existing distributed scheduling baselines. Building on TD-Orch, we present TDO-GP, a distributed graph processing system for general graph problems, demonstrating the effectiveness of the underlying framework. We design three families of implementation techniques to fully leverage the execution flow provided by TD-Orch. Experimental results show that TDO-GP achieves an average speedup of 4.1x over the best prior open-source distributed graph systems for general graph processing.\n    link: https://arxiv.org/abs/2511.11843v2\n    "}}
{"custom_id": "2512.11727v1", "method": "POST", "url": "/v1/responses", "body": {"model": "gpt-5-mini", "input": "You are a specialist research analyst in Web3, DeFi, cryptography, and distributed systems.\n\n    Your task:\n    From the paper below (Title + Summary + Link), evaluate how useful each paper is for understanding investment opportunities or technological advantages within the Web3 / crypto / DeFi ecosystem.\n    Rate each paper on a five-level scale: Highest / High / Medium / Low / Lowest.\n\n    \"Useful\" means:\n\n    - Improves understanding of new cryptographic primitives relevant to blockchain performance or security\n    - Enhances scalability: distributed systems, P2P networking, consensus mechanisms\n    - Advances in zero knowledge, MPC, PQC that could impact future L1/L2 chains\n    - DeFi modeling, AMMs, MEV, risk models, liquidity dynamics\n    - Smart contract security, attack vectors, economic incentives\n    - Token economics, mechanism design for decentralized systems\n    - Quantum threats to blockchain or cryptography\n    - Any breakthrough that meaningfully improves decentralization, scalability, privacy, or composability\n\n    Output instructions:\n\n    - Output each JSON object in JSON Lines format (one line per paper).\n\n    {\n        \"title\": title of the paper (in Japanese),\n        \"summary\": A concise summary of the paper (in Japanese),\n        \"impact_level\": \"Highest|High|Medium|Low|Lowest\",\n        \"why_matters\": An array (JSON array) containing 2\u20134 bullet points explaining why this paper matters for Web3 investment\n    }\n\n    - Do not output anything except valid JSON object in JSON Lines.\n    - \"title\", \"summary\", \"why_matters\" text in the output must be written in Japanese.\n\n    Paper:\n    title: ECCO: Leveraging Cross-Camera Correlations for Efficient Live Video Continuous Learning\n    summary: Recent advances in video analytics address real-time data drift by continuously retraining specialized, lightweight DNN models for individual cameras. However, the current practice of retraining a separate model for each camera suffers from high compute and communication costs, making it unscalable. We present ECCO, a new video analytics framework designed for resource-efficient continuous learning. The key insight is that the data drift, which necessitates model retraining, often shows temporal and spatial correlations across nearby cameras. By identifying cameras that experience similar drift and retraining a shared model for them, ECCO can substantially reduce the associated compute and communication costs. Specifically, ECCO introduces: (i) a lightweight grouping algorithm that dynamically forms and updates camera groups; (ii) a GPU allocator that dynamically assigns GPU resources across different groups to improve retraining accuracy and ensure fairness; and (iii) a transmission controller at each camera that configures frame sampling and coordinates bandwidth sharing with other cameras based on its assigned GPU resources. We conducted extensive evaluations on three distinctive datasets for two vision tasks. Compared to leading baselines, ECCO improves retraining accuracy by 6.7%-18.1% using the same compute and communication resources, or supports 3.3 times more concurrent cameras at the same accuracy.\n    link: https://arxiv.org/abs/2512.11727v1\n    "}}
{"custom_id": "2512.11704v1", "method": "POST", "url": "/v1/responses", "body": {"model": "gpt-5-mini", "input": "You are a specialist research analyst in Web3, DeFi, cryptography, and distributed systems.\n\n    Your task:\n    From the paper below (Title + Summary + Link), evaluate how useful each paper is for understanding investment opportunities or technological advantages within the Web3 / crypto / DeFi ecosystem.\n    Rate each paper on a five-level scale: Highest / High / Medium / Low / Lowest.\n\n    \"Useful\" means:\n\n    - Improves understanding of new cryptographic primitives relevant to blockchain performance or security\n    - Enhances scalability: distributed systems, P2P networking, consensus mechanisms\n    - Advances in zero knowledge, MPC, PQC that could impact future L1/L2 chains\n    - DeFi modeling, AMMs, MEV, risk models, liquidity dynamics\n    - Smart contract security, attack vectors, economic incentives\n    - Token economics, mechanism design for decentralized systems\n    - Quantum threats to blockchain or cryptography\n    - Any breakthrough that meaningfully improves decentralization, scalability, privacy, or composability\n\n    Output instructions:\n\n    - Output each JSON object in JSON Lines format (one line per paper).\n\n    {\n        \"title\": title of the paper (in Japanese),\n        \"summary\": A concise summary of the paper (in Japanese),\n        \"impact_level\": \"Highest|High|Medium|Low|Lowest\",\n        \"why_matters\": An array (JSON array) containing 2\u20134 bullet points explaining why this paper matters for Web3 investment\n    }\n\n    - Do not output anything except valid JSON object in JSON Lines.\n    - \"title\", \"summary\", \"why_matters\" text in the output must be written in Japanese.\n\n    Paper:\n    title: Approximating $\\mathrm{SU}(2)$ Chern-Simons theory by finite group gauge theories\n    summary: Motivated by some previously known facts from mathematical and physics literature, we explore certain relations between 3-dimensional topological gauge theories with continuous and finite gauge groups, commonly known as Chern-Simons (CS) and Dijkgraaf-Witten (DW) theories, respectively. Specifically, we consider the continuous and finite gauge groups to be the same algebraic group over the complex numbers and a finite field, respectively. In this paper, we focus on the $\\mathrm{SU}(2)$ example and consider the relationship on the level of the corresponding partition functions on closed 3-manifolds. Mathematically, these are Witten-Reshetikhin-Turaev and DW invariants. We find that the asymptotics of the DW theory when the number of elements of the finite field is large recovers the leading asymptotics of the CS theory at large level when the 3-manifold contains no hyperbolic components. As a byproduct, we develop efficient techniques to count the number of points over finite fields $\\mathbb{F}_q$ of $\\mathrm{SL}(2)$ representation varieties of fundamental groups of 3-manifolds, possibly with weights pulled back from a chosen class in $H^3(\\mathrm{SL}(2,\\mathbb{F}_q),\\mathrm{U}(1))$.\n    link: https://arxiv.org/abs/2512.11704v1\n    "}}
{"custom_id": "2512.11699v1", "method": "POST", "url": "/v1/responses", "body": {"model": "gpt-5-mini", "input": "You are a specialist research analyst in Web3, DeFi, cryptography, and distributed systems.\n\n    Your task:\n    From the paper below (Title + Summary + Link), evaluate how useful each paper is for understanding investment opportunities or technological advantages within the Web3 / crypto / DeFi ecosystem.\n    Rate each paper on a five-level scale: Highest / High / Medium / Low / Lowest.\n\n    \"Useful\" means:\n\n    - Improves understanding of new cryptographic primitives relevant to blockchain performance or security\n    - Enhances scalability: distributed systems, P2P networking, consensus mechanisms\n    - Advances in zero knowledge, MPC, PQC that could impact future L1/L2 chains\n    - DeFi modeling, AMMs, MEV, risk models, liquidity dynamics\n    - Smart contract security, attack vectors, economic incentives\n    - Token economics, mechanism design for decentralized systems\n    - Quantum threats to blockchain or cryptography\n    - Any breakthrough that meaningfully improves decentralization, scalability, privacy, or composability\n\n    Output instructions:\n\n    - Output each JSON object in JSON Lines format (one line per paper).\n\n    {\n        \"title\": title of the paper (in Japanese),\n        \"summary\": A concise summary of the paper (in Japanese),\n        \"impact_level\": \"Highest|High|Medium|Low|Lowest\",\n        \"why_matters\": An array (JSON array) containing 2\u20134 bullet points explaining why this paper matters for Web3 investment\n    }\n\n    - Do not output anything except valid JSON object in JSON Lines.\n    - \"title\", \"summary\", \"why_matters\" text in the output must be written in Japanese.\n\n    Paper:\n    title: SoK: Demystifying the multiverse of MPC protocols\n    summary: This paper systematizes knowledge on the performance of Multi-Party Computation (MPC) protocols. Despite strong privacy and correctness guarantees, MPC adoption in real-world applications remains limited by high costs (especially in the malicious setting) and lack of guidance on choosing suitable protocols for concrete workloads. We identify the theoretical and practical parameters that shape MPC efficiency and conduct an extensive experimental study across diverse benchmarks. Our analysis discusses the trade-offs between protocols, and highlights which techniques align best with different application scenarios and needs. By providing actionable guidance for developers and outlining open challenges for researchers, this work seeks to narrow the gap between MPC theory and practice.\n    link: https://arxiv.org/abs/2512.11699v1\n    "}}
{"custom_id": "2512.11690v1", "method": "POST", "url": "/v1/responses", "body": {"model": "gpt-5-mini", "input": "You are a specialist research analyst in Web3, DeFi, cryptography, and distributed systems.\n\n    Your task:\n    From the paper below (Title + Summary + Link), evaluate how useful each paper is for understanding investment opportunities or technological advantages within the Web3 / crypto / DeFi ecosystem.\n    Rate each paper on a five-level scale: Highest / High / Medium / Low / Lowest.\n\n    \"Useful\" means:\n\n    - Improves understanding of new cryptographic primitives relevant to blockchain performance or security\n    - Enhances scalability: distributed systems, P2P networking, consensus mechanisms\n    - Advances in zero knowledge, MPC, PQC that could impact future L1/L2 chains\n    - DeFi modeling, AMMs, MEV, risk models, liquidity dynamics\n    - Smart contract security, attack vectors, economic incentives\n    - Token economics, mechanism design for decentralized systems\n    - Quantum threats to blockchain or cryptography\n    - Any breakthrough that meaningfully improves decentralization, scalability, privacy, or composability\n\n    Output instructions:\n\n    - Output each JSON object in JSON Lines format (one line per paper).\n\n    {\n        \"title\": title of the paper (in Japanese),\n        \"summary\": A concise summary of the paper (in Japanese),\n        \"impact_level\": \"Highest|High|Medium|Low|Lowest\",\n        \"why_matters\": An array (JSON array) containing 2\u20134 bullet points explaining why this paper matters for Web3 investment\n    }\n\n    - Do not output anything except valid JSON object in JSON Lines.\n    - \"title\", \"summary\", \"why_matters\" text in the output must be written in Japanese.\n\n    Paper:\n    title: Leveraging FPGAs for Homomorphic Matrix-Vector Multiplication in Oblivious Message Retrieval\n    summary: While end-to-end encryption protects the content of messages, it does not secure metadata, which exposes sender and receiver information through traffic analysis. A plausible approach to protecting this metadata is to have senders post encrypted messages on a public bulletin board and receivers scan it for relevant messages. Oblivious message retrieval (OMR) leverages homomorphic encryption (HE) to improve user experience in this solution by delegating the scan to a resource-rich server while preserving privacy. A key process in OMR is the homomorphic detection of pertinent messages for the receiver from the bulletin board. It relies on a specialized matrix-vector multiplication algorithm, which involves extensive multiplications between ciphertext vectors and plaintext matrices, as well as homomorphic rotations. The computationally intensive nature of this process limits the practicality of OMR. To address this challenge, this paper proposes a hardware architecture to accelerate the matrix-vector multiplication algorithm. The building homomorphic operators in this algorithm are implemented using high-level synthesis, with design parameters for different parallelism levels. These operators are then deployed on a field-programmable gate array platform using an efficient design space exploration strategy to accelerate homomorphic matrix-vector multiplication. Compared to a software implementation, the proposed hardware accelerator achieves a 13.86x speedup.\n    link: https://arxiv.org/abs/2512.11690v1\n    "}}
{"custom_id": "2512.11675v1", "method": "POST", "url": "/v1/responses", "body": {"model": "gpt-5-mini", "input": "You are a specialist research analyst in Web3, DeFi, cryptography, and distributed systems.\n\n    Your task:\n    From the paper below (Title + Summary + Link), evaluate how useful each paper is for understanding investment opportunities or technological advantages within the Web3 / crypto / DeFi ecosystem.\n    Rate each paper on a five-level scale: Highest / High / Medium / Low / Lowest.\n\n    \"Useful\" means:\n\n    - Improves understanding of new cryptographic primitives relevant to blockchain performance or security\n    - Enhances scalability: distributed systems, P2P networking, consensus mechanisms\n    - Advances in zero knowledge, MPC, PQC that could impact future L1/L2 chains\n    - DeFi modeling, AMMs, MEV, risk models, liquidity dynamics\n    - Smart contract security, attack vectors, economic incentives\n    - Token economics, mechanism design for decentralized systems\n    - Quantum threats to blockchain or cryptography\n    - Any breakthrough that meaningfully improves decentralization, scalability, privacy, or composability\n\n    Output instructions:\n\n    - Output each JSON object in JSON Lines format (one line per paper).\n\n    {\n        \"title\": title of the paper (in Japanese),\n        \"summary\": A concise summary of the paper (in Japanese),\n        \"impact_level\": \"Highest|High|Medium|Low|Lowest\",\n        \"why_matters\": An array (JSON array) containing 2\u20134 bullet points explaining why this paper matters for Web3 investment\n    }\n\n    - Do not output anything except valid JSON object in JSON Lines.\n    - \"title\", \"summary\", \"why_matters\" text in the output must be written in Japanese.\n\n    Paper:\n    title: Bloch oscillation in a Floquet engineering quadratic potential system\n    summary: We investigate the quantum dynamics of a one-dimensional tight-binding lattice driven by a spatially quadratic and time-periodic potential. Both Hermitian ($J_1 = J_2$) and non-Hermitian ($J_1 \\neq J_2$) hopping regimes are analyzed. Within the framework of Floquet theory, the time-dependent Hamiltonian is mapped onto an effective static Floquet Hamiltonian, enabling a detailed study of the quasi-energy spectrum and eigenstate localization as function of the driving frequency $\u03c9$. We identify critical frequencies $\u03c9_c$ at which nearly equidistant quasi-energy ladders emerge, characterized by a pronounced minimum in the normalized variance of level spacings. This spectral regularity, which coincides with a peak in the mean inverse participation ratio (\\textrm{MIPR}), leads to robust periodic revivals and Bloch-like oscillations in the time evolution. Numerical simulations confirm that such coherent oscillations persist even in the non-Hermitian regime, where the periodic driving stabilizes an almost real and uniformly spaced quasi-energy ladder.\n    link: https://arxiv.org/abs/2512.11675v1\n    "}}
{"custom_id": "2512.11667v1", "method": "POST", "url": "/v1/responses", "body": {"model": "gpt-5-mini", "input": "You are a specialist research analyst in Web3, DeFi, cryptography, and distributed systems.\n\n    Your task:\n    From the paper below (Title + Summary + Link), evaluate how useful each paper is for understanding investment opportunities or technological advantages within the Web3 / crypto / DeFi ecosystem.\n    Rate each paper on a five-level scale: Highest / High / Medium / Low / Lowest.\n\n    \"Useful\" means:\n\n    - Improves understanding of new cryptographic primitives relevant to blockchain performance or security\n    - Enhances scalability: distributed systems, P2P networking, consensus mechanisms\n    - Advances in zero knowledge, MPC, PQC that could impact future L1/L2 chains\n    - DeFi modeling, AMMs, MEV, risk models, liquidity dynamics\n    - Smart contract security, attack vectors, economic incentives\n    - Token economics, mechanism design for decentralized systems\n    - Quantum threats to blockchain or cryptography\n    - Any breakthrough that meaningfully improves decentralization, scalability, privacy, or composability\n\n    Output instructions:\n\n    - Output each JSON object in JSON Lines format (one line per paper).\n\n    {\n        \"title\": title of the paper (in Japanese),\n        \"summary\": A concise summary of the paper (in Japanese),\n        \"impact_level\": \"Highest|High|Medium|Low|Lowest\",\n        \"why_matters\": An array (JSON array) containing 2\u20134 bullet points explaining why this paper matters for Web3 investment\n    }\n\n    - Do not output anything except valid JSON object in JSON Lines.\n    - \"title\", \"summary\", \"why_matters\" text in the output must be written in Japanese.\n\n    Paper:\n    title: Toward Scalable VR-Cloud Gaming: An Attention-aware Adaptive Resource Allocation Framework for 6G Networks\n    summary: Virtual Reality Cloud Gaming (VR-CG) represents a demanding class of immersive applications, requiring high bandwidth, ultra-low latency, and intelligent resource management to ensure optimal user experience. In this paper, we propose a scalable and QoE-aware multi-stage optimization framework for resource allocation in VR-CG over 6G networks. Our solution decomposes the joint resource allocation problem into three interdependent stages: (i) user association and communication resource allocation; (ii) VR-CG game engine placement with adaptive multipath routing; and (iii) attention-aware scheduling and wireless resource allocation based on motion-to-photon latency. For each stage, we design specialized heuristic algorithms that achieve near-optimal performance while significantly reducing computational time. We introduce a novel user-centric QoE model based on visual attention to virtual objects, guiding adaptive resolution and frame rate selection. A dataset-driven evaluation demonstrates that, when compared against state-of-the-art approaches, our framework improves QoE by up to 50\\%, reduces communication resource usage by 75\\%, and achieves up to 35\\% cost savings, while maintaining an average optimality gap of 5\\%. Our proposed heuristics solve large-scale scenarios in under 0.1 seconds, highlighting their potential for real-time deployment in next-generation mobile networks.\n    link: https://arxiv.org/abs/2512.11667v1\n    "}}
{"custom_id": "2512.11643v1", "method": "POST", "url": "/v1/responses", "body": {"model": "gpt-5-mini", "input": "You are a specialist research analyst in Web3, DeFi, cryptography, and distributed systems.\n\n    Your task:\n    From the paper below (Title + Summary + Link), evaluate how useful each paper is for understanding investment opportunities or technological advantages within the Web3 / crypto / DeFi ecosystem.\n    Rate each paper on a five-level scale: Highest / High / Medium / Low / Lowest.\n\n    \"Useful\" means:\n\n    - Improves understanding of new cryptographic primitives relevant to blockchain performance or security\n    - Enhances scalability: distributed systems, P2P networking, consensus mechanisms\n    - Advances in zero knowledge, MPC, PQC that could impact future L1/L2 chains\n    - DeFi modeling, AMMs, MEV, risk models, liquidity dynamics\n    - Smart contract security, attack vectors, economic incentives\n    - Token economics, mechanism design for decentralized systems\n    - Quantum threats to blockchain or cryptography\n    - Any breakthrough that meaningfully improves decentralization, scalability, privacy, or composability\n\n    Output instructions:\n\n    - Output each JSON object in JSON Lines format (one line per paper).\n\n    {\n        \"title\": title of the paper (in Japanese),\n        \"summary\": A concise summary of the paper (in Japanese),\n        \"impact_level\": \"Highest|High|Medium|Low|Lowest\",\n        \"why_matters\": An array (JSON array) containing 2\u20134 bullet points explaining why this paper matters for Web3 investment\n    }\n\n    - Do not output anything except valid JSON object in JSON Lines.\n    - \"title\", \"summary\", \"why_matters\" text in the output must be written in Japanese.\n\n    Paper:\n    title: Stateless Snowflake: A Cloud-Agnostic Distributed ID Generator Using Network-Derived Identity\n    summary: Snowflake-style distributed ID generators are the industry standard for producing k-ordered, unique identifiers at scale. However, the traditional requirement for manually assigned or centrally coordinated worker IDs introduces significant friction in modern container-orchestrated environments (e.g., Kubernetes), where workloads are ephemeral and autoscaled. In such systems, maintaining stable worker identities requires complex stateful sets or external coordination services (e.g., ZooKeeper), negating the operational benefits of stateless microservices.\n  This paper presents a cloud-agnostic, container-native ID generation protocol that eliminates the dependency on explicit worker IDs. By deriving node uniqueness deterministically from ephemeral network properties - specifically the container's private IPv4 address - the proposed method removes the need for centralized coordination. We introduce a modified bit-allocation scheme (1-41-16-6) that accommodates 16 bits of network-derived entropy while preserving strict monotonicity. We validate the approach across AWS, GCP, and Azure environments. Evaluation results demonstrate that while the design has a theoretical single-node ceiling of approximately 64,000 TPS, in practical microservice deployments the network I/O dominates latency, resulting in end-to-end performance (approximately 31,000 TPS on a 3-node cluster) comparable to classic stateful generators while offering effectively unbounded horizontal scalability.\n    link: https://arxiv.org/abs/2512.11643v1\n    "}}
{"custom_id": "2408.08772v2", "method": "POST", "url": "/v1/responses", "body": {"model": "gpt-5-mini", "input": "You are a specialist research analyst in Web3, DeFi, cryptography, and distributed systems.\n\n    Your task:\n    From the paper below (Title + Summary + Link), evaluate how useful each paper is for understanding investment opportunities or technological advantages within the Web3 / crypto / DeFi ecosystem.\n    Rate each paper on a five-level scale: Highest / High / Medium / Low / Lowest.\n\n    \"Useful\" means:\n\n    - Improves understanding of new cryptographic primitives relevant to blockchain performance or security\n    - Enhances scalability: distributed systems, P2P networking, consensus mechanisms\n    - Advances in zero knowledge, MPC, PQC that could impact future L1/L2 chains\n    - DeFi modeling, AMMs, MEV, risk models, liquidity dynamics\n    - Smart contract security, attack vectors, economic incentives\n    - Token economics, mechanism design for decentralized systems\n    - Quantum threats to blockchain or cryptography\n    - Any breakthrough that meaningfully improves decentralization, scalability, privacy, or composability\n\n    Output instructions:\n\n    - Output each JSON object in JSON Lines format (one line per paper).\n\n    {\n        \"title\": title of the paper (in Japanese),\n        \"summary\": A concise summary of the paper (in Japanese),\n        \"impact_level\": \"Highest|High|Medium|Low|Lowest\",\n        \"why_matters\": An array (JSON array) containing 2\u20134 bullet points explaining why this paper matters for Web3 investment\n    }\n\n    - Do not output anything except valid JSON object in JSON Lines.\n    - \"title\", \"summary\", \"why_matters\" text in the output must be written in Japanese.\n\n    Paper:\n    title: Vital: Vulnerability-Oriented Symbolic Execution via Type-Unsafe Pointer-Guided Monte Carlo Tree Search\n    summary: How to find memory safety bugs efficiently when navigating a symbolic execution tree that suffers from path explosion? Existing solutions either adopt path search heuristics to maximize coverage rate or chopped symbolic execution to skip uninteresting code (i.e., manually labeled as vulnerability-unrelated) during path exploration. However, most existing search heuristics are not vulnerability-oriented, and manual labeling of irrelevant code-to-be-skipped relies heavily on prior expert knowledge, making it hard to detect vulnerabilities effectively in practice.\n  This paper proposes Vital, a new vulnerability-oriented path exploration for symbolic execution with two innovations. First, a new indicator (i.e., type-unsafe pointers) is suggested to approximate vulnerable paths. A pointer that is type-unsafe cannot be statically proven to be safely dereferenced without memory corruption. Our key hypothesis is that a path with more type-unsafe pointers is more likely to be vulnerable. Second, a new type-unsafe pointer-guided Monte Carlo Tree Search algorithm is implemented to guide the path exploration towards the areas that contain more unsafe pointers, aiming to increase the likelihood of detecting vulnerabilities. We built Vital on top of KLEE and compared it with existing path searching strategies and chopped symbolic execution. In the former, the results demonstrate that Vital could cover up to 90.03% more unsafe pointers and detect up to 57.14% more unique memory errors. In the latter, the results show that Vital could achieve a speedup of up to 30x execution time and a reduction of up to 20x memory consumption to detect known vulnerabilities without prior expert knowledge automatically. In practice, Vital also detected one previously unknown vulnerability (a new CVE ID is assigned), which has been fixed by developers.\n    link: https://arxiv.org/abs/2408.08772v2\n    "}}
{"custom_id": "2512.11634v1", "method": "POST", "url": "/v1/responses", "body": {"model": "gpt-5-mini", "input": "You are a specialist research analyst in Web3, DeFi, cryptography, and distributed systems.\n\n    Your task:\n    From the paper below (Title + Summary + Link), evaluate how useful each paper is for understanding investment opportunities or technological advantages within the Web3 / crypto / DeFi ecosystem.\n    Rate each paper on a five-level scale: Highest / High / Medium / Low / Lowest.\n\n    \"Useful\" means:\n\n    - Improves understanding of new cryptographic primitives relevant to blockchain performance or security\n    - Enhances scalability: distributed systems, P2P networking, consensus mechanisms\n    - Advances in zero knowledge, MPC, PQC that could impact future L1/L2 chains\n    - DeFi modeling, AMMs, MEV, risk models, liquidity dynamics\n    - Smart contract security, attack vectors, economic incentives\n    - Token economics, mechanism design for decentralized systems\n    - Quantum threats to blockchain or cryptography\n    - Any breakthrough that meaningfully improves decentralization, scalability, privacy, or composability\n\n    Output instructions:\n\n    - Output each JSON object in JSON Lines format (one line per paper).\n\n    {\n        \"title\": title of the paper (in Japanese),\n        \"summary\": A concise summary of the paper (in Japanese),\n        \"impact_level\": \"Highest|High|Medium|Low|Lowest\",\n        \"why_matters\": An array (JSON array) containing 2\u20134 bullet points explaining why this paper matters for Web3 investment\n    }\n\n    - Do not output anything except valid JSON object in JSON Lines.\n    - \"title\", \"summary\", \"why_matters\" text in the output must be written in Japanese.\n\n    Paper:\n    title: FirecREST v2: lessons learned from redesigning an API for scalable HPC resource access\n    summary: Introducing FirecREST v2, the next generation of our open-source RESTful API for programmatic access to HPC resources. FirecREST v2 delivers a 100x performance improvement over its predecessor. This paper explores the lessons learned from redesigning FirecREST from the ground up, with a focus on integrating enhanced security and high throughput as core requirements.\n  We provide a detailed account of our systematic performance testing methodology, highlighting common bottlenecks in proxy-based APIs with intensive I/O operations. Key design and architectural changes that enabled these performance gains are presented. Finally, we demonstrate the impact of these improvements, supported by independent peer validation, and discuss opportunities for further improvements.\n    link: https://arxiv.org/abs/2512.11634v1\n    "}}
{"custom_id": "2506.18982v3", "method": "POST", "url": "/v1/responses", "body": {"model": "gpt-5-mini", "input": "You are a specialist research analyst in Web3, DeFi, cryptography, and distributed systems.\n\n    Your task:\n    From the paper below (Title + Summary + Link), evaluate how useful each paper is for understanding investment opportunities or technological advantages within the Web3 / crypto / DeFi ecosystem.\n    Rate each paper on a five-level scale: Highest / High / Medium / Low / Lowest.\n\n    \"Useful\" means:\n\n    - Improves understanding of new cryptographic primitives relevant to blockchain performance or security\n    - Enhances scalability: distributed systems, P2P networking, consensus mechanisms\n    - Advances in zero knowledge, MPC, PQC that could impact future L1/L2 chains\n    - DeFi modeling, AMMs, MEV, risk models, liquidity dynamics\n    - Smart contract security, attack vectors, economic incentives\n    - Token economics, mechanism design for decentralized systems\n    - Quantum threats to blockchain or cryptography\n    - Any breakthrough that meaningfully improves decentralization, scalability, privacy, or composability\n\n    Output instructions:\n\n    - Output each JSON object in JSON Lines format (one line per paper).\n\n    {\n        \"title\": title of the paper (in Japanese),\n        \"summary\": A concise summary of the paper (in Japanese),\n        \"impact_level\": \"Highest|High|Medium|Low|Lowest\",\n        \"why_matters\": An array (JSON array) containing 2\u20134 bullet points explaining why this paper matters for Web3 investment\n    }\n\n    - Do not output anything except valid JSON object in JSON Lines.\n    - \"title\", \"summary\", \"why_matters\" text in the output must be written in Japanese.\n\n    Paper:\n    title: First direct search for light dark matter interactions in a transition-edge sensor\n    summary: We propose the use of transition-edge sensor (TES) single-photon detectors as a simultaneous target and sensor for direct dark matter searches, and report results from the first search of this kind. We perform a 489 h science run with a TES device optimized for the detection of 1064 nm photons, with a mass of ~0.2 ng and an energy threshold of ~0.3 eV, and set new limits on dark matter interactions with both electrons and nucleons for dark matter with mass below the MeV scale. With their excellent energy resolution, TESs enable search strategies that are complementary to recent results from superconducting nanowire single-photon detectors and kinetic inductance detectors. We show that next-generation TES arrays hold promise to probe new regions of light dark matter parameter space.\n    link: https://arxiv.org/abs/2506.18982v3\n    "}}
{"custom_id": "2504.13141v3", "method": "POST", "url": "/v1/responses", "body": {"model": "gpt-5-mini", "input": "You are a specialist research analyst in Web3, DeFi, cryptography, and distributed systems.\n\n    Your task:\n    From the paper below (Title + Summary + Link), evaluate how useful each paper is for understanding investment opportunities or technological advantages within the Web3 / crypto / DeFi ecosystem.\n    Rate each paper on a five-level scale: Highest / High / Medium / Low / Lowest.\n\n    \"Useful\" means:\n\n    - Improves understanding of new cryptographic primitives relevant to blockchain performance or security\n    - Enhances scalability: distributed systems, P2P networking, consensus mechanisms\n    - Advances in zero knowledge, MPC, PQC that could impact future L1/L2 chains\n    - DeFi modeling, AMMs, MEV, risk models, liquidity dynamics\n    - Smart contract security, attack vectors, economic incentives\n    - Token economics, mechanism design for decentralized systems\n    - Quantum threats to blockchain or cryptography\n    - Any breakthrough that meaningfully improves decentralization, scalability, privacy, or composability\n\n    Output instructions:\n\n    - Output each JSON object in JSON Lines format (one line per paper).\n\n    {\n        \"title\": title of the paper (in Japanese),\n        \"summary\": A concise summary of the paper (in Japanese),\n        \"impact_level\": \"Highest|High|Medium|Low|Lowest\",\n        \"why_matters\": An array (JSON array) containing 2\u20134 bullet points explaining why this paper matters for Web3 investment\n    }\n\n    - Do not output anything except valid JSON object in JSON Lines.\n    - \"title\", \"summary\", \"why_matters\" text in the output must be written in Japanese.\n\n    Paper:\n    title: Complexity at Scale: A Quantitative Analysis of an Alibaba Microservice Deployment\n    summary: Microservice management and testbed research often rests on assumptions about deployments that have rarely been validated at production scale. While recent studies have begun to characterise production microservice deployments, they are often limited in breadth, do not compare findings across deployments, and lack consideration of the implications of findings for commonly held assumptions. We analyse a distributed tracing dataset from Alibaba's production microservice deployment to examine its scale, heterogeneity, and dynamicity. By comparing our findings to prior measurements of Meta's MSA we illustrate both convergent and divergent properties, clarifying which patterns may generalise. Our study reveals extreme architectural scale, long-tail distributions of workloads and dependencies, highly diverse functionality, substantial call graph variability, and pronounced time-varying behaviour which diverge from assumptions underlying research models and testbeds. We summarise how these observations challenge common assumptions in research on fault management, scaling, and testbed design, and outline recommendations for more realistic future approaches and evaluations.\n    link: https://arxiv.org/abs/2504.13141v3\n    "}}
{"custom_id": "2512.11613v1", "method": "POST", "url": "/v1/responses", "body": {"model": "gpt-5-mini", "input": "You are a specialist research analyst in Web3, DeFi, cryptography, and distributed systems.\n\n    Your task:\n    From the paper below (Title + Summary + Link), evaluate how useful each paper is for understanding investment opportunities or technological advantages within the Web3 / crypto / DeFi ecosystem.\n    Rate each paper on a five-level scale: Highest / High / Medium / Low / Lowest.\n\n    \"Useful\" means:\n\n    - Improves understanding of new cryptographic primitives relevant to blockchain performance or security\n    - Enhances scalability: distributed systems, P2P networking, consensus mechanisms\n    - Advances in zero knowledge, MPC, PQC that could impact future L1/L2 chains\n    - DeFi modeling, AMMs, MEV, risk models, liquidity dynamics\n    - Smart contract security, attack vectors, economic incentives\n    - Token economics, mechanism design for decentralized systems\n    - Quantum threats to blockchain or cryptography\n    - Any breakthrough that meaningfully improves decentralization, scalability, privacy, or composability\n\n    Output instructions:\n\n    - Output each JSON object in JSON Lines format (one line per paper).\n\n    {\n        \"title\": title of the paper (in Japanese),\n        \"summary\": A concise summary of the paper (in Japanese),\n        \"impact_level\": \"Highest|High|Medium|Low|Lowest\",\n        \"why_matters\": An array (JSON array) containing 2\u20134 bullet points explaining why this paper matters for Web3 investment\n    }\n\n    - Do not output anything except valid JSON object in JSON Lines.\n    - \"title\", \"summary\", \"why_matters\" text in the output must be written in Japanese.\n\n    Paper:\n    title: Boltzmann to Lindblad: Classical and Quantum Approaches to Out-of-Equilibrium Statistical Mechanics\n    summary: Open quantum systems play a central role in contemporary nanoscale technologies, including molecular electronics, quantum heat engines, quantum computation and information processing. A major theoretical challenge is to construct dynamical models that are simultaneously consistent with classical thermodynamics and complete positivity. In this work, we develop a framework that addresses this issue by extending classical stochastic dynamics to the quantum domain. We begin by formulating a generalized Langevin equation in which both friction and noise act symmetrically on the two Hamiltonian equations. From this, we derive a generalized Klein-Kramers equation expressed in terms of Poisson brackets, and we show that it admits the Boltzmann distribution as its stationary solution while satisfying the first and second laws of thermodynamics along individual trajectories. Applying canonical quantization to this classical framework yields two distinct quantum master equations, depending on whether the friction operators are taken to be Hermitian or non-Hermitian. By analyzing the dynamics of a harmonic oscillator, we determine the conditions under which these equations reduce to a Lindblad-type generator. Our results demonstrate that complete positivity is ensured only when friction and noise are included in both Hamiltonian equations, thus fully justifying the classical construction. Moreover, we find that the friction coefficients must satisfy the same positivity condition in both the Hermitian and non-Hermitian formulations, revealing a form of universality that transcends the specific operator representation. The formalism offers a versatile tool for deriving quantum versions of the thermodynamic laws and is directly applicable to a wide class of nonequilibrium nanoscale systems.\n    link: https://arxiv.org/abs/2512.11613v1\n    "}}
{"custom_id": "2512.11602v1", "method": "POST", "url": "/v1/responses", "body": {"model": "gpt-5-mini", "input": "You are a specialist research analyst in Web3, DeFi, cryptography, and distributed systems.\n\n    Your task:\n    From the paper below (Title + Summary + Link), evaluate how useful each paper is for understanding investment opportunities or technological advantages within the Web3 / crypto / DeFi ecosystem.\n    Rate each paper on a five-level scale: Highest / High / Medium / Low / Lowest.\n\n    \"Useful\" means:\n\n    - Improves understanding of new cryptographic primitives relevant to blockchain performance or security\n    - Enhances scalability: distributed systems, P2P networking, consensus mechanisms\n    - Advances in zero knowledge, MPC, PQC that could impact future L1/L2 chains\n    - DeFi modeling, AMMs, MEV, risk models, liquidity dynamics\n    - Smart contract security, attack vectors, economic incentives\n    - Token economics, mechanism design for decentralized systems\n    - Quantum threats to blockchain or cryptography\n    - Any breakthrough that meaningfully improves decentralization, scalability, privacy, or composability\n\n    Output instructions:\n\n    - Output each JSON object in JSON Lines format (one line per paper).\n\n    {\n        \"title\": title of the paper (in Japanese),\n        \"summary\": A concise summary of the paper (in Japanese),\n        \"impact_level\": \"Highest|High|Medium|Low|Lowest\",\n        \"why_matters\": An array (JSON array) containing 2\u20134 bullet points explaining why this paper matters for Web3 investment\n    }\n\n    - Do not output anything except valid JSON object in JSON Lines.\n    - \"title\", \"summary\", \"why_matters\" text in the output must be written in Japanese.\n\n    Paper:\n    title: Granite: Granular Runtime Enforcement for GitHub Actions Permissions\n    summary: Modern software projects use automated CI/CD pipelines to streamline their development, build, and deployment processes. GitHub Actions is a popular CI/CD platform that enables project maintainers to create custom workflows -- collections of jobs composed of sequential steps -- using reusable components known as actions. Wary of the security risks introduced by fully-privileged actions, GitHub provides a job-level permission model for controlling workflow access to repository resources. Unfortunately, this model is too coarse-grained to reduce the attack surface pertaining to permission misuse attacks: All actions within a job share the same permissions granted to the job. This violates the principle of least privilege and can lead to broader software supply chain attacks, whenever a compromised action exploits the granted permissions to compromise the repository resources. In this paper, we present Granite, a runtime proxy-based system that enforces fine-grained permissions for GitHub Actions at the step-level granularity within a job. Granite transparently monitors requests made by JavaScript and composite actions during workflow execution and checks them against predefined step-level policies at runtime. We evaluate Granite in terms of compatibility, security, and performance overhead using a dataset of 500 workflows comprising 12,916 jobs from the most-starred GitHub repositories that use GitHub Actions. Our analysis reveals that 52.7% of the jobs can be protected by Granite against permission misuse attacks. We evaluate Granite on 20 top-starred repositories (63 actions, 58 workflows), validate attack prevention using 10 permission misuse attacks across 42 overprivileged jobs, and measure an average overhead of 55% (3.67 seconds) per job, concluding that Granite effectively reduces CI/CD attack surfaces.\n    link: https://arxiv.org/abs/2512.11602v1\n    "}}
{"custom_id": "2512.11597v1", "method": "POST", "url": "/v1/responses", "body": {"model": "gpt-5-mini", "input": "You are a specialist research analyst in Web3, DeFi, cryptography, and distributed systems.\n\n    Your task:\n    From the paper below (Title + Summary + Link), evaluate how useful each paper is for understanding investment opportunities or technological advantages within the Web3 / crypto / DeFi ecosystem.\n    Rate each paper on a five-level scale: Highest / High / Medium / Low / Lowest.\n\n    \"Useful\" means:\n\n    - Improves understanding of new cryptographic primitives relevant to blockchain performance or security\n    - Enhances scalability: distributed systems, P2P networking, consensus mechanisms\n    - Advances in zero knowledge, MPC, PQC that could impact future L1/L2 chains\n    - DeFi modeling, AMMs, MEV, risk models, liquidity dynamics\n    - Smart contract security, attack vectors, economic incentives\n    - Token economics, mechanism design for decentralized systems\n    - Quantum threats to blockchain or cryptography\n    - Any breakthrough that meaningfully improves decentralization, scalability, privacy, or composability\n\n    Output instructions:\n\n    - Output each JSON object in JSON Lines format (one line per paper).\n\n    {\n        \"title\": title of the paper (in Japanese),\n        \"summary\": A concise summary of the paper (in Japanese),\n        \"impact_level\": \"Highest|High|Medium|Low|Lowest\",\n        \"why_matters\": An array (JSON array) containing 2\u20134 bullet points explaining why this paper matters for Web3 investment\n    }\n\n    - Do not output anything except valid JSON object in JSON Lines.\n    - \"title\", \"summary\", \"why_matters\" text in the output must be written in Japanese.\n\n    Paper:\n    title: A slightly improved upper bound for quantum statistical zero-knowledge\n    summary: The complexity class Quantum Statistical Zero-Knowledge ($\\mathsf{QSZK}$), introduced by Watrous (FOCS 2002) and later refined in Watrous (SICOMP, 2009), has the best known upper bound $\\mathsf{QIP(2)} \\cap \\text{co-}\\mathsf{QIP(2)}$, which was simplified following the inclusion $\\mathsf{QIP(2)} \\subseteq \\mathsf{PSPACE}$ established in Jain, Upadhyay, and Watrous (FOCS 2009). Here, $\\mathsf{QIP(2)}$ denotes the class of promise problems that admit two-message quantum interactive proof systems in which the honest prover is typically \\textit{computationally unbounded}, and $\\text{co-}\\mathsf{QIP(2)}$ denotes the complement of $\\mathsf{QIP(2)}$.\n  We slightly improve this upper bound to $\\mathsf{QIP(2)} \\cap \\text{co-}\\mathsf{QIP(2)}$ with a quantum linear-space honest prover. A similar improvement also applies to the upper bound for the non-interactive variant $\\mathsf{NIQSZK}$. Our main techniques are an algorithmic version of the Holevo-Helstrom measurement and the Uhlmann transform, both implementable in quantum linear space, implying polynomial-time complexity in the state dimension, using the recent space-efficient quantum singular value transformation of Le Gall, Liu, and Wang (CC, to appear).\n    link: https://arxiv.org/abs/2512.11597v1\n    "}}
{"custom_id": "2512.08432v2", "method": "POST", "url": "/v1/responses", "body": {"model": "gpt-5-mini", "input": "You are a specialist research analyst in Web3, DeFi, cryptography, and distributed systems.\n\n    Your task:\n    From the paper below (Title + Summary + Link), evaluate how useful each paper is for understanding investment opportunities or technological advantages within the Web3 / crypto / DeFi ecosystem.\n    Rate each paper on a five-level scale: Highest / High / Medium / Low / Lowest.\n\n    \"Useful\" means:\n\n    - Improves understanding of new cryptographic primitives relevant to blockchain performance or security\n    - Enhances scalability: distributed systems, P2P networking, consensus mechanisms\n    - Advances in zero knowledge, MPC, PQC that could impact future L1/L2 chains\n    - DeFi modeling, AMMs, MEV, risk models, liquidity dynamics\n    - Smart contract security, attack vectors, economic incentives\n    - Token economics, mechanism design for decentralized systems\n    - Quantum threats to blockchain or cryptography\n    - Any breakthrough that meaningfully improves decentralization, scalability, privacy, or composability\n\n    Output instructions:\n\n    - Output each JSON object in JSON Lines format (one line per paper).\n\n    {\n        \"title\": title of the paper (in Japanese),\n        \"summary\": A concise summary of the paper (in Japanese),\n        \"impact_level\": \"Highest|High|Medium|Low|Lowest\",\n        \"why_matters\": An array (JSON array) containing 2\u20134 bullet points explaining why this paper matters for Web3 investment\n    }\n\n    - Do not output anything except valid JSON object in JSON Lines.\n    - \"title\", \"summary\", \"why_matters\" text in the output must be written in Japanese.\n\n    Paper:\n    title: A Grover-compatible manifold optimization algorithm for quantum search\n    summary: Grover's algorithm is a fundamental quantum algorithm that offers a quadratic speedup for the unstructured search problem by alternately applying physically implementable oracle and diffusion operators. In this paper, we reformulate the unstructured search as a maximization problem on the unitary manifold and solve it via the Riemannian gradient ascent (RGA) method. To overcome the difficulty that generic RGA updates do not, in general, correspond to physically implementable quantum operators, we introduce Grover-compatible retractions to restrict RGA updates to valid oracle and diffusion operators. Theoretically, we establish a local Riemannian $\u03bc$-Polyak-\u0141ojasiewicz (PL) inequality with $\u03bc= \\tfrac{1}{2}$, which yields a linear convergence rate of $1 - \u03ba^{-1}$ toward the global solution. Here, the condition number $\u03ba= L_{\\mathrm{Rie}} / \u03bc$, where $L_{\\mathrm{Rie}}$ denotes the Riemannian Lipschitz constant of the gradient. Taking into account both the geometry of the unitary manifold and the special structure of the cost function, we show that $L_{\\mathrm{Rie}} = O(\\sqrt{N})$ for problem size $N = 2^n$. Consequently, the resulting iteration complexity is $O(\\sqrt{N} \\log(1/\\varepsilon))$ for attaining an $\\varepsilon$-accurate solution, which matches the quadratic speedup of $O(\\sqrt{N})$ achieved by Grover's algorithm. These results demonstrate that an optimization-based viewpoint can offer fresh conceptual insights and lead to new advances in the design of quantum algorithms.\n    link: https://arxiv.org/abs/2512.08432v2\n    "}}
{"custom_id": "2509.07469v2", "method": "POST", "url": "/v1/responses", "body": {"model": "gpt-5-mini", "input": "You are a specialist research analyst in Web3, DeFi, cryptography, and distributed systems.\n\n    Your task:\n    From the paper below (Title + Summary + Link), evaluate how useful each paper is for understanding investment opportunities or technological advantages within the Web3 / crypto / DeFi ecosystem.\n    Rate each paper on a five-level scale: Highest / High / Medium / Low / Lowest.\n\n    \"Useful\" means:\n\n    - Improves understanding of new cryptographic primitives relevant to blockchain performance or security\n    - Enhances scalability: distributed systems, P2P networking, consensus mechanisms\n    - Advances in zero knowledge, MPC, PQC that could impact future L1/L2 chains\n    - DeFi modeling, AMMs, MEV, risk models, liquidity dynamics\n    - Smart contract security, attack vectors, economic incentives\n    - Token economics, mechanism design for decentralized systems\n    - Quantum threats to blockchain or cryptography\n    - Any breakthrough that meaningfully improves decentralization, scalability, privacy, or composability\n\n    Output instructions:\n\n    - Output each JSON object in JSON Lines format (one line per paper).\n\n    {\n        \"title\": title of the paper (in Japanese),\n        \"summary\": A concise summary of the paper (in Japanese),\n        \"impact_level\": \"Highest|High|Medium|Low|Lowest\",\n        \"why_matters\": An array (JSON array) containing 2\u20134 bullet points explaining why this paper matters for Web3 investment\n    }\n\n    - Do not output anything except valid JSON object in JSON Lines.\n    - \"title\", \"summary\", \"why_matters\" text in the output must be written in Japanese.\n\n    Paper:\n    title: Steady state diagram of interacting fermionic atoms coupled to dissipative cavities\n    summary: We investigate fermionic atoms subjected to an optical lattice and coupled to a high finesse optical cavity with photon losses. A transverse pump beam introduces a coupling between the atoms and the cavity field. We explore the steady state phase diagram taking fluctuations around the mean-field of the atoms-cavity coupling into account. Our approach allows us to investigate both one- and higher-dimensional atomic systems. The fluctuations beyond mean-field lead to an effective temperature which changes the nature of the self-organization transition. We find a strong dependence of the results on the atomic filling, in particular when contrasting the behavior at low filling and at half filling. At low filling the transition to a self-organized phase takes place at a critical value of the pump strength. In the self-organized phase the cavity field takes a finite expectation value and the atoms show a modulation in the density. Surprisingly, at even larger pump strengths a strongly non-monotonous behavior of the temperature is found and hints towards effects of cavity cooling at many-body resonances. Additionally multiple self-organized stable solutions of the cavity field and the atoms occur, signaling the presence of a fluctuation-induced bistability, with the two solutions having different effective temperatures previously discussed in [Tolle et al., Phys. Rev. Lett. 134, 133602 (2025)]. In contrast, at half filling a bistable region arises at the self-organization transition already neglecting the fluctuations. The presence of the fluctuations induce an effective temperature as at lower filling and change the behavior of the transition and the steady states drastically. We analyze the properties of the occurring steady states of the coupled atoms-cavity system.\n    link: https://arxiv.org/abs/2509.07469v2\n    "}}
{"custom_id": "2512.11533v1", "method": "POST", "url": "/v1/responses", "body": {"model": "gpt-5-mini", "input": "You are a specialist research analyst in Web3, DeFi, cryptography, and distributed systems.\n\n    Your task:\n    From the paper below (Title + Summary + Link), evaluate how useful each paper is for understanding investment opportunities or technological advantages within the Web3 / crypto / DeFi ecosystem.\n    Rate each paper on a five-level scale: Highest / High / Medium / Low / Lowest.\n\n    \"Useful\" means:\n\n    - Improves understanding of new cryptographic primitives relevant to blockchain performance or security\n    - Enhances scalability: distributed systems, P2P networking, consensus mechanisms\n    - Advances in zero knowledge, MPC, PQC that could impact future L1/L2 chains\n    - DeFi modeling, AMMs, MEV, risk models, liquidity dynamics\n    - Smart contract security, attack vectors, economic incentives\n    - Token economics, mechanism design for decentralized systems\n    - Quantum threats to blockchain or cryptography\n    - Any breakthrough that meaningfully improves decentralization, scalability, privacy, or composability\n\n    Output instructions:\n\n    - Output each JSON object in JSON Lines format (one line per paper).\n\n    {\n        \"title\": title of the paper (in Japanese),\n        \"summary\": A concise summary of the paper (in Japanese),\n        \"impact_level\": \"Highest|High|Medium|Low|Lowest\",\n        \"why_matters\": An array (JSON array) containing 2\u20134 bullet points explaining why this paper matters for Web3 investment\n    }\n\n    - Do not output anything except valid JSON object in JSON Lines.\n    - \"title\", \"summary\", \"why_matters\" text in the output must be written in Japanese.\n\n    Paper:\n    title: The Lattice Schwinger Model and Its Quantum Simulation\n    summary: In this chapter we review results on the lattice Schwinger model. In par-ticular, we show how the effect of the anomaly is reproduced on the lattice. We connect these results to recent developments in the field of quantum simulation of interacting field theories. Schemes for the quantum simulation of (approximations of) Schwinger models are discussed.\n    link: https://arxiv.org/abs/2512.11533v1\n    "}}
{"custom_id": "2512.11532v1", "method": "POST", "url": "/v1/responses", "body": {"model": "gpt-5-mini", "input": "You are a specialist research analyst in Web3, DeFi, cryptography, and distributed systems.\n\n    Your task:\n    From the paper below (Title + Summary + Link), evaluate how useful each paper is for understanding investment opportunities or technological advantages within the Web3 / crypto / DeFi ecosystem.\n    Rate each paper on a five-level scale: Highest / High / Medium / Low / Lowest.\n\n    \"Useful\" means:\n\n    - Improves understanding of new cryptographic primitives relevant to blockchain performance or security\n    - Enhances scalability: distributed systems, P2P networking, consensus mechanisms\n    - Advances in zero knowledge, MPC, PQC that could impact future L1/L2 chains\n    - DeFi modeling, AMMs, MEV, risk models, liquidity dynamics\n    - Smart contract security, attack vectors, economic incentives\n    - Token economics, mechanism design for decentralized systems\n    - Quantum threats to blockchain or cryptography\n    - Any breakthrough that meaningfully improves decentralization, scalability, privacy, or composability\n\n    Output instructions:\n\n    - Output each JSON object in JSON Lines format (one line per paper).\n\n    {\n        \"title\": title of the paper (in Japanese),\n        \"summary\": A concise summary of the paper (in Japanese),\n        \"impact_level\": \"Highest|High|Medium|Low|Lowest\",\n        \"why_matters\": An array (JSON array) containing 2\u20134 bullet points explaining why this paper matters for Web3 investment\n    }\n\n    - Do not output anything except valid JSON object in JSON Lines.\n    - \"title\", \"summary\", \"why_matters\" text in the output must be written in Japanese.\n\n    Paper:\n    title: Parallax: Runtime Parallelization for Operator Fallbacks in Heterogeneous Edge Systems\n    summary: The growing demand for real-time DNN applications on edge devices necessitates faster inference of increasingly complex models. Although many devices include specialized accelerators (e.g., mobile GPUs), dynamic control-flow operators and unsupported kernels often fall back to CPU execution. Existing frameworks handle these fallbacks poorly, leaving CPU cores idle and causing high latency and memory spikes. We introduce Parallax, a framework that accelerates mobile DNN inference without model refactoring or custom operator implementations. Parallax first partitions the computation DAG to expose parallelism, then employs branch-aware memory management with dedicated arenas and buffer reuse to reduce runtime footprint. An adaptive scheduler executes branches according to device memory constraints, meanwhile, fine-grained subgraph control enables heterogeneous inference of dynamic models. By evaluating on five representative DNNs across three different mobile devices, Parallax achieves up to 46% latency reduction, maintains controlled memory overhead (26.5% on average), and delivers up to 30% energy savings compared with state-of-the-art frameworks, offering improvements aligned with the responsiveness demands of real-time mobile inference.\n    link: https://arxiv.org/abs/2512.11532v1\n    "}}
{"custom_id": "2511.20255v2", "method": "POST", "url": "/v1/responses", "body": {"model": "gpt-5-mini", "input": "You are a specialist research analyst in Web3, DeFi, cryptography, and distributed systems.\n\n    Your task:\n    From the paper below (Title + Summary + Link), evaluate how useful each paper is for understanding investment opportunities or technological advantages within the Web3 / crypto / DeFi ecosystem.\n    Rate each paper on a five-level scale: Highest / High / Medium / Low / Lowest.\n\n    \"Useful\" means:\n\n    - Improves understanding of new cryptographic primitives relevant to blockchain performance or security\n    - Enhances scalability: distributed systems, P2P networking, consensus mechanisms\n    - Advances in zero knowledge, MPC, PQC that could impact future L1/L2 chains\n    - DeFi modeling, AMMs, MEV, risk models, liquidity dynamics\n    - Smart contract security, attack vectors, economic incentives\n    - Token economics, mechanism design for decentralized systems\n    - Quantum threats to blockchain or cryptography\n    - Any breakthrough that meaningfully improves decentralization, scalability, privacy, or composability\n\n    Output instructions:\n\n    - Output each JSON object in JSON Lines format (one line per paper).\n\n    {\n        \"title\": title of the paper (in Japanese),\n        \"summary\": A concise summary of the paper (in Japanese),\n        \"impact_level\": \"Highest|High|Medium|Low|Lowest\",\n        \"why_matters\": An array (JSON array) containing 2\u20134 bullet points explaining why this paper matters for Web3 investment\n    }\n\n    - Do not output anything except valid JSON object in JSON Lines.\n    - \"title\", \"summary\", \"why_matters\" text in the output must be written in Japanese.\n\n    Paper:\n    title: Escaping AB caging via Floquet engineering: photo-induced long-range interference in an all-band-flat model\n    summary: Flat-band lattices hosting compact localized states are highly sensitive to external modulation, and the tailored design of a perturbation to imprint specific features becomes relevant. Here we show that periodic driving in the high-frequency regime transforms the all-flat-band diamond chain into one featuring two tunable quasi-flat bands and a residual flat band pinned at $E=0$. The interplay between lattice geometry and the symmetries of the driven system gives rise to drive-induced tunneling processes that redefine the interference conditions and open a controllable route to escaping Aharonov-Bohm caging. Under driving, the diamond chain effectively acquires the geometry of a dimerized lattice, exhibiting charge oscillations between opposite boundaries. This feature can be exploited to generate two-particle entanglement that is directly accessible experimentally. The resulting drive-engineered quasi-flat bands thus provide a versatile platform for manipulating quantum correlations, revealing a direct link between spectral fine structure and dynamical entanglement.\n    link: https://arxiv.org/abs/2511.20255v2\n    "}}
{"custom_id": "2512.11512v1", "method": "POST", "url": "/v1/responses", "body": {"model": "gpt-5-mini", "input": "You are a specialist research analyst in Web3, DeFi, cryptography, and distributed systems.\n\n    Your task:\n    From the paper below (Title + Summary + Link), evaluate how useful each paper is for understanding investment opportunities or technological advantages within the Web3 / crypto / DeFi ecosystem.\n    Rate each paper on a five-level scale: Highest / High / Medium / Low / Lowest.\n\n    \"Useful\" means:\n\n    - Improves understanding of new cryptographic primitives relevant to blockchain performance or security\n    - Enhances scalability: distributed systems, P2P networking, consensus mechanisms\n    - Advances in zero knowledge, MPC, PQC that could impact future L1/L2 chains\n    - DeFi modeling, AMMs, MEV, risk models, liquidity dynamics\n    - Smart contract security, attack vectors, economic incentives\n    - Token economics, mechanism design for decentralized systems\n    - Quantum threats to blockchain or cryptography\n    - Any breakthrough that meaningfully improves decentralization, scalability, privacy, or composability\n\n    Output instructions:\n\n    - Output each JSON object in JSON Lines format (one line per paper).\n\n    {\n        \"title\": title of the paper (in Japanese),\n        \"summary\": A concise summary of the paper (in Japanese),\n        \"impact_level\": \"Highest|High|Medium|Low|Lowest\",\n        \"why_matters\": An array (JSON array) containing 2\u20134 bullet points explaining why this paper matters for Web3 investment\n    }\n\n    - Do not output anything except valid JSON object in JSON Lines.\n    - \"title\", \"summary\", \"why_matters\" text in the output must be written in Japanese.\n\n    Paper:\n    title: Enhanced Pruning for Distributed Closeness Centrality under Multi-Packet Messaging\n    summary: Identifying central nodes using closeness centrality is a critical task in analyzing large-scale complex networks, yet its decentralized computation remains challenging due to high communication overhead. Existing distributed approximation techniques, such as pruning, often fail to fully mitigate the cost of exchanging numerous data packets in large network settings. In this paper, we introduce a novel enhancement to the distributed pruning method specifically designed to overcome this communication bottleneck. Our core contribution is a technique that leverages multi-packet messaging, allowing nodes to batch and transmit larger, consolidated data blocks. This approach significantly reduces the number of exchanged messages and minimizes data loss without compromising the accuracy of the centrality estimates. We demonstrate that our multi-packet approach substantially outperforms the original pruning technique in both message efficiency (fewer overall messages) and computation time, preserving the core approximation properties of the baseline method. While we observe a manageable trade-off in increased per-node memory usage and local overhead, our findings show that this is outweighed by the gains in communication efficiency, particularly for very large networks and complex packet structures. Our work offers a more scalable and efficient solution for decentralized closeness centrality computation, promising a significant step forward for large-scale network analysis.\n    link: https://arxiv.org/abs/2512.11512v1\n    "}}
{"custom_id": "2512.11484v1", "method": "POST", "url": "/v1/responses", "body": {"model": "gpt-5-mini", "input": "You are a specialist research analyst in Web3, DeFi, cryptography, and distributed systems.\n\n    Your task:\n    From the paper below (Title + Summary + Link), evaluate how useful each paper is for understanding investment opportunities or technological advantages within the Web3 / crypto / DeFi ecosystem.\n    Rate each paper on a five-level scale: Highest / High / Medium / Low / Lowest.\n\n    \"Useful\" means:\n\n    - Improves understanding of new cryptographic primitives relevant to blockchain performance or security\n    - Enhances scalability: distributed systems, P2P networking, consensus mechanisms\n    - Advances in zero knowledge, MPC, PQC that could impact future L1/L2 chains\n    - DeFi modeling, AMMs, MEV, risk models, liquidity dynamics\n    - Smart contract security, attack vectors, economic incentives\n    - Token economics, mechanism design for decentralized systems\n    - Quantum threats to blockchain or cryptography\n    - Any breakthrough that meaningfully improves decentralization, scalability, privacy, or composability\n\n    Output instructions:\n\n    - Output each JSON object in JSON Lines format (one line per paper).\n\n    {\n        \"title\": title of the paper (in Japanese),\n        \"summary\": A concise summary of the paper (in Japanese),\n        \"impact_level\": \"Highest|High|Medium|Low|Lowest\",\n        \"why_matters\": An array (JSON array) containing 2\u20134 bullet points explaining why this paper matters for Web3 investment\n    }\n\n    - Do not output anything except valid JSON object in JSON Lines.\n    - \"title\", \"summary\", \"why_matters\" text in the output must be written in Japanese.\n\n    Paper:\n    title: Capacitive Touchscreens at Risk: Recovering Handwritten Trajectory on Smartphone via Electromagnetic Emanations\n    summary: This paper reveals and exploits a critical security vulnerability: the electromagnetic (EM) side channel of capacitive touchscreens leaks sufficient information to recover fine-grained, continuous handwriting trajectories. We present Touchscreen Electromagnetic Side-channel Leakage Attack (TESLA), a non-contact attack framework that captures EM signals generated during on-screen writing and regresses them into two-dimensional (2D) handwriting trajectories in real time. Extensive evaluations across a variety of commercial off-the-shelf (COTS) smartphones show that TESLA achieves 77% character recognition accuracy and a Jaccard index of 0.74, demonstrating its capability to recover highly recognizable motion trajectories that closely resemble the original handwriting under realistic attack conditions.\n    link: https://arxiv.org/abs/2512.11484v1\n    "}}
{"custom_id": "2512.11482v1", "method": "POST", "url": "/v1/responses", "body": {"model": "gpt-5-mini", "input": "You are a specialist research analyst in Web3, DeFi, cryptography, and distributed systems.\n\n    Your task:\n    From the paper below (Title + Summary + Link), evaluate how useful each paper is for understanding investment opportunities or technological advantages within the Web3 / crypto / DeFi ecosystem.\n    Rate each paper on a five-level scale: Highest / High / Medium / Low / Lowest.\n\n    \"Useful\" means:\n\n    - Improves understanding of new cryptographic primitives relevant to blockchain performance or security\n    - Enhances scalability: distributed systems, P2P networking, consensus mechanisms\n    - Advances in zero knowledge, MPC, PQC that could impact future L1/L2 chains\n    - DeFi modeling, AMMs, MEV, risk models, liquidity dynamics\n    - Smart contract security, attack vectors, economic incentives\n    - Token economics, mechanism design for decentralized systems\n    - Quantum threats to blockchain or cryptography\n    - Any breakthrough that meaningfully improves decentralization, scalability, privacy, or composability\n\n    Output instructions:\n\n    - Output each JSON object in JSON Lines format (one line per paper).\n\n    {\n        \"title\": title of the paper (in Japanese),\n        \"summary\": A concise summary of the paper (in Japanese),\n        \"impact_level\": \"Highest|High|Medium|Low|Lowest\",\n        \"why_matters\": An array (JSON array) containing 2\u20134 bullet points explaining why this paper matters for Web3 investment\n    }\n\n    - Do not output anything except valid JSON object in JSON Lines.\n    - \"title\", \"summary\", \"why_matters\" text in the output must be written in Japanese.\n\n    Paper:\n    title: Towards Privacy-Preserving Code Generation: Differentially Private Code Language Models\n    summary: Large language models specialized for code (CodeLLMs) have demonstrated remarkable capabilities in generating code snippets, documentation, and test cases. However, despite their promising capabilities, CodeLLMs can inadvertently memorize and reproduce snippets from their training data, which poses risks of privacy breaches and intellectual property violations. These risks restrict the deployment of CodeLLMs in sensitive domains and limit their training datasets to publicly available sources. To mitigate the memorization risk without compromising their task performance, we apply Differential Privacy (DP) to CodeLLMs. To the best of our knowledge, this is the first comprehensive study that systematically evaluates the effectiveness of DP in CodeLLMs. DP adds calibrated noise to the training process to protect individual data points while still allowing the model to learn useful patterns. To this end, we first identify and understand the driving reasons of the memorization behaviour of the CodeLLMs during their fine-tuning. Then, to address this issue, we empirically evaluate the effect of DP on mitigating memorization while preserving code generation capabilities. Our findings show that DP substantially reduces memorization in CodeLLMs across all the tested snippet types. The snippet types most prone to memorization are also the most effectively mitigated by DP. Furthermore, we observe that DP slightly increases perplexity but preserves, and can even enhance, the code generation capabilities of CodeLLMs, which makes it feasible to apply DP in practice without significantly compromising model utility. Finally, we analyze the impact of DP on training efficiency and energy consumption, finding that DP does not significantly affect training time or energy usage, making it a practical choice for privacy-preserving CodeLLMs training.\n    link: https://arxiv.org/abs/2512.11482v1\n    "}}
{"custom_id": "2512.11466v1", "method": "POST", "url": "/v1/responses", "body": {"model": "gpt-5-mini", "input": "You are a specialist research analyst in Web3, DeFi, cryptography, and distributed systems.\n\n    Your task:\n    From the paper below (Title + Summary + Link), evaluate how useful each paper is for understanding investment opportunities or technological advantages within the Web3 / crypto / DeFi ecosystem.\n    Rate each paper on a five-level scale: Highest / High / Medium / Low / Lowest.\n\n    \"Useful\" means:\n\n    - Improves understanding of new cryptographic primitives relevant to blockchain performance or security\n    - Enhances scalability: distributed systems, P2P networking, consensus mechanisms\n    - Advances in zero knowledge, MPC, PQC that could impact future L1/L2 chains\n    - DeFi modeling, AMMs, MEV, risk models, liquidity dynamics\n    - Smart contract security, attack vectors, economic incentives\n    - Token economics, mechanism design for decentralized systems\n    - Quantum threats to blockchain or cryptography\n    - Any breakthrough that meaningfully improves decentralization, scalability, privacy, or composability\n\n    Output instructions:\n\n    - Output each JSON object in JSON Lines format (one line per paper).\n\n    {\n        \"title\": title of the paper (in Japanese),\n        \"summary\": A concise summary of the paper (in Japanese),\n        \"impact_level\": \"Highest|High|Medium|Low|Lowest\",\n        \"why_matters\": An array (JSON array) containing 2\u20134 bullet points explaining why this paper matters for Web3 investment\n    }\n\n    - Do not output anything except valid JSON object in JSON Lines.\n    - \"title\", \"summary\", \"why_matters\" text in the output must be written in Japanese.\n\n    Paper:\n    title: Spin-correlation dynamics: A semiclassical framework for nonlinear quantum magnetism\n    summary: Classical nonlinear theories are highly successful in describing far-from-equilibrium dynamics of magnets, encompassing phenomena such as parametric resonance, ultrafast switching, and even chaos. However, at ultrashort length and time scales, where quantum correlations become significant, these models inevitably break down. While numerous methods exist to simulate quantum many-body spin systems, they are often limited to near-equilibrium conditions, capture only short-time dynamics, or obscure the intuitive connection between nonlinear behavior and its geometric origin in the su(2) spin algebra. To advance nonlinear magnetism into the quantum regime, we develop a theory in which semiclassical spin correlations, rather than individual spins, serve as the fundamental dynamical variables. Defined on the bonds of a bipartite lattice, these correlations are inherently nonlocal, with dynamics following through a semiclassical mapping that preserves the original spin algebra. The resulting semiclassical theory captures nonlinear dynamics that are entirely nonclassical and naturally accommodates phenomenological damping at the level of correlations, which is typically challenging to include in quantum methods. As an application, we focus on Heisenberg antiferromagnets, which feature significant quantum effects. We predict nonlinear scaling of the mean frequency of quantum oscillations in the N\u00e9el state with the spin quantum number S. These have no classical analog and exhibit features reminiscent of nonlinear parametric resonance, fully confirmed by exact diagonalization. The predicted dynamical features are embedded in the geometric structure of the semiclassical phase space of spin correlations, making their physical origin much more transparent than in full quantum methods. With this, semiclassical spin-correlation dynamics provide a foundation for exploring nonlinear quantum magnetism.\n    link: https://arxiv.org/abs/2512.11466v1\n    "}}
{"custom_id": "2505.01012v3", "method": "POST", "url": "/v1/responses", "body": {"model": "gpt-5-mini", "input": "You are a specialist research analyst in Web3, DeFi, cryptography, and distributed systems.\n\n    Your task:\n    From the paper below (Title + Summary + Link), evaluate how useful each paper is for understanding investment opportunities or technological advantages within the Web3 / crypto / DeFi ecosystem.\n    Rate each paper on a five-level scale: Highest / High / Medium / Low / Lowest.\n\n    \"Useful\" means:\n\n    - Improves understanding of new cryptographic primitives relevant to blockchain performance or security\n    - Enhances scalability: distributed systems, P2P networking, consensus mechanisms\n    - Advances in zero knowledge, MPC, PQC that could impact future L1/L2 chains\n    - DeFi modeling, AMMs, MEV, risk models, liquidity dynamics\n    - Smart contract security, attack vectors, economic incentives\n    - Token economics, mechanism design for decentralized systems\n    - Quantum threats to blockchain or cryptography\n    - Any breakthrough that meaningfully improves decentralization, scalability, privacy, or composability\n\n    Output instructions:\n\n    - Output each JSON object in JSON Lines format (one line per paper).\n\n    {\n        \"title\": title of the paper (in Japanese),\n        \"summary\": A concise summary of the paper (in Japanese),\n        \"impact_level\": \"Highest|High|Medium|Low|Lowest\",\n        \"why_matters\": An array (JSON array) containing 2\u20134 bullet points explaining why this paper matters for Web3 investment\n    }\n\n    - Do not output anything except valid JSON object in JSON Lines.\n    - \"title\", \"summary\", \"why_matters\" text in the output must be written in Japanese.\n\n    Paper:\n    title: Quantum Support Vector Regression for Robust Anomaly Detection\n    summary: Anomaly Detection (AD) is critical in data analysis, particularly within the domain of IT security. In this study, we explore the potential of Quantum Machine Learning for application to AD with special focus on the robustness to noise and adversarial attacks. We build upon previous work on Quantum Support Vector Regression (QSVR) for semisupervised AD by conducting a comprehensive benchmark on IBM quantum hardware using eleven datasets. Our results demonstrate that QSVR achieves strong classification performance and even outperforms the noiseless simulation on two of these datasets. Moreover, we investigate the influence of - in the NISQ-era inevitable - quantum noise on the performance of the QSVR. Our findings reveal that the model exhibits robustness to depolarizing, phase damping, phase flip, and bit flip noise, while amplitude damping and miscalibration noise prove to be more disruptive. Finally, we explore the domain of Quantum Adversarial Machine Learning by demonstrating that QSVR is highly vulnerable to adversarial attacks, with neither quantum noise nor adversarial training improving the model's robustness against such attacks.\n    link: https://arxiv.org/abs/2505.01012v3\n    "}}
{"custom_id": "2512.11431v1", "method": "POST", "url": "/v1/responses", "body": {"model": "gpt-5-mini", "input": "You are a specialist research analyst in Web3, DeFi, cryptography, and distributed systems.\n\n    Your task:\n    From the paper below (Title + Summary + Link), evaluate how useful each paper is for understanding investment opportunities or technological advantages within the Web3 / crypto / DeFi ecosystem.\n    Rate each paper on a five-level scale: Highest / High / Medium / Low / Lowest.\n\n    \"Useful\" means:\n\n    - Improves understanding of new cryptographic primitives relevant to blockchain performance or security\n    - Enhances scalability: distributed systems, P2P networking, consensus mechanisms\n    - Advances in zero knowledge, MPC, PQC that could impact future L1/L2 chains\n    - DeFi modeling, AMMs, MEV, risk models, liquidity dynamics\n    - Smart contract security, attack vectors, economic incentives\n    - Token economics, mechanism design for decentralized systems\n    - Quantum threats to blockchain or cryptography\n    - Any breakthrough that meaningfully improves decentralization, scalability, privacy, or composability\n\n    Output instructions:\n\n    - Output each JSON object in JSON Lines format (one line per paper).\n\n    {\n        \"title\": title of the paper (in Japanese),\n        \"summary\": A concise summary of the paper (in Japanese),\n        \"impact_level\": \"Highest|High|Medium|Low|Lowest\",\n        \"why_matters\": An array (JSON array) containing 2\u20134 bullet points explaining why this paper matters for Web3 investment\n    }\n\n    - Do not output anything except valid JSON object in JSON Lines.\n    - \"title\", \"summary\", \"why_matters\" text in the output must be written in Japanese.\n\n    Paper:\n    title: Proving DNSSEC Correctness: A Formal Approach to Secure Domain Name Resolution\n    summary: The Domain Name System Security Extensions (DNSSEC) are critical for preventing DNS spoofing, yet its specifications contain ambiguities and vulnerabilities that elude traditional \"break-and-fix\" approaches. A holistic, foundational security analysis of the protocol has thus remained an open problem. This paper introduces DNSSECVerif, the first framework for comprehensive, automated formal security analysis of the DNSSEC protocol suite. Built on the SAPIC+ symbolic verifier, our high-fidelity model captures protocol-level interactions, including cryptographic operations and stateful caching with fine-grained concurrency control. Using DNSSECVerif, we formally prove four of DNSSEC's core security guarantees and uncover critical ambiguities in the standards--notably, the insecure coexistence of NSEC and NSEC3. Our model also automatically rediscovers three classes of known attacks, demonstrating fundamental weaknesses in the protocol design. To bridge the model-to-reality gap, we validate our findings through targeted testing of mainstream DNS software and a large-scale measurement study of over 2.2 million open resolvers, confirming the real-world impact of these flaws. Our work provides crucial, evidence-based recommendations for hardening DNSSEC specifications and implementations.\n    link: https://arxiv.org/abs/2512.11431v1\n    "}}
{"custom_id": "2511.17144v2", "method": "POST", "url": "/v1/responses", "body": {"model": "gpt-5-mini", "input": "You are a specialist research analyst in Web3, DeFi, cryptography, and distributed systems.\n\n    Your task:\n    From the paper below (Title + Summary + Link), evaluate how useful each paper is for understanding investment opportunities or technological advantages within the Web3 / crypto / DeFi ecosystem.\n    Rate each paper on a five-level scale: Highest / High / Medium / Low / Lowest.\n\n    \"Useful\" means:\n\n    - Improves understanding of new cryptographic primitives relevant to blockchain performance or security\n    - Enhances scalability: distributed systems, P2P networking, consensus mechanisms\n    - Advances in zero knowledge, MPC, PQC that could impact future L1/L2 chains\n    - DeFi modeling, AMMs, MEV, risk models, liquidity dynamics\n    - Smart contract security, attack vectors, economic incentives\n    - Token economics, mechanism design for decentralized systems\n    - Quantum threats to blockchain or cryptography\n    - Any breakthrough that meaningfully improves decentralization, scalability, privacy, or composability\n\n    Output instructions:\n\n    - Output each JSON object in JSON Lines format (one line per paper).\n\n    {\n        \"title\": title of the paper (in Japanese),\n        \"summary\": A concise summary of the paper (in Japanese),\n        \"impact_level\": \"Highest|High|Medium|Low|Lowest\",\n        \"why_matters\": An array (JSON array) containing 2\u20134 bullet points explaining why this paper matters for Web3 investment\n    }\n\n    - Do not output anything except valid JSON object in JSON Lines.\n    - \"title\", \"summary\", \"why_matters\" text in the output must be written in Japanese.\n\n    Paper:\n    title: Anyon Quasilocalization in a Quasicrystalline Toric Code\n    summary: An exactly solvable model of a quantum spin liquid on a quasicrystal, akin to Kitaev's honeycomb model, was introduced in Kim \\textit{et al.}, \\href{https://doi.org/10.1103/PhysRevB.110.214438}{\\text{Phys. Rev. B} \\textbf{110}, 214438 (2024)}. It was shown that in contrast to the translationally invariant models, such a spin liquid stabilizes a gapped ground state with a finite irrational flux density. In this work, we analyze the strong bond-anisotropic limit of the model and demonstrate that the aperiodic lattice geometry naturally generates a hierarchy of exponentially separated coupling constants in the resulting toric code Hamiltonian. Furthermore, a perturbative magnetic field leads to anomalous localization properties where an anyonic excitation sequentially delocalizes over subsets of sites forming equipotential contours in the quasicrystal. In addition, certain background flux configurations, together with the underlying geometry, give rise to strictly localized eigenstates that remain decoupled from the rest of the spectrum. Using numerical studies, we uncover the key mechanisms responsible for this unconventional localization behavior. Our study highlights that topologically ordered phases, in the presence of geometrical constraints can lead to highly anomalous localization properties of fractionalized charges.\n    link: https://arxiv.org/abs/2511.17144v2\n    "}}
{"custom_id": "2512.11358v1", "method": "POST", "url": "/v1/responses", "body": {"model": "gpt-5-mini", "input": "You are a specialist research analyst in Web3, DeFi, cryptography, and distributed systems.\n\n    Your task:\n    From the paper below (Title + Summary + Link), evaluate how useful each paper is for understanding investment opportunities or technological advantages within the Web3 / crypto / DeFi ecosystem.\n    Rate each paper on a five-level scale: Highest / High / Medium / Low / Lowest.\n\n    \"Useful\" means:\n\n    - Improves understanding of new cryptographic primitives relevant to blockchain performance or security\n    - Enhances scalability: distributed systems, P2P networking, consensus mechanisms\n    - Advances in zero knowledge, MPC, PQC that could impact future L1/L2 chains\n    - DeFi modeling, AMMs, MEV, risk models, liquidity dynamics\n    - Smart contract security, attack vectors, economic incentives\n    - Token economics, mechanism design for decentralized systems\n    - Quantum threats to blockchain or cryptography\n    - Any breakthrough that meaningfully improves decentralization, scalability, privacy, or composability\n\n    Output instructions:\n\n    - Output each JSON object in JSON Lines format (one line per paper).\n\n    {\n        \"title\": title of the paper (in Japanese),\n        \"summary\": A concise summary of the paper (in Japanese),\n        \"impact_level\": \"Highest|High|Medium|Low|Lowest\",\n        \"why_matters\": An array (JSON array) containing 2\u20134 bullet points explaining why this paper matters for Web3 investment\n    }\n\n    - Do not output anything except valid JSON object in JSON Lines.\n    - \"title\", \"summary\", \"why_matters\" text in the output must be written in Japanese.\n\n    Paper:\n    title: Why cut-and-choose quantum state verification cannot be both efficient and secure\n    summary: Quantum state verification plays a vital role in many quantum cryptographic protocols, as it allows the use of quantum states from untrusted sources. While some progress has been made in this direction, the question of whether the most prevalent type of quantum state verification, namely cut-and-choose verification, can be efficient and secure, is still not answered in full generality. In this work, we show a fundamental limit for quantum state verification for all cut-and-choose approaches used to verify arbitrary quantum states. We provide a no-go result showing that the cut-and-choose techniques cannot lead to quantum state verification protocols that are both efficient in the number of rounds and secure. We show this trade-off for stand-alone and composable security, where the scaling of the lower bound for the security parameters renders cut-and-choose quantum state verification effectively unusable.\n    link: https://arxiv.org/abs/2512.11358v1\n    "}}
{"custom_id": "2501.05928v3", "method": "POST", "url": "/v1/responses", "body": {"model": "gpt-5-mini", "input": "You are a specialist research analyst in Web3, DeFi, cryptography, and distributed systems.\n\n    Your task:\n    From the paper below (Title + Summary + Link), evaluate how useful each paper is for understanding investment opportunities or technological advantages within the Web3 / crypto / DeFi ecosystem.\n    Rate each paper on a five-level scale: Highest / High / Medium / Low / Lowest.\n\n    \"Useful\" means:\n\n    - Improves understanding of new cryptographic primitives relevant to blockchain performance or security\n    - Enhances scalability: distributed systems, P2P networking, consensus mechanisms\n    - Advances in zero knowledge, MPC, PQC that could impact future L1/L2 chains\n    - DeFi modeling, AMMs, MEV, risk models, liquidity dynamics\n    - Smart contract security, attack vectors, economic incentives\n    - Token economics, mechanism design for decentralized systems\n    - Quantum threats to blockchain or cryptography\n    - Any breakthrough that meaningfully improves decentralization, scalability, privacy, or composability\n\n    Output instructions:\n\n    - Output each JSON object in JSON Lines format (one line per paper).\n\n    {\n        \"title\": title of the paper (in Japanese),\n        \"summary\": A concise summary of the paper (in Japanese),\n        \"impact_level\": \"Highest|High|Medium|Low|Lowest\",\n        \"why_matters\": An array (JSON array) containing 2\u20134 bullet points explaining why this paper matters for Web3 investment\n    }\n\n    - Do not output anything except valid JSON object in JSON Lines.\n    - \"title\", \"summary\", \"why_matters\" text in the output must be written in Japanese.\n\n    Paper:\n    title: Towards Backdoor Stealthiness in Model Parameter Space\n    summary: Recent research on backdoor stealthiness focuses mainly on indistinguishable triggers in input space and inseparable backdoor representations in feature space, aiming to circumvent backdoor defenses that examine these respective spaces. However, existing backdoor attacks are typically designed to resist a specific type of backdoor defense without considering the diverse range of defense mechanisms. Based on this observation, we pose a natural question: Are current backdoor attacks truly a real-world threat when facing diverse practical defenses?\n  To answer this question, we examine 12 common backdoor attacks that focus on input-space or feature-space stealthiness and 17 diverse representative defenses. Surprisingly, we reveal a critical blind spot: Backdoor attacks designed to be stealthy in input and feature spaces can be mitigated by examining backdoored models in parameter space. To investigate the underlying causes behind this common vulnerability, we study the characteristics of backdoor attacks in the parameter space. Notably, we find that input- and feature-space attacks introduce prominent backdoor-related neurons in parameter space, which are not thoroughly considered by current backdoor attacks. Taking comprehensive stealthiness into account, we propose a novel supply-chain attack called Grond. Grond limits the parameter changes by a simple yet effective module, Adversarial Backdoor Injection (ABI), which adaptively increases the parameter-space stealthiness during the backdoor injection. Extensive experiments demonstrate that Grond outperforms all 12 backdoor attacks against state-of-the-art (including adaptive) defenses on CIFAR-10, GTSRB, and a subset of ImageNet. In addition, we show that ABI consistently improves the effectiveness of common backdoor attacks.\n    link: https://arxiv.org/abs/2501.05928v3\n    "}}
{"custom_id": "2512.11316v1", "method": "POST", "url": "/v1/responses", "body": {"model": "gpt-5-mini", "input": "You are a specialist research analyst in Web3, DeFi, cryptography, and distributed systems.\n\n    Your task:\n    From the paper below (Title + Summary + Link), evaluate how useful each paper is for understanding investment opportunities or technological advantages within the Web3 / crypto / DeFi ecosystem.\n    Rate each paper on a five-level scale: Highest / High / Medium / Low / Lowest.\n\n    \"Useful\" means:\n\n    - Improves understanding of new cryptographic primitives relevant to blockchain performance or security\n    - Enhances scalability: distributed systems, P2P networking, consensus mechanisms\n    - Advances in zero knowledge, MPC, PQC that could impact future L1/L2 chains\n    - DeFi modeling, AMMs, MEV, risk models, liquidity dynamics\n    - Smart contract security, attack vectors, economic incentives\n    - Token economics, mechanism design for decentralized systems\n    - Quantum threats to blockchain or cryptography\n    - Any breakthrough that meaningfully improves decentralization, scalability, privacy, or composability\n\n    Output instructions:\n\n    - Output each JSON object in JSON Lines format (one line per paper).\n\n    {\n        \"title\": title of the paper (in Japanese),\n        \"summary\": A concise summary of the paper (in Japanese),\n        \"impact_level\": \"Highest|High|Medium|Low|Lowest\",\n        \"why_matters\": An array (JSON array) containing 2\u20134 bullet points explaining why this paper matters for Web3 investment\n    }\n\n    - Do not output anything except valid JSON object in JSON Lines.\n    - \"title\", \"summary\", \"why_matters\" text in the output must be written in Japanese.\n\n    Paper:\n    title: Visualisation for the CIS benchmark scanning results\n    summary: In this paper, we introduce GraphSecure, a web application that provides advanced analysis and visualisation of security scanning results. GraphSecure enables users to initiate scans for their AWS account, validate them against specific Center for Internet Security (CIS) Benchmarks and return results, showcase those returned results in the form of statistical charts and warn the users about their account status.\n    link: https://arxiv.org/abs/2512.11316v1\n    "}}
{"custom_id": "2507.05578v2", "method": "POST", "url": "/v1/responses", "body": {"model": "gpt-5-mini", "input": "You are a specialist research analyst in Web3, DeFi, cryptography, and distributed systems.\n\n    Your task:\n    From the paper below (Title + Summary + Link), evaluate how useful each paper is for understanding investment opportunities or technological advantages within the Web3 / crypto / DeFi ecosystem.\n    Rate each paper on a five-level scale: Highest / High / Medium / Low / Lowest.\n\n    \"Useful\" means:\n\n    - Improves understanding of new cryptographic primitives relevant to blockchain performance or security\n    - Enhances scalability: distributed systems, P2P networking, consensus mechanisms\n    - Advances in zero knowledge, MPC, PQC that could impact future L1/L2 chains\n    - DeFi modeling, AMMs, MEV, risk models, liquidity dynamics\n    - Smart contract security, attack vectors, economic incentives\n    - Token economics, mechanism design for decentralized systems\n    - Quantum threats to blockchain or cryptography\n    - Any breakthrough that meaningfully improves decentralization, scalability, privacy, or composability\n\n    Output instructions:\n\n    - Output each JSON object in JSON Lines format (one line per paper).\n\n    {\n        \"title\": title of the paper (in Japanese),\n        \"summary\": A concise summary of the paper (in Japanese),\n        \"impact_level\": \"Highest|High|Medium|Low|Lowest\",\n        \"why_matters\": An array (JSON array) containing 2\u20134 bullet points explaining why this paper matters for Web3 investment\n    }\n\n    - Do not output anything except valid JSON object in JSON Lines.\n    - \"title\", \"summary\", \"why_matters\" text in the output must be written in Japanese.\n\n    Paper:\n    title: The Landscape of Memorization in LLMs: Mechanisms, Measurement, and Mitigation\n    summary: Large Language Models (LLMs) have demonstrated remarkable capabilities across a wide range of tasks, yet they also exhibit memorization of their training data. This phenomenon raises critical questions about model behavior, privacy risks, and the boundary between learning and memorization. Addressing these concerns, this paper synthesizes recent studies and investigates the landscape of memorization, the factors influencing it, and methods for its detection and mitigation. We explore key drivers, including training data duplication, training dynamics, and fine-tuning procedures that influence data memorization. In addition, we examine methodologies such as prefix-based extraction, membership inference, and adversarial prompting, assessing their effectiveness in detecting and measuring memorized content. Beyond technical analysis, we also explore the broader implications of memorization, including the legal and ethical implications. Finally, we discuss mitigation strategies, including data cleaning, differential privacy, and post-training unlearning, while highlighting open challenges in balancing the need to minimize harmful memorization with model utility. This paper provides a comprehensive overview of the current state of research on LLM memorization across technical, privacy, and performance dimensions, identifying critical directions for future work.\n    link: https://arxiv.org/abs/2507.05578v2\n    "}}
{"custom_id": "2512.11306v1", "method": "POST", "url": "/v1/responses", "body": {"model": "gpt-5-mini", "input": "You are a specialist research analyst in Web3, DeFi, cryptography, and distributed systems.\n\n    Your task:\n    From the paper below (Title + Summary + Link), evaluate how useful each paper is for understanding investment opportunities or technological advantages within the Web3 / crypto / DeFi ecosystem.\n    Rate each paper on a five-level scale: Highest / High / Medium / Low / Lowest.\n\n    \"Useful\" means:\n\n    - Improves understanding of new cryptographic primitives relevant to blockchain performance or security\n    - Enhances scalability: distributed systems, P2P networking, consensus mechanisms\n    - Advances in zero knowledge, MPC, PQC that could impact future L1/L2 chains\n    - DeFi modeling, AMMs, MEV, risk models, liquidity dynamics\n    - Smart contract security, attack vectors, economic incentives\n    - Token economics, mechanism design for decentralized systems\n    - Quantum threats to blockchain or cryptography\n    - Any breakthrough that meaningfully improves decentralization, scalability, privacy, or composability\n\n    Output instructions:\n\n    - Output each JSON object in JSON Lines format (one line per paper).\n\n    {\n        \"title\": title of the paper (in Japanese),\n        \"summary\": A concise summary of the paper (in Japanese),\n        \"impact_level\": \"Highest|High|Medium|Low|Lowest\",\n        \"why_matters\": An array (JSON array) containing 2\u20134 bullet points explaining why this paper matters for Web3 investment\n    }\n\n    - Do not output anything except valid JSON object in JSON Lines.\n    - \"title\", \"summary\", \"why_matters\" text in the output must be written in Japanese.\n\n    Paper:\n    title: RollMux: Phase-Level Multiplexing for Disaggregated RL Post-Training\n    summary: Rollout-training disaggregation is emerging as the standard architecture for Reinforcement Learning (RL) post-training, where memory-bound rollout and compute-bound training are physically disaggregated onto purpose-built clusters to maximize hardware efficiency. However, the strict synchronization required by on-policy algorithms introduces severe dependency bubbles, forcing one cluster to idle while the dependent phase is running on the other. We present RollMux, a cluster scheduling framework that reclaims these bubbles through cross-cluster orchestration. RollMux is built on the insight that the structural idleness of one job can be effectively utilized by the active phase of another. To realize this, we introduce the co-execution group abstraction, which partitions the cluster into isolated locality domains. This abstraction enables a two-tier scheduling architecture: an inter-group scheduler that optimizes job placement using conservative stochastic planning, and an intra-group scheduler that orchestrates a provably optimal round-robin schedule. The group abstraction also imposes a residency constraint, ensuring that massive model states remain cached in host memory to enable \"warm-star\" context switching. We evaluate RollMux on a production-scale testbed with 328 H20 and 328 H800 GPUs. RollMux improves cost efficiency by 1.84x over standard disaggregation and 1.38x over state-of-the-art co-located baselines, all while achieving 100% SLO attainment.\n    link: https://arxiv.org/abs/2512.11306v1\n    "}}
{"custom_id": "2512.11286v1", "method": "POST", "url": "/v1/responses", "body": {"model": "gpt-5-mini", "input": "You are a specialist research analyst in Web3, DeFi, cryptography, and distributed systems.\n\n    Your task:\n    From the paper below (Title + Summary + Link), evaluate how useful each paper is for understanding investment opportunities or technological advantages within the Web3 / crypto / DeFi ecosystem.\n    Rate each paper on a five-level scale: Highest / High / Medium / Low / Lowest.\n\n    \"Useful\" means:\n\n    - Improves understanding of new cryptographic primitives relevant to blockchain performance or security\n    - Enhances scalability: distributed systems, P2P networking, consensus mechanisms\n    - Advances in zero knowledge, MPC, PQC that could impact future L1/L2 chains\n    - DeFi modeling, AMMs, MEV, risk models, liquidity dynamics\n    - Smart contract security, attack vectors, economic incentives\n    - Token economics, mechanism design for decentralized systems\n    - Quantum threats to blockchain or cryptography\n    - Any breakthrough that meaningfully improves decentralization, scalability, privacy, or composability\n\n    Output instructions:\n\n    - Output each JSON object in JSON Lines format (one line per paper).\n\n    {\n        \"title\": title of the paper (in Japanese),\n        \"summary\": A concise summary of the paper (in Japanese),\n        \"impact_level\": \"Highest|High|Medium|Low|Lowest\",\n        \"why_matters\": An array (JSON array) containing 2\u20134 bullet points explaining why this paper matters for Web3 investment\n    }\n\n    - Do not output anything except valid JSON object in JSON Lines.\n    - \"title\", \"summary\", \"why_matters\" text in the output must be written in Japanese.\n\n    Paper:\n    title: A Survey of OAM-Encoded High-Dimensional Quantum Key Distribution: Foundations, Experiments, and Recent Trends\n    summary: High-dimensional quantum key distribution (HD-QKD) enhances information efficiency and noise tolerance by encoding data in large Hilbert spaces. The orbital angular momentum (OAM) of light provides a scalable basis for such encoding and supports high-dimensional photonic communication. Practical OAM-based implementations remain constrained by challenges in state generation, transmission, and detection. This survey offers a consolidated overview of OAM-encoded HD-QKD, outlining fundamental principles, representative experiments, and system-level limitations. Recent progress in hybrid encodings, mode sorting, adaptive optics, and TF, CV, MDI, and DI frameworks is summarized with emphasis on practical feasibility.\n    link: https://arxiv.org/abs/2512.11286v1\n    "}}
{"custom_id": "2506.16666v3", "method": "POST", "url": "/v1/responses", "body": {"model": "gpt-5-mini", "input": "You are a specialist research analyst in Web3, DeFi, cryptography, and distributed systems.\n\n    Your task:\n    From the paper below (Title + Summary + Link), evaluate how useful each paper is for understanding investment opportunities or technological advantages within the Web3 / crypto / DeFi ecosystem.\n    Rate each paper on a five-level scale: Highest / High / Medium / Low / Lowest.\n\n    \"Useful\" means:\n\n    - Improves understanding of new cryptographic primitives relevant to blockchain performance or security\n    - Enhances scalability: distributed systems, P2P networking, consensus mechanisms\n    - Advances in zero knowledge, MPC, PQC that could impact future L1/L2 chains\n    - DeFi modeling, AMMs, MEV, risk models, liquidity dynamics\n    - Smart contract security, attack vectors, economic incentives\n    - Token economics, mechanism design for decentralized systems\n    - Quantum threats to blockchain or cryptography\n    - Any breakthrough that meaningfully improves decentralization, scalability, privacy, or composability\n\n    Output instructions:\n\n    - Output each JSON object in JSON Lines format (one line per paper).\n\n    {\n        \"title\": title of the paper (in Japanese),\n        \"summary\": A concise summary of the paper (in Japanese),\n        \"impact_level\": \"Highest|High|Medium|Low|Lowest\",\n        \"why_matters\": An array (JSON array) containing 2\u20134 bullet points explaining why this paper matters for Web3 investment\n    }\n\n    - Do not output anything except valid JSON object in JSON Lines.\n    - \"title\", \"summary\", \"why_matters\" text in the output must be written in Japanese.\n\n    Paper:\n    title: The Hitchhiker's Guide to Efficient, End-to-End, and Tight DP Auditing\n    summary: In this paper, we systematize research on auditing Differential Privacy (DP) techniques, aiming to identify key insights and open challenges. First, we introduce a comprehensive framework for reviewing work in the field and establish three cross-contextual desiderata that DP audits should target -- namely, efficiency, end-to-end-ness, and tightness. Then, we systematize the modes of operation of state-of-the-art DP auditing techniques, including threat models, attacks, and evaluation functions. This allows us to highlight key details overlooked by prior work, analyze the limiting factors to achieving the three desiderata, and identify open research problems. Overall, our work provides a reusable and systematic methodology geared to assess progress in the field and identify friction points and future directions for our community to focus on.\n    link: https://arxiv.org/abs/2506.16666v3\n    "}}
{"custom_id": "2512.09385v2", "method": "POST", "url": "/v1/responses", "body": {"model": "gpt-5-mini", "input": "You are a specialist research analyst in Web3, DeFi, cryptography, and distributed systems.\n\n    Your task:\n    From the paper below (Title + Summary + Link), evaluate how useful each paper is for understanding investment opportunities or technological advantages within the Web3 / crypto / DeFi ecosystem.\n    Rate each paper on a five-level scale: Highest / High / Medium / Low / Lowest.\n\n    \"Useful\" means:\n\n    - Improves understanding of new cryptographic primitives relevant to blockchain performance or security\n    - Enhances scalability: distributed systems, P2P networking, consensus mechanisms\n    - Advances in zero knowledge, MPC, PQC that could impact future L1/L2 chains\n    - DeFi modeling, AMMs, MEV, risk models, liquidity dynamics\n    - Smart contract security, attack vectors, economic incentives\n    - Token economics, mechanism design for decentralized systems\n    - Quantum threats to blockchain or cryptography\n    - Any breakthrough that meaningfully improves decentralization, scalability, privacy, or composability\n\n    Output instructions:\n\n    - Output each JSON object in JSON Lines format (one line per paper).\n\n    {\n        \"title\": title of the paper (in Japanese),\n        \"summary\": A concise summary of the paper (in Japanese),\n        \"impact_level\": \"Highest|High|Medium|Low|Lowest\",\n        \"why_matters\": An array (JSON array) containing 2\u20134 bullet points explaining why this paper matters for Web3 investment\n    }\n\n    - Do not output anything except valid JSON object in JSON Lines.\n    - \"title\", \"summary\", \"why_matters\" text in the output must be written in Japanese.\n\n    Paper:\n    title: BugSweeper: Function-Level Detection of Smart Contract Vulnerabilities Using Graph Neural Networks\n    summary: The rapid growth of Ethereum has made it more important to quickly and accurately detect smart contract vulnerabilities. While machine-learning-based methods have shown some promise, many still rely on rule-based preprocessing designed by domain experts. Rule-based preprocessing methods often discard crucial context from the source code, potentially causing certain vulnerabilities to be overlooked and limiting adaptability to newly emerging threats. We introduce BugSweeper, an end-to-end deep learning framework that detects vulnerabilities directly from the source code without manual engineering. BugSweeper represents each Solidity function as a Function-Level Abstract Syntax Graph (FLAG), a novel graph that combines its Abstract Syntax Tree (AST) with enriched control-flow and data-flow semantics. Then, our two-stage Graph Neural Network (GNN) analyzes these graphs. The first-stage GNN filters noise from the syntax graphs, while the second-stage GNN conducts high-level reasoning to detect diverse vulnerabilities. Extensive experiments on real-world contracts show that BugSweeper significantly outperforms all state-of-the-art detection methods. By removing the need for handcrafted rules, our approach offers a robust, automated, and scalable solution for securing smart contracts without any dependence on security experts.\n    link: https://arxiv.org/abs/2512.09385v2\n    "}}
{"custom_id": "2512.11272v1", "method": "POST", "url": "/v1/responses", "body": {"model": "gpt-5-mini", "input": "You are a specialist research analyst in Web3, DeFi, cryptography, and distributed systems.\n\n    Your task:\n    From the paper below (Title + Summary + Link), evaluate how useful each paper is for understanding investment opportunities or technological advantages within the Web3 / crypto / DeFi ecosystem.\n    Rate each paper on a five-level scale: Highest / High / Medium / Low / Lowest.\n\n    \"Useful\" means:\n\n    - Improves understanding of new cryptographic primitives relevant to blockchain performance or security\n    - Enhances scalability: distributed systems, P2P networking, consensus mechanisms\n    - Advances in zero knowledge, MPC, PQC that could impact future L1/L2 chains\n    - DeFi modeling, AMMs, MEV, risk models, liquidity dynamics\n    - Smart contract security, attack vectors, economic incentives\n    - Token economics, mechanism design for decentralized systems\n    - Quantum threats to blockchain or cryptography\n    - Any breakthrough that meaningfully improves decentralization, scalability, privacy, or composability\n\n    Output instructions:\n\n    - Output each JSON object in JSON Lines format (one line per paper).\n\n    {\n        \"title\": title of the paper (in Japanese),\n        \"summary\": A concise summary of the paper (in Japanese),\n        \"impact_level\": \"Highest|High|Medium|Low|Lowest\",\n        \"why_matters\": An array (JSON array) containing 2\u20134 bullet points explaining why this paper matters for Web3 investment\n    }\n\n    - Do not output anything except valid JSON object in JSON Lines.\n    - \"title\", \"summary\", \"why_matters\" text in the output must be written in Japanese.\n\n    Paper:\n    title: Vision-Based Learning for Cyberattack Detection in Blockchain Smart Contracts and Transactions\n    summary: Blockchain technology has experienced rapid growth and has been widely adopted across various sectors, including healthcare, finance, and energy. However, blockchain platforms remain vulnerable to a broad range of cyberattacks, particularly those aimed at exploiting transactions and smart contracts (SCs) to steal digital assets or compromise system integrity. To address this issue, we propose a novel and effective framework for detecting cyberattacks within blockchain systems. Our framework begins with a preprocessing tool that uses Natural Language Processing (NLP) techniques to transform key features of blockchain transactions into image representations. These images are then analyzed through vision-based analysis using Vision Transformers (ViT), a recent advancement in computer vision known for its superior ability to capture complex patterns and semantic relationships. By integrating NLP-based preprocessing with vision-based learning, our framework can detect a wide variety of attack types. Experimental evaluations on benchmark datasets demonstrate that our approach significantly outperforms existing state-of-the-art methods in terms of both accuracy (achieving 99.5%) and robustness in cyberattack detection for blockchain transactions and SCs.\n    link: https://arxiv.org/abs/2512.11272v1\n    "}}
{"custom_id": "2512.11269v1", "method": "POST", "url": "/v1/responses", "body": {"model": "gpt-5-mini", "input": "You are a specialist research analyst in Web3, DeFi, cryptography, and distributed systems.\n\n    Your task:\n    From the paper below (Title + Summary + Link), evaluate how useful each paper is for understanding investment opportunities or technological advantages within the Web3 / crypto / DeFi ecosystem.\n    Rate each paper on a five-level scale: Highest / High / Medium / Low / Lowest.\n\n    \"Useful\" means:\n\n    - Improves understanding of new cryptographic primitives relevant to blockchain performance or security\n    - Enhances scalability: distributed systems, P2P networking, consensus mechanisms\n    - Advances in zero knowledge, MPC, PQC that could impact future L1/L2 chains\n    - DeFi modeling, AMMs, MEV, risk models, liquidity dynamics\n    - Smart contract security, attack vectors, economic incentives\n    - Token economics, mechanism design for decentralized systems\n    - Quantum threats to blockchain or cryptography\n    - Any breakthrough that meaningfully improves decentralization, scalability, privacy, or composability\n\n    Output instructions:\n\n    - Output each JSON object in JSON Lines format (one line per paper).\n\n    {\n        \"title\": title of the paper (in Japanese),\n        \"summary\": A concise summary of the paper (in Japanese),\n        \"impact_level\": \"Highest|High|Medium|Low|Lowest\",\n        \"why_matters\": An array (JSON array) containing 2\u20134 bullet points explaining why this paper matters for Web3 investment\n    }\n\n    - Do not output anything except valid JSON object in JSON Lines.\n    - \"title\", \"summary\", \"why_matters\" text in the output must be written in Japanese.\n\n    Paper:\n    title: A Scalable Multi-GPU Framework for Encrypted Large-Model Inference\n    summary: Encrypted AI using fully homomorphic encryption (FHE) provides strong privacy guarantees; but its slow performance has limited practical deployment. Recent works proposed ASICs to accelerate FHE, but require expensive advanced manufacturing processes that constrain their accessibility. GPUs are a far more accessible platform, but achieving ASIC-level performance using GPUs has remained elusive. Furthermore, state-of-the-art approaches primarily focus on small models that fit comfortably within a single device. Supporting large models such as LLMs in FHE introduces a dramatic increase in computational complexity that requires optimized GPU kernels, along with managing terabyte-scale memory footprints that far exceed the capacity of a single GPU. This paper presents Cerium, a multi-GPU framework for FHE inference on large models. Cerium integrates a domain-specific language, an optimizing compiler, and a runtime system to automatically generate high-performance GPU kernels, manage terabyte-scale memory footprints, and parallelize computation across multiple GPUs. It introduces new IR constructs, compiler passes, sparse polynomial representations, memory-efficient data layouts, and communication-aware parallelization techniques that together enable encrypted inference for models ranging from small CNNs to Llama3-8B. We build Cerium on NVIDIA GPUs and demonstrate significant performance gains. For small models, Cerium outperforms expert-written hand-optimized GPU libraries by up to 2.25 times. Cerium achieves performance competitive with state-of-the-art FHE ASICs, outright matching prior FHE ASIC CraterLake. It is the first GPU system to execute bootstrapping in under 10 milliseconds, achieving 7.5 milliseconds, and is the first to demonstrate encrypted inference for BERT-Base and Llama3-8B in 8 seconds and 134 seconds, respectively.\n    link: https://arxiv.org/abs/2512.11269v1\n    "}}
{"custom_id": "2511.20975v2", "method": "POST", "url": "/v1/responses", "body": {"model": "gpt-5-mini", "input": "You are a specialist research analyst in Web3, DeFi, cryptography, and distributed systems.\n\n    Your task:\n    From the paper below (Title + Summary + Link), evaluate how useful each paper is for understanding investment opportunities or technological advantages within the Web3 / crypto / DeFi ecosystem.\n    Rate each paper on a five-level scale: Highest / High / Medium / Low / Lowest.\n\n    \"Useful\" means:\n\n    - Improves understanding of new cryptographic primitives relevant to blockchain performance or security\n    - Enhances scalability: distributed systems, P2P networking, consensus mechanisms\n    - Advances in zero knowledge, MPC, PQC that could impact future L1/L2 chains\n    - DeFi modeling, AMMs, MEV, risk models, liquidity dynamics\n    - Smart contract security, attack vectors, economic incentives\n    - Token economics, mechanism design for decentralized systems\n    - Quantum threats to blockchain or cryptography\n    - Any breakthrough that meaningfully improves decentralization, scalability, privacy, or composability\n\n    Output instructions:\n\n    - Output each JSON object in JSON Lines format (one line per paper).\n\n    {\n        \"title\": title of the paper (in Japanese),\n        \"summary\": A concise summary of the paper (in Japanese),\n        \"impact_level\": \"Highest|High|Medium|Low|Lowest\",\n        \"why_matters\": An array (JSON array) containing 2\u20134 bullet points explaining why this paper matters for Web3 investment\n    }\n\n    - Do not output anything except valid JSON object in JSON Lines.\n    - \"title\", \"summary\", \"why_matters\" text in the output must be written in Japanese.\n\n    Paper:\n    title: Aragog: Just-in-Time Model Routing for Scalable Serving of Agentic Workflows\n    summary: Agentic workflows have emerged as a powerful paradigm for solving complex, multi-stage tasks, but serving them at scale is computationally expensive given the many LLM inferences that each request must pass through. Configuration selection, or the cost-aware assignment of workflow agents to specific LLMs, can reduce these costs, but existing approaches bind configuration decisions before request execution, making them ill-suited for the heterogeneous and lengthy execution of workflows. Specifically, system loads can fluctuate rapidly and substantially during a request's lifetime, causing fixed configurations to quickly become suboptimal. We present Aragog, a system that progressively adapts a request's configuration throughout its execution to match runtime dynamics. To make this practical despite the massive space of workflow configurations, Aragog decouples the problem into two core elements -- a one-time routing step that identifies all accuracy-preserving configurations, and a cheap per-stage scheduler that selects among them using up-to-date system observations -- and introduces novel strategies to accelerate each. Across diverse workflows and model families, Aragog increases maximum serving throughput by 50.0--217.0\\% and reduces median latency by 32.5--78.9\\% at peak request rates, while maintaining accuracy comparable to the most expensive configurations.\n    link: https://arxiv.org/abs/2511.20975v2\n    "}}
{"custom_id": "2508.14319v2", "method": "POST", "url": "/v1/responses", "body": {"model": "gpt-5-mini", "input": "You are a specialist research analyst in Web3, DeFi, cryptography, and distributed systems.\n\n    Your task:\n    From the paper below (Title + Summary + Link), evaluate how useful each paper is for understanding investment opportunities or technological advantages within the Web3 / crypto / DeFi ecosystem.\n    Rate each paper on a five-level scale: Highest / High / Medium / Low / Lowest.\n\n    \"Useful\" means:\n\n    - Improves understanding of new cryptographic primitives relevant to blockchain performance or security\n    - Enhances scalability: distributed systems, P2P networking, consensus mechanisms\n    - Advances in zero knowledge, MPC, PQC that could impact future L1/L2 chains\n    - DeFi modeling, AMMs, MEV, risk models, liquidity dynamics\n    - Smart contract security, attack vectors, economic incentives\n    - Token economics, mechanism design for decentralized systems\n    - Quantum threats to blockchain or cryptography\n    - Any breakthrough that meaningfully improves decentralization, scalability, privacy, or composability\n\n    Output instructions:\n\n    - Output each JSON object in JSON Lines format (one line per paper).\n\n    {\n        \"title\": title of the paper (in Japanese),\n        \"summary\": A concise summary of the paper (in Japanese),\n        \"impact_level\": \"Highest|High|Medium|Low|Lowest\",\n        \"why_matters\": An array (JSON array) containing 2\u20134 bullet points explaining why this paper matters for Web3 investment\n    }\n\n    - Do not output anything except valid JSON object in JSON Lines.\n    - \"title\", \"summary\", \"why_matters\" text in the output must be written in Japanese.\n\n    Paper:\n    title: SSSP-Del: Fully Dynamic Distributed Algorithm for Single-Source Shortest Path\n    summary: Modern graphs are both large and dynamic, presenting significant challenges for fundamental queries, such as the Single-Source Shortest Path (SSSP) problem. Naively recomputing the SSSP tree after each topology change is prohibitively expensive, causing on-demand computation to suffer from high latency. Existing dynamic SSSP algorithms often cannot simultaneously handle both edge additions and deletions, operate in distributed memory, and provide low-latency query results. To address these challenges, this paper presents SSSP-Del, a new vertex-centric, asynchronous, and fully distributed algorithm for dynamic SSSP. Operating in a shared-nothing architecture, our algorithm processes streams of both edge insertions and deletions. We conduct a comprehensive evaluation on large real-world and synthetic graphs with millions of vertices, and provide a thorough analysis by evaluating result latency, solution stability, and throughput.\n    link: https://arxiv.org/abs/2508.14319v2\n    "}}
{"custom_id": "2512.11233v1", "method": "POST", "url": "/v1/responses", "body": {"model": "gpt-5-mini", "input": "You are a specialist research analyst in Web3, DeFi, cryptography, and distributed systems.\n\n    Your task:\n    From the paper below (Title + Summary + Link), evaluate how useful each paper is for understanding investment opportunities or technological advantages within the Web3 / crypto / DeFi ecosystem.\n    Rate each paper on a five-level scale: Highest / High / Medium / Low / Lowest.\n\n    \"Useful\" means:\n\n    - Improves understanding of new cryptographic primitives relevant to blockchain performance or security\n    - Enhances scalability: distributed systems, P2P networking, consensus mechanisms\n    - Advances in zero knowledge, MPC, PQC that could impact future L1/L2 chains\n    - DeFi modeling, AMMs, MEV, risk models, liquidity dynamics\n    - Smart contract security, attack vectors, economic incentives\n    - Token economics, mechanism design for decentralized systems\n    - Quantum threats to blockchain or cryptography\n    - Any breakthrough that meaningfully improves decentralization, scalability, privacy, or composability\n\n    Output instructions:\n\n    - Output each JSON object in JSON Lines format (one line per paper).\n\n    {\n        \"title\": title of the paper (in Japanese),\n        \"summary\": A concise summary of the paper (in Japanese),\n        \"impact_level\": \"Highest|High|Medium|Low|Lowest\",\n        \"why_matters\": An array (JSON array) containing 2\u20134 bullet points explaining why this paper matters for Web3 investment\n    }\n\n    - Do not output anything except valid JSON object in JSON Lines.\n    - \"title\", \"summary\", \"why_matters\" text in the output must be written in Japanese.\n\n    Paper:\n    title: On Shor's conjecture on the accessible information of quantum dichotomies\n    summary: Around the turn of the century, Shor formulated his well-known and still-open conjecture stating that the accessible information of any quantum dichotomy, that is the maximum amount of classical information that can be decoded from a binary quantum encoding, is attained by a von Neumann measurement. A quarter of a century later, new developments on the Lorenz curves of quantum dichotomies in the field of quantum majorization and statistical comparison may provide the key to unlock such a longstanding open problem. Here, we first investigate the tradeoff relations between accessible information and guessing probability in the binary case, thus disproving the claimed monotonicity of the former quantity in the latter that, if true, would have settled Shor's problem in the qubit case. Our second result is to provide a state-dependent generalization of extremality for quantum measurements, to characterize state-dependent extremality for qubit dichotomies, and to apply such results to tighten previous results on the accessible information of qubit dichotomies.\n    link: https://arxiv.org/abs/2512.11233v1\n    "}}
{"custom_id": "2512.11230v1", "method": "POST", "url": "/v1/responses", "body": {"model": "gpt-5-mini", "input": "You are a specialist research analyst in Web3, DeFi, cryptography, and distributed systems.\n\n    Your task:\n    From the paper below (Title + Summary + Link), evaluate how useful each paper is for understanding investment opportunities or technological advantages within the Web3 / crypto / DeFi ecosystem.\n    Rate each paper on a five-level scale: Highest / High / Medium / Low / Lowest.\n\n    \"Useful\" means:\n\n    - Improves understanding of new cryptographic primitives relevant to blockchain performance or security\n    - Enhances scalability: distributed systems, P2P networking, consensus mechanisms\n    - Advances in zero knowledge, MPC, PQC that could impact future L1/L2 chains\n    - DeFi modeling, AMMs, MEV, risk models, liquidity dynamics\n    - Smart contract security, attack vectors, economic incentives\n    - Token economics, mechanism design for decentralized systems\n    - Quantum threats to blockchain or cryptography\n    - Any breakthrough that meaningfully improves decentralization, scalability, privacy, or composability\n\n    Output instructions:\n\n    - Output each JSON object in JSON Lines format (one line per paper).\n\n    {\n        \"title\": title of the paper (in Japanese),\n        \"summary\": A concise summary of the paper (in Japanese),\n        \"impact_level\": \"Highest|High|Medium|Low|Lowest\",\n        \"why_matters\": An array (JSON array) containing 2\u20134 bullet points explaining why this paper matters for Web3 investment\n    }\n\n    - Do not output anything except valid JSON object in JSON Lines.\n    - \"title\", \"summary\", \"why_matters\" text in the output must be written in Japanese.\n\n    Paper:\n    title: Distributed Resource Allocation and Application Deployment in Mesh Edge Networks\n    summary: Virtual Network Embedding (VNE) approaches typically assume static or slowly-changing network topologies, but emerging applications require deployment in mobile environments where traditional methods become insufficient. This work extends VNE to constrained mesh networks of mobile edge devices, addressing the unique challenges of rapid topology changes and limited resources. We develop models incorporating device capabilities, connectivity, mobility and energy constraints to evaluate optimal deployment strategies for mobile edge environments. Our approach handles the dynamic nature of mobile networks through three allocation strategies: an integer linear program for optimal allocation, a greedy heuristic for immediate deployment, and a multi-objective genetic algorithm for balanced optimization. Our initial evaluation analyzes application acceptance rates, resource utilization, and latency performance under resource limitations. Results demonstrate improvements over traditional approaches, providing a foundation for VNE deployment in highly mobile environments.\n    link: https://arxiv.org/abs/2512.11230v1\n    "}}
{"custom_id": "2504.21228v2", "method": "POST", "url": "/v1/responses", "body": {"model": "gpt-5-mini", "input": "You are a specialist research analyst in Web3, DeFi, cryptography, and distributed systems.\n\n    Your task:\n    From the paper below (Title + Summary + Link), evaluate how useful each paper is for understanding investment opportunities or technological advantages within the Web3 / crypto / DeFi ecosystem.\n    Rate each paper on a five-level scale: Highest / High / Medium / Low / Lowest.\n\n    \"Useful\" means:\n\n    - Improves understanding of new cryptographic primitives relevant to blockchain performance or security\n    - Enhances scalability: distributed systems, P2P networking, consensus mechanisms\n    - Advances in zero knowledge, MPC, PQC that could impact future L1/L2 chains\n    - DeFi modeling, AMMs, MEV, risk models, liquidity dynamics\n    - Smart contract security, attack vectors, economic incentives\n    - Token economics, mechanism design for decentralized systems\n    - Quantum threats to blockchain or cryptography\n    - Any breakthrough that meaningfully improves decentralization, scalability, privacy, or composability\n\n    Output instructions:\n\n    - Output each JSON object in JSON Lines format (one line per paper).\n\n    {\n        \"title\": title of the paper (in Japanese),\n        \"summary\": A concise summary of the paper (in Japanese),\n        \"impact_level\": \"Highest|High|Medium|Low|Lowest\",\n        \"why_matters\": An array (JSON array) containing 2\u20134 bullet points explaining why this paper matters for Web3 investment\n    }\n\n    - Do not output anything except valid JSON object in JSON Lines.\n    - \"title\", \"summary\", \"why_matters\" text in the output must be written in Japanese.\n\n    Paper:\n    title: CachePrune: Neural-Based Attribution Defense Against Indirect Prompt Injection Attacks\n    summary: Large Language Models (LLMs) are susceptible to indirect prompt injection attacks, in which the model inadvertently responds to task messages injected within the prompt context. This vulnerability stems from LLMs' inability to distinguish between data and instructions within a prompt. In this paper, we propose CachePrune, a defense method that identifies and prunes task-triggering neurons from the KV cache of the input prompt context. By pruning such neurons, we encourage the LLM to interpret the input prompt context purely as data rather than as cues for instruction following. To identify these neurons, we introduce a neural attribution mechanism guided by a preferential attribution loss, which enables effective attribution with only a few samples while preserving response quality after pruning. We further enhance the efficacy of neural attribution by leveraging an observed triggering effect inherent in the model's response generation behavior. Notably, our approach does not impose additional formatting on the prompt or introduce extra test-time LLM calls. Experiments show that CachePrune can significantly reduce attack success rates while maintaining clean response quality.\n    link: https://arxiv.org/abs/2504.21228v2\n    "}}
{"custom_id": "2303.13775v3", "method": "POST", "url": "/v1/responses", "body": {"model": "gpt-5-mini", "input": "You are a specialist research analyst in Web3, DeFi, cryptography, and distributed systems.\n\n    Your task:\n    From the paper below (Title + Summary + Link), evaluate how useful each paper is for understanding investment opportunities or technological advantages within the Web3 / crypto / DeFi ecosystem.\n    Rate each paper on a five-level scale: Highest / High / Medium / Low / Lowest.\n\n    \"Useful\" means:\n\n    - Improves understanding of new cryptographic primitives relevant to blockchain performance or security\n    - Enhances scalability: distributed systems, P2P networking, consensus mechanisms\n    - Advances in zero knowledge, MPC, PQC that could impact future L1/L2 chains\n    - DeFi modeling, AMMs, MEV, risk models, liquidity dynamics\n    - Smart contract security, attack vectors, economic incentives\n    - Token economics, mechanism design for decentralized systems\n    - Quantum threats to blockchain or cryptography\n    - Any breakthrough that meaningfully improves decentralization, scalability, privacy, or composability\n\n    Output instructions:\n\n    - Output each JSON object in JSON Lines format (one line per paper).\n\n    {\n        \"title\": title of the paper (in Japanese),\n        \"summary\": A concise summary of the paper (in Japanese),\n        \"impact_level\": \"Highest|High|Medium|Low|Lowest\",\n        \"why_matters\": An array (JSON array) containing 2\u20134 bullet points explaining why this paper matters for Web3 investment\n    }\n\n    - Do not output anything except valid JSON object in JSON Lines.\n    - \"title\", \"summary\", \"why_matters\" text in the output must be written in Japanese.\n\n    Paper:\n    title: GSplit: Scaling Graph Neural Network Training on Large Graphs via Split-Parallelism\n    summary: Graph neural networks (GNNs), an emerging class of machine learning models for graphs, have gained popularity for their superior performance in various graph analytical tasks. Mini-batch training is commonly used to train GNNs on large graphs, and data parallelism is the standard approach to scale mini-batch training across multiple GPUs. Data parallel approaches contain redundant work as subgraphs sampled by different GPUs contain significant overlap. To address this issue, we introduce a hybrid parallel mini-batch training paradigm called split parallelism. Split parallelism avoids redundant work by splitting the sampling, loading, and training of each mini-batch across multiple GPUs. Split parallelism, however, introduces communication overheads that can be more than the savings from removing redundant work. We further present a lightweight partitioning algorithm that probabilistically minimizes these overheads. We implement split parallelism in GSplit and show that it outperforms state-of-the-art mini-batch training systems like DGL, Quiver, and $P^3$.\n    link: https://arxiv.org/abs/2303.13775v3\n    "}}
{"custom_id": "2512.11200v1", "method": "POST", "url": "/v1/responses", "body": {"model": "gpt-5-mini", "input": "You are a specialist research analyst in Web3, DeFi, cryptography, and distributed systems.\n\n    Your task:\n    From the paper below (Title + Summary + Link), evaluate how useful each paper is for understanding investment opportunities or technological advantages within the Web3 / crypto / DeFi ecosystem.\n    Rate each paper on a five-level scale: Highest / High / Medium / Low / Lowest.\n\n    \"Useful\" means:\n\n    - Improves understanding of new cryptographic primitives relevant to blockchain performance or security\n    - Enhances scalability: distributed systems, P2P networking, consensus mechanisms\n    - Advances in zero knowledge, MPC, PQC that could impact future L1/L2 chains\n    - DeFi modeling, AMMs, MEV, risk models, liquidity dynamics\n    - Smart contract security, attack vectors, economic incentives\n    - Token economics, mechanism design for decentralized systems\n    - Quantum threats to blockchain or cryptography\n    - Any breakthrough that meaningfully improves decentralization, scalability, privacy, or composability\n\n    Output instructions:\n\n    - Output each JSON object in JSON Lines format (one line per paper).\n\n    {\n        \"title\": title of the paper (in Japanese),\n        \"summary\": A concise summary of the paper (in Japanese),\n        \"impact_level\": \"Highest|High|Medium|Low|Lowest\",\n        \"why_matters\": An array (JSON array) containing 2\u20134 bullet points explaining why this paper matters for Web3 investment\n    }\n\n    - Do not output anything except valid JSON object in JSON Lines.\n    - \"title\", \"summary\", \"why_matters\" text in the output must be written in Japanese.\n\n    Paper:\n    title: Theoretical Foundations of GPU-Native Compilation for Rapid Code Iteration\n    summary: Current AI code generation systems suffer from significant latency bottlenecks due to CPU-GPU data transfers during compilation, execution, and testing phases. We establish theoretical foundations for three complementary approaches to GPU-native compilation that eliminate these transfers: (1) parallel traditional compilation adapted for GPU execution, (2) neural compilation using learned sequence-to-sequence translation with probabilistic verification, and (3) hybrid architectures combining both strategies. We derive latency and energy bounds demonstrating potential speedups of 10-100x for code iteration cycles. Our analysis shows that traditional GPU compilation provides 2-5x improvements through transfer elimination, neural compilation achieves 10-100x speedups via massive parallelism, and hybrid approaches offer practical deployment paths with guaranteed correctness. We formalize the probabilistic verification framework that enables trading compilation accuracy for parallel exploration, and discuss implications for self-improving AI systems and future analog computing substrates.\n    link: https://arxiv.org/abs/2512.11200v1\n    "}}
{"custom_id": "2509.02447v2", "method": "POST", "url": "/v1/responses", "body": {"model": "gpt-5-mini", "input": "You are a specialist research analyst in Web3, DeFi, cryptography, and distributed systems.\n\n    Your task:\n    From the paper below (Title + Summary + Link), evaluate how useful each paper is for understanding investment opportunities or technological advantages within the Web3 / crypto / DeFi ecosystem.\n    Rate each paper on a five-level scale: Highest / High / Medium / Low / Lowest.\n\n    \"Useful\" means:\n\n    - Improves understanding of new cryptographic primitives relevant to blockchain performance or security\n    - Enhances scalability: distributed systems, P2P networking, consensus mechanisms\n    - Advances in zero knowledge, MPC, PQC that could impact future L1/L2 chains\n    - DeFi modeling, AMMs, MEV, risk models, liquidity dynamics\n    - Smart contract security, attack vectors, economic incentives\n    - Token economics, mechanism design for decentralized systems\n    - Quantum threats to blockchain or cryptography\n    - Any breakthrough that meaningfully improves decentralization, scalability, privacy, or composability\n\n    Output instructions:\n\n    - Output each JSON object in JSON Lines format (one line per paper).\n\n    {\n        \"title\": title of the paper (in Japanese),\n        \"summary\": A concise summary of the paper (in Japanese),\n        \"impact_level\": \"Highest|High|Medium|Low|Lowest\",\n        \"why_matters\": An array (JSON array) containing 2\u20134 bullet points explaining why this paper matters for Web3 investment\n    }\n\n    - Do not output anything except valid JSON object in JSON Lines.\n    - \"title\", \"summary\", \"why_matters\" text in the output must be written in Japanese.\n\n    Paper:\n    title: An Efficient and Adaptive Watermark Detection System with Tile-based Error Correction\n    summary: Efficient and reliable detection of generated images is critical for the responsible deployment of generative models. Existing approaches primarily focus on improving detection accuracy and robustness under various image transformations and adversarial manipulations, yet they largely overlook the efficiency challenges of watermark detection across large-scale image collections. To address this gap, we propose QRMark, an efficient and adaptive end-to-end method for detecting embedded image watermarks. The core idea of QRMark is to combine QR Code-inspired error correction with tailored tiling techniques to improve detection efficiency while preserving accuracy and robustness. At the algorithmic level, QRMark employs a Reed-Solomon error correction mechanism to mitigate the accuracy degradation introduced by tiling. At the system level, QRMark implements a resource-aware multi-channel horizontal fusion policy that adaptively assigns more streams to GPU-intensive stages of the detection pipeline. It further employs a tile-based workload interleaving strategy to overlap data-loading overhead with computation and schedules kernels across stages to maximize efficiency. End-to-end evaluations show that QRMark achieves an average 2.43x inference speedup over the sequential baseline.\n    link: https://arxiv.org/abs/2509.02447v2\n    "}}
{"custom_id": "2511.11907v2", "method": "POST", "url": "/v1/responses", "body": {"model": "gpt-5-mini", "input": "You are a specialist research analyst in Web3, DeFi, cryptography, and distributed systems.\n\n    Your task:\n    From the paper below (Title + Summary + Link), evaluate how useful each paper is for understanding investment opportunities or technological advantages within the Web3 / crypto / DeFi ecosystem.\n    Rate each paper on a five-level scale: Highest / High / Medium / Low / Lowest.\n\n    \"Useful\" means:\n\n    - Improves understanding of new cryptographic primitives relevant to blockchain performance or security\n    - Enhances scalability: distributed systems, P2P networking, consensus mechanisms\n    - Advances in zero knowledge, MPC, PQC that could impact future L1/L2 chains\n    - DeFi modeling, AMMs, MEV, risk models, liquidity dynamics\n    - Smart contract security, attack vectors, economic incentives\n    - Token economics, mechanism design for decentralized systems\n    - Quantum threats to blockchain or cryptography\n    - Any breakthrough that meaningfully improves decentralization, scalability, privacy, or composability\n\n    Output instructions:\n\n    - Output each JSON object in JSON Lines format (one line per paper).\n\n    {\n        \"title\": title of the paper (in Japanese),\n        \"summary\": A concise summary of the paper (in Japanese),\n        \"impact_level\": \"Highest|High|Medium|Low|Lowest\",\n        \"why_matters\": An array (JSON array) containing 2\u20134 bullet points explaining why this paper matters for Web3 investment\n    }\n\n    - Do not output anything except valid JSON object in JSON Lines.\n    - \"title\", \"summary\", \"why_matters\" text in the output must be written in Japanese.\n\n    Paper:\n    title: KVSwap: Disk-aware KV Cache Offloading for Long-Context On-device Inference\n    summary: Language models (LMs) underpin emerging mobile and embedded AI applications like meeting and video summarization and document analysis, which often require processing multiple long-context inputs. Running an LM locally on-device improves privacy, enables offline use, and reduces cost, but long-context inference quickly hits a \\emph{memory capacity wall} as the key-value (KV) cache grows linearly with context length and batch size. Existing KV-cache offloading schemes are designed to transfer cache data from GPU memory to CPU memory; however, they are not suitable for embedded and mobile systems, where the CPU and GPU (or NPU) typically share a unified memory and the non-volatile secondary storage (disk) offers limited I/O bandwidth. We present KVSwap, a software framework tailored for local devices that achieves high memory efficiency while effectively leveraging disk storage. KVSwap stores the full cache on disk, uses highly compact in-memory metadata to predict which entries to preload, overlaps computation with hardware-aware disk access, and orchestrates read patterns to match storage device characteristics. Our evaluation shows that across representative LMs and storage types, KVSwap delivers higher throughput under tight memory budgets while maintaining generation quality over existing KV cache offloading schemes.\n    link: https://arxiv.org/abs/2511.11907v2\n    "}}
{"custom_id": "2512.11156v1", "method": "POST", "url": "/v1/responses", "body": {"model": "gpt-5-mini", "input": "You are a specialist research analyst in Web3, DeFi, cryptography, and distributed systems.\n\n    Your task:\n    From the paper below (Title + Summary + Link), evaluate how useful each paper is for understanding investment opportunities or technological advantages within the Web3 / crypto / DeFi ecosystem.\n    Rate each paper on a five-level scale: Highest / High / Medium / Low / Lowest.\n\n    \"Useful\" means:\n\n    - Improves understanding of new cryptographic primitives relevant to blockchain performance or security\n    - Enhances scalability: distributed systems, P2P networking, consensus mechanisms\n    - Advances in zero knowledge, MPC, PQC that could impact future L1/L2 chains\n    - DeFi modeling, AMMs, MEV, risk models, liquidity dynamics\n    - Smart contract security, attack vectors, economic incentives\n    - Token economics, mechanism design for decentralized systems\n    - Quantum threats to blockchain or cryptography\n    - Any breakthrough that meaningfully improves decentralization, scalability, privacy, or composability\n\n    Output instructions:\n\n    - Output each JSON object in JSON Lines format (one line per paper).\n\n    {\n        \"title\": title of the paper (in Japanese),\n        \"summary\": A concise summary of the paper (in Japanese),\n        \"impact_level\": \"Highest|High|Medium|Low|Lowest\",\n        \"why_matters\": An array (JSON array) containing 2\u20134 bullet points explaining why this paper matters for Web3 investment\n    }\n\n    - Do not output anything except valid JSON object in JSON Lines.\n    - \"title\", \"summary\", \"why_matters\" text in the output must be written in Japanese.\n\n    Paper:\n    title: BIER-Star: Stateless Geographic Multicast for Scalable Satellite-Terrestrial Integration\n    summary: The rapid expansion of LEO satellite constellations has enabled an integrated terrestrial network and non-terrestrial network (TN-NTN), connecting diverse users such as aircraft, ships, and remote communities. These networks increasingly need a scalable and efficient multicast protocol for critical applications like emergency alerts, large-scale software updates, and real-time broadcasting. However, traditional multicast protocols, such as IP-based multicast and software-defined multicast approaches, introduce significant control overhead and struggle to adapt to the dynamic and mobile nature of satellite topologies. This paper presents BIER-Star, a stateless multicast protocol designed for the integrated TN-NTN. BIER-Star uses a two-layer geospatial gridding scheme (i.e., H3) to encode destinations as Earth- and space-cell identifiers rather than per-terminal addresses. This cell-based abstraction shortens the header bitstring, simplifies forwarding, and eliminates per-flow state and complex signaling. Our simulations indicate that BIER-Star reduces header size versus BIER and avoids geographic path-finding failures seen in greedy methods.\n    link: https://arxiv.org/abs/2512.11156v1\n    "}}
{"custom_id": "2512.11147v1", "method": "POST", "url": "/v1/responses", "body": {"model": "gpt-5-mini", "input": "You are a specialist research analyst in Web3, DeFi, cryptography, and distributed systems.\n\n    Your task:\n    From the paper below (Title + Summary + Link), evaluate how useful each paper is for understanding investment opportunities or technological advantages within the Web3 / crypto / DeFi ecosystem.\n    Rate each paper on a five-level scale: Highest / High / Medium / Low / Lowest.\n\n    \"Useful\" means:\n\n    - Improves understanding of new cryptographic primitives relevant to blockchain performance or security\n    - Enhances scalability: distributed systems, P2P networking, consensus mechanisms\n    - Advances in zero knowledge, MPC, PQC that could impact future L1/L2 chains\n    - DeFi modeling, AMMs, MEV, risk models, liquidity dynamics\n    - Smart contract security, attack vectors, economic incentives\n    - Token economics, mechanism design for decentralized systems\n    - Quantum threats to blockchain or cryptography\n    - Any breakthrough that meaningfully improves decentralization, scalability, privacy, or composability\n\n    Output instructions:\n\n    - Output each JSON object in JSON Lines format (one line per paper).\n\n    {\n        \"title\": title of the paper (in Japanese),\n        \"summary\": A concise summary of the paper (in Japanese),\n        \"impact_level\": \"Highest|High|Medium|Low|Lowest\",\n        \"why_matters\": An array (JSON array) containing 2\u20134 bullet points explaining why this paper matters for Web3 investment\n    }\n\n    - Do not output anything except valid JSON object in JSON Lines.\n    - \"title\", \"summary\", \"why_matters\" text in the output must be written in Japanese.\n\n    Paper:\n    title: MiniScope: A Least Privilege Framework for Authorizing Tool Calling Agents\n    summary: Tool calling agents are an emerging paradigm in LLM deployment, with major platforms such as ChatGPT, Claude, and Gemini adding connectors and autonomous capabilities. However, the inherent unreliability of LLMs introduces fundamental security risks when these agents operate over sensitive user services. Prior approaches either rely on manually written policies that require security expertise, or place LLMs in the confinement loop, which lacks rigorous security guarantees. We present MiniScope, a framework that enables tool calling agents to operate on user accounts while confining potential damage from unreliable LLMs. MiniScope introduces a novel way to automatically and rigorously enforce least privilege principles by reconstructing permission hierarchies that reflect relationships among tool calls and combining them with a mobile-style permission model to balance security and ease of use. To evaluate MiniScope, we create a synthetic dataset derived from ten popular real-world applications, capturing the complexity of realistic agentic tasks beyond existing simplified benchmarks. Our evaluation shows that MiniScope incurs only 1-6% latency overhead compared to vanilla tool calling agents, while significantly outperforming the LLM based baseline in minimizing permissions as well as computational and operational costs.\n    link: https://arxiv.org/abs/2512.11147v1\n    "}}
{"custom_id": "2512.11143v1", "method": "POST", "url": "/v1/responses", "body": {"model": "gpt-5-mini", "input": "You are a specialist research analyst in Web3, DeFi, cryptography, and distributed systems.\n\n    Your task:\n    From the paper below (Title + Summary + Link), evaluate how useful each paper is for understanding investment opportunities or technological advantages within the Web3 / crypto / DeFi ecosystem.\n    Rate each paper on a five-level scale: Highest / High / Medium / Low / Lowest.\n\n    \"Useful\" means:\n\n    - Improves understanding of new cryptographic primitives relevant to blockchain performance or security\n    - Enhances scalability: distributed systems, P2P networking, consensus mechanisms\n    - Advances in zero knowledge, MPC, PQC that could impact future L1/L2 chains\n    - DeFi modeling, AMMs, MEV, risk models, liquidity dynamics\n    - Smart contract security, attack vectors, economic incentives\n    - Token economics, mechanism design for decentralized systems\n    - Quantum threats to blockchain or cryptography\n    - Any breakthrough that meaningfully improves decentralization, scalability, privacy, or composability\n\n    Output instructions:\n\n    - Output each JSON object in JSON Lines format (one line per paper).\n\n    {\n        \"title\": title of the paper (in Japanese),\n        \"summary\": A concise summary of the paper (in Japanese),\n        \"impact_level\": \"Highest|High|Medium|Low|Lowest\",\n        \"why_matters\": An array (JSON array) containing 2\u20134 bullet points explaining why this paper matters for Web3 investment\n    }\n\n    - Do not output anything except valid JSON object in JSON Lines.\n    - \"title\", \"summary\", \"why_matters\" text in the output must be written in Japanese.\n\n    Paper:\n    title: Automated Penetration Testing with LLM Agents and Classical Planning\n    summary: While penetration testing plays a vital role in cybersecurity, achieving fully automated, hands-off-the-keyboard execution remains a significant research challenge. In this paper, we introduce the \"Planner-Executor-Perceptor (PEP)\" design paradigm and use it to systematically review existing work and identify the key challenges in this area. We also evaluate existing penetration testing systems, with a particular focus on the use of Large Language Model (LLM) agents for this task. The results show that the out-of-the-box Claude Code and Sonnet 4.5 exhibit superior penetration capabilities observed to date, substantially outperforming all prior systems. However, a detailed analysis of their testing processes reveals specific strengths and limitations; notably, LLM agents struggle with maintaining coherent long-horizon plans, performing complex reasoning, and effectively utilizing specialized tools. These limitations significantly constrain its overall capability, efficiency, and stability. To address these limitations, we propose CHECKMATE, a framework that integrates enhanced classical planning with LLM agents, providing an external, structured \"brain\" that mitigates the inherent weaknesses of LLM agents. Our evaluation shows that CHECKMATE outperforms the state-of-the-art system (Claude Code) in penetration capability, improving benchmark success rates by over 20%. In addition, it delivers substantially greater stability, cutting both time and monetary costs by more than 50%.\n    link: https://arxiv.org/abs/2512.11143v1\n    "}}
{"custom_id": "2512.11135v1", "method": "POST", "url": "/v1/responses", "body": {"model": "gpt-5-mini", "input": "You are a specialist research analyst in Web3, DeFi, cryptography, and distributed systems.\n\n    Your task:\n    From the paper below (Title + Summary + Link), evaluate how useful each paper is for understanding investment opportunities or technological advantages within the Web3 / crypto / DeFi ecosystem.\n    Rate each paper on a five-level scale: Highest / High / Medium / Low / Lowest.\n\n    \"Useful\" means:\n\n    - Improves understanding of new cryptographic primitives relevant to blockchain performance or security\n    - Enhances scalability: distributed systems, P2P networking, consensus mechanisms\n    - Advances in zero knowledge, MPC, PQC that could impact future L1/L2 chains\n    - DeFi modeling, AMMs, MEV, risk models, liquidity dynamics\n    - Smart contract security, attack vectors, economic incentives\n    - Token economics, mechanism design for decentralized systems\n    - Quantum threats to blockchain or cryptography\n    - Any breakthrough that meaningfully improves decentralization, scalability, privacy, or composability\n\n    Output instructions:\n\n    - Output each JSON object in JSON Lines format (one line per paper).\n\n    {\n        \"title\": title of the paper (in Japanese),\n        \"summary\": A concise summary of the paper (in Japanese),\n        \"impact_level\": \"Highest|High|Medium|Low|Lowest\",\n        \"why_matters\": An array (JSON array) containing 2\u20134 bullet points explaining why this paper matters for Web3 investment\n    }\n\n    - Do not output anything except valid JSON object in JSON Lines.\n    - \"title\", \"summary\", \"why_matters\" text in the output must be written in Japanese.\n\n    Paper:\n    title: Network and Compiler Optimizations for Efficient Linear Algebra Kernels in Private Transformer Inference\n    summary: Large language model (LLM) based services are primarily structured as client-server interactions, with clients sending queries directly to cloud providers that host LLMs. This approach currently compromises data privacy as all queries must be processed in the cloud and in the clear. Fully Homomorphic Encryption (FHE) is a solution to this data privacy issue by enabling computations directly upon encrypted queries. However, running encrypted transformer inference is challenging as programmers must map standard kernels to the constrained instruction set provided by FHE. In this work, we explore implementations of linear algebra kernels needed for transformer inference in FHE and understand how network optimization can help mitigate FHE costs while remaining performant.\n  We leverage the Orion PyTorch to FHE framework to benchmark several linear algebra kernels in order to profile two linear transformation methods, packed row and BSGS, and find that BSGS outperforms packed row methods by up to $13.7 \\times$ at transformer-level scales. We also incorporate network-level pruning strategies that reduce FHE runtimes of feed forward layers by up to $11.46\\times$. Furthermore, we extend Orion to include ciphertext-ciphertext matrix-matrix products, a key component in the self-attention blocks. Finally, we perform a roofline analysis of FHE primitives and encrypted linear transformations and find that (SIMD encoded) implementations are memory-bound with primitives having roughly $0.1$ integer operations per byte of DRAM traffic. These findings illustrate the need for exploring alternative encoding schemes and models of computation within CKKS to unlock scalable private transformer inference. We conduct all experiments using the Orion framework which can be found at: https://github.com/baahl-nyu/orion.\n    link: https://arxiv.org/abs/2512.11135v1\n    "}}
{"custom_id": "2506.15924v2", "method": "POST", "url": "/v1/responses", "body": {"model": "gpt-5-mini", "input": "You are a specialist research analyst in Web3, DeFi, cryptography, and distributed systems.\n\n    Your task:\n    From the paper below (Title + Summary + Link), evaluate how useful each paper is for understanding investment opportunities or technological advantages within the Web3 / crypto / DeFi ecosystem.\n    Rate each paper on a five-level scale: Highest / High / Medium / Low / Lowest.\n\n    \"Useful\" means:\n\n    - Improves understanding of new cryptographic primitives relevant to blockchain performance or security\n    - Enhances scalability: distributed systems, P2P networking, consensus mechanisms\n    - Advances in zero knowledge, MPC, PQC that could impact future L1/L2 chains\n    - DeFi modeling, AMMs, MEV, risk models, liquidity dynamics\n    - Smart contract security, attack vectors, economic incentives\n    - Token economics, mechanism design for decentralized systems\n    - Quantum threats to blockchain or cryptography\n    - Any breakthrough that meaningfully improves decentralization, scalability, privacy, or composability\n\n    Output instructions:\n\n    - Output each JSON object in JSON Lines format (one line per paper).\n\n    {\n        \"title\": title of the paper (in Japanese),\n        \"summary\": A concise summary of the paper (in Japanese),\n        \"impact_level\": \"Highest|High|Medium|Low|Lowest\",\n        \"why_matters\": An array (JSON array) containing 2\u20134 bullet points explaining why this paper matters for Web3 investment\n    }\n\n    - Do not output anything except valid JSON object in JSON Lines.\n    - \"title\", \"summary\", \"why_matters\" text in the output must be written in Japanese.\n\n    Paper:\n    title: SNPeek: Side-Channel Analysis for Privacy Applications on Confidential VMs\n    summary: Confidential virtual machines (CVMs) based on trusted execution environments (TEEs) enable new privacy-preserving solutions. Yet, they leave side-channel leakage outside their threat model, shifting the responsibility of mitigating such attacks to developers. However, mitigations are either not generic or too slow for practical use, and developers currently lack a systematic, efficient way to measure and compare leakage across real-world deployments.\n  In this paper, we present SNPeek, an open-source toolkit that offers configurable side-channel tracing primitives on production AMD SEV-SNP hardware and couples them with statistical and machine-learning-based analysis pipelines for automated leakage estimation. We apply SNPeek to three representative workloads that are deployed on CVMs to enhance user privacy-private information retrieval, private heavy hitters, and Wasm user-defined functions-and uncover previously unnoticed leaks, including a covert channel that exfiltrates data at 497 kbit/s. The results show that SNPeek pinpoints vulnerabilities and guides low-overhead mitigations based on oblivious memory and differential privacy, giving practitioners a practical path to deploy CVMs with meaningful confidentiality guarantees.\n    link: https://arxiv.org/abs/2506.15924v2\n    "}}
{"custom_id": "2512.11122v1", "method": "POST", "url": "/v1/responses", "body": {"model": "gpt-5-mini", "input": "You are a specialist research analyst in Web3, DeFi, cryptography, and distributed systems.\n\n    Your task:\n    From the paper below (Title + Summary + Link), evaluate how useful each paper is for understanding investment opportunities or technological advantages within the Web3 / crypto / DeFi ecosystem.\n    Rate each paper on a five-level scale: Highest / High / Medium / Low / Lowest.\n\n    \"Useful\" means:\n\n    - Improves understanding of new cryptographic primitives relevant to blockchain performance or security\n    - Enhances scalability: distributed systems, P2P networking, consensus mechanisms\n    - Advances in zero knowledge, MPC, PQC that could impact future L1/L2 chains\n    - DeFi modeling, AMMs, MEV, risk models, liquidity dynamics\n    - Smart contract security, attack vectors, economic incentives\n    - Token economics, mechanism design for decentralized systems\n    - Quantum threats to blockchain or cryptography\n    - Any breakthrough that meaningfully improves decentralization, scalability, privacy, or composability\n\n    Output instructions:\n\n    - Output each JSON object in JSON Lines format (one line per paper).\n\n    {\n        \"title\": title of the paper (in Japanese),\n        \"summary\": A concise summary of the paper (in Japanese),\n        \"impact_level\": \"Highest|High|Medium|Low|Lowest\",\n        \"why_matters\": An array (JSON array) containing 2\u20134 bullet points explaining why this paper matters for Web3 investment\n    }\n\n    - Do not output anything except valid JSON object in JSON Lines.\n    - \"title\", \"summary\", \"why_matters\" text in the output must be written in Japanese.\n\n    Paper:\n    title: Cybersecurity policy adoption in South Africa: Does public trust matter?\n    summary: This study examines how public perception influences the implementation and adoption of cybersecurity frameworks in South Africa. Using the PRISMA methodology, a systematic literature review was conducted across reputable scholarly databases, yielding 34 relevant sources aligned with predefined inclusion criteria. Cybersecurity, governance, trust, privacy, cybercrime, and public opinion emerged as dominant thematic clusters. Bibliometric and thematic analyses, supported by network visualisations, revealed that while trust and public sentiment affect cybersecurity policy adoption globally, these factors have minimal influence within the South African policy landscape, despite the country's high cybercrime prevalence. In response, the study proposes a trust-centric policymaking framework designed to integrate public perception as a proactive dimension of cybersecurity governance. This framework seeks to prevent trust deficits from obstructing policy effectiveness and provides guidance for restoring trust where it has eroded.\n    link: https://arxiv.org/abs/2512.11122v1\n    "}}
{"custom_id": "2512.11118v1", "method": "POST", "url": "/v1/responses", "body": {"model": "gpt-5-mini", "input": "You are a specialist research analyst in Web3, DeFi, cryptography, and distributed systems.\n\n    Your task:\n    From the paper below (Title + Summary + Link), evaluate how useful each paper is for understanding investment opportunities or technological advantages within the Web3 / crypto / DeFi ecosystem.\n    Rate each paper on a five-level scale: Highest / High / Medium / Low / Lowest.\n\n    \"Useful\" means:\n\n    - Improves understanding of new cryptographic primitives relevant to blockchain performance or security\n    - Enhances scalability: distributed systems, P2P networking, consensus mechanisms\n    - Advances in zero knowledge, MPC, PQC that could impact future L1/L2 chains\n    - DeFi modeling, AMMs, MEV, risk models, liquidity dynamics\n    - Smart contract security, attack vectors, economic incentives\n    - Token economics, mechanism design for decentralized systems\n    - Quantum threats to blockchain or cryptography\n    - Any breakthrough that meaningfully improves decentralization, scalability, privacy, or composability\n\n    Output instructions:\n\n    - Output each JSON object in JSON Lines format (one line per paper).\n\n    {\n        \"title\": title of the paper (in Japanese),\n        \"summary\": A concise summary of the paper (in Japanese),\n        \"impact_level\": \"Highest|High|Medium|Low|Lowest\",\n        \"why_matters\": An array (JSON array) containing 2\u20134 bullet points explaining why this paper matters for Web3 investment\n    }\n\n    - Do not output anything except valid JSON object in JSON Lines.\n    - \"title\", \"summary\", \"why_matters\" text in the output must be written in Japanese.\n\n    Paper:\n    title: Network-Irreducible Multiparty Entanglement in Quantum Matter\n    summary: We show that the standard approach to characterize collective entanglement via genuine multiparty entanglement (GME) leads to an area law in ground and thermal Gibbs states of local Hamiltonians. To capture the truly collective part one needs to go beyond this short-range contribution tied to interfaces between subregions. Genuine network multiparty entanglement (GNME) achieves a systematic resolution of this goal by analyzing whether a $k$-party state can be prepared by a quantum network consisting of $(k-1)$-partite resources. We develop tools to certify and quantify GNME, and benchmark them for GHZ, W and Dicke states. We then study the 1d transverse field Ising model, where we find a sharp peak of GNME near the critical phase transition, and rapid suppression elsewhere. Finite temperature leads to a faster death of GNME compared to GME. Furthermore, certain 2d quantum spin liquids do not have GNME in microscopic subregions while possessing strong GME. This approach will allow to chart truly collective entanglement in quantum matter both in and out of equilibrium.\n    link: https://arxiv.org/abs/2512.11118v1\n    "}}
{"custom_id": "2512.11112v1", "method": "POST", "url": "/v1/responses", "body": {"model": "gpt-5-mini", "input": "You are a specialist research analyst in Web3, DeFi, cryptography, and distributed systems.\n\n    Your task:\n    From the paper below (Title + Summary + Link), evaluate how useful each paper is for understanding investment opportunities or technological advantages within the Web3 / crypto / DeFi ecosystem.\n    Rate each paper on a five-level scale: Highest / High / Medium / Low / Lowest.\n\n    \"Useful\" means:\n\n    - Improves understanding of new cryptographic primitives relevant to blockchain performance or security\n    - Enhances scalability: distributed systems, P2P networking, consensus mechanisms\n    - Advances in zero knowledge, MPC, PQC that could impact future L1/L2 chains\n    - DeFi modeling, AMMs, MEV, risk models, liquidity dynamics\n    - Smart contract security, attack vectors, economic incentives\n    - Token economics, mechanism design for decentralized systems\n    - Quantum threats to blockchain or cryptography\n    - Any breakthrough that meaningfully improves decentralization, scalability, privacy, or composability\n\n    Output instructions:\n\n    - Output each JSON object in JSON Lines format (one line per paper).\n\n    {\n        \"title\": title of the paper (in Japanese),\n        \"summary\": A concise summary of the paper (in Japanese),\n        \"impact_level\": \"Highest|High|Medium|Low|Lowest\",\n        \"why_matters\": An array (JSON array) containing 2\u20134 bullet points explaining why this paper matters for Web3 investment\n    }\n\n    - Do not output anything except valid JSON object in JSON Lines.\n    - \"title\", \"summary\", \"why_matters\" text in the output must be written in Japanese.\n\n    Paper:\n    title: An LLVM-Based Optimization Pipeline for SPDZ\n    summary: Actively secure arithmetic MPC is now practical for real applications, but performance and usability are still limited by framework-specific compilation stacks, the need for programmers to explicitly express parallelism, and high communication overhead. We design and implement a proof-of-concept LLVM-based optimization pipeline for the SPDZ protocol that addresses these bottlenecks. Our front end accepts a subset of C with lightweight privacy annotations and lowers it to LLVM IR, allowing us to reuse mature analyses and transformations to automatically batch independent arithmetic operations. Our back end performs data-flow and control-flow analysis on the optimized IR to drive a non-blocking runtime scheduler that overlaps independent operations and aggressively overlaps communication with computation; when enabled, it can map batched operations to GPU kernels. This design preserves a low learning curve by using a mainstream language and hiding optimization and hardware-specific mechanics from programmers. We evaluate the system on controlled microbenchmarks against MP-SPDZ, focusing on online phase performance. Our CPU back end achieves up to 5.56 times speedup under intermediate and heavy algebraic workloads, shows strong scaling with thread count, and our GPU back end scales better as the input size increases. Overall, these results indicate that leveraging LLVM with protocol-aware scheduling is an effective architectural direction for extracting parallelism without sacrificing usability.\n    link: https://arxiv.org/abs/2512.11112v1\n    "}}
{"custom_id": "2512.11107v1", "method": "POST", "url": "/v1/responses", "body": {"model": "gpt-5-mini", "input": "You are a specialist research analyst in Web3, DeFi, cryptography, and distributed systems.\n\n    Your task:\n    From the paper below (Title + Summary + Link), evaluate how useful each paper is for understanding investment opportunities or technological advantages within the Web3 / crypto / DeFi ecosystem.\n    Rate each paper on a five-level scale: Highest / High / Medium / Low / Lowest.\n\n    \"Useful\" means:\n\n    - Improves understanding of new cryptographic primitives relevant to blockchain performance or security\n    - Enhances scalability: distributed systems, P2P networking, consensus mechanisms\n    - Advances in zero knowledge, MPC, PQC that could impact future L1/L2 chains\n    - DeFi modeling, AMMs, MEV, risk models, liquidity dynamics\n    - Smart contract security, attack vectors, economic incentives\n    - Token economics, mechanism design for decentralized systems\n    - Quantum threats to blockchain or cryptography\n    - Any breakthrough that meaningfully improves decentralization, scalability, privacy, or composability\n\n    Output instructions:\n\n    - Output each JSON object in JSON Lines format (one line per paper).\n\n    {\n        \"title\": title of the paper (in Japanese),\n        \"summary\": A concise summary of the paper (in Japanese),\n        \"impact_level\": \"Highest|High|Medium|Low|Lowest\",\n        \"why_matters\": An array (JSON array) containing 2\u20134 bullet points explaining why this paper matters for Web3 investment\n    }\n\n    - Do not output anything except valid JSON object in JSON Lines.\n    - \"title\", \"summary\", \"why_matters\" text in the output must be written in Japanese.\n\n    Paper:\n    title: Digital Coherent-State QRNG Using System-Jitter Entropy via Random Permutation\n    summary: We present a fully digital framework that replicates the statistical behavior of coherent-state quantum random number generation (QRNG) by harnessing system timing jitter through random permutation processes. Our approach transforms computational timing variations from hardware and operating system sources into permutation dynamics that generate Poisson-distributed numbers, accurately reproducing the photon statistics of optical coherent states. The theoretical foundation is established by the Uniform Convergence Theorem, which provides exponential convergence to uniformity under modular projection with rigorous error bounds. Extensive experimental validation across multiple parameter regimes and sample sizes up to $10^8$ bytes demonstrates exceptional performance: Shannon entropy approaching 7.999998 bits/byte and min-entropy exceeding 7.99 bits/byte, outperforming theoretical bounds at scale. The architecture inherently resists side-channel attacks through compound timing distributions and adaptive permutation behavior, while operating without classical cryptographic post-processing. Our results establish that coherent-state QRNG functionality can be entirely realized through classical computational processes, delivering mathematically provable uniformity and practical cryptographic security without quantum photonic hardware.\n    link: https://arxiv.org/abs/2512.11107v1\n    "}}
{"custom_id": "2512.09321v2", "method": "POST", "url": "/v1/responses", "body": {"model": "gpt-5-mini", "input": "You are a specialist research analyst in Web3, DeFi, cryptography, and distributed systems.\n\n    Your task:\n    From the paper below (Title + Summary + Link), evaluate how useful each paper is for understanding investment opportunities or technological advantages within the Web3 / crypto / DeFi ecosystem.\n    Rate each paper on a five-level scale: Highest / High / Medium / Low / Lowest.\n\n    \"Useful\" means:\n\n    - Improves understanding of new cryptographic primitives relevant to blockchain performance or security\n    - Enhances scalability: distributed systems, P2P networking, consensus mechanisms\n    - Advances in zero knowledge, MPC, PQC that could impact future L1/L2 chains\n    - DeFi modeling, AMMs, MEV, risk models, liquidity dynamics\n    - Smart contract security, attack vectors, economic incentives\n    - Token economics, mechanism design for decentralized systems\n    - Quantum threats to blockchain or cryptography\n    - Any breakthrough that meaningfully improves decentralization, scalability, privacy, or composability\n\n    Output instructions:\n\n    - Output each JSON object in JSON Lines format (one line per paper).\n\n    {\n        \"title\": title of the paper (in Japanese),\n        \"summary\": A concise summary of the paper (in Japanese),\n        \"impact_level\": \"Highest|High|Medium|Low|Lowest\",\n        \"why_matters\": An array (JSON array) containing 2\u20134 bullet points explaining why this paper matters for Web3 investment\n    }\n\n    - Do not output anything except valid JSON object in JSON Lines.\n    - \"title\", \"summary\", \"why_matters\" text in the output must be written in Japanese.\n\n    Paper:\n    title: ObliInjection: Order-Oblivious Prompt Injection Attack to LLM Agents with Multi-source Data\n    summary: Prompt injection attacks aim to contaminate the input data of an LLM to mislead it into completing an attacker-chosen task instead of the intended task. In many applications and agents, the input data originates from multiple sources, with each source contributing a segment of the overall input. In these multi-source scenarios, an attacker may control only a subset of the sources and contaminate the corresponding segments, but typically does not know the order in which the segments are arranged within the input. Existing prompt injection attacks either assume that the entire input data comes from a single source under the attacker's control or ignore the uncertainty in the ordering of segments from different sources. As a result, their success is limited in domains involving multi-source data.\n  In this work, we propose ObliInjection, the first prompt injection attack targeting LLM applications and agents with multi-source input data. ObliInjection introduces two key technical innovations: the order-oblivious loss, which quantifies the likelihood that the LLM will complete the attacker-chosen task regardless of how the clean and contaminated segments are ordered; and the orderGCG algorithm, which is tailored to minimize the order-oblivious loss and optimize the contaminated segments. Comprehensive experiments across three datasets spanning diverse application domains and twelve LLMs demonstrate that ObliInjection is highly effective, even when only one out of 6-100 segments in the input data is contaminated.\n    link: https://arxiv.org/abs/2512.09321v2\n    "}}
{"custom_id": "2512.11094v1", "method": "POST", "url": "/v1/responses", "body": {"model": "gpt-5-mini", "input": "You are a specialist research analyst in Web3, DeFi, cryptography, and distributed systems.\n\n    Your task:\n    From the paper below (Title + Summary + Link), evaluate how useful each paper is for understanding investment opportunities or technological advantages within the Web3 / crypto / DeFi ecosystem.\n    Rate each paper on a five-level scale: Highest / High / Medium / Low / Lowest.\n\n    \"Useful\" means:\n\n    - Improves understanding of new cryptographic primitives relevant to blockchain performance or security\n    - Enhances scalability: distributed systems, P2P networking, consensus mechanisms\n    - Advances in zero knowledge, MPC, PQC that could impact future L1/L2 chains\n    - DeFi modeling, AMMs, MEV, risk models, liquidity dynamics\n    - Smart contract security, attack vectors, economic incentives\n    - Token economics, mechanism design for decentralized systems\n    - Quantum threats to blockchain or cryptography\n    - Any breakthrough that meaningfully improves decentralization, scalability, privacy, or composability\n\n    Output instructions:\n\n    - Output each JSON object in JSON Lines format (one line per paper).\n\n    {\n        \"title\": title of the paper (in Japanese),\n        \"summary\": A concise summary of the paper (in Japanese),\n        \"impact_level\": \"Highest|High|Medium|Low|Lowest\",\n        \"why_matters\": An array (JSON array) containing 2\u20134 bullet points explaining why this paper matters for Web3 investment\n    }\n\n    - Do not output anything except valid JSON object in JSON Lines.\n    - \"title\", \"summary\", \"why_matters\" text in the output must be written in Japanese.\n\n    Paper:\n    title: SHIFT: An RDMA Failure-Resilient Layer for Distributed Training\n    summary: With gang scheduling in large-scale distributed Large Language Model training, a single network anomaly can propagate and cause complete task failure. The frequency of such anomalies increases with network scale. However, existing fault-tolerance mechanisms, such as checkpointing and runtime resilience methods, primarily operate at the application layer and inevitably cause disruptions in training progress.\n  We propose to address this challenge by introducing fault tolerance at the Remote Direct Memory Access (RDMA) layer and integrating it with existing application-layer techniques. We present SHIFT, a fault-resilient layer over RDMA that enables seamless redirection of RDMA traffic across different intra-host NICs. By allowing applications to continue execution in the presence of network anomalies until the next checkpoint, SHIFT effectively minimizes training progress loss. SHIFT is designed to be application-agnostic, transparent to applications, and low-overhead.\n  Through a carefully designed failure state machine and control flow, unmodified applications such as PyTorch with NCCL can run with RDMA-level fault tolerance. Experimental results demonstrate that SHIFT introduces minimal data path overhead while ensuring application continuity under network failures.\n    link: https://arxiv.org/abs/2512.11094v1\n    "}}
{"custom_id": "2512.11087v1", "method": "POST", "url": "/v1/responses", "body": {"model": "gpt-5-mini", "input": "You are a specialist research analyst in Web3, DeFi, cryptography, and distributed systems.\n\n    Your task:\n    From the paper below (Title + Summary + Link), evaluate how useful each paper is for understanding investment opportunities or technological advantages within the Web3 / crypto / DeFi ecosystem.\n    Rate each paper on a five-level scale: Highest / High / Medium / Low / Lowest.\n\n    \"Useful\" means:\n\n    - Improves understanding of new cryptographic primitives relevant to blockchain performance or security\n    - Enhances scalability: distributed systems, P2P networking, consensus mechanisms\n    - Advances in zero knowledge, MPC, PQC that could impact future L1/L2 chains\n    - DeFi modeling, AMMs, MEV, risk models, liquidity dynamics\n    - Smart contract security, attack vectors, economic incentives\n    - Token economics, mechanism design for decentralized systems\n    - Quantum threats to blockchain or cryptography\n    - Any breakthrough that meaningfully improves decentralization, scalability, privacy, or composability\n\n    Output instructions:\n\n    - Output each JSON object in JSON Lines format (one line per paper).\n\n    {\n        \"title\": title of the paper (in Japanese),\n        \"summary\": A concise summary of the paper (in Japanese),\n        \"impact_level\": \"Highest|High|Medium|Low|Lowest\",\n        \"why_matters\": An array (JSON array) containing 2\u20134 bullet points explaining why this paper matters for Web3 investment\n    }\n\n    - Do not output anything except valid JSON object in JSON Lines.\n    - \"title\", \"summary\", \"why_matters\" text in the output must be written in Japanese.\n\n    Paper:\n    title: Clip-and-Verify: Linear Constraint-Driven Domain Clipping for Accelerating Neural Network Verification\n    summary: State-of-the-art neural network (NN) verifiers demonstrate that applying the branch-and-bound (BaB) procedure with fast bounding techniques plays a key role in tackling many challenging verification properties. In this work, we introduce the linear constraint-driven clipping framework, a class of scalable and efficient methods designed to enhance the efficacy of NN verifiers. Under this framework, we develop two novel algorithms that efficiently utilize linear constraints to 1) reduce portions of the input space that are either verified or irrelevant to a subproblem in the context of branch-and-bound, and 2) directly improve intermediate bounds throughout the network. The process novelly leverages linear constraints that often arise from bound propagation methods and is general enough to also incorporate constraints from other sources. It efficiently handles linear constraints using a specialized GPU procedure that can scale to large neural networks without the use of expensive external solvers. Our verification procedure, Clip-and-Verify, consistently tightens bounds across multiple benchmarks and can significantly reduce the number of subproblems handled during BaB. We show that our clipping algorithms can be integrated with BaB-based verifiers such as $\u03b1,\u03b2$-CROWN, utilizing either the split constraints in activation-space BaB or the output constraints that denote the unverified input space. We demonstrate the effectiveness of our procedure on a broad range of benchmarks where, in some instances, we witness a 96% reduction in the number of subproblems during branch-and-bound, and also achieve state-of-the-art verified accuracy across multiple benchmarks. Clip-and-Verify is part of the $\u03b1,\u03b2$-CROWN verifier (http://abcrown.org), the VNN-COMP 2025 winner. Code available at https://github.com/Verified-Intelligence/Clip_and_Verify.\n    link: https://arxiv.org/abs/2512.11087v1\n    "}}
{"custom_id": "2512.11084v1", "method": "POST", "url": "/v1/responses", "body": {"model": "gpt-5-mini", "input": "You are a specialist research analyst in Web3, DeFi, cryptography, and distributed systems.\n\n    Your task:\n    From the paper below (Title + Summary + Link), evaluate how useful each paper is for understanding investment opportunities or technological advantages within the Web3 / crypto / DeFi ecosystem.\n    Rate each paper on a five-level scale: Highest / High / Medium / Low / Lowest.\n\n    \"Useful\" means:\n\n    - Improves understanding of new cryptographic primitives relevant to blockchain performance or security\n    - Enhances scalability: distributed systems, P2P networking, consensus mechanisms\n    - Advances in zero knowledge, MPC, PQC that could impact future L1/L2 chains\n    - DeFi modeling, AMMs, MEV, risk models, liquidity dynamics\n    - Smart contract security, attack vectors, economic incentives\n    - Token economics, mechanism design for decentralized systems\n    - Quantum threats to blockchain or cryptography\n    - Any breakthrough that meaningfully improves decentralization, scalability, privacy, or composability\n\n    Output instructions:\n\n    - Output each JSON object in JSON Lines format (one line per paper).\n\n    {\n        \"title\": title of the paper (in Japanese),\n        \"summary\": A concise summary of the paper (in Japanese),\n        \"impact_level\": \"Highest|High|Medium|Low|Lowest\",\n        \"why_matters\": An array (JSON array) containing 2\u20134 bullet points explaining why this paper matters for Web3 investment\n    }\n\n    - Do not output anything except valid JSON object in JSON Lines.\n    - \"title\", \"summary\", \"why_matters\" text in the output must be written in Japanese.\n\n    Paper:\n    title: Topological Order and Non-Hermitian Skin Effect in Generalized Ideal Chern Bands\n    summary: Fractionalization in ideal Chern bands and non-Hermitian topological physics are two active but so far separate research directions. Merging these, we generalize the notion of ideal Chern bands to the non-Hermitian realm and uncover several striking consequences both on the level of band theory and in the strongly interacting regime. Specifically, we show that the lowest band of a Kapit--Mueller lattice model with an imaginary gauge potential satisfies a generalized ideal condition with complex Berry curvature in sync with a complex quantum metric. The ideal band remains purely real and exactly flat yet all right and left eigenstates accumulate at the boundaries on a cylinder, implying a non-Hermitian skin effect without an accompanying spectral winding. The skin effect is inherited by the many-body zero modes, yielding skin-Laughlin states with an exponential profile on the lattice. Moreover, at a critical strength of non-Hermiticity there is an unconventional phase transition on the torus, which is absent on the cylinder. Our findings lead to an extension of topological order in non-Hermitian systems.\n    link: https://arxiv.org/abs/2512.11084v1\n    "}}
{"custom_id": "2512.11068v1", "method": "POST", "url": "/v1/responses", "body": {"model": "gpt-5-mini", "input": "You are a specialist research analyst in Web3, DeFi, cryptography, and distributed systems.\n\n    Your task:\n    From the paper below (Title + Summary + Link), evaluate how useful each paper is for understanding investment opportunities or technological advantages within the Web3 / crypto / DeFi ecosystem.\n    Rate each paper on a five-level scale: Highest / High / Medium / Low / Lowest.\n\n    \"Useful\" means:\n\n    - Improves understanding of new cryptographic primitives relevant to blockchain performance or security\n    - Enhances scalability: distributed systems, P2P networking, consensus mechanisms\n    - Advances in zero knowledge, MPC, PQC that could impact future L1/L2 chains\n    - DeFi modeling, AMMs, MEV, risk models, liquidity dynamics\n    - Smart contract security, attack vectors, economic incentives\n    - Token economics, mechanism design for decentralized systems\n    - Quantum threats to blockchain or cryptography\n    - Any breakthrough that meaningfully improves decentralization, scalability, privacy, or composability\n\n    Output instructions:\n\n    - Output each JSON object in JSON Lines format (one line per paper).\n\n    {\n        \"title\": title of the paper (in Japanese),\n        \"summary\": A concise summary of the paper (in Japanese),\n        \"impact_level\": \"Highest|High|Medium|Low|Lowest\",\n        \"why_matters\": An array (JSON array) containing 2\u20134 bullet points explaining why this paper matters for Web3 investment\n    }\n\n    - Do not output anything except valid JSON object in JSON Lines.\n    - \"title\", \"summary\", \"why_matters\" text in the output must be written in Japanese.\n\n    Paper:\n    title: Asymptotic-freedom and massive glueballs in a qubit-regularized SU(2) gauge theory\n    summary: We argue that a simple qubit-regularized $\\mathrm{SU}(2)$ lattice gauge theory on a plaquette chain serves as a pseudo-one-dimensional toy model for Yang-Mills theory in three spatial dimensions. We map the chain Hamiltonian to the Transverse Field Ising Model in a uniform magnetic field and demonstrate that it can be tuned to a continuum limit in which the short-distance physics is governed by the asymptotically free Ising conformal field theory describing free Majorana fermions, while the long-distance regime contains massive excitations of the $E_8$ quantum field theory that can be interpreted as one-dimensional analogues of glueballs. Furthermore, we find $\\sqrt\u03c3/m_1 = 0.1763(5)$ where $\u03c3$ is the string tension between two static quarks and $m_1$ is the mass of the lightest glueball.\n    link: https://arxiv.org/abs/2512.11068v1\n    "}}
{"custom_id": "2411.10614v3", "method": "POST", "url": "/v1/responses", "body": {"model": "gpt-5-mini", "input": "You are a specialist research analyst in Web3, DeFi, cryptography, and distributed systems.\n\n    Your task:\n    From the paper below (Title + Summary + Link), evaluate how useful each paper is for understanding investment opportunities or technological advantages within the Web3 / crypto / DeFi ecosystem.\n    Rate each paper on a five-level scale: Highest / High / Medium / Low / Lowest.\n\n    \"Useful\" means:\n\n    - Improves understanding of new cryptographic primitives relevant to blockchain performance or security\n    - Enhances scalability: distributed systems, P2P networking, consensus mechanisms\n    - Advances in zero knowledge, MPC, PQC that could impact future L1/L2 chains\n    - DeFi modeling, AMMs, MEV, risk models, liquidity dynamics\n    - Smart contract security, attack vectors, economic incentives\n    - Token economics, mechanism design for decentralized systems\n    - Quantum threats to blockchain or cryptography\n    - Any breakthrough that meaningfully improves decentralization, scalability, privacy, or composability\n\n    Output instructions:\n\n    - Output each JSON object in JSON Lines format (one line per paper).\n\n    {\n        \"title\": title of the paper (in Japanese),\n        \"summary\": A concise summary of the paper (in Japanese),\n        \"impact_level\": \"Highest|High|Medium|Low|Lowest\",\n        \"why_matters\": An array (JSON array) containing 2\u20134 bullet points explaining why this paper matters for Web3 investment\n    }\n\n    - Do not output anything except valid JSON object in JSON Lines.\n    - \"title\", \"summary\", \"why_matters\" text in the output must be written in Japanese.\n\n    Paper:\n    title: To Shuffle or not to Shuffle: Auditing DP-SGD with Shuffling\n    summary: The Differentially Private Stochastic Gradient Descent (DP-SGD) algorithm supports the training of machine learning (ML) models with formal Differential Privacy (DP) guarantees. Traditionally, DP-SGD processes training data in batches using Poisson subsampling to select each batch at every iteration. More recently, shuffling has become a common alternative due to its better compatibility and lower computational overhead. However, computing tight theoretical DP guarantees under shuffling remains an open problem. As a result, models trained with shuffling are often evaluated as if Poisson subsampling were used, which might result in incorrect privacy guarantees.\n  This raises a compelling research question: can we verify whether there are gaps between the theoretical DP guarantees reported by state-of-the-art models using shuffling and their actual leakage? To do so, we define novel DP-auditing procedures to analyze DP-SGD with shuffling and measure their ability to tightly estimate privacy leakage vis-\u00e0-vis batch sizes, privacy budgets, and threat models. Overall, we demonstrate that DP models trained using this approach have considerably overestimated their privacy guarantees (by up to 4 times). However, we also find that the gap between the theoretical Poisson DP guarantees and the actual privacy leakage from shuffling is not uniform across all parameter settings and threat models. Finally, we study two common variations of the shuffling procedure that result in even further privacy leakage (up to 10 times). Overall, our work highlights the risk of using shuffling instead of Poisson subsampling in the absence of rigorous analysis methods.\n    link: https://arxiv.org/abs/2411.10614v3\n    "}}
