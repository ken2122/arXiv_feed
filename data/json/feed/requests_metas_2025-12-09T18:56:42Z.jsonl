{"custom_id": "2512.08918v1", "method": "POST", "url": "/v1/responses", "body": {"model": "gpt-5-mini", "input": "You are a specialist research analyst in Web3, DeFi, cryptography, and distributed systems.\n\n    Your task:\n    From the paper below (Title + Summary + Link), evaluate how useful each paper is for understanding investment opportunities or technological advantages within the Web3 / crypto / DeFi ecosystem.\n    Rate each paper on a five-level scale: Highest / High / Medium / Low / Lowest.\n\n    \"Useful\" means:\n\n    - Improves understanding of new cryptographic primitives relevant to blockchain performance or security\n    - Enhances scalability: distributed systems, P2P networking, consensus mechanisms\n    - Advances in zero knowledge, MPC, PQC that could impact future L1/L2 chains\n    - DeFi modeling, AMMs, MEV, risk models, liquidity dynamics\n    - Smart contract security, attack vectors, economic incentives\n    - Token economics, mechanism design for decentralized systems\n    - Quantum threats to blockchain or cryptography\n    - Any breakthrough that meaningfully improves decentralization, scalability, privacy, or composability\n\n    Output instructions:\n\n    - Output each JSON object in JSON Lines format (one line per paper).\n\n    {\n        \"title\": title of the paper (in Japanese),\n        \"summary\": A concise summary of the paper (in Japanese),\n        \"impact_level\": \"Highest|High|Medium|Low|Lowest\",\n        \"why_matters\": An array (JSON array) containing 2\u20134 bullet points explaining why this paper matters for Web3 investment\n    }\n\n    - Do not output anything except valid JSON object in JSON Lines.\n    - \"title\", \"summary\", \"why_matters\" text in the output must be written in Japanese.\n\n    Paper:\n    title: Improved Pseudorandom Codes from Permuted Puzzles\n    summary: Watermarks are an essential tool for identifying AI-generated content. Recently, Christ and Gunn (CRYPTO '24) introduced pseudorandom error-correcting codes (PRCs), which are equivalent to watermarks with strong robustness and quality guarantees. A PRC is a pseudorandom encryption scheme whose decryption algorithm tolerates a high rate of errors. Pseudorandomness ensures quality preservation of the watermark, and error tolerance of decryption translates to the watermark's ability to withstand modification of the content.\n  In the short time since the introduction of PRCs, several works (NeurIPS '24, RANDOM '25, STOC '25) have proposed new constructions. Curiously, all of these constructions are vulnerable to quasipolynomial-time distinguishing attacks. Furthermore, all lack robustness to edits over a constant-sized alphabet, which is necessary for a meaningfully robust LLM watermark. Lastly, they lack robustness to adversaries who know the watermarking detection key. Until now, it was not clear whether any of these properties was achievable individually, let alone together.\n  We construct pseudorandom codes that achieve all of the above: plausible subexponential pseudorandomness security, robustness to worst-case edits over a binary alphabet, and robustness against even computationally unbounded adversaries that have the detection key. Pseudorandomness rests on a new assumption that we formalize, the permuted codes conjecture, which states that a distribution of permuted noisy codewords is pseudorandom. We show that this conjecture is implied by the permuted puzzles conjecture used previously to construct doubly efficient private information retrieval. To give further evidence, we show that the conjecture holds against a broad class of simple distinguishers, including read-once branching programs.\n    link: https://arxiv.org/abs/2512.08918v1\n    "}}
{"custom_id": "2507.14810v2", "method": "POST", "url": "/v1/responses", "body": {"model": "gpt-5-mini", "input": "You are a specialist research analyst in Web3, DeFi, cryptography, and distributed systems.\n\n    Your task:\n    From the paper below (Title + Summary + Link), evaluate how useful each paper is for understanding investment opportunities or technological advantages within the Web3 / crypto / DeFi ecosystem.\n    Rate each paper on a five-level scale: Highest / High / Medium / Low / Lowest.\n\n    \"Useful\" means:\n\n    - Improves understanding of new cryptographic primitives relevant to blockchain performance or security\n    - Enhances scalability: distributed systems, P2P networking, consensus mechanisms\n    - Advances in zero knowledge, MPC, PQC that could impact future L1/L2 chains\n    - DeFi modeling, AMMs, MEV, risk models, liquidity dynamics\n    - Smart contract security, attack vectors, economic incentives\n    - Token economics, mechanism design for decentralized systems\n    - Quantum threats to blockchain or cryptography\n    - Any breakthrough that meaningfully improves decentralization, scalability, privacy, or composability\n\n    Output instructions:\n\n    - Output each JSON object in JSON Lines format (one line per paper).\n\n    {\n        \"title\": title of the paper (in Japanese),\n        \"summary\": A concise summary of the paper (in Japanese),\n        \"impact_level\": \"Highest|High|Medium|Low|Lowest\",\n        \"why_matters\": An array (JSON array) containing 2\u20134 bullet points explaining why this paper matters for Web3 investment\n    }\n\n    - Do not output anything except valid JSON object in JSON Lines.\n    - \"title\", \"summary\", \"why_matters\" text in the output must be written in Japanese.\n\n    Paper:\n    title: Optimal Decisions for Liquid Staking: Allocation and Exit Timing\n    summary: In this paper, we study an investor's optimal entry and exit decisions in a liquid staking protocol (LSP) and an automated market maker (AMM), primarily from the standpoint of the investor. Our analysis focuses on two key investor actions: the initial allocation decision at time $t=0$, and the optimal timing of exit. First, we derive an optimal allocation strategy that enables the investor to distribute risk across the LSP, AMM, and direct holding. Our results also offer insights for LSP and AMM designers, identifying the necessary and sufficient conditions under which the investor is incentivized to stake through an LSP, and further, to provide liquidity in addition to staking. These conditions include a lower bound on the transaction fee, for which we propose a fee mechanism that attains the bound. Second, given a fixed protocol design, we model the optimal exit timing of an individual investor using Laplace transforms and free-boundary techniques. We analyze scenarios with and without transaction fees. In the absence of fees, we decompose the investor's payoff into impermanent loss and opportunity cost, and provide theoretical results characterizing the investor's payoff and the optimal exit threshold. With transaction fees, we conduct numerical analyses to examine how fee accumulation influences exit strategies. Our results reveal that in both settings, a stop-loss strategy often maximizes the investor's expected payoff, driven by opportunity gains and the accumulation of fees where fees are present. Our analyses rely on various tools from stochastic processes and control theory, as well as convex optimization and analysis. We further support our theoretical insights with numerical experiments and explore additional properties of the investor's value function and optimal behavior.\n    link: https://arxiv.org/abs/2507.14810v2\n    "}}
{"custom_id": "2512.05210v2", "method": "POST", "url": "/v1/responses", "body": {"model": "gpt-5-mini", "input": "You are a specialist research analyst in Web3, DeFi, cryptography, and distributed systems.\n\n    Your task:\n    From the paper below (Title + Summary + Link), evaluate how useful each paper is for understanding investment opportunities or technological advantages within the Web3 / crypto / DeFi ecosystem.\n    Rate each paper on a five-level scale: Highest / High / Medium / Low / Lowest.\n\n    \"Useful\" means:\n\n    - Improves understanding of new cryptographic primitives relevant to blockchain performance or security\n    - Enhances scalability: distributed systems, P2P networking, consensus mechanisms\n    - Advances in zero knowledge, MPC, PQC that could impact future L1/L2 chains\n    - DeFi modeling, AMMs, MEV, risk models, liquidity dynamics\n    - Smart contract security, attack vectors, economic incentives\n    - Token economics, mechanism design for decentralized systems\n    - Quantum threats to blockchain or cryptography\n    - Any breakthrough that meaningfully improves decentralization, scalability, privacy, or composability\n\n    Output instructions:\n\n    - Output each JSON object in JSON Lines format (one line per paper).\n\n    {\n        \"title\": title of the paper (in Japanese),\n        \"summary\": A concise summary of the paper (in Japanese),\n        \"impact_level\": \"Highest|High|Medium|Low|Lowest\",\n        \"why_matters\": An array (JSON array) containing 2\u20134 bullet points explaining why this paper matters for Web3 investment\n    }\n\n    - Do not output anything except valid JSON object in JSON Lines.\n    - \"title\", \"summary\", \"why_matters\" text in the output must be written in Japanese.\n\n    Paper:\n    title: A Framework for Quantum Simulations of Energy-Loss and Hadronization in Non-Abelian Gauge Theories: SU(2) Lattice Gauge Theory in 1+1D\n    summary: Simulations of energy loss and hadronization are essential for understanding a range of phenomena in non-equilibrium strongly-interacting matter. We establish a framework for performing such simulations on a quantum computer and apply it to a heavy quark moving across a modest-sized 1+1D SU(2) lattice of light quarks. Conceptual advances with regard to simulations of non-Abelian versus Abelian theories are developed, allowing for the evolution of the energy in light quarks, of their local non-Abelian charge densities, and of their multi-partite entanglement to be computed. The non-trivial action of non-Abelian charge operators on arbitrary states suggests mapping the heavy quarks to qubits alongside the light quarks, and limits the heavy-quark motion to discrete steps among spatial lattice sites. Further, the color entanglement among the heavy quarks and light quarks is implemented using hadronic operators, and Domain Decomposition is shown to be effective in quantum state preparation. Scalable quantum circuits that account for the heterogeneity of non-Abelian charge sectors across the lattice are used to prepare the interacting ground-state wavefunction in the presence of heavy quarks. The discrete motion of heavy quarks between adjacent spatial sites is implemented using fermionic SWAP operations. Quantum simulations of the dynamics of a system on $L=3$ spatial sites are performed using IBM's ${\\tt ibm\\_pittsburgh}$ quantum computer using 18 qubits, for which the circuits for state preparation, motion, and one second-order Trotter step of time evolution have a two-qubit depth of 398. A suite of error mitigation techniques are used to extract the observables from the simulations, providing results that are in good agreement with classical simulations. The framework presented here generalizes straightforwardly to other non-Abelian groups, including SU(3) for quantum chromodynamics.\n    link: https://arxiv.org/abs/2512.05210v2\n    "}}
{"custom_id": "2512.08882v1", "method": "POST", "url": "/v1/responses", "body": {"model": "gpt-5-mini", "input": "You are a specialist research analyst in Web3, DeFi, cryptography, and distributed systems.\n\n    Your task:\n    From the paper below (Title + Summary + Link), evaluate how useful each paper is for understanding investment opportunities or technological advantages within the Web3 / crypto / DeFi ecosystem.\n    Rate each paper on a five-level scale: Highest / High / Medium / Low / Lowest.\n\n    \"Useful\" means:\n\n    - Improves understanding of new cryptographic primitives relevant to blockchain performance or security\n    - Enhances scalability: distributed systems, P2P networking, consensus mechanisms\n    - Advances in zero knowledge, MPC, PQC that could impact future L1/L2 chains\n    - DeFi modeling, AMMs, MEV, risk models, liquidity dynamics\n    - Smart contract security, attack vectors, economic incentives\n    - Token economics, mechanism design for decentralized systems\n    - Quantum threats to blockchain or cryptography\n    - Any breakthrough that meaningfully improves decentralization, scalability, privacy, or composability\n\n    Output instructions:\n\n    - Output each JSON object in JSON Lines format (one line per paper).\n\n    {\n        \"title\": title of the paper (in Japanese),\n        \"summary\": A concise summary of the paper (in Japanese),\n        \"impact_level\": \"Highest|High|Medium|Low|Lowest\",\n        \"why_matters\": An array (JSON array) containing 2\u20134 bullet points explaining why this paper matters for Web3 investment\n    }\n\n    - Do not output anything except valid JSON object in JSON Lines.\n    - \"title\", \"summary\", \"why_matters\" text in the output must be written in Japanese.\n\n    Paper:\n    title: Decentralized Trust for Space AI: Blockchain-Based Federated Learning Across Multi-Vendor LEO Satellite Networks\n    summary: The rise of space AI is reshaping government and industry through applications such as disaster detection, border surveillance, and climate monitoring, powered by massive data from commercial and governmental low Earth orbit (LEO) satellites. Federated satellite learning (FSL) enables joint model training without sharing raw data, but suffers from slow convergence due to intermittent connectivity and introduces critical trust challenges--where biased or falsified updates can arise across satellite constellations, including those injected through cyberattacks on inter-satellite or satellite-ground communication links. We propose OrbitChain, a blockchain-backed framework that empowers trustworthy multi-vendor collaboration in LEO networks. OrbitChain (i) offloads consensus to high-altitude platforms (HAPs) with greater computational capacity, (ii) ensures transparent, auditable provenance of model updates from different orbits owned by different vendors, and (iii) prevents manipulated or incomplete contributions from affecting global FSL model aggregation. Extensive simulations show that OrbitChain reduces computational and communication overhead while improving privacy, security, and global model accuracy. Its permissioned proof-of-authority ledger finalizes over 1000 blocks with sub-second latency (0.16,s, 0.26,s, 0.35,s for 1-of-5, 3-of-5, and 5-of-5 quorums). Moreover, OrbitChain reduces convergence time by up to 30 hours on real satellite datasets compared to single-vendor, demonstrating its effectiveness for real-time, multi-vendor learning. Our code is available at https://github.com/wsu-cyber-security-lab-ai/OrbitChain.git\n    link: https://arxiv.org/abs/2512.08882v1\n    "}}
{"custom_id": "2512.08880v1", "method": "POST", "url": "/v1/responses", "body": {"model": "gpt-5-mini", "input": "You are a specialist research analyst in Web3, DeFi, cryptography, and distributed systems.\n\n    Your task:\n    From the paper below (Title + Summary + Link), evaluate how useful each paper is for understanding investment opportunities or technological advantages within the Web3 / crypto / DeFi ecosystem.\n    Rate each paper on a five-level scale: Highest / High / Medium / Low / Lowest.\n\n    \"Useful\" means:\n\n    - Improves understanding of new cryptographic primitives relevant to blockchain performance or security\n    - Enhances scalability: distributed systems, P2P networking, consensus mechanisms\n    - Advances in zero knowledge, MPC, PQC that could impact future L1/L2 chains\n    - DeFi modeling, AMMs, MEV, risk models, liquidity dynamics\n    - Smart contract security, attack vectors, economic incentives\n    - Token economics, mechanism design for decentralized systems\n    - Quantum threats to blockchain or cryptography\n    - Any breakthrough that meaningfully improves decentralization, scalability, privacy, or composability\n\n    Output instructions:\n\n    - Output each JSON object in JSON Lines format (one line per paper).\n\n    {\n        \"title\": title of the paper (in Japanese),\n        \"summary\": A concise summary of the paper (in Japanese),\n        \"impact_level\": \"Highest|High|Medium|Low|Lowest\",\n        \"why_matters\": An array (JSON array) containing 2\u20134 bullet points explaining why this paper matters for Web3 investment\n    }\n\n    - Do not output anything except valid JSON object in JSON Lines.\n    - \"title\", \"summary\", \"why_matters\" text in the output must be written in Japanese.\n\n    Paper:\n    title: Floquet Topological Frequency-Converting Amplifier\n    summary: We introduce a driven-dissipative Floquet model in which a single harmonic oscillator with modulated frequency and decay realizes a non-Hermitian synthetic lattice with an effective electric field gradient in frequency space. Using the Floquet-Green's function and its doubled-space representation, we identify a topological regime that supports directional amplification and frequency conversion, accurately captured by a local winding number. The underlying mode structure is well described by a Jackiw-Rebbi-like continuum theory with Dirac cones and solitonic zero modes in synthetic frequency. Our results establish a simple and experimentally feasible route to non-Hermitian topological amplification, naturally implementable in current quantum technologies such as superconducting circuits.\n    link: https://arxiv.org/abs/2512.08880v1\n    "}}
{"custom_id": "2508.06457v2", "method": "POST", "url": "/v1/responses", "body": {"model": "gpt-5-mini", "input": "You are a specialist research analyst in Web3, DeFi, cryptography, and distributed systems.\n\n    Your task:\n    From the paper below (Title + Summary + Link), evaluate how useful each paper is for understanding investment opportunities or technological advantages within the Web3 / crypto / DeFi ecosystem.\n    Rate each paper on a five-level scale: Highest / High / Medium / Low / Lowest.\n\n    \"Useful\" means:\n\n    - Improves understanding of new cryptographic primitives relevant to blockchain performance or security\n    - Enhances scalability: distributed systems, P2P networking, consensus mechanisms\n    - Advances in zero knowledge, MPC, PQC that could impact future L1/L2 chains\n    - DeFi modeling, AMMs, MEV, risk models, liquidity dynamics\n    - Smart contract security, attack vectors, economic incentives\n    - Token economics, mechanism design for decentralized systems\n    - Quantum threats to blockchain or cryptography\n    - Any breakthrough that meaningfully improves decentralization, scalability, privacy, or composability\n\n    Output instructions:\n\n    - Output each JSON object in JSON Lines format (one line per paper).\n\n    {\n        \"title\": title of the paper (in Japanese),\n        \"summary\": A concise summary of the paper (in Japanese),\n        \"impact_level\": \"Highest|High|Medium|Low|Lowest\",\n        \"why_matters\": An array (JSON array) containing 2\u20134 bullet points explaining why this paper matters for Web3 investment\n    }\n\n    - Do not output anything except valid JSON object in JSON Lines.\n    - \"title\", \"summary\", \"why_matters\" text in the output must be written in Japanese.\n\n    Paper:\n    title: ScamAgents: How AI Agents Can Simulate Human-Level Scam Calls\n    summary: Large Language Models (LLMs) have demonstrated impressive fluency and reasoning capabilities, but their potential for misuse has raised growing concern. In this paper, we present ScamAgent, an autonomous multi-turn agent built on top of LLMs, capable of generating highly realistic scam call scripts that simulate real-world fraud scenarios. Unlike prior work focused on single-shot prompt misuse, ScamAgent maintains dialogue memory, adapts dynamically to simulated user responses, and employs deceptive persuasion strategies across conversational turns. We show that current LLM safety guardrails, including refusal mechanisms and content filters, are ineffective against such agent-based threats. Even models with strong prompt-level safeguards can be bypassed when prompts are decomposed, disguised, or delivered incrementally within an agent framework. We further demonstrate the transformation of scam scripts into lifelike voice calls using modern text-to-speech systems, completing a fully automated scam pipeline. Our findings highlight an urgent need for multi-turn safety auditing, agent-level control frameworks, and new methods to detect and disrupt conversational deception powered by generative AI.\n    link: https://arxiv.org/abs/2508.06457v2\n    "}}
{"custom_id": "2512.08869v1", "method": "POST", "url": "/v1/responses", "body": {"model": "gpt-5-mini", "input": "You are a specialist research analyst in Web3, DeFi, cryptography, and distributed systems.\n\n    Your task:\n    From the paper below (Title + Summary + Link), evaluate how useful each paper is for understanding investment opportunities or technological advantages within the Web3 / crypto / DeFi ecosystem.\n    Rate each paper on a five-level scale: Highest / High / Medium / Low / Lowest.\n\n    \"Useful\" means:\n\n    - Improves understanding of new cryptographic primitives relevant to blockchain performance or security\n    - Enhances scalability: distributed systems, P2P networking, consensus mechanisms\n    - Advances in zero knowledge, MPC, PQC that could impact future L1/L2 chains\n    - DeFi modeling, AMMs, MEV, risk models, liquidity dynamics\n    - Smart contract security, attack vectors, economic incentives\n    - Token economics, mechanism design for decentralized systems\n    - Quantum threats to blockchain or cryptography\n    - Any breakthrough that meaningfully improves decentralization, scalability, privacy, or composability\n\n    Output instructions:\n\n    - Output each JSON object in JSON Lines format (one line per paper).\n\n    {\n        \"title\": title of the paper (in Japanese),\n        \"summary\": A concise summary of the paper (in Japanese),\n        \"impact_level\": \"Highest|High|Medium|Low|Lowest\",\n        \"why_matters\": An array (JSON array) containing 2\u20134 bullet points explaining why this paper matters for Web3 investment\n    }\n\n    - Do not output anything except valid JSON object in JSON Lines.\n    - \"title\", \"summary\", \"why_matters\" text in the output must be written in Japanese.\n\n    Paper:\n    title: Differentially Private Synthetic Data Generation Using Context-Aware GANs\n    summary: The widespread use of big data across sectors has raised major privacy concerns, especially when sensitive information is shared or analyzed. Regulations such as GDPR and HIPAA impose strict controls on data handling, making it difficult to balance the need for insights with privacy requirements. Synthetic data offers a promising solution by creating artificial datasets that reflect real patterns without exposing sensitive information. However, traditional synthetic data methods often fail to capture complex, implicit rules that link different elements of the data and are essential in domains like healthcare. They may reproduce explicit patterns but overlook domain-specific constraints that are not directly stated yet crucial for realism and utility. For example, prescription guidelines that restrict certain medications for specific conditions or prevent harmful drug interactions may not appear explicitly in the original data. Synthetic data generated without these implicit rules can lead to medically inappropriate or unrealistic profiles. To address this gap, we propose ContextGAN, a Context-Aware Differentially Private Generative Adversarial Network that integrates domain-specific rules through a constraint matrix encoding both explicit and implicit knowledge. The constraint-aware discriminator evaluates synthetic data against these rules to ensure adherence to domain constraints, while differential privacy protects sensitive details from the original data. We validate ContextGAN across healthcare, security, and finance, showing that it produces high-quality synthetic data that respects domain rules and preserves privacy. Our results demonstrate that ContextGAN improves realism and utility by enforcing domain constraints, making it suitable for applications that require compliance with both explicit patterns and implicit rules under strict privacy guarantees.\n    link: https://arxiv.org/abs/2512.08869v1\n    "}}
{"custom_id": "2510.06385v2", "method": "POST", "url": "/v1/responses", "body": {"model": "gpt-5-mini", "input": "You are a specialist research analyst in Web3, DeFi, cryptography, and distributed systems.\n\n    Your task:\n    From the paper below (Title + Summary + Link), evaluate how useful each paper is for understanding investment opportunities or technological advantages within the Web3 / crypto / DeFi ecosystem.\n    Rate each paper on a five-level scale: Highest / High / Medium / Low / Lowest.\n\n    \"Useful\" means:\n\n    - Improves understanding of new cryptographic primitives relevant to blockchain performance or security\n    - Enhances scalability: distributed systems, P2P networking, consensus mechanisms\n    - Advances in zero knowledge, MPC, PQC that could impact future L1/L2 chains\n    - DeFi modeling, AMMs, MEV, risk models, liquidity dynamics\n    - Smart contract security, attack vectors, economic incentives\n    - Token economics, mechanism design for decentralized systems\n    - Quantum threats to blockchain or cryptography\n    - Any breakthrough that meaningfully improves decentralization, scalability, privacy, or composability\n\n    Output instructions:\n\n    - Output each JSON object in JSON Lines format (one line per paper).\n\n    {\n        \"title\": title of the paper (in Japanese),\n        \"summary\": A concise summary of the paper (in Japanese),\n        \"impact_level\": \"Highest|High|Medium|Low|Lowest\",\n        \"why_matters\": An array (JSON array) containing 2\u20134 bullet points explaining why this paper matters for Web3 investment\n    }\n\n    - Do not output anything except valid JSON object in JSON Lines.\n    - \"title\", \"summary\", \"why_matters\" text in the output must be written in Japanese.\n\n    Paper:\n    title: Fourier Spectrum of Noisy Quantum Algorithms\n    summary: Quantum computing promises exponential speedups for certain problems, yet fully universal quantum computers remain out of reach and near-term devices are inherently noisy. Motivated by this, we study noisy quantum algorithms and the landscape between $\\mathsf{BQP}$ and $\\mathsf{BPP}$. We build on a powerful technique to differentiate quantum and classical algorithms called the level-$\\ell$ Fourier growth (the sum of absolute values of Fourier coefficients of sets of size $\\ell$) and show that it can also be used to differentiate quantum algorithms based on the types of resources used. We show that noise acting on a quantum algorithm dampens its Fourier growth in ways intricately linked to the type of noise.\n  Concretely, we study noisy models of quantum computation where highly mixed states are prevalent, namely: $\\mathsf{DQC}_k$ algorithms, where $k$ qubits are clean and the rest are maximally mixed, and $\\frac{1}{2}\\mathsf {BQP}$ algorithms, where the initial state is maximally mixed, but the algorithm is given knowledge of the initial state at the end of the computation. We establish upper bounds on the Fourier growth of $\\mathsf{DQC}_k$, $\\frac{1}{2}\\mathsf{BQP}$ and $\\mathsf{BQP}$ algorithms and leverage the differences between these bounds to derive oracle separations between these models. In particular, we show that 2-Forrelation and 3-Forrelation require $N^{\u03a9(1)}$ queries in the $\\mathsf{DQC}_1$ and $\\frac{1}{2}\\mathsf{BQP}$ models respectively. Our results are proved using a new matrix decomposition lemma that might be of independent interest.\n    link: https://arxiv.org/abs/2510.06385v2\n    "}}
{"custom_id": "2512.08862v1", "method": "POST", "url": "/v1/responses", "body": {"model": "gpt-5-mini", "input": "You are a specialist research analyst in Web3, DeFi, cryptography, and distributed systems.\n\n    Your task:\n    From the paper below (Title + Summary + Link), evaluate how useful each paper is for understanding investment opportunities or technological advantages within the Web3 / crypto / DeFi ecosystem.\n    Rate each paper on a five-level scale: Highest / High / Medium / Low / Lowest.\n\n    \"Useful\" means:\n\n    - Improves understanding of new cryptographic primitives relevant to blockchain performance or security\n    - Enhances scalability: distributed systems, P2P networking, consensus mechanisms\n    - Advances in zero knowledge, MPC, PQC that could impact future L1/L2 chains\n    - DeFi modeling, AMMs, MEV, risk models, liquidity dynamics\n    - Smart contract security, attack vectors, economic incentives\n    - Token economics, mechanism design for decentralized systems\n    - Quantum threats to blockchain or cryptography\n    - Any breakthrough that meaningfully improves decentralization, scalability, privacy, or composability\n\n    Output instructions:\n\n    - Output each JSON object in JSON Lines format (one line per paper).\n\n    {\n        \"title\": title of the paper (in Japanese),\n        \"summary\": A concise summary of the paper (in Japanese),\n        \"impact_level\": \"Highest|High|Medium|Low|Lowest\",\n        \"why_matters\": An array (JSON array) containing 2\u20134 bullet points explaining why this paper matters for Web3 investment\n    }\n\n    - Do not output anything except valid JSON object in JSON Lines.\n    - \"title\", \"summary\", \"why_matters\" text in the output must be written in Japanese.\n\n    Paper:\n    title: Secure and Privacy-Preserving Federated Learning for Next-Generation Underground Mine Safety\n    summary: Underground mining operations depend on sensor networks to monitor critical parameters such as temperature, gas concentration, and miner movement, enabling timely hazard detection and safety decisions. However, transmitting raw sensor data to a centralized server for machine learning (ML) model training raises serious privacy and security concerns. Federated Learning (FL) offers a promising alternative by enabling decentralized model training without exposing sensitive local data. Yet, applying FL in underground mining presents unique challenges: (i) Adversaries may eavesdrop on shared model updates to launch model inversion or membership inference attacks, compromising data privacy and operational safety; (ii) Non-IID data distributions across mines and sensor noise can hinder model convergence. To address these issues, we propose FedMining--a privacy-preserving FL framework tailored for underground mining. FedMining introduces two core innovations: (1) a Decentralized Functional Encryption (DFE) scheme that keeps local models encrypted, thwarting unauthorized access and inference attacks; and (2) a balancing aggregation mechanism to mitigate data heterogeneity and enhance convergence. Evaluations on real-world mining datasets demonstrate FedMining's ability to safeguard privacy while maintaining high model accuracy and achieving rapid convergence with reduced communication and computation overhead. These advantages make FedMining both secure and practical for real-time underground safety monitoring.\n    link: https://arxiv.org/abs/2512.08862v1\n    "}}
{"custom_id": "2512.08858v1", "method": "POST", "url": "/v1/responses", "body": {"model": "gpt-5-mini", "input": "You are a specialist research analyst in Web3, DeFi, cryptography, and distributed systems.\n\n    Your task:\n    From the paper below (Title + Summary + Link), evaluate how useful each paper is for understanding investment opportunities or technological advantages within the Web3 / crypto / DeFi ecosystem.\n    Rate each paper on a five-level scale: Highest / High / Medium / Low / Lowest.\n\n    \"Useful\" means:\n\n    - Improves understanding of new cryptographic primitives relevant to blockchain performance or security\n    - Enhances scalability: distributed systems, P2P networking, consensus mechanisms\n    - Advances in zero knowledge, MPC, PQC that could impact future L1/L2 chains\n    - DeFi modeling, AMMs, MEV, risk models, liquidity dynamics\n    - Smart contract security, attack vectors, economic incentives\n    - Token economics, mechanism design for decentralized systems\n    - Quantum threats to blockchain or cryptography\n    - Any breakthrough that meaningfully improves decentralization, scalability, privacy, or composability\n\n    Output instructions:\n\n    - Output each JSON object in JSON Lines format (one line per paper).\n\n    {\n        \"title\": title of the paper (in Japanese),\n        \"summary\": A concise summary of the paper (in Japanese),\n        \"impact_level\": \"Highest|High|Medium|Low|Lowest\",\n        \"why_matters\": An array (JSON array) containing 2\u20134 bullet points explaining why this paper matters for Web3 investment\n    }\n\n    - Do not output anything except valid JSON object in JSON Lines.\n    - \"title\", \"summary\", \"why_matters\" text in the output must be written in Japanese.\n\n    Paper:\n    title: NecoFuzz: Effective Fuzzing of Nested Virtualization via Fuzz-Harness Virtual Machines\n    summary: Nested virtualization is now widely supported by major cloud vendors, allowing users to leverage virtualization-based technologies in the cloud. However, supporting nested virtualization significantly increases host hypervisor complexity and introduces a new attack surface in cloud platforms. While many prior studies have explored hypervisor fuzzing, none has explicitly addressed nested virtualization due to the challenge of generating effective virtual machine (VM) instances with a vast state space as fuzzing inputs.\n  We present NecoFuzz, the first fuzzing framework that systematically targets nested virtualization-specific logic in hypervisors. NecoFuzz synthesizes executable fuzz-harness VMs with internal states near the boundary between valid and invalid, guided by an approximate model of hardware-assisted virtualization specifications. Since vulnerabilities in nested virtualization often stem from incorrect handling of unexpected VM states, this specification-guided, boundary-oriented generation significantly improves coverage of security-critical code across different hypervisors.\n  We implemented NecoFuzz on Intel VT-x and AMD-V by extending AFL++ to support fuzz-harness VMs. NecoFuzz achieved 84.7% and 74.2% code coverage for nested virtualization-specific code on Intel VT-x and AMD-V, respectively, and uncovered six previously unknown vulnerabilities across three hypervisors, including two assigned CVEs.\n    link: https://arxiv.org/abs/2512.08858v1\n    "}}
{"custom_id": "2512.08856v1", "method": "POST", "url": "/v1/responses", "body": {"model": "gpt-5-mini", "input": "You are a specialist research analyst in Web3, DeFi, cryptography, and distributed systems.\n\n    Your task:\n    From the paper below (Title + Summary + Link), evaluate how useful each paper is for understanding investment opportunities or technological advantages within the Web3 / crypto / DeFi ecosystem.\n    Rate each paper on a five-level scale: Highest / High / Medium / Low / Lowest.\n\n    \"Useful\" means:\n\n    - Improves understanding of new cryptographic primitives relevant to blockchain performance or security\n    - Enhances scalability: distributed systems, P2P networking, consensus mechanisms\n    - Advances in zero knowledge, MPC, PQC that could impact future L1/L2 chains\n    - DeFi modeling, AMMs, MEV, risk models, liquidity dynamics\n    - Smart contract security, attack vectors, economic incentives\n    - Token economics, mechanism design for decentralized systems\n    - Quantum threats to blockchain or cryptography\n    - Any breakthrough that meaningfully improves decentralization, scalability, privacy, or composability\n\n    Output instructions:\n\n    - Output each JSON object in JSON Lines format (one line per paper).\n\n    {\n        \"title\": title of the paper (in Japanese),\n        \"summary\": A concise summary of the paper (in Japanese),\n        \"impact_level\": \"Highest|High|Medium|Low|Lowest\",\n        \"why_matters\": An array (JSON array) containing 2\u20134 bullet points explaining why this paper matters for Web3 investment\n    }\n\n    - Do not output anything except valid JSON object in JSON Lines.\n    - \"title\", \"summary\", \"why_matters\" text in the output must be written in Japanese.\n\n    Paper:\n    title: Can the GPC standard eliminate consent banners in the EU?\n    summary: In the EU, the General Data Protection Regulation and the ePrivacy Directive mandate informed consent for behavioural advertising and use of tracking technologies. However, the ubiquity of consent banners and popups has led to widespread consent fatigue and questions regarding the effectiveness of these mechanisms in protecting users' data. In contrast, users in California and other US jurisdictions can utilize Global Privacy Control (GPC), a browser-based privacy signal that automatically broadcasts a legally binding opt-out request to websites. In this paper we explore whether, and to what extent, GPC can be adapted to the EU legal framework to mitigate consent fatigue and improve privacy protections for EU residents.\n  We analyse GPC as a technical specification standardized at the World Wide Web Consortium and examine its standing under current EU data protection law. Generally, GPC can be mapped to the various legal bases for processing under the GDPR. However, our evaluation also identifies friction between the GPC specification and EU data protection law as it stands. These discrepancies are resolvable and present an opportunity for EU legislators and regulators to interpret GPC in alignment with EU data protection requirements, particularly, considering the European Commission's recent Digital Omnibus proposal. We conclude that while GPC is not a silver bullet, its adoption -- supported by clear authoritative guidance and specification updates -- can offer a pragmatic path toward more automated and effective data protection in the EU.\n    link: https://arxiv.org/abs/2512.08856v1\n    "}}
{"custom_id": "2507.10733v2", "method": "POST", "url": "/v1/responses", "body": {"model": "gpt-5-mini", "input": "You are a specialist research analyst in Web3, DeFi, cryptography, and distributed systems.\n\n    Your task:\n    From the paper below (Title + Summary + Link), evaluate how useful each paper is for understanding investment opportunities or technological advantages within the Web3 / crypto / DeFi ecosystem.\n    Rate each paper on a five-level scale: Highest / High / Medium / Low / Lowest.\n\n    \"Useful\" means:\n\n    - Improves understanding of new cryptographic primitives relevant to blockchain performance or security\n    - Enhances scalability: distributed systems, P2P networking, consensus mechanisms\n    - Advances in zero knowledge, MPC, PQC that could impact future L1/L2 chains\n    - DeFi modeling, AMMs, MEV, risk models, liquidity dynamics\n    - Smart contract security, attack vectors, economic incentives\n    - Token economics, mechanism design for decentralized systems\n    - Quantum threats to blockchain or cryptography\n    - Any breakthrough that meaningfully improves decentralization, scalability, privacy, or composability\n\n    Output instructions:\n\n    - Output each JSON object in JSON Lines format (one line per paper).\n\n    {\n        \"title\": title of the paper (in Japanese),\n        \"summary\": A concise summary of the paper (in Japanese),\n        \"impact_level\": \"Highest|High|Medium|Low|Lowest\",\n        \"why_matters\": An array (JSON array) containing 2\u20134 bullet points explaining why this paper matters for Web3 investment\n    }\n\n    - Do not output anything except valid JSON object in JSON Lines.\n    - \"title\", \"summary\", \"why_matters\" text in the output must be written in Japanese.\n\n    Paper:\n    title: 3S-Attack: Spatial, Spectral and Semantic Invisible Backdoor Attack Against DNN Models\n    summary: Backdoor attacks implant hidden behaviors into models by poisoning training data or modifying the model directly. These attacks aim to maintain high accuracy on benign inputs while causing misclassification when a specific trigger is present. While existing studies have explored stealthy triggers in spatial and spectral domains, few incorporate the semantic domain. In this paper, we propose 3S-attack, a novel backdoor attack which is stealthy across the spatial, spectral, and semantic domains. The key idea is to exploit the semantic features of benign samples as triggers, using Gradient-weighted Class Activation Mapping (Grad-CAM) and a preliminary model for extraction. Then we embedded the trigger in the spectral domain, followed by pixel-level restrictions in the spatial domain. This process minimizes the distance between poisoned and benign samples, making the attack harder to detect by existing defenses and human inspection. And it exposes a vulnerability at the intersection of robustness and semantic interpretability, revealing that models can be manipulated to act in semantically consistent yet malicious ways. Extensive experiments on various datasets, along with theoretical analysis, demonstrate the stealthiness of 3S-attack and highlight the need for stronger defenses to ensure AI security.\n    link: https://arxiv.org/abs/2507.10733v2\n    "}}
{"custom_id": "2512.08809v1", "method": "POST", "url": "/v1/responses", "body": {"model": "gpt-5-mini", "input": "You are a specialist research analyst in Web3, DeFi, cryptography, and distributed systems.\n\n    Your task:\n    From the paper below (Title + Summary + Link), evaluate how useful each paper is for understanding investment opportunities or technological advantages within the Web3 / crypto / DeFi ecosystem.\n    Rate each paper on a five-level scale: Highest / High / Medium / Low / Lowest.\n\n    \"Useful\" means:\n\n    - Improves understanding of new cryptographic primitives relevant to blockchain performance or security\n    - Enhances scalability: distributed systems, P2P networking, consensus mechanisms\n    - Advances in zero knowledge, MPC, PQC that could impact future L1/L2 chains\n    - DeFi modeling, AMMs, MEV, risk models, liquidity dynamics\n    - Smart contract security, attack vectors, economic incentives\n    - Token economics, mechanism design for decentralized systems\n    - Quantum threats to blockchain or cryptography\n    - Any breakthrough that meaningfully improves decentralization, scalability, privacy, or composability\n\n    Output instructions:\n\n    - Output each JSON object in JSON Lines format (one line per paper).\n\n    {\n        \"title\": title of the paper (in Japanese),\n        \"summary\": A concise summary of the paper (in Japanese),\n        \"impact_level\": \"Highest|High|Medium|Low|Lowest\",\n        \"why_matters\": An array (JSON array) containing 2\u20134 bullet points explaining why this paper matters for Web3 investment\n    }\n\n    - Do not output anything except valid JSON object in JSON Lines.\n    - \"title\", \"summary\", \"why_matters\" text in the output must be written in Japanese.\n\n    Paper:\n    title: PrivTune: Efficient and Privacy-Preserving Fine-Tuning of Large Language Models via Device-Cloud Collaboration\n    summary: With the rise of large language models, service providers offer language models as a service, enabling users to fine-tune customized models via uploaded private datasets. However, this raises concerns about sensitive data leakage. Prior methods, relying on differential privacy within device-cloud collaboration frameworks, struggle to balance privacy and utility, exposing users to inference attacks or degrading fine-tuning performance. To address this, we propose PrivTune, an efficient and privacy-preserving fine-tuning framework via Split Learning (SL). The key idea of PrivTune is to inject crafted noise into token representations from the SL bottom model, making each token resemble the $n$-hop indirect neighbors. PrivTune formulates this as an optimization problem to compute the optimal noise vector, aligning with defense-utility goals. On this basis, it then adjusts the parameters (i.e., mean) of the $d_\u03c7$-Privacy noise distribution to align with the optimization direction and scales the noise according to token importance to minimize distortion. Experiments on five datasets (covering both classification and generation tasks) against three embedding inversion and three attribute inference attacks show that, using RoBERTa on the Stanford Sentiment Treebank dataset, PrivTune reduces the attack success rate to 10% with only a 3.33% drop in utility performance, outperforming state-of-the-art baselines.\n    link: https://arxiv.org/abs/2512.08809v1\n    "}}
{"custom_id": "2512.08808v1", "method": "POST", "url": "/v1/responses", "body": {"model": "gpt-5-mini", "input": "You are a specialist research analyst in Web3, DeFi, cryptography, and distributed systems.\n\n    Your task:\n    From the paper below (Title + Summary + Link), evaluate how useful each paper is for understanding investment opportunities or technological advantages within the Web3 / crypto / DeFi ecosystem.\n    Rate each paper on a five-level scale: Highest / High / Medium / Low / Lowest.\n\n    \"Useful\" means:\n\n    - Improves understanding of new cryptographic primitives relevant to blockchain performance or security\n    - Enhances scalability: distributed systems, P2P networking, consensus mechanisms\n    - Advances in zero knowledge, MPC, PQC that could impact future L1/L2 chains\n    - DeFi modeling, AMMs, MEV, risk models, liquidity dynamics\n    - Smart contract security, attack vectors, economic incentives\n    - Token economics, mechanism design for decentralized systems\n    - Quantum threats to blockchain or cryptography\n    - Any breakthrough that meaningfully improves decentralization, scalability, privacy, or composability\n\n    Output instructions:\n\n    - Output each JSON object in JSON Lines format (one line per paper).\n\n    {\n        \"title\": title of the paper (in Japanese),\n        \"summary\": A concise summary of the paper (in Japanese),\n        \"impact_level\": \"Highest|High|Medium|Low|Lowest\",\n        \"why_matters\": An array (JSON array) containing 2\u20134 bullet points explaining why this paper matters for Web3 investment\n    }\n\n    - Do not output anything except valid JSON object in JSON Lines.\n    - \"title\", \"summary\", \"why_matters\" text in the output must be written in Japanese.\n\n    Paper:\n    title: WikIPedia: Unearthing a 20-Year History of IPv6 Client Addressing\n    summary: Due to their article editing policies, Wikimedia sites like Wikipedia have become inadvertent time capsules for IPv6 addresses. When Wikimedia users make edits without signing into an account, their IP addresses are used in lieu of a username. Wikimedia site dumps therefore provide researchers with over two decades worth of timestamped client IPv6 addresses to understand address assignments and how they have changed over time and space.\n  In this work, we extract 19M unique IPv6 addresses from Wikimedia sites like Wikipedia that were used by editors from 2003 to 2024. We use these addresses to understand the prevalence of IPv6 in countries corresponding to Wikimedia site languages, how IPv6 adoption has grown over time, and the prevalence of EUI-64 addressing on client devices like desktops, laptops, and mobile phones.\n    link: https://arxiv.org/abs/2512.08808v1\n    "}}
{"custom_id": "2512.08802v1", "method": "POST", "url": "/v1/responses", "body": {"model": "gpt-5-mini", "input": "You are a specialist research analyst in Web3, DeFi, cryptography, and distributed systems.\n\n    Your task:\n    From the paper below (Title + Summary + Link), evaluate how useful each paper is for understanding investment opportunities or technological advantages within the Web3 / crypto / DeFi ecosystem.\n    Rate each paper on a five-level scale: Highest / High / Medium / Low / Lowest.\n\n    \"Useful\" means:\n\n    - Improves understanding of new cryptographic primitives relevant to blockchain performance or security\n    - Enhances scalability: distributed systems, P2P networking, consensus mechanisms\n    - Advances in zero knowledge, MPC, PQC that could impact future L1/L2 chains\n    - DeFi modeling, AMMs, MEV, risk models, liquidity dynamics\n    - Smart contract security, attack vectors, economic incentives\n    - Token economics, mechanism design for decentralized systems\n    - Quantum threats to blockchain or cryptography\n    - Any breakthrough that meaningfully improves decentralization, scalability, privacy, or composability\n\n    Output instructions:\n\n    - Output each JSON object in JSON Lines format (one line per paper).\n\n    {\n        \"title\": title of the paper (in Japanese),\n        \"summary\": A concise summary of the paper (in Japanese),\n        \"impact_level\": \"Highest|High|Medium|Low|Lowest\",\n        \"why_matters\": An array (JSON array) containing 2\u20134 bullet points explaining why this paper matters for Web3 investment\n    }\n\n    - Do not output anything except valid JSON object in JSON Lines.\n    - \"title\", \"summary\", \"why_matters\" text in the output must be written in Japanese.\n\n    Paper:\n    title: Democratizing ML for Enterprise Security: A Self-Sustained Attack Detection Framework\n    summary: Despite advancements in machine learning for security, rule-based detection remains prevalent in Security Operations Centers due to the resource intensiveness and skill gap associated with ML solutions. While traditional rule-based methods offer efficiency, their rigidity leads to high false positives or negatives and requires continuous manual maintenance. This paper proposes a novel, two-stage hybrid framework to democratize ML-based threat detection. The first stage employs intentionally loose YARA rules for coarse-grained filtering, optimized for high recall. The second stage utilizes an ML classifier to filter out false positives from the first stage's output. To overcome data scarcity, the system leverages Simula, a seedless synthetic data generation framework, enabling security analysts to create high-quality training datasets without extensive data science expertise or pre-labeled examples. A continuous feedback loop incorporates real-time investigation results to adaptively tune the ML model, preventing rule degradation.\n  This proposed model with active learning has been rigorously tested for a prolonged time in a production environment spanning tens of thousands of systems. The system handles initial raw log volumes often reaching 250 billion events per day, significantly reducing them through filtering and ML inference to a handful of daily tickets for human investigation. Live experiments over an extended timeline demonstrate a general improvement in the model's precision over time due to the active learning feature. This approach offers a self-sustained, low-overhead, and low-maintenance solution, allowing security professionals to guide model learning as expert ``teachers''.\n    link: https://arxiv.org/abs/2512.08802v1\n    "}}
{"custom_id": "2512.08799v1", "method": "POST", "url": "/v1/responses", "body": {"model": "gpt-5-mini", "input": "You are a specialist research analyst in Web3, DeFi, cryptography, and distributed systems.\n\n    Your task:\n    From the paper below (Title + Summary + Link), evaluate how useful each paper is for understanding investment opportunities or technological advantages within the Web3 / crypto / DeFi ecosystem.\n    Rate each paper on a five-level scale: Highest / High / Medium / Low / Lowest.\n\n    \"Useful\" means:\n\n    - Improves understanding of new cryptographic primitives relevant to blockchain performance or security\n    - Enhances scalability: distributed systems, P2P networking, consensus mechanisms\n    - Advances in zero knowledge, MPC, PQC that could impact future L1/L2 chains\n    - DeFi modeling, AMMs, MEV, risk models, liquidity dynamics\n    - Smart contract security, attack vectors, economic incentives\n    - Token economics, mechanism design for decentralized systems\n    - Quantum threats to blockchain or cryptography\n    - Any breakthrough that meaningfully improves decentralization, scalability, privacy, or composability\n\n    Output instructions:\n\n    - Output each JSON object in JSON Lines format (one line per paper).\n\n    {\n        \"title\": title of the paper (in Japanese),\n        \"summary\": A concise summary of the paper (in Japanese),\n        \"impact_level\": \"Highest|High|Medium|Low|Lowest\",\n        \"why_matters\": An array (JSON array) containing 2\u20134 bullet points explaining why this paper matters for Web3 investment\n    }\n\n    - Do not output anything except valid JSON object in JSON Lines.\n    - \"title\", \"summary\", \"why_matters\" text in the output must be written in Japanese.\n\n    Paper:\n    title: Delay-Oriented Distributed Scheduling with TransGNN\n    summary: Minimizing transmission delay in wireless multi-hop networks is a fundamental yet challenging task due to the complex coupling among interference, queue dynamics, and distributed control. Traditional scheduling algorithms, such as max-weight or queue-length-based policies, primarily aim to optimize throughput but often suffer from high latency, especially in heterogeneous or dynamically changing topologies. Recent learning-based approaches, particularly those employing Graph Neural Networks (GNNs), have shown promise in capturing spatial interference structures. However, conventional Graph Convolutional Networks (GCNs) remain limited by their local aggregation mechanism and their inability to model long-range dependencies within the conflict graph. To address these challenges, this paper proposes a delay-oriented distributed scheduling framework based on Transformer GNN. The proposed model employs an attention-based graph encoder to generate adaptive per-link utility scores that reflect both queue backlog and interference intensity. A Local Greedy Solver (LGS) then utilizes these utilities to construct a feasible independent set of links for transmission, ensuring distributed and conflict-free scheduling.\n    link: https://arxiv.org/abs/2512.08799v1\n    "}}
{"custom_id": "2512.08782v1", "method": "POST", "url": "/v1/responses", "body": {"model": "gpt-5-mini", "input": "You are a specialist research analyst in Web3, DeFi, cryptography, and distributed systems.\n\n    Your task:\n    From the paper below (Title + Summary + Link), evaluate how useful each paper is for understanding investment opportunities or technological advantages within the Web3 / crypto / DeFi ecosystem.\n    Rate each paper on a five-level scale: Highest / High / Medium / Low / Lowest.\n\n    \"Useful\" means:\n\n    - Improves understanding of new cryptographic primitives relevant to blockchain performance or security\n    - Enhances scalability: distributed systems, P2P networking, consensus mechanisms\n    - Advances in zero knowledge, MPC, PQC that could impact future L1/L2 chains\n    - DeFi modeling, AMMs, MEV, risk models, liquidity dynamics\n    - Smart contract security, attack vectors, economic incentives\n    - Token economics, mechanism design for decentralized systems\n    - Quantum threats to blockchain or cryptography\n    - Any breakthrough that meaningfully improves decentralization, scalability, privacy, or composability\n\n    Output instructions:\n\n    - Output each JSON object in JSON Lines format (one line per paper).\n\n    {\n        \"title\": title of the paper (in Japanese),\n        \"summary\": A concise summary of the paper (in Japanese),\n        \"impact_level\": \"Highest|High|Medium|Low|Lowest\",\n        \"why_matters\": An array (JSON array) containing 2\u20134 bullet points explaining why this paper matters for Web3 investment\n    }\n\n    - Do not output anything except valid JSON object in JSON Lines.\n    - \"title\", \"summary\", \"why_matters\" text in the output must be written in Japanese.\n\n    Paper:\n    title: An Explainable AI Model for the Detecting Malicious Smart Contracts Based on EVM Opcode Based Features\n    summary: Hackers may create malicious solidity programs and deploy it in the Ethereum block chain. These malicious smart contracts try to attack legitimate programs by exploiting its vulnerabilities such as reentrancy, tx.origin attack, bad randomness, deligatecall and so on. This may lead to drain of the funds, denial of service and so on . Hence, it is necessary to identify and prevent the malicious smart contract before deploying it into the blockchain. In this paper, we propose an ML based malicious smart contract detection mechanism by analyzing the EVM opcodes. After balancing the opcode frequency dataset with SMOTE algorithm, we transformed opcode frequencies to the binary values (0,1) using an entropy based supervised binning method. Then, an explainable AI model is trained with the proposed binary opcode based features. From the implementations, we found that the proposed mechanism can detect 99% of malicious smart contracts with a false positive rate of only 0.01. Finally, we incorporated LIME algorithm in our classifier to justify its predictions. We found that, LIME algorithm can explain why a particular smart contract app is declared as malicious by our ML classifier based on the binary value of EVM opcodes.\n    link: https://arxiv.org/abs/2512.08782v1\n    "}}
{"custom_id": "2411.10138v2", "method": "POST", "url": "/v1/responses", "body": {"model": "gpt-5-mini", "input": "You are a specialist research analyst in Web3, DeFi, cryptography, and distributed systems.\n\n    Your task:\n    From the paper below (Title + Summary + Link), evaluate how useful each paper is for understanding investment opportunities or technological advantages within the Web3 / crypto / DeFi ecosystem.\n    Rate each paper on a five-level scale: Highest / High / Medium / Low / Lowest.\n\n    \"Useful\" means:\n\n    - Improves understanding of new cryptographic primitives relevant to blockchain performance or security\n    - Enhances scalability: distributed systems, P2P networking, consensus mechanisms\n    - Advances in zero knowledge, MPC, PQC that could impact future L1/L2 chains\n    - DeFi modeling, AMMs, MEV, risk models, liquidity dynamics\n    - Smart contract security, attack vectors, economic incentives\n    - Token economics, mechanism design for decentralized systems\n    - Quantum threats to blockchain or cryptography\n    - Any breakthrough that meaningfully improves decentralization, scalability, privacy, or composability\n\n    Output instructions:\n\n    - Output each JSON object in JSON Lines format (one line per paper).\n\n    {\n        \"title\": title of the paper (in Japanese),\n        \"summary\": A concise summary of the paper (in Japanese),\n        \"impact_level\": \"Highest|High|Medium|Low|Lowest\",\n        \"why_matters\": An array (JSON array) containing 2\u20134 bullet points explaining why this paper matters for Web3 investment\n    }\n\n    - Do not output anything except valid JSON object in JSON Lines.\n    - \"title\", \"summary\", \"why_matters\" text in the output must be written in Japanese.\n\n    Paper:\n    title: Architecture Proposal for 6G Systems Integrating Sensing and Communication\n    summary: Integrating sensing functionality into 6G communication networks requires some changes to existing components as well as new entities processing the radar sensing signals received by the communication antennas. This whitepaper provides a comprehensive overview of the 6G design proposal for ISaC (Integrated Sensing and Communication). The whitepaper has been created by the architecture group of the KOMSENS-6G project with the intend to serve as a basis for further discussions and alignment across innovative 6G projects.\n    link: https://arxiv.org/abs/2411.10138v2\n    "}}
{"custom_id": "2512.08751v1", "method": "POST", "url": "/v1/responses", "body": {"model": "gpt-5-mini", "input": "You are a specialist research analyst in Web3, DeFi, cryptography, and distributed systems.\n\n    Your task:\n    From the paper below (Title + Summary + Link), evaluate how useful each paper is for understanding investment opportunities or technological advantages within the Web3 / crypto / DeFi ecosystem.\n    Rate each paper on a five-level scale: Highest / High / Medium / Low / Lowest.\n\n    \"Useful\" means:\n\n    - Improves understanding of new cryptographic primitives relevant to blockchain performance or security\n    - Enhances scalability: distributed systems, P2P networking, consensus mechanisms\n    - Advances in zero knowledge, MPC, PQC that could impact future L1/L2 chains\n    - DeFi modeling, AMMs, MEV, risk models, liquidity dynamics\n    - Smart contract security, attack vectors, economic incentives\n    - Token economics, mechanism design for decentralized systems\n    - Quantum threats to blockchain or cryptography\n    - Any breakthrough that meaningfully improves decentralization, scalability, privacy, or composability\n\n    Output instructions:\n\n    - Output each JSON object in JSON Lines format (one line per paper).\n\n    {\n        \"title\": title of the paper (in Japanese),\n        \"summary\": A concise summary of the paper (in Japanese),\n        \"impact_level\": \"Highest|High|Medium|Low|Lowest\",\n        \"why_matters\": An array (JSON array) containing 2\u20134 bullet points explaining why this paper matters for Web3 investment\n    }\n\n    - Do not output anything except valid JSON object in JSON Lines.\n    - \"title\", \"summary\", \"why_matters\" text in the output must be written in Japanese.\n\n    Paper:\n    title: Skewness-Guided Pruning of Multimodal Swin Transformers for Federated Skin Lesion Classification on Edge Devices\n    summary: In recent years, high-performance computer vision models have achieved remarkable success in medical imaging, with some skin lesion classification systems even surpassing dermatology specialists in diagnostic accuracy. However, such models are computationally intensive and large in size, making them unsuitable for deployment on edge devices. In addition, strict privacy constraints hinder centralized data management, motivating the adoption of Federated Learning (FL). To address these challenges, this study proposes a skewness-guided pruning method that selectively prunes the Multi-Head Self-Attention and Multi-Layer Perceptron layers of a multimodal Swin Transformer based on the statistical skewness of their output distributions. The proposed method was validated in a horizontal FL environment and shown to maintain performance while substantially reducing model complexity. Experiments on the compact Swin Transformer demonstrate approximately 36\\% model size reduction with no loss in accuracy. These findings highlight the feasibility of achieving efficient model compression and privacy-preserving distributed learning for multimodal medical AI on edge devices.\n    link: https://arxiv.org/abs/2512.08751v1\n    "}}
{"custom_id": "2512.08749v1", "method": "POST", "url": "/v1/responses", "body": {"model": "gpt-5-mini", "input": "You are a specialist research analyst in Web3, DeFi, cryptography, and distributed systems.\n\n    Your task:\n    From the paper below (Title + Summary + Link), evaluate how useful each paper is for understanding investment opportunities or technological advantages within the Web3 / crypto / DeFi ecosystem.\n    Rate each paper on a five-level scale: Highest / High / Medium / Low / Lowest.\n\n    \"Useful\" means:\n\n    - Improves understanding of new cryptographic primitives relevant to blockchain performance or security\n    - Enhances scalability: distributed systems, P2P networking, consensus mechanisms\n    - Advances in zero knowledge, MPC, PQC that could impact future L1/L2 chains\n    - DeFi modeling, AMMs, MEV, risk models, liquidity dynamics\n    - Smart contract security, attack vectors, economic incentives\n    - Token economics, mechanism design for decentralized systems\n    - Quantum threats to blockchain or cryptography\n    - Any breakthrough that meaningfully improves decentralization, scalability, privacy, or composability\n\n    Output instructions:\n\n    - Output each JSON object in JSON Lines format (one line per paper).\n\n    {\n        \"title\": title of the paper (in Japanese),\n        \"summary\": A concise summary of the paper (in Japanese),\n        \"impact_level\": \"Highest|High|Medium|Low|Lowest\",\n        \"why_matters\": An array (JSON array) containing 2\u20134 bullet points explaining why this paper matters for Web3 investment\n    }\n\n    - Do not output anything except valid JSON object in JSON Lines.\n    - \"title\", \"summary\", \"why_matters\" text in the output must be written in Japanese.\n\n    Paper:\n    title: Non-abelian quantum double models from iterated gauging\n    summary: We reconstruct all (2+1)D quantum double models of finite groups from their boundary symmetries through the repeated application of a gauging procedure, extending the existing construction for abelian groups. We employ the recently proposed categorical gauging framework, based on matrix product operators (MPOs), to derive the appropriate gauging procedure for the $\\mathsf{Rep}\\, G$ symmetries appearing in our construction and give an explicit description of the dual emergent $G$ symmetry, which is our main technical contribution. Furthermore, we relate the possible gapped boundaries of the quantum double models to the quantum phases of the one-dimensional input state to the iterated gauging procedure. Finally, we propose a gauging procedure for 1-form $\\mathsf{Rep}\\, G$ symmetries on a two-dimensional lattice and use it to extend our results to the construction of (3+1)D quantum doubles models through the iterative gauging of (2+1)-dimensional symmetries.\n    link: https://arxiv.org/abs/2512.08749v1\n    "}}
{"custom_id": "2512.08742v1", "method": "POST", "url": "/v1/responses", "body": {"model": "gpt-5-mini", "input": "You are a specialist research analyst in Web3, DeFi, cryptography, and distributed systems.\n\n    Your task:\n    From the paper below (Title + Summary + Link), evaluate how useful each paper is for understanding investment opportunities or technological advantages within the Web3 / crypto / DeFi ecosystem.\n    Rate each paper on a five-level scale: Highest / High / Medium / Low / Lowest.\n\n    \"Useful\" means:\n\n    - Improves understanding of new cryptographic primitives relevant to blockchain performance or security\n    - Enhances scalability: distributed systems, P2P networking, consensus mechanisms\n    - Advances in zero knowledge, MPC, PQC that could impact future L1/L2 chains\n    - DeFi modeling, AMMs, MEV, risk models, liquidity dynamics\n    - Smart contract security, attack vectors, economic incentives\n    - Token economics, mechanism design for decentralized systems\n    - Quantum threats to blockchain or cryptography\n    - Any breakthrough that meaningfully improves decentralization, scalability, privacy, or composability\n\n    Output instructions:\n\n    - Output each JSON object in JSON Lines format (one line per paper).\n\n    {\n        \"title\": title of the paper (in Japanese),\n        \"summary\": A concise summary of the paper (in Japanese),\n        \"impact_level\": \"Highest|High|Medium|Low|Lowest\",\n        \"why_matters\": An array (JSON array) containing 2\u20134 bullet points explaining why this paper matters for Web3 investment\n    }\n\n    - Do not output anything except valid JSON object in JSON Lines.\n    - \"title\", \"summary\", \"why_matters\" text in the output must be written in Japanese.\n\n    Paper:\n    title: Parallel Batch Dynamic Vertex Coloring in $O(\\log \u0394)$ Amortized Update Time\n    summary: We present the first parallel batch-dynamic algorithm for maintaining a proper $(\u0394+ 1)$-vertex coloring. Our approach builds on a new sequential dynamic algorithm inspired by the work of Bhattacharya et al. (SODA'18). The resulting randomized algorithm achieves $O(\\log \u0394)$ expected amortized update time and, for any batch of $b$ updates, has parallel span $O(\\operatorname{polylog} b + \\operatorname{polylog} n)$ with high probability.\n    link: https://arxiv.org/abs/2512.08742v1\n    "}}
{"custom_id": "2509.18545v2", "method": "POST", "url": "/v1/responses", "body": {"model": "gpt-5-mini", "input": "You are a specialist research analyst in Web3, DeFi, cryptography, and distributed systems.\n\n    Your task:\n    From the paper below (Title + Summary + Link), evaluate how useful each paper is for understanding investment opportunities or technological advantages within the Web3 / crypto / DeFi ecosystem.\n    Rate each paper on a five-level scale: Highest / High / Medium / Low / Lowest.\n\n    \"Useful\" means:\n\n    - Improves understanding of new cryptographic primitives relevant to blockchain performance or security\n    - Enhances scalability: distributed systems, P2P networking, consensus mechanisms\n    - Advances in zero knowledge, MPC, PQC that could impact future L1/L2 chains\n    - DeFi modeling, AMMs, MEV, risk models, liquidity dynamics\n    - Smart contract security, attack vectors, economic incentives\n    - Token economics, mechanism design for decentralized systems\n    - Quantum threats to blockchain or cryptography\n    - Any breakthrough that meaningfully improves decentralization, scalability, privacy, or composability\n\n    Output instructions:\n\n    - Output each JSON object in JSON Lines format (one line per paper).\n\n    {\n        \"title\": title of the paper (in Japanese),\n        \"summary\": A concise summary of the paper (in Japanese),\n        \"impact_level\": \"Highest|High|Medium|Low|Lowest\",\n        \"why_matters\": An array (JSON array) containing 2\u20134 bullet points explaining why this paper matters for Web3 investment\n    }\n\n    - Do not output anything except valid JSON object in JSON Lines.\n    - \"title\", \"summary\", \"why_matters\" text in the output must be written in Japanese.\n\n    Paper:\n    title: SlicePilot: Demystifying Network Slice Placement in Heterogeneous Cloud Infrastructures\n    summary: Cellular networks are comprised of software-based entities, with main functions encapsulated as Virtual Network Functions (VNFs) deployed on Commercial-off-the-Shelf (COTS) hardware. As a key enabler of 5G, network slicing offers logically isolated Quality of Service (QoS) for diverse use cases. With the transition to cloud-native infrastructures, optimizing network slice placement across multi-cloud environments remains challenging due to heterogeneous resource capabilities and varying slice-specific demands. This paper presents SlicePilot, a modular framework that enables autonomous and near-optimal VNF placement using a disaggregated Multi-Agent Reinforcement Learning (MARL) approach. SlicePilot collects real-world traffic profiles to estimate resource needs for each slice type. These estimates guide a MARL-based scheduler that minimizes deployment costs while satisfying QoS constraints. We evaluate SlicePilot on a multi-cloud testbed and demonstrate a 19x speed-up over combinatorial optimization methods, while keeping deployment costs within 7.8% of the optimal. Although SlicePilot results in 2.42x more QoS violations under high-load conditions, this trade-off is offset by faster decision-making and reduced computational overhead. Overall, SlicePilot delivers a scalable, cost-efficient solution for network slice placement, making it suitable for real-time deployments where responsiveness and efficiency are critical.\n    link: https://arxiv.org/abs/2509.18545v2\n    "}}
{"custom_id": "2512.08728v1", "method": "POST", "url": "/v1/responses", "body": {"model": "gpt-5-mini", "input": "You are a specialist research analyst in Web3, DeFi, cryptography, and distributed systems.\n\n    Your task:\n    From the paper below (Title + Summary + Link), evaluate how useful each paper is for understanding investment opportunities or technological advantages within the Web3 / crypto / DeFi ecosystem.\n    Rate each paper on a five-level scale: Highest / High / Medium / Low / Lowest.\n\n    \"Useful\" means:\n\n    - Improves understanding of new cryptographic primitives relevant to blockchain performance or security\n    - Enhances scalability: distributed systems, P2P networking, consensus mechanisms\n    - Advances in zero knowledge, MPC, PQC that could impact future L1/L2 chains\n    - DeFi modeling, AMMs, MEV, risk models, liquidity dynamics\n    - Smart contract security, attack vectors, economic incentives\n    - Token economics, mechanism design for decentralized systems\n    - Quantum threats to blockchain or cryptography\n    - Any breakthrough that meaningfully improves decentralization, scalability, privacy, or composability\n\n    Output instructions:\n\n    - Output each JSON object in JSON Lines format (one line per paper).\n\n    {\n        \"title\": title of the paper (in Japanese),\n        \"summary\": A concise summary of the paper (in Japanese),\n        \"impact_level\": \"Highest|High|Medium|Low|Lowest\",\n        \"why_matters\": An array (JSON array) containing 2\u20134 bullet points explaining why this paper matters for Web3 investment\n    }\n\n    - Do not output anything except valid JSON object in JSON Lines.\n    - \"title\", \"summary\", \"why_matters\" text in the output must be written in Japanese.\n\n    Paper:\n    title: A Task Parallel Orthonormalization Multigrid Method For Multiphase Elliptic Problems\n    summary: Multigrid methods have been a popular approach for solving linear systems arising from the discretization of partial differential equations (PDEs) for several decades. They are particularly effective for accelerating convergence rates with optimal complexity in terms of both time and space. K-cycle orthonormalization multigrid is a robust variant of the multigrid method that combines the efficiency of multigrid with the robustness of Krylov-type residual minimalizations for problems with strong anisotropies. However, traditional implementations of K-cycle orthonormalization multigrid often rely on bulk-synchronous parallelism, which can limit scalability on modern high-performance computing (HPC) systems. This paper presents a task- parallel variant of the K-cycle orthonormalization multigrid method that leverages asynchronous execution to improve scalability and performance on large-scale parallel systems.\n    link: https://arxiv.org/abs/2512.08728v1\n    "}}
{"custom_id": "2512.08725v1", "method": "POST", "url": "/v1/responses", "body": {"model": "gpt-5-mini", "input": "You are a specialist research analyst in Web3, DeFi, cryptography, and distributed systems.\n\n    Your task:\n    From the paper below (Title + Summary + Link), evaluate how useful each paper is for understanding investment opportunities or technological advantages within the Web3 / crypto / DeFi ecosystem.\n    Rate each paper on a five-level scale: Highest / High / Medium / Low / Lowest.\n\n    \"Useful\" means:\n\n    - Improves understanding of new cryptographic primitives relevant to blockchain performance or security\n    - Enhances scalability: distributed systems, P2P networking, consensus mechanisms\n    - Advances in zero knowledge, MPC, PQC that could impact future L1/L2 chains\n    - DeFi modeling, AMMs, MEV, risk models, liquidity dynamics\n    - Smart contract security, attack vectors, economic incentives\n    - Token economics, mechanism design for decentralized systems\n    - Quantum threats to blockchain or cryptography\n    - Any breakthrough that meaningfully improves decentralization, scalability, privacy, or composability\n\n    Output instructions:\n\n    - Output each JSON object in JSON Lines format (one line per paper).\n\n    {\n        \"title\": title of the paper (in Japanese),\n        \"summary\": A concise summary of the paper (in Japanese),\n        \"impact_level\": \"Highest|High|Medium|Low|Lowest\",\n        \"why_matters\": An array (JSON array) containing 2\u20134 bullet points explaining why this paper matters for Web3 investment\n    }\n\n    - Do not output anything except valid JSON object in JSON Lines.\n    - \"title\", \"summary\", \"why_matters\" text in the output must be written in Japanese.\n\n    Paper:\n    title: Spatio-Temporal Shifting to Reduce Carbon, Water, and Land-Use Footprints of Cloud Workloads\n    summary: In this paper, we investigate the potential of spatial and temporal cloud workload shifting to reduce carbon, water, and land-use footprints. Specifically, we perform a simulation study using real-world data from multiple cloud providers (AWS and Azure) and workload traces for different applications (big data analytics and FaaS). Our simulation results indicate that spatial shifting can substantially lower carbon, water, and land use footprints, with observed reductions ranging from 20% to 85%, depending on the scenario and optimization criteria. Temporal shifting also decreases the footprint, though to a lesser extent. When applied together, the two strategies yield the greatest overall reduction, driven mainly by spatial shifting with temporal adjustments providing an additional, incremental benefit. Sensitivity analysis demonstrates that such shifting is robust to prediction errors in grid mix data and to variations across different seasons.\n    link: https://arxiv.org/abs/2512.08725v1\n    "}}
{"custom_id": "2508.09369v2", "method": "POST", "url": "/v1/responses", "body": {"model": "gpt-5-mini", "input": "You are a specialist research analyst in Web3, DeFi, cryptography, and distributed systems.\n\n    Your task:\n    From the paper below (Title + Summary + Link), evaluate how useful each paper is for understanding investment opportunities or technological advantages within the Web3 / crypto / DeFi ecosystem.\n    Rate each paper on a five-level scale: Highest / High / Medium / Low / Lowest.\n\n    \"Useful\" means:\n\n    - Improves understanding of new cryptographic primitives relevant to blockchain performance or security\n    - Enhances scalability: distributed systems, P2P networking, consensus mechanisms\n    - Advances in zero knowledge, MPC, PQC that could impact future L1/L2 chains\n    - DeFi modeling, AMMs, MEV, risk models, liquidity dynamics\n    - Smart contract security, attack vectors, economic incentives\n    - Token economics, mechanism design for decentralized systems\n    - Quantum threats to blockchain or cryptography\n    - Any breakthrough that meaningfully improves decentralization, scalability, privacy, or composability\n\n    Output instructions:\n\n    - Output each JSON object in JSON Lines format (one line per paper).\n\n    {\n        \"title\": title of the paper (in Japanese),\n        \"summary\": A concise summary of the paper (in Japanese),\n        \"impact_level\": \"Highest|High|Medium|Low|Lowest\",\n        \"why_matters\": An array (JSON array) containing 2\u20134 bullet points explaining why this paper matters for Web3 investment\n    }\n\n    - Do not output anything except valid JSON object in JSON Lines.\n    - \"title\", \"summary\", \"why_matters\" text in the output must be written in Japanese.\n\n    Paper:\n    title: FedJam: Multimodal Federated Learning Framework for Jamming Detection\n    summary: Jamming attacks pose a critical threat to wireless networks, yet existing detection methods remain largely unimodal, centralized and resource-intensive, limiting their performance, scalability, and deployment feasibility, respectively. To address these limitations, we present FedJam, a multimodal Federated Learning (FL) framework for on-device jamming detection and classification. FedJam locally fuses spectrograms and cross-layer network Key Performance Indicators (KPIs) using a lightweight dual-encoder architecture with an integrated fusion module and multimodal projection head, that enables privacy-preserving training and inference without transmitting raw data. We prototype and deploy FedJam on a wireless experimental testbed and evaluate it using the first, over-the-air multimodal dataset comprising synchronized samples across benign and three distinct jamming attack types. FedJam outperforms state-of-the-art unimodal baselines by up to 15% in accuracy, while requiring 60% fewer communication rounds to converge, and maintains low resource utilization. Its advantage is especially pronounced in realistic scenarios, where it remains extremely robust under heterogeneous data distributions across devices.\n    link: https://arxiv.org/abs/2508.09369v2\n    "}}
{"custom_id": "2512.08698v1", "method": "POST", "url": "/v1/responses", "body": {"model": "gpt-5-mini", "input": "You are a specialist research analyst in Web3, DeFi, cryptography, and distributed systems.\n\n    Your task:\n    From the paper below (Title + Summary + Link), evaluate how useful each paper is for understanding investment opportunities or technological advantages within the Web3 / crypto / DeFi ecosystem.\n    Rate each paper on a five-level scale: Highest / High / Medium / Low / Lowest.\n\n    \"Useful\" means:\n\n    - Improves understanding of new cryptographic primitives relevant to blockchain performance or security\n    - Enhances scalability: distributed systems, P2P networking, consensus mechanisms\n    - Advances in zero knowledge, MPC, PQC that could impact future L1/L2 chains\n    - DeFi modeling, AMMs, MEV, risk models, liquidity dynamics\n    - Smart contract security, attack vectors, economic incentives\n    - Token economics, mechanism design for decentralized systems\n    - Quantum threats to blockchain or cryptography\n    - Any breakthrough that meaningfully improves decentralization, scalability, privacy, or composability\n\n    Output instructions:\n\n    - Output each JSON object in JSON Lines format (one line per paper).\n\n    {\n        \"title\": title of the paper (in Japanese),\n        \"summary\": A concise summary of the paper (in Japanese),\n        \"impact_level\": \"Highest|High|Medium|Low|Lowest\",\n        \"why_matters\": An array (JSON array) containing 2\u20134 bullet points explaining why this paper matters for Web3 investment\n    }\n\n    - Do not output anything except valid JSON object in JSON Lines.\n    - \"title\", \"summary\", \"why_matters\" text in the output must be written in Japanese.\n\n    Paper:\n    title: Model-based Testing of Practical Distributed Systems in Actor Model\n    summary: Designing and implementing distributed systems correctly can be quite challenging. Although these systems are often accompanied by formal specifications that are verified using model-checking techniques, a gap still exists between the implementation and its formal specification: there is no guarantee that the implementation is free of bugs.\n  To bridge this gap, we can use model-based testing. Specifically, if the model of the system can be interpreted as a finite-state automaton, we can generate an exhaustive test suite for the implementation that covers all possible states and transitions.\n  In this paper, we discuss how to efficiently generate such a test suite for distributed systems written in the actor model. Importantly, our approach does not require any modifications to the code or interfering with the distributed system execution environment. As an example, we verified an implementation of a replication algorithm based on Viewstamped Replication, which is used in a real-world system.\n    link: https://arxiv.org/abs/2512.08698v1\n    "}}
{"custom_id": "2512.01646v2", "method": "POST", "url": "/v1/responses", "body": {"model": "gpt-5-mini", "input": "You are a specialist research analyst in Web3, DeFi, cryptography, and distributed systems.\n\n    Your task:\n    From the paper below (Title + Summary + Link), evaluate how useful each paper is for understanding investment opportunities or technological advantages within the Web3 / crypto / DeFi ecosystem.\n    Rate each paper on a five-level scale: Highest / High / Medium / Low / Lowest.\n\n    \"Useful\" means:\n\n    - Improves understanding of new cryptographic primitives relevant to blockchain performance or security\n    - Enhances scalability: distributed systems, P2P networking, consensus mechanisms\n    - Advances in zero knowledge, MPC, PQC that could impact future L1/L2 chains\n    - DeFi modeling, AMMs, MEV, risk models, liquidity dynamics\n    - Smart contract security, attack vectors, economic incentives\n    - Token economics, mechanism design for decentralized systems\n    - Quantum threats to blockchain or cryptography\n    - Any breakthrough that meaningfully improves decentralization, scalability, privacy, or composability\n\n    Output instructions:\n\n    - Output each JSON object in JSON Lines format (one line per paper).\n\n    {\n        \"title\": title of the paper (in Japanese),\n        \"summary\": A concise summary of the paper (in Japanese),\n        \"impact_level\": \"Highest|High|Medium|Low|Lowest\",\n        \"why_matters\": An array (JSON array) containing 2\u20134 bullet points explaining why this paper matters for Web3 investment\n    }\n\n    - Do not output anything except valid JSON object in JSON Lines.\n    - \"title\", \"summary\", \"why_matters\" text in the output must be written in Japanese.\n\n    Paper:\n    title: StarDist: A Code Generator for Distributed Graph Algorithms\n    summary: Relational data, occurring in the real world, are often structured as graphs, which provide the logical abstraction required to make analytical derivations simpler. As graphs get larger, the irregular access patterns exhibited in most graph algorithms, hamper performance. This, along with NUMA and physical memory limits, results in scaling complexities with sequential/shared memory frameworks. StarPlat's MPI backend abstracts away the programmatic complexity involved in designing optimal distributed graph algorithms. It provides an instrument for coding graph algorithms that scale over distributed memory. In this work, we provide an analysis-transformation framework that leverages general semantics associated with iterations involving nodes and their neighbors, within StarPlat, to aggregate communication. The framework scans for patterns that warrant re-ordering in neighborhood access patterns, aggregate communication, and avoid communication altogether with opportunistic caching in reduction constructs. We also architect an optimized bulk-reduction substrate using Open MPI's passive Remote Memory Access (RMA) constructs. We applied our optimization logic to StarPlat's distributed backend and outperformed d-Galois by 2.05 and DRONE by 1.44 times in Single Source Shortest Paths across several big data graphs.\n    link: https://arxiv.org/abs/2512.01646v2\n    "}}
{"custom_id": "2512.08695v1", "method": "POST", "url": "/v1/responses", "body": {"model": "gpt-5-mini", "input": "You are a specialist research analyst in Web3, DeFi, cryptography, and distributed systems.\n\n    Your task:\n    From the paper below (Title + Summary + Link), evaluate how useful each paper is for understanding investment opportunities or technological advantages within the Web3 / crypto / DeFi ecosystem.\n    Rate each paper on a five-level scale: Highest / High / Medium / Low / Lowest.\n\n    \"Useful\" means:\n\n    - Improves understanding of new cryptographic primitives relevant to blockchain performance or security\n    - Enhances scalability: distributed systems, P2P networking, consensus mechanisms\n    - Advances in zero knowledge, MPC, PQC that could impact future L1/L2 chains\n    - DeFi modeling, AMMs, MEV, risk models, liquidity dynamics\n    - Smart contract security, attack vectors, economic incentives\n    - Token economics, mechanism design for decentralized systems\n    - Quantum threats to blockchain or cryptography\n    - Any breakthrough that meaningfully improves decentralization, scalability, privacy, or composability\n\n    Output instructions:\n\n    - Output each JSON object in JSON Lines format (one line per paper).\n\n    {\n        \"title\": title of the paper (in Japanese),\n        \"summary\": A concise summary of the paper (in Japanese),\n        \"impact_level\": \"Highest|High|Medium|Low|Lowest\",\n        \"why_matters\": An array (JSON array) containing 2\u20134 bullet points explaining why this paper matters for Web3 investment\n    }\n\n    - Do not output anything except valid JSON object in JSON Lines.\n    - \"title\", \"summary\", \"why_matters\" text in the output must be written in Japanese.\n\n    Paper:\n    title: ITU-T Y.2325: NGN Evolution Towards Future\n    summary: International Telecommunications Union (ITU) defined Next Generation Network (NGN) underlies most wireline and wireless packet-based telecommunications networks. A key design principle of NGN is decoupling of service-related functions from the underlying transport stratum, making user services independent of transport technologies. Interestingly, the NGN architecture, as defined in ITU standards, did not follow this design principle for internal network services, e.g., mobility, or authentication though adhering for external user services like IPTV or Multimedia services. These internal services are handled by the NGN transport control plane, making them an intrinsic part of the transport stratum, resulting in a tightly coupled service and transport functionality as opposed to the proclaimed design goal. This design choice may force each transport technology to support internal services individually, e.g., separate authentication service for each transport, leading to duplication. Since the NGN architecture is the base underlying architecture for most packet-based telecommunications network including advanced cellular networks like 4th/5th Generation cellular networks, the limitation persists in these cellular networks as well. To remedy the situation, the decoupling of service and transport can be generalized to include internal services like mobility and authentication also. In this context, the recently published ITU Y.2325 recommendation, defines an evolved NGN architecture, wherein all services, including internal network services, are decoupled from the transport stratum. The proposal results in a more scalable and modular evolved NGN architecture that can be used as a template for all future telecom networks including IMT-2030 (6th generation mobile networks). In this article, we review the evolved NGN architecture, as proposed in ITU-T Y.2325.\n    link: https://arxiv.org/abs/2512.08695v1\n    "}}
{"custom_id": "2502.13223v2", "method": "POST", "url": "/v1/responses", "body": {"model": "gpt-5-mini", "input": "You are a specialist research analyst in Web3, DeFi, cryptography, and distributed systems.\n\n    Your task:\n    From the paper below (Title + Summary + Link), evaluate how useful each paper is for understanding investment opportunities or technological advantages within the Web3 / crypto / DeFi ecosystem.\n    Rate each paper on a five-level scale: Highest / High / Medium / Low / Lowest.\n\n    \"Useful\" means:\n\n    - Improves understanding of new cryptographic primitives relevant to blockchain performance or security\n    - Enhances scalability: distributed systems, P2P networking, consensus mechanisms\n    - Advances in zero knowledge, MPC, PQC that could impact future L1/L2 chains\n    - DeFi modeling, AMMs, MEV, risk models, liquidity dynamics\n    - Smart contract security, attack vectors, economic incentives\n    - Token economics, mechanism design for decentralized systems\n    - Quantum threats to blockchain or cryptography\n    - Any breakthrough that meaningfully improves decentralization, scalability, privacy, or composability\n\n    Output instructions:\n\n    - Output each JSON object in JSON Lines format (one line per paper).\n\n    {\n        \"title\": title of the paper (in Japanese),\n        \"summary\": A concise summary of the paper (in Japanese),\n        \"impact_level\": \"Highest|High|Medium|Low|Lowest\",\n        \"why_matters\": An array (JSON array) containing 2\u20134 bullet points explaining why this paper matters for Web3 investment\n    }\n\n    - Do not output anything except valid JSON object in JSON Lines.\n    - \"title\", \"summary\", \"why_matters\" text in the output must be written in Japanese.\n\n    Paper:\n    title: Triangular lattice models of the Kalmeyer-Laughlin spin liquid from coupled wires\n    summary: Chiral spin liquids (CSLs) are exotic phases of interacting spins in two dimensions, characterized by long-range entanglement and fractional excitations. We construct a local Hamiltonian on the triangular lattice that stabilizes the Kalmeyer-Laughlin CSL without requiring fine-tuning. Our approach employs coupled-wire constructions and introduces a lattice duality to construct a solvable chiral sliding Luttinger liquid, which is driven toward the CSL phase by generic perturbations. By combining symmetry analysis and bosonization, we make sharp predictions for the ground states on quasi-one-dimensional cylinders and tori, which exhibit a fourfold periodicity in the circumference. Extensive tensor network simulations demonstrating ground-state degeneracies, fractional quasiparticles, nonvanishing long-range order parameters, and entanglement signatures confirm the emergence of the CSL in the lattice Hamiltonian.\n    link: https://arxiv.org/abs/2502.13223v2\n    "}}
{"custom_id": "2409.00881v2", "method": "POST", "url": "/v1/responses", "body": {"model": "gpt-5-mini", "input": "You are a specialist research analyst in Web3, DeFi, cryptography, and distributed systems.\n\n    Your task:\n    From the paper below (Title + Summary + Link), evaluate how useful each paper is for understanding investment opportunities or technological advantages within the Web3 / crypto / DeFi ecosystem.\n    Rate each paper on a five-level scale: Highest / High / Medium / Low / Lowest.\n\n    \"Useful\" means:\n\n    - Improves understanding of new cryptographic primitives relevant to blockchain performance or security\n    - Enhances scalability: distributed systems, P2P networking, consensus mechanisms\n    - Advances in zero knowledge, MPC, PQC that could impact future L1/L2 chains\n    - DeFi modeling, AMMs, MEV, risk models, liquidity dynamics\n    - Smart contract security, attack vectors, economic incentives\n    - Token economics, mechanism design for decentralized systems\n    - Quantum threats to blockchain or cryptography\n    - Any breakthrough that meaningfully improves decentralization, scalability, privacy, or composability\n\n    Output instructions:\n\n    - Output each JSON object in JSON Lines format (one line per paper).\n\n    {\n        \"title\": title of the paper (in Japanese),\n        \"summary\": A concise summary of the paper (in Japanese),\n        \"impact_level\": \"Highest|High|Medium|Low|Lowest\",\n        \"why_matters\": An array (JSON array) containing 2\u20134 bullet points explaining why this paper matters for Web3 investment\n    }\n\n    - Do not output anything except valid JSON object in JSON Lines.\n    - \"title\", \"summary\", \"why_matters\" text in the output must be written in Japanese.\n\n    Paper:\n    title: Near coincidences and nilpotent division fields\n    summary: Let $E/\\mathbb{Q}$ be an elliptic curve. We say that $E$ has a near coincidence of level $(n,m)$ if $m \\mid n$ and $\\mathbb{Q}(E[n]) = \\mathbb{Q}(E[m],\u03b6_{n})$. We classify near coincidences of prime power level and use this result to give a classification of values of $n$ for which ${\\rm Gal}(\\mathbb{Q}(E[n])/\\mathbb{Q})$ is a nilpotent group. Along the way we prove a Gauss-Wantzel analog for the elliptic curve $E\\colon y^2 = x^3-x$, showing that $\\mathbb{Q}(E[n])/\\mathbb{Q}$ is constructible if and only if $\\varphi(n)$ is a power of 2. Assuming that there are no non-CM rational points on the modular curves $X_{ns}^{+}(p)$ for primes $p > 11$, we show that ${\\rm Gal}(\\mathbb{Q}(E[n])/\\mathbb{Q})$ nilpotent implies that $n$ is a power of $2$ or $n \\in \\{ 3, 5, 6, 7, 15, 21 \\}$.\n    link: https://arxiv.org/abs/2409.00881v2\n    "}}
{"custom_id": "2512.08641v1", "method": "POST", "url": "/v1/responses", "body": {"model": "gpt-5-mini", "input": "You are a specialist research analyst in Web3, DeFi, cryptography, and distributed systems.\n\n    Your task:\n    From the paper below (Title + Summary + Link), evaluate how useful each paper is for understanding investment opportunities or technological advantages within the Web3 / crypto / DeFi ecosystem.\n    Rate each paper on a five-level scale: Highest / High / Medium / Low / Lowest.\n\n    \"Useful\" means:\n\n    - Improves understanding of new cryptographic primitives relevant to blockchain performance or security\n    - Enhances scalability: distributed systems, P2P networking, consensus mechanisms\n    - Advances in zero knowledge, MPC, PQC that could impact future L1/L2 chains\n    - DeFi modeling, AMMs, MEV, risk models, liquidity dynamics\n    - Smart contract security, attack vectors, economic incentives\n    - Token economics, mechanism design for decentralized systems\n    - Quantum threats to blockchain or cryptography\n    - Any breakthrough that meaningfully improves decentralization, scalability, privacy, or composability\n\n    Output instructions:\n\n    - Output each JSON object in JSON Lines format (one line per paper).\n\n    {\n        \"title\": title of the paper (in Japanese),\n        \"summary\": A concise summary of the paper (in Japanese),\n        \"impact_level\": \"Highest|High|Medium|Low|Lowest\",\n        \"why_matters\": An array (JSON array) containing 2\u20134 bullet points explaining why this paper matters for Web3 investment\n    }\n\n    - Do not output anything except valid JSON object in JSON Lines.\n    - \"title\", \"summary\", \"why_matters\" text in the output must be written in Japanese.\n\n    Paper:\n    title: Quantum Brownian Motion as a Classical Stochastic Process in Phase Space\n    summary: We establish that the exact quantum dynamics of a Brownian particle in the Caldeira-Leggett model can be mapped, at any temperature, onto a classical, non-Markovian stochastic process in phase space. Starting from a correlated thermal equilibrium state between the particle and bath, we prove that this correspondence is exact for quadratic potentials under arbitrary quantum state preparations of the particle itself. For more general, smooth potentials, we identify and exploit a natural small parameter: the density matrix becomes strongly quasidiagonal in the coordinate representation, with its off-diagonal width shrinking as the bath's spectral cutoff increases, providing a controlled parameter for accurate approximation. The framework is fully general: arbitrary initial quantum states-including highly non-classical superpositions-are incorporated via their Wigner functions, which serve as statistical weights for trajectory ensembles. Furthermore, the formalism naturally accommodates external manipulations and measurements modeled by preparation functions acting at arbitrary times, enabling the simulation of complex driven-dissipative quantum protocols.\n    link: https://arxiv.org/abs/2512.08641v1\n    "}}
{"custom_id": "2512.08638v1", "method": "POST", "url": "/v1/responses", "body": {"model": "gpt-5-mini", "input": "You are a specialist research analyst in Web3, DeFi, cryptography, and distributed systems.\n\n    Your task:\n    From the paper below (Title + Summary + Link), evaluate how useful each paper is for understanding investment opportunities or technological advantages within the Web3 / crypto / DeFi ecosystem.\n    Rate each paper on a five-level scale: Highest / High / Medium / Low / Lowest.\n\n    \"Useful\" means:\n\n    - Improves understanding of new cryptographic primitives relevant to blockchain performance or security\n    - Enhances scalability: distributed systems, P2P networking, consensus mechanisms\n    - Advances in zero knowledge, MPC, PQC that could impact future L1/L2 chains\n    - DeFi modeling, AMMs, MEV, risk models, liquidity dynamics\n    - Smart contract security, attack vectors, economic incentives\n    - Token economics, mechanism design for decentralized systems\n    - Quantum threats to blockchain or cryptography\n    - Any breakthrough that meaningfully improves decentralization, scalability, privacy, or composability\n\n    Output instructions:\n\n    - Output each JSON object in JSON Lines format (one line per paper).\n\n    {\n        \"title\": title of the paper (in Japanese),\n        \"summary\": A concise summary of the paper (in Japanese),\n        \"impact_level\": \"Highest|High|Medium|Low|Lowest\",\n        \"why_matters\": An array (JSON array) containing 2\u20134 bullet points explaining why this paper matters for Web3 investment\n    }\n\n    - Do not output anything except valid JSON object in JSON Lines.\n    - \"title\", \"summary\", \"why_matters\" text in the output must be written in Japanese.\n\n    Paper:\n    title: Strain sensitivity enhancement in a Grover-Michelson interferometer\n    summary: The Michelson interferometric phase detection resolution can be enhanced by replacing conventional beam splitters with novel directionally unbiased four-port scatterers, such as Grover coins. We present a quantitative analysis of the noise-to-signal ratio of sideband frequencies generated by gravitational wave-induced phase perturbations in a Grover-Michelson interferometer (GMI). We discuss the principles of GMI signal enhancement and demonstrate how combining this configuration with additional light-recycling arrangements further enhances the performance.\n    link: https://arxiv.org/abs/2512.08638v1\n    "}}
{"custom_id": "2512.08626v1", "method": "POST", "url": "/v1/responses", "body": {"model": "gpt-5-mini", "input": "You are a specialist research analyst in Web3, DeFi, cryptography, and distributed systems.\n\n    Your task:\n    From the paper below (Title + Summary + Link), evaluate how useful each paper is for understanding investment opportunities or technological advantages within the Web3 / crypto / DeFi ecosystem.\n    Rate each paper on a five-level scale: Highest / High / Medium / Low / Lowest.\n\n    \"Useful\" means:\n\n    - Improves understanding of new cryptographic primitives relevant to blockchain performance or security\n    - Enhances scalability: distributed systems, P2P networking, consensus mechanisms\n    - Advances in zero knowledge, MPC, PQC that could impact future L1/L2 chains\n    - DeFi modeling, AMMs, MEV, risk models, liquidity dynamics\n    - Smart contract security, attack vectors, economic incentives\n    - Token economics, mechanism design for decentralized systems\n    - Quantum threats to blockchain or cryptography\n    - Any breakthrough that meaningfully improves decentralization, scalability, privacy, or composability\n\n    Output instructions:\n\n    - Output each JSON object in JSON Lines format (one line per paper).\n\n    {\n        \"title\": title of the paper (in Japanese),\n        \"summary\": A concise summary of the paper (in Japanese),\n        \"impact_level\": \"Highest|High|Medium|Low|Lowest\",\n        \"why_matters\": An array (JSON array) containing 2\u20134 bullet points explaining why this paper matters for Web3 investment\n    }\n\n    - Do not output anything except valid JSON object in JSON Lines.\n    - \"title\", \"summary\", \"why_matters\" text in the output must be written in Japanese.\n\n    Paper:\n    title: Inferring Causal Relationships to Improve Caching for Clients with Correlated Requests: Applications to VR\n    summary: Efficient edge caching reduces latency and alleviates backhaul congestion in modern networks. Traditional caching policies, such as Least Recently Used (LRU) and Least Frequently Used (LFU), perform well under specific request patterns. LRU excels in workloads with strong temporal locality, while LFU is effective when content popularity remains static. However, real-world client requests often exhibit correlations due to shared contexts and coordinated activities. This is particularly evident in Virtual Reality (VR) environments, where groups of clients navigate shared virtual spaces, leading to correlated content requests.\n  In this paper, we introduce the \\textit{grouped client request model}, a generalization of the Independent Reference Model that explicitly captures different types of request correlations. Our theoretical analysis of LRU under this model reveals that the optimal causal caching policy depends on cache size: LFU is optimal for small to moderate caches, while LRU outperforms it for larger caches. To address the limitations of existing policies, we propose Least Following and Recently Used (LFRU), a novel online caching policy that dynamically infers and adapts to causal relationships in client requests to optimize evictions. LFRU prioritizes objects likely to be requested based on inferred dependencies, achieving near-optimal performance compared to the offline optimal Belady policy in structured correlation settings.\n  We develop VR based datasets to evaluate caching policies under realistic correlated requests. Our results show that LFRU consistently performs at least as well as LRU and LFU, outperforming LRU by up to 2.9x and LFU by up to1.9x in certain settings.\n    link: https://arxiv.org/abs/2512.08626v1\n    "}}
{"custom_id": "2512.08623v1", "method": "POST", "url": "/v1/responses", "body": {"model": "gpt-5-mini", "input": "You are a specialist research analyst in Web3, DeFi, cryptography, and distributed systems.\n\n    Your task:\n    From the paper below (Title + Summary + Link), evaluate how useful each paper is for understanding investment opportunities or technological advantages within the Web3 / crypto / DeFi ecosystem.\n    Rate each paper on a five-level scale: Highest / High / Medium / Low / Lowest.\n\n    \"Useful\" means:\n\n    - Improves understanding of new cryptographic primitives relevant to blockchain performance or security\n    - Enhances scalability: distributed systems, P2P networking, consensus mechanisms\n    - Advances in zero knowledge, MPC, PQC that could impact future L1/L2 chains\n    - DeFi modeling, AMMs, MEV, risk models, liquidity dynamics\n    - Smart contract security, attack vectors, economic incentives\n    - Token economics, mechanism design for decentralized systems\n    - Quantum threats to blockchain or cryptography\n    - Any breakthrough that meaningfully improves decentralization, scalability, privacy, or composability\n\n    Output instructions:\n\n    - Output each JSON object in JSON Lines format (one line per paper).\n\n    {\n        \"title\": title of the paper (in Japanese),\n        \"summary\": A concise summary of the paper (in Japanese),\n        \"impact_level\": \"Highest|High|Medium|Low|Lowest\",\n        \"why_matters\": An array (JSON array) containing 2\u20134 bullet points explaining why this paper matters for Web3 investment\n    }\n\n    - Do not output anything except valid JSON object in JSON Lines.\n    - \"title\", \"summary\", \"why_matters\" text in the output must be written in Japanese.\n\n    Paper:\n    title: An Efficient Secret Communication Scheme for the Bosonic Wiretap Channel\n    summary: We propose a new secret communication scheme over the bosonic wiretap channel. It uses readily available hardware such as lasers and direct photodetectors. The scheme is based on randomness extractors, pulse-position modulation, and Reed-Solomon codes and is therefore computationally efficient. It is secure against an eavesdropper performing coherent joint measurements on the quantum states it observes. In the low-photon-flow limit, the scheme is asymptotically optimal and achieves the same dominant term as the secrecy capacity of the same channel.\n    link: https://arxiv.org/abs/2512.08623v1\n    "}}
{"custom_id": "2512.08575v1", "method": "POST", "url": "/v1/responses", "body": {"model": "gpt-5-mini", "input": "You are a specialist research analyst in Web3, DeFi, cryptography, and distributed systems.\n\n    Your task:\n    From the paper below (Title + Summary + Link), evaluate how useful each paper is for understanding investment opportunities or technological advantages within the Web3 / crypto / DeFi ecosystem.\n    Rate each paper on a five-level scale: Highest / High / Medium / Low / Lowest.\n\n    \"Useful\" means:\n\n    - Improves understanding of new cryptographic primitives relevant to blockchain performance or security\n    - Enhances scalability: distributed systems, P2P networking, consensus mechanisms\n    - Advances in zero knowledge, MPC, PQC that could impact future L1/L2 chains\n    - DeFi modeling, AMMs, MEV, risk models, liquidity dynamics\n    - Smart contract security, attack vectors, economic incentives\n    - Token economics, mechanism design for decentralized systems\n    - Quantum threats to blockchain or cryptography\n    - Any breakthrough that meaningfully improves decentralization, scalability, privacy, or composability\n\n    Output instructions:\n\n    - Output each JSON object in JSON Lines format (one line per paper).\n\n    {\n        \"title\": title of the paper (in Japanese),\n        \"summary\": A concise summary of the paper (in Japanese),\n        \"impact_level\": \"Highest|High|Medium|Low|Lowest\",\n        \"why_matters\": An array (JSON array) containing 2\u20134 bullet points explaining why this paper matters for Web3 investment\n    }\n\n    - Do not output anything except valid JSON object in JSON Lines.\n    - \"title\", \"summary\", \"why_matters\" text in the output must be written in Japanese.\n\n    Paper:\n    title: Integrating Public Input and Technical Expertise for Effective Cybersecurity Policy Formulation\n    summary: The evolving of digital transformation and increased use of technology comes with increased cyber vulnerabilities, which compromise national security. Cyber-threats become more sophisticated as the technology advances. This emphasises the need for strong risk mitigation strategies. To define strong and robust cybersecurity, policies requires an integrated approach of balancing technical expertise with public input. This paper aims to explore strategies used to balance technical expertise and public input to develop effective and robust cybersecurity policies. It also studied how the effective integration of technical expertise with public input is critical to developing effective strategies and resilient cybersecurity frameworks that strengthens national security. A lack of a holistic approach and collaborative efforts to cybersecurity can hinder the effectiveness of cybersecurity policies. This paper followed a systematic literature review with bibliometric analysis using the PRISMA methodology to explore how technical expertise and public input can be integrated to guide cybersecurity policy making. The thematic analysis identified five important themes in developing effective cybersecurity policies, these key themes are: Multi-Stakeholder Involvement and Human Centric Approaches (MSI & HCA), Governance and Policy Frameworks (GPF), Technical Infrastructure (TI), Evaluation and Compliance (EC), and Legal Rights and Sovereignty (LRS). The synthesis shows that there is no adequate exploration of collaborative efforts which undermines the effectiveness of the cybersecurity policies. The findings suggest that inclusive, flexible governance strategies that integrate public input at every stage are necessary for future cybersecurity policy research and practice, which must shift away from a primarily technical and legal perspective.\n    link: https://arxiv.org/abs/2512.08575v1\n    "}}
{"custom_id": "2512.08563v1", "method": "POST", "url": "/v1/responses", "body": {"model": "gpt-5-mini", "input": "You are a specialist research analyst in Web3, DeFi, cryptography, and distributed systems.\n\n    Your task:\n    From the paper below (Title + Summary + Link), evaluate how useful each paper is for understanding investment opportunities or technological advantages within the Web3 / crypto / DeFi ecosystem.\n    Rate each paper on a five-level scale: Highest / High / Medium / Low / Lowest.\n\n    \"Useful\" means:\n\n    - Improves understanding of new cryptographic primitives relevant to blockchain performance or security\n    - Enhances scalability: distributed systems, P2P networking, consensus mechanisms\n    - Advances in zero knowledge, MPC, PQC that could impact future L1/L2 chains\n    - DeFi modeling, AMMs, MEV, risk models, liquidity dynamics\n    - Smart contract security, attack vectors, economic incentives\n    - Token economics, mechanism design for decentralized systems\n    - Quantum threats to blockchain or cryptography\n    - Any breakthrough that meaningfully improves decentralization, scalability, privacy, or composability\n\n    Output instructions:\n\n    - Output each JSON object in JSON Lines format (one line per paper).\n\n    {\n        \"title\": title of the paper (in Japanese),\n        \"summary\": A concise summary of the paper (in Japanese),\n        \"impact_level\": \"Highest|High|Medium|Low|Lowest\",\n        \"why_matters\": An array (JSON array) containing 2\u20134 bullet points explaining why this paper matters for Web3 investment\n    }\n\n    - Do not output anything except valid JSON object in JSON Lines.\n    - \"title\", \"summary\", \"why_matters\" text in the output must be written in Japanese.\n\n    Paper:\n    title: Basic Lock Algorithms in Lightweight Thread Environments\n    summary: Traditionally, multithreaded data structures have been designed for access by the threads of Operating Systems (OS). However, implementations for access by programmable alternatives known as lightweight threads (also referred to as asynchronous calls or coroutines) have not been thoroughly studied. The main advantage of lightweight threads is their significantly lower overhead during launch and context switching. However, this comes at a cost: to achieve proper parallelism, context switches must be manually invoked in the code; without these switches, new lightweight threads will never be executed.\n  In this paper, we focus on the simplest multithreaded data structure: a mutex (also known as a lock). We demonstrate that original implementations for OS threads cannot be used effectively in this new context due to the potential for deadlocks. Furthermore, correctness is not the only concern. In certain languages, such as C++, there are various lightweight thread libraries, each with different implementations and interfaces, which necessitate distinct lock implementations.\n  In this work, we present a modification of TTAS and MCS locks for the use from lightweight threads and demonstrate that the two context switch mechanisms of lightweight threads, yielding and sleeping, are crucial. However, the performance of TTAS and MCS may differ significantly depending on the settings. If one wants to have a lock that works well for any library, we suggest using the cohort lock, which strikes a balance between MCS and TTAS by utilizing several MCS queues with a common TTAS.\n    link: https://arxiv.org/abs/2512.08563v1\n    "}}
{"custom_id": "2512.08558v1", "method": "POST", "url": "/v1/responses", "body": {"model": "gpt-5-mini", "input": "You are a specialist research analyst in Web3, DeFi, cryptography, and distributed systems.\n\n    Your task:\n    From the paper below (Title + Summary + Link), evaluate how useful each paper is for understanding investment opportunities or technological advantages within the Web3 / crypto / DeFi ecosystem.\n    Rate each paper on a five-level scale: Highest / High / Medium / Low / Lowest.\n\n    \"Useful\" means:\n\n    - Improves understanding of new cryptographic primitives relevant to blockchain performance or security\n    - Enhances scalability: distributed systems, P2P networking, consensus mechanisms\n    - Advances in zero knowledge, MPC, PQC that could impact future L1/L2 chains\n    - DeFi modeling, AMMs, MEV, risk models, liquidity dynamics\n    - Smart contract security, attack vectors, economic incentives\n    - Token economics, mechanism design for decentralized systems\n    - Quantum threats to blockchain or cryptography\n    - Any breakthrough that meaningfully improves decentralization, scalability, privacy, or composability\n\n    Output instructions:\n\n    - Output each JSON object in JSON Lines format (one line per paper).\n\n    {\n        \"title\": title of the paper (in Japanese),\n        \"summary\": A concise summary of the paper (in Japanese),\n        \"impact_level\": \"Highest|High|Medium|Low|Lowest\",\n        \"why_matters\": An array (JSON array) containing 2\u20134 bullet points explaining why this paper matters for Web3 investment\n    }\n\n    - Do not output anything except valid JSON object in JSON Lines.\n    - \"title\", \"summary\", \"why_matters\" text in the output must be written in Japanese.\n\n    Paper:\n    title: Labeled Delegated PSI and its Applications in the Public Sector\n    summary: Sensitive citizen data, such as social, medical, and fiscal data, is heavily fragmented across\n  public bodies and the private domain. Mining the combined data sets allows for new insights that otherwise remain hidden.\n  Examples are improved healthcare, fraud detection, and evidence-based policy making.\n  (Multi-party) delegated private set intersection (D-PSI) is a privacy-enhancing technology to link data across multiple data providers using a data collector.\n  However, before it can be deployed in these use cases, it needs to be enhanced with additional functions, e.g., securely delivering payload only for elements in the intersection.\n  Although there has been recent progress in the communication and computation requirements of D-PSI, these practical obstacles have not yet been addressed.\n  This paper is the result of a collaboration with a governmental organization responsible for collecting, linking, and pseudonymizing data.\n  Based on their requirements, we design a new D-PSI protocol with composable output functions, including encrypted payload and pseudonymized identifiers.\n  We show that our protocol is secure in the standard model against colluding semi-honest data providers and against a non-colluding, possibly malicious independent party, the data collector.\n  It, hence, allows to privately link and collect data from multiple data providers suitable for deployment in these use cases in the public sector.\n    link: https://arxiv.org/abs/2512.08558v1\n    "}}
{"custom_id": "2512.08555v1", "method": "POST", "url": "/v1/responses", "body": {"model": "gpt-5-mini", "input": "You are a specialist research analyst in Web3, DeFi, cryptography, and distributed systems.\n\n    Your task:\n    From the paper below (Title + Summary + Link), evaluate how useful each paper is for understanding investment opportunities or technological advantages within the Web3 / crypto / DeFi ecosystem.\n    Rate each paper on a five-level scale: Highest / High / Medium / Low / Lowest.\n\n    \"Useful\" means:\n\n    - Improves understanding of new cryptographic primitives relevant to blockchain performance or security\n    - Enhances scalability: distributed systems, P2P networking, consensus mechanisms\n    - Advances in zero knowledge, MPC, PQC that could impact future L1/L2 chains\n    - DeFi modeling, AMMs, MEV, risk models, liquidity dynamics\n    - Smart contract security, attack vectors, economic incentives\n    - Token economics, mechanism design for decentralized systems\n    - Quantum threats to blockchain or cryptography\n    - Any breakthrough that meaningfully improves decentralization, scalability, privacy, or composability\n\n    Output instructions:\n\n    - Output each JSON object in JSON Lines format (one line per paper).\n\n    {\n        \"title\": title of the paper (in Japanese),\n        \"summary\": A concise summary of the paper (in Japanese),\n        \"impact_level\": \"Highest|High|Medium|Low|Lowest\",\n        \"why_matters\": An array (JSON array) containing 2\u20134 bullet points explaining why this paper matters for Web3 investment\n    }\n\n    - Do not output anything except valid JSON object in JSON Lines.\n    - \"title\", \"summary\", \"why_matters\" text in the output must be written in Japanese.\n\n    Paper:\n    title: A scalable high-order multigrid-FFT Poisson solver for unbounded domains on adaptive multiresolution grids\n    summary: Multigrid solvers are among the most efficient methods for solving the Poisson equation, which is ubiquitous in computational physics. For example, in the context of incompressible flows, it is typically the costliest operation. The present document expounds upon the implementation of a flexible multigrid solver that is capable of handling any type of boundary conditions within murphy, a multiresolution framework for solving partial differential equations (PDEs) on collocated adaptive grids. The utilization of a Fourier-based direct solver facilitates the attainment of flexibility and enhanced performance by accommodating any combination of unbounded and semi-unbounded boundary conditions. The employment of high-order compact stencils contributes to the reduction of communication demands while concurrently enhancing the accuracy of the system. The resulting solver is validated against analytical solutions for periodic and unbounded domains. In conclusion, the solver has been demonstrated to demonstrate scalability to 16,384 cores within the context of leading European high-performance computing infrastructures.\n    link: https://arxiv.org/abs/2512.08555v1\n    "}}
{"custom_id": "2410.08122v2", "method": "POST", "url": "/v1/responses", "body": {"model": "gpt-5-mini", "input": "You are a specialist research analyst in Web3, DeFi, cryptography, and distributed systems.\n\n    Your task:\n    From the paper below (Title + Summary + Link), evaluate how useful each paper is for understanding investment opportunities or technological advantages within the Web3 / crypto / DeFi ecosystem.\n    Rate each paper on a five-level scale: Highest / High / Medium / Low / Lowest.\n\n    \"Useful\" means:\n\n    - Improves understanding of new cryptographic primitives relevant to blockchain performance or security\n    - Enhances scalability: distributed systems, P2P networking, consensus mechanisms\n    - Advances in zero knowledge, MPC, PQC that could impact future L1/L2 chains\n    - DeFi modeling, AMMs, MEV, risk models, liquidity dynamics\n    - Smart contract security, attack vectors, economic incentives\n    - Token economics, mechanism design for decentralized systems\n    - Quantum threats to blockchain or cryptography\n    - Any breakthrough that meaningfully improves decentralization, scalability, privacy, or composability\n\n    Output instructions:\n\n    - Output each JSON object in JSON Lines format (one line per paper).\n\n    {\n        \"title\": title of the paper (in Japanese),\n        \"summary\": A concise summary of the paper (in Japanese),\n        \"impact_level\": \"Highest|High|Medium|Low|Lowest\",\n        \"why_matters\": An array (JSON array) containing 2\u20134 bullet points explaining why this paper matters for Web3 investment\n    }\n\n    - Do not output anything except valid JSON object in JSON Lines.\n    - \"title\", \"summary\", \"why_matters\" text in the output must be written in Japanese.\n\n    Paper:\n    title: PP-GWAS: Privacy Preserving Multi-Site Genome-wide Association Studies\n    summary: Genome-wide association studies are pivotal in understanding the genetic underpinnings of complex traits and diseases. Collaborative, multi-site GWAS aim to enhance statistical power but face obstacles due to the sensitive nature of genomic data sharing. Current state-of-the-art methods provide a privacy-focused approach utilizing computationally expensive methods such as Secure Multi-Party Computation and Homomorphic Encryption. In this context, we present a novel algorithm PP-GWAS designed to improve upon existing standards in terms of computational efficiency and scalability without sacrificing data privacy. This algorithm employs randomized encoding within a distributed architecture to perform stacked ridge regression on a Linear Mixed Model to ensure rigorous analysis. Experimental evaluation with real world and synthetic data indicates that PP-GWAS can achieve computational speeds twice as fast as similar state-of-the-art algorithms while using lesser computational resources, all while adhering to a robust security model that caters to an all-but-one semi-honest adversary setting. We have assessed its performance using various datasets, emphasizing its potential in facilitating more efficient and private genomic analyses.\n    link: https://arxiv.org/abs/2410.08122v2\n    "}}
{"custom_id": "2512.08493v1", "method": "POST", "url": "/v1/responses", "body": {"model": "gpt-5-mini", "input": "You are a specialist research analyst in Web3, DeFi, cryptography, and distributed systems.\n\n    Your task:\n    From the paper below (Title + Summary + Link), evaluate how useful each paper is for understanding investment opportunities or technological advantages within the Web3 / crypto / DeFi ecosystem.\n    Rate each paper on a five-level scale: Highest / High / Medium / Low / Lowest.\n\n    \"Useful\" means:\n\n    - Improves understanding of new cryptographic primitives relevant to blockchain performance or security\n    - Enhances scalability: distributed systems, P2P networking, consensus mechanisms\n    - Advances in zero knowledge, MPC, PQC that could impact future L1/L2 chains\n    - DeFi modeling, AMMs, MEV, risk models, liquidity dynamics\n    - Smart contract security, attack vectors, economic incentives\n    - Token economics, mechanism design for decentralized systems\n    - Quantum threats to blockchain or cryptography\n    - Any breakthrough that meaningfully improves decentralization, scalability, privacy, or composability\n\n    Output instructions:\n\n    - Output each JSON object in JSON Lines format (one line per paper).\n\n    {\n        \"title\": title of the paper (in Japanese),\n        \"summary\": A concise summary of the paper (in Japanese),\n        \"impact_level\": \"Highest|High|Medium|Low|Lowest\",\n        \"why_matters\": An array (JSON array) containing 2\u20134 bullet points explaining why this paper matters for Web3 investment\n    }\n\n    - Do not output anything except valid JSON object in JSON Lines.\n    - \"title\", \"summary\", \"why_matters\" text in the output must be written in Japanese.\n\n    Paper:\n    title: LLM-based Vulnerable Code Augmentation: Generate or Refactor?\n    summary: Vulnerability code-bases often suffer from severe imbalance, limiting the effectiveness of Deep Learning-based vulnerability classifiers. Data Augmentation could help solve this by mitigating the scarcity of under-represented CWEs. In this context, we investigate LLM-based augmentation for vulnerable functions, comparing controlled generation of new vulnerable samples with semantics-preserving refactoring of existing ones. Using Qwen2.5-Coder to produce augmented data and CodeBERT as a vulnerability classifier on the SVEN dataset, we find that our approaches are indeed effective in enriching vulnerable code-bases through a simple process and with reasonable quality, and that a hybrid strategy best boosts vulnerability classifiers' performance.\n    link: https://arxiv.org/abs/2512.08493v1\n    "}}
{"custom_id": "2511.20016v3", "method": "POST", "url": "/v1/responses", "body": {"model": "gpt-5-mini", "input": "You are a specialist research analyst in Web3, DeFi, cryptography, and distributed systems.\n\n    Your task:\n    From the paper below (Title + Summary + Link), evaluate how useful each paper is for understanding investment opportunities or technological advantages within the Web3 / crypto / DeFi ecosystem.\n    Rate each paper on a five-level scale: Highest / High / Medium / Low / Lowest.\n\n    \"Useful\" means:\n\n    - Improves understanding of new cryptographic primitives relevant to blockchain performance or security\n    - Enhances scalability: distributed systems, P2P networking, consensus mechanisms\n    - Advances in zero knowledge, MPC, PQC that could impact future L1/L2 chains\n    - DeFi modeling, AMMs, MEV, risk models, liquidity dynamics\n    - Smart contract security, attack vectors, economic incentives\n    - Token economics, mechanism design for decentralized systems\n    - Quantum threats to blockchain or cryptography\n    - Any breakthrough that meaningfully improves decentralization, scalability, privacy, or composability\n\n    Output instructions:\n\n    - Output each JSON object in JSON Lines format (one line per paper).\n\n    {\n        \"title\": title of the paper (in Japanese),\n        \"summary\": A concise summary of the paper (in Japanese),\n        \"impact_level\": \"Highest|High|Medium|Low|Lowest\",\n        \"why_matters\": An array (JSON array) containing 2\u20134 bullet points explaining why this paper matters for Web3 investment\n    }\n\n    - Do not output anything except valid JSON object in JSON Lines.\n    - \"title\", \"summary\", \"why_matters\" text in the output must be written in Japanese.\n\n    Paper:\n    title: Kernelized Decoded Quantum Interferometry\n    summary: Decoded Quantum Interferometry (DQI) promises superpolynomial speedups for structured optimization; however, its practical realization is often hindered by significant sensitivity to hardware noise and spectral dispersion. To bridge this gap, we introduce Kernelized Decoded Quantum Interferometry (k-DQI), a unified framework that integrates spectral engineering directly into the quantum circuit architecture. By inserting a unitary kernel prior to the interference step, k-DQI actively reshapes the problem's energy landscape, concentrating the solution mass into a ``decoder-friendly'' low-frequency head. We formalize this advantage through a novel robustness metric, the noise-weighted head mass $\u03a3_K$, and prove a Monotonic Improvement Theorem, which establishes that maximizing $\u03a3_K$ guarantees higher decoding success rates under local depolarizing noise. We substantiate these theoretical gains in Optimal Polynomial Interpolation (OPI) and LDPC-like problems, demonstrating that kernel tuning functions as a ``spectral lens'' to recover signal otherwise lost to isotropic noise. Crucially, we provide explicit, efficient circuit realizations using Chirp and Linear Canonical Transform (LCT) kernels that achieve significant boosts in effective signal-to-noise ratio with negligible depth overhead ($\\tilde{O}(n)$ to $\\tilde{O}(n^2)$). Collectively, these results reframe DQI from a static algorithm into a tunable, noise-aware protocol suited for near-term error-corrected environments.\n    link: https://arxiv.org/abs/2511.20016v3\n    "}}
{"custom_id": "2512.04656v2", "method": "POST", "url": "/v1/responses", "body": {"model": "gpt-5-mini", "input": "You are a specialist research analyst in Web3, DeFi, cryptography, and distributed systems.\n\n    Your task:\n    From the paper below (Title + Summary + Link), evaluate how useful each paper is for understanding investment opportunities or technological advantages within the Web3 / crypto / DeFi ecosystem.\n    Rate each paper on a five-level scale: Highest / High / Medium / Low / Lowest.\n\n    \"Useful\" means:\n\n    - Improves understanding of new cryptographic primitives relevant to blockchain performance or security\n    - Enhances scalability: distributed systems, P2P networking, consensus mechanisms\n    - Advances in zero knowledge, MPC, PQC that could impact future L1/L2 chains\n    - DeFi modeling, AMMs, MEV, risk models, liquidity dynamics\n    - Smart contract security, attack vectors, economic incentives\n    - Token economics, mechanism design for decentralized systems\n    - Quantum threats to blockchain or cryptography\n    - Any breakthrough that meaningfully improves decentralization, scalability, privacy, or composability\n\n    Output instructions:\n\n    - Output each JSON object in JSON Lines format (one line per paper).\n\n    {\n        \"title\": title of the paper (in Japanese),\n        \"summary\": A concise summary of the paper (in Japanese),\n        \"impact_level\": \"Highest|High|Medium|Low|Lowest\",\n        \"why_matters\": An array (JSON array) containing 2\u20134 bullet points explaining why this paper matters for Web3 investment\n    }\n\n    - Do not output anything except valid JSON object in JSON Lines.\n    - \"title\", \"summary\", \"why_matters\" text in the output must be written in Japanese.\n\n    Paper:\n    title: Collective cluster nucleation dynamics in 2D Ising quantum magnets\n    summary: Strongly interacting many-body systems often show collective properties that are non-trivially related to the microscopic degrees of freedom. Collectivity is responsible for intriguing ground state properties, for example, in superconductors. However, collective effects may also govern the non-equilibrium response of quantum systems, not only in condensed matter physics but also in quantum field theories modeling the properties of our universe. Understanding emergent collective dynamics from first principles, in particular in non-perturbative regimes, is therefore one of the central challenges in quantum many-body physics. Here we report on the observation of collective cluster nucleation in 2D quantum Ising systems realized in an atomic Rydberg array. We observe a confined regime in which the steady-state cluster size is energy-dependent and a deconfined regime characterized by kinetically constrained dynamics of cluster nucleation. Our results mark a qualitative leap for quantum simulations with Rydberg arrays and shed light on highly collective non-equilibrium processes in one of the most important textbook models of condensed matter physics with relevance from quantum magnets and the kinetics of glass formers to cosmology.\n    link: https://arxiv.org/abs/2512.04656v2\n    "}}
{"custom_id": "2507.01101v2", "method": "POST", "url": "/v1/responses", "body": {"model": "gpt-5-mini", "input": "You are a specialist research analyst in Web3, DeFi, cryptography, and distributed systems.\n\n    Your task:\n    From the paper below (Title + Summary + Link), evaluate how useful each paper is for understanding investment opportunities or technological advantages within the Web3 / crypto / DeFi ecosystem.\n    Rate each paper on a five-level scale: Highest / High / Medium / Low / Lowest.\n\n    \"Useful\" means:\n\n    - Improves understanding of new cryptographic primitives relevant to blockchain performance or security\n    - Enhances scalability: distributed systems, P2P networking, consensus mechanisms\n    - Advances in zero knowledge, MPC, PQC that could impact future L1/L2 chains\n    - DeFi modeling, AMMs, MEV, risk models, liquidity dynamics\n    - Smart contract security, attack vectors, economic incentives\n    - Token economics, mechanism design for decentralized systems\n    - Quantum threats to blockchain or cryptography\n    - Any breakthrough that meaningfully improves decentralization, scalability, privacy, or composability\n\n    Output instructions:\n\n    - Output each JSON object in JSON Lines format (one line per paper).\n\n    {\n        \"title\": title of the paper (in Japanese),\n        \"summary\": A concise summary of the paper (in Japanese),\n        \"impact_level\": \"Highest|High|Medium|Low|Lowest\",\n        \"why_matters\": An array (JSON array) containing 2\u20134 bullet points explaining why this paper matters for Web3 investment\n    }\n\n    - Do not output anything except valid JSON object in JSON Lines.\n    - \"title\", \"summary\", \"why_matters\" text in the output must be written in Japanese.\n\n    Paper:\n    title: Anonymous and private parameter estimation in networks of quantum sensors\n    summary: Anonymity and privacy are two key properties of modern communication networks. In quantum networks, distributed quantum sensing has emerged as a powerful use case, with applications to clock synchronisation, detecting gravitational effects and more. In this work, we develop a new protocol that, for the first time, combines the different cryptographic properties of anonymity and privacy for the task of distributed parameter estimation. That is, we present a protocol that allows a selected subset of network participants to anonymously collaborate in estimating the average of their private parameters. Crucially, this is achieved without disclosing either the individual parameter values or the identities of the participants, neither to each other nor to the broader network.\n    link: https://arxiv.org/abs/2507.01101v2\n    "}}
{"custom_id": "2512.08432v1", "method": "POST", "url": "/v1/responses", "body": {"model": "gpt-5-mini", "input": "You are a specialist research analyst in Web3, DeFi, cryptography, and distributed systems.\n\n    Your task:\n    From the paper below (Title + Summary + Link), evaluate how useful each paper is for understanding investment opportunities or technological advantages within the Web3 / crypto / DeFi ecosystem.\n    Rate each paper on a five-level scale: Highest / High / Medium / Low / Lowest.\n\n    \"Useful\" means:\n\n    - Improves understanding of new cryptographic primitives relevant to blockchain performance or security\n    - Enhances scalability: distributed systems, P2P networking, consensus mechanisms\n    - Advances in zero knowledge, MPC, PQC that could impact future L1/L2 chains\n    - DeFi modeling, AMMs, MEV, risk models, liquidity dynamics\n    - Smart contract security, attack vectors, economic incentives\n    - Token economics, mechanism design for decentralized systems\n    - Quantum threats to blockchain or cryptography\n    - Any breakthrough that meaningfully improves decentralization, scalability, privacy, or composability\n\n    Output instructions:\n\n    - Output each JSON object in JSON Lines format (one line per paper).\n\n    {\n        \"title\": title of the paper (in Japanese),\n        \"summary\": A concise summary of the paper (in Japanese),\n        \"impact_level\": \"Highest|High|Medium|Low|Lowest\",\n        \"why_matters\": An array (JSON array) containing 2\u20134 bullet points explaining why this paper matters for Web3 investment\n    }\n\n    - Do not output anything except valid JSON object in JSON Lines.\n    - \"title\", \"summary\", \"why_matters\" text in the output must be written in Japanese.\n\n    Paper:\n    title: A Grover-compatible manifold optimization algorithm for quantum search\n    summary: Grover's algorithm is a fundamental quantum algorithm that offers a quadratic speedup for the unstructured search problem by alternately applying physically implementable oracle and diffusion operators. In this paper, we reformulate the unstructured search as a maximization problem on the unitary manifold and solve it via the Riemannian gradient ascent (RGA) method. To overcome the difficulty that generic RGA updates do not, in general, correspond to physically implementable quantum operators, we introduce Grover-compatible retractions to restrict RGA updates to valid oracle and diffusion operators. Theoretically, we establish a local Riemannian $\u03bc$-Polyak-\u0141ojasiewicz (PL) inequality with $\u03bc= \\tfrac{1}{2}$, which yields a linear convergence rate of $1 - \u03ba^{-1}$ toward the global solution. Here, the condition number $\u03ba= L_{\\mathrm{Rie}} / \u03bc$, where $L_{\\mathrm{Rie}}$ denotes the Riemannian Lipschitz constant of the gradient. Taking into account both the geometry of the unitary manifold and the special structure of the cost function, we show that $L_{\\mathrm{Rie}} = O(\\sqrt{N})$ for problem size $N = 2^n$. Consequently, the resulting iteration complexity is $O(\\sqrt{N} \\log(1/\\varepsilon))$ for attaining an $\\varepsilon$-accurate solution, which matches the quadratic speedup of $O(\\sqrt{N})$ achieved by Grover's algorithm. These results demonstrate that an optimization-based viewpoint can offer fresh conceptual insights and lead to new advances in the design of quantum algorithms.\n    link: https://arxiv.org/abs/2512.08432v1\n    "}}
{"custom_id": "2512.08421v1", "method": "POST", "url": "/v1/responses", "body": {"model": "gpt-5-mini", "input": "You are a specialist research analyst in Web3, DeFi, cryptography, and distributed systems.\n\n    Your task:\n    From the paper below (Title + Summary + Link), evaluate how useful each paper is for understanding investment opportunities or technological advantages within the Web3 / crypto / DeFi ecosystem.\n    Rate each paper on a five-level scale: Highest / High / Medium / Low / Lowest.\n\n    \"Useful\" means:\n\n    - Improves understanding of new cryptographic primitives relevant to blockchain performance or security\n    - Enhances scalability: distributed systems, P2P networking, consensus mechanisms\n    - Advances in zero knowledge, MPC, PQC that could impact future L1/L2 chains\n    - DeFi modeling, AMMs, MEV, risk models, liquidity dynamics\n    - Smart contract security, attack vectors, economic incentives\n    - Token economics, mechanism design for decentralized systems\n    - Quantum threats to blockchain or cryptography\n    - Any breakthrough that meaningfully improves decentralization, scalability, privacy, or composability\n\n    Output instructions:\n\n    - Output each JSON object in JSON Lines format (one line per paper).\n\n    {\n        \"title\": title of the paper (in Japanese),\n        \"summary\": A concise summary of the paper (in Japanese),\n        \"impact_level\": \"Highest|High|Medium|Low|Lowest\",\n        \"why_matters\": An array (JSON array) containing 2\u20134 bullet points explaining why this paper matters for Web3 investment\n    }\n\n    - Do not output anything except valid JSON object in JSON Lines.\n    - \"title\", \"summary\", \"why_matters\" text in the output must be written in Japanese.\n\n    Paper:\n    title: Decay of spin helices in XXZ quantum spin chains with single-ion anisotropy\n    summary: Long-lived spin-helix states facilitate the study of non-equilibrium dynamics in quantum magnets. We consider the decay of transverse spin-helices in antiferromagnetic spin-$S$ XXZ chains with single-ion anisostropy. The spin-helix decay is observable in the time evolution of the local magnetization that we calculate numerically for the system in the thermodynamic limit using infinite time-evolving block decimation simulations. Although the single-ion anisotropy prevents helix states from being eigenstates of the Hamiltonian, they still can be long-lived for appropriately chosen wave numbers. In case of an easy-axis exchange anisotropy the single-ion anisotropy may even stabilize the helices. Within a spin-wave approximation, we obtain a condition giving an estimate for the most stable wave number $Q$ that agrees qualitatively with our numerical results.\n    link: https://arxiv.org/abs/2512.08421v1\n    "}}
{"custom_id": "2512.08417v1", "method": "POST", "url": "/v1/responses", "body": {"model": "gpt-5-mini", "input": "You are a specialist research analyst in Web3, DeFi, cryptography, and distributed systems.\n\n    Your task:\n    From the paper below (Title + Summary + Link), evaluate how useful each paper is for understanding investment opportunities or technological advantages within the Web3 / crypto / DeFi ecosystem.\n    Rate each paper on a five-level scale: Highest / High / Medium / Low / Lowest.\n\n    \"Useful\" means:\n\n    - Improves understanding of new cryptographic primitives relevant to blockchain performance or security\n    - Enhances scalability: distributed systems, P2P networking, consensus mechanisms\n    - Advances in zero knowledge, MPC, PQC that could impact future L1/L2 chains\n    - DeFi modeling, AMMs, MEV, risk models, liquidity dynamics\n    - Smart contract security, attack vectors, economic incentives\n    - Token economics, mechanism design for decentralized systems\n    - Quantum threats to blockchain or cryptography\n    - Any breakthrough that meaningfully improves decentralization, scalability, privacy, or composability\n\n    Output instructions:\n\n    - Output each JSON object in JSON Lines format (one line per paper).\n\n    {\n        \"title\": title of the paper (in Japanese),\n        \"summary\": A concise summary of the paper (in Japanese),\n        \"impact_level\": \"Highest|High|Medium|Low|Lowest\",\n        \"why_matters\": An array (JSON array) containing 2\u20134 bullet points explaining why this paper matters for Web3 investment\n    }\n\n    - Do not output anything except valid JSON object in JSON Lines.\n    - \"title\", \"summary\", \"why_matters\" text in the output must be written in Japanese.\n\n    Paper:\n    title: Attention is All You Need to Defend Against Indirect Prompt Injection Attacks in LLMs\n    summary: Large Language Models (LLMs) have been integrated into many applications (e.g., web agents) to perform more sophisticated tasks. However, LLM-empowered applications are vulnerable to Indirect Prompt Injection (IPI) attacks, where instructions are injected via untrustworthy external data sources. This paper presents Rennervate, a defense framework to detect and prevent IPI attacks. Rennervate leverages attention features to detect the covert injection at a fine-grained token level, enabling precise sanitization that neutralizes IPI attacks while maintaining LLM functionalities. Specifically, the token-level detector is materialized with a 2-step attentive pooling mechanism, which aggregates attention heads and response tokens for IPI detection and sanitization. Moreover, we establish a fine-grained IPI dataset, FIPI, to be open-sourced to support further research. Extensive experiments verify that Rennervate outperforms 15 commercial and academic IPI defense methods, achieving high precision on 5 LLMs and 6 datasets. We also demonstrate that Rennervate is transferable to unseen attacks and robust against adaptive adversaries.\n    link: https://arxiv.org/abs/2512.08417v1\n    "}}
{"custom_id": "2512.08416v1", "method": "POST", "url": "/v1/responses", "body": {"model": "gpt-5-mini", "input": "You are a specialist research analyst in Web3, DeFi, cryptography, and distributed systems.\n\n    Your task:\n    From the paper below (Title + Summary + Link), evaluate how useful each paper is for understanding investment opportunities or technological advantages within the Web3 / crypto / DeFi ecosystem.\n    Rate each paper on a five-level scale: Highest / High / Medium / Low / Lowest.\n\n    \"Useful\" means:\n\n    - Improves understanding of new cryptographic primitives relevant to blockchain performance or security\n    - Enhances scalability: distributed systems, P2P networking, consensus mechanisms\n    - Advances in zero knowledge, MPC, PQC that could impact future L1/L2 chains\n    - DeFi modeling, AMMs, MEV, risk models, liquidity dynamics\n    - Smart contract security, attack vectors, economic incentives\n    - Token economics, mechanism design for decentralized systems\n    - Quantum threats to blockchain or cryptography\n    - Any breakthrough that meaningfully improves decentralization, scalability, privacy, or composability\n\n    Output instructions:\n\n    - Output each JSON object in JSON Lines format (one line per paper).\n\n    {\n        \"title\": title of the paper (in Japanese),\n        \"summary\": A concise summary of the paper (in Japanese),\n        \"impact_level\": \"Highest|High|Medium|Low|Lowest\",\n        \"why_matters\": An array (JSON array) containing 2\u20134 bullet points explaining why this paper matters for Web3 investment\n    }\n\n    - Do not output anything except valid JSON object in JSON Lines.\n    - \"title\", \"summary\", \"why_matters\" text in the output must be written in Japanese.\n\n    Paper:\n    title: Improvement and Stabilization of Output Voltages in a Vertical Tidal Turbine Using Intelligent Control Strategies\n    summary: This article investigates on the improvement and stabilization of alternating current (AC) and direct current (DC) output voltages in a Permanent Magnet Synchronous Generator (PMSG) driven by a vertical-axis tidal turbine using advanced control strategies. The research integrates artificial intelligence (AI)-based techniques to enhance voltage stability and efficiency. Initially, the Maximum Power Point Tracking (MPPT) approach based on Tip Speed Ratio (TSR) and Artificial Neural Network (ANN) Fuzzy logic controllers is explored. To further optimize the performance, Particle Swarm Optimization (PSO) and a hybrid ANN-PSO methodology are implemented. These strategies aim to refine the reference rotational speed of the turbine while minimizing deviations from optimal power extraction conditions. The simulation results of a tidal turbine operating at a water flow velocity of 1.5 m/s demonstrate that the PSO-based control approach significantly enhances the voltage stability compared to conventional MPPT-TSR and ANN-Fuzzy controllers. The hybrid ANN-PSO technique improves the voltage regulation by dynamically adapting to system variations and providing real-time reference speed adjustments. This research highlights the AI-based hybrid optimization benefit to stabilize the output voltage of tidal energy systems, thereby increasing reliability and efficiency in renewable energy applications.\n    link: https://arxiv.org/abs/2512.08416v1\n    "}}
{"custom_id": "2512.08384v1", "method": "POST", "url": "/v1/responses", "body": {"model": "gpt-5-mini", "input": "You are a specialist research analyst in Web3, DeFi, cryptography, and distributed systems.\n\n    Your task:\n    From the paper below (Title + Summary + Link), evaluate how useful each paper is for understanding investment opportunities or technological advantages within the Web3 / crypto / DeFi ecosystem.\n    Rate each paper on a five-level scale: Highest / High / Medium / Low / Lowest.\n\n    \"Useful\" means:\n\n    - Improves understanding of new cryptographic primitives relevant to blockchain performance or security\n    - Enhances scalability: distributed systems, P2P networking, consensus mechanisms\n    - Advances in zero knowledge, MPC, PQC that could impact future L1/L2 chains\n    - DeFi modeling, AMMs, MEV, risk models, liquidity dynamics\n    - Smart contract security, attack vectors, economic incentives\n    - Token economics, mechanism design for decentralized systems\n    - Quantum threats to blockchain or cryptography\n    - Any breakthrough that meaningfully improves decentralization, scalability, privacy, or composability\n\n    Output instructions:\n\n    - Output each JSON object in JSON Lines format (one line per paper).\n\n    {\n        \"title\": title of the paper (in Japanese),\n        \"summary\": A concise summary of the paper (in Japanese),\n        \"impact_level\": \"Highest|High|Medium|Low|Lowest\",\n        \"why_matters\": An array (JSON array) containing 2\u20134 bullet points explaining why this paper matters for Web3 investment\n    }\n\n    - Do not output anything except valid JSON object in JSON Lines.\n    - \"title\", \"summary\", \"why_matters\" text in the output must be written in Japanese.\n\n    Paper:\n    title: Constraint-oriented biased quantum search for general constrained combinatorial optimization problems\n    summary: We present a quantum algorithmic routine that extends the realm of Grover-based heuristics for tackling combinatorial optimization problems with arbitrary efficiently computable objective and constraint functions. Building on previously developed quantum methods that were primarily restricted to linear constraints, we generalize the approach to encompass a broader class of problems in discrete domains. To evaluate the potential of our algorithm, we assume the existence of sufficiently advanced logical quantum hardware. With this assumption, we demonstrate that our method has the potential to outperform state-of-the-art classical solvers and heuristics in terms of both runtime scaling and solution quality. The same may be true for more realistic implementations, as the logical quantum algorithm can achieve runtime savings of up to $10^2-10^3$.\n    link: https://arxiv.org/abs/2512.08384v1\n    "}}
{"custom_id": "2512.08372v1", "method": "POST", "url": "/v1/responses", "body": {"model": "gpt-5-mini", "input": "You are a specialist research analyst in Web3, DeFi, cryptography, and distributed systems.\n\n    Your task:\n    From the paper below (Title + Summary + Link), evaluate how useful each paper is for understanding investment opportunities or technological advantages within the Web3 / crypto / DeFi ecosystem.\n    Rate each paper on a five-level scale: Highest / High / Medium / Low / Lowest.\n\n    \"Useful\" means:\n\n    - Improves understanding of new cryptographic primitives relevant to blockchain performance or security\n    - Enhances scalability: distributed systems, P2P networking, consensus mechanisms\n    - Advances in zero knowledge, MPC, PQC that could impact future L1/L2 chains\n    - DeFi modeling, AMMs, MEV, risk models, liquidity dynamics\n    - Smart contract security, attack vectors, economic incentives\n    - Token economics, mechanism design for decentralized systems\n    - Quantum threats to blockchain or cryptography\n    - Any breakthrough that meaningfully improves decentralization, scalability, privacy, or composability\n\n    Output instructions:\n\n    - Output each JSON object in JSON Lines format (one line per paper).\n\n    {\n        \"title\": title of the paper (in Japanese),\n        \"summary\": A concise summary of the paper (in Japanese),\n        \"impact_level\": \"Highest|High|Medium|Low|Lowest\",\n        \"why_matters\": An array (JSON array) containing 2\u20134 bullet points explaining why this paper matters for Web3 investment\n    }\n\n    - Do not output anything except valid JSON object in JSON Lines.\n    - \"title\", \"summary\", \"why_matters\" text in the output must be written in Japanese.\n\n    Paper:\n    title: USCSA: Evolution-Aware Security Analysis for Proxy-Based Upgradeable Smart Contracts\n    summary: In the case of upgrading smart contracts on blockchain systems, it is essential to consider the continuity of upgrade and subsequent maintenance. In practice, upgrade operations often introduce new vulnerabilities. To address this, we propose an Upgradable Smart Contract Security Analyzer, USCSA, which evaluates the risks associated with the upgrade process using the Abstract Syntax Tree (AST) differential analysis. We collected and analyzed 3,546 cases of vulnerabilities in upgradable contracts,covering common vulnerability categories such as reentrancy, access control flaws, and integer overflow. Experimental results show that USCSA achieves an accuracy of 92.3%, recall of 89.7%, and F1-score of 91.0% in detecting upgrade-induced vulnerabilities.\n  In addition, the efficiency of mapping high-risk changes has achieved a 30% improvement over the conventional approach. As a result, USCSA provides a significant advantage to improve the security and integrity of upgradable smart contracts, providing a novel and efficient solution to secure audits on blockchain applications.\n    link: https://arxiv.org/abs/2512.08372v1\n    "}}
{"custom_id": "2512.08365v1", "method": "POST", "url": "/v1/responses", "body": {"model": "gpt-5-mini", "input": "You are a specialist research analyst in Web3, DeFi, cryptography, and distributed systems.\n\n    Your task:\n    From the paper below (Title + Summary + Link), evaluate how useful each paper is for understanding investment opportunities or technological advantages within the Web3 / crypto / DeFi ecosystem.\n    Rate each paper on a five-level scale: Highest / High / Medium / Low / Lowest.\n\n    \"Useful\" means:\n\n    - Improves understanding of new cryptographic primitives relevant to blockchain performance or security\n    - Enhances scalability: distributed systems, P2P networking, consensus mechanisms\n    - Advances in zero knowledge, MPC, PQC that could impact future L1/L2 chains\n    - DeFi modeling, AMMs, MEV, risk models, liquidity dynamics\n    - Smart contract security, attack vectors, economic incentives\n    - Token economics, mechanism design for decentralized systems\n    - Quantum threats to blockchain or cryptography\n    - Any breakthrough that meaningfully improves decentralization, scalability, privacy, or composability\n\n    Output instructions:\n\n    - Output each JSON object in JSON Lines format (one line per paper).\n\n    {\n        \"title\": title of the paper (in Japanese),\n        \"summary\": A concise summary of the paper (in Japanese),\n        \"impact_level\": \"Highest|High|Medium|Low|Lowest\",\n        \"why_matters\": An array (JSON array) containing 2\u20134 bullet points explaining why this paper matters for Web3 investment\n    }\n\n    - Do not output anything except valid JSON object in JSON Lines.\n    - \"title\", \"summary\", \"why_matters\" text in the output must be written in Japanese.\n\n    Paper:\n    title: Magneton: Optimizing Energy Efficiency of ML Systems via Differential Energy Debugging\n    summary: The training and deployment of machine learning (ML) models have become extremely energy-intensive. While existing optimization efforts focus primarily on hardware energy efficiency, a significant but overlooked source of inefficiency is software energy waste caused by poor software design. This often includes redundant or poorly designed operations that consume more energy without improving performance. These inefficiencies arise in widely used ML frameworks and applications, yet developers often lack the visibility and tools to detect and diagnose them.\n  We propose differential energy debugging, a novel approach that leverages the observation that competing ML systems often implement similar functionality with vastly different energy consumption. Building on this insight, we design and implement Magneton, an energy profiler that compares energy consumption between similar ML systems at the operator level and automatically pinpoints code regions and configuration choices responsible for excessive energy use. Applied to 9 popular ML systems spanning LLM inference, general ML frameworks, and image generation, Magneton detects and diagnoses 16 known cases of software energy inefficiency and further discovers 8 previously unknown cases, 7 of which have been confirmed by developers.\n    link: https://arxiv.org/abs/2512.08365v1\n    "}}
{"custom_id": "2512.08351v1", "method": "POST", "url": "/v1/responses", "body": {"model": "gpt-5-mini", "input": "You are a specialist research analyst in Web3, DeFi, cryptography, and distributed systems.\n\n    Your task:\n    From the paper below (Title + Summary + Link), evaluate how useful each paper is for understanding investment opportunities or technological advantages within the Web3 / crypto / DeFi ecosystem.\n    Rate each paper on a five-level scale: Highest / High / Medium / Low / Lowest.\n\n    \"Useful\" means:\n\n    - Improves understanding of new cryptographic primitives relevant to blockchain performance or security\n    - Enhances scalability: distributed systems, P2P networking, consensus mechanisms\n    - Advances in zero knowledge, MPC, PQC that could impact future L1/L2 chains\n    - DeFi modeling, AMMs, MEV, risk models, liquidity dynamics\n    - Smart contract security, attack vectors, economic incentives\n    - Token economics, mechanism design for decentralized systems\n    - Quantum threats to blockchain or cryptography\n    - Any breakthrough that meaningfully improves decentralization, scalability, privacy, or composability\n\n    Output instructions:\n\n    - Output each JSON object in JSON Lines format (one line per paper).\n\n    {\n        \"title\": title of the paper (in Japanese),\n        \"summary\": A concise summary of the paper (in Japanese),\n        \"impact_level\": \"Highest|High|Medium|Low|Lowest\",\n        \"why_matters\": An array (JSON array) containing 2\u20134 bullet points explaining why this paper matters for Web3 investment\n    }\n\n    - Do not output anything except valid JSON object in JSON Lines.\n    - \"title\", \"summary\", \"why_matters\" text in the output must be written in Japanese.\n\n    Paper:\n    title: Turning Threat into Opportunity: DRL-Powered Anti-Jamming via Energy Harvesting in UAV-Disrupted Channels\n    summary: The open and broadcast nature of wireless communication systems, while enabling ubiquitous connectivity, also exposes them to jamming attacks that may critically compromise network performance or disrupt service availability. The proliferation of Unmanned Aerial Vehicles (UAVs) introduces a new dimension to this threat, as UAVs can act as mobile, intelligent jammers capable of launching sophisticated attacks by leveraging Line-of-Sight (LoS) channels and adaptive strategies. This paper addresses a critical challenge of countering intelligent UAV jamming in the context of energy-constrained ambient backscatter communication systems. Traditional anti-jamming techniques often fall short against such dynamic threats or are unsuitable for low-power backscatter devices. Hence, we propose a novel anti-jamming framework based on Deep Reinforcement Learning (DRL) that empowers the transmitter to not only defend against but also strategically exploit the UAV's jamming signals. In particular, our approach allows the transmitter to learn an optimal policy for switching between active transmission, energy harvesting from the jamming signal, and backscattering information using the jammer's own emissions. We then formulate the problem as a Markov Decision Process (MDP) and employ a Deep Q-Network (DQN) to derive the optimal operational strategy. Simulation results demonstrate that our DQN-based method significantly outperforms conventional Q-learning in convergence speed and surpasses a greedy anti-jamming strategy in terms of average throughput, packet loss rate, and packet delivery ratio.\n    link: https://arxiv.org/abs/2512.08351v1\n    "}}
{"custom_id": "2512.08341v1", "method": "POST", "url": "/v1/responses", "body": {"model": "gpt-5-mini", "input": "You are a specialist research analyst in Web3, DeFi, cryptography, and distributed systems.\n\n    Your task:\n    From the paper below (Title + Summary + Link), evaluate how useful each paper is for understanding investment opportunities or technological advantages within the Web3 / crypto / DeFi ecosystem.\n    Rate each paper on a five-level scale: Highest / High / Medium / Low / Lowest.\n\n    \"Useful\" means:\n\n    - Improves understanding of new cryptographic primitives relevant to blockchain performance or security\n    - Enhances scalability: distributed systems, P2P networking, consensus mechanisms\n    - Advances in zero knowledge, MPC, PQC that could impact future L1/L2 chains\n    - DeFi modeling, AMMs, MEV, risk models, liquidity dynamics\n    - Smart contract security, attack vectors, economic incentives\n    - Token economics, mechanism design for decentralized systems\n    - Quantum threats to blockchain or cryptography\n    - Any breakthrough that meaningfully improves decentralization, scalability, privacy, or composability\n\n    Output instructions:\n\n    - Output each JSON object in JSON Lines format (one line per paper).\n\n    {\n        \"title\": title of the paper (in Japanese),\n        \"summary\": A concise summary of the paper (in Japanese),\n        \"impact_level\": \"Highest|High|Medium|Low|Lowest\",\n        \"why_matters\": An array (JSON array) containing 2\u20134 bullet points explaining why this paper matters for Web3 investment\n    }\n\n    - Do not output anything except valid JSON object in JSON Lines.\n    - \"title\", \"summary\", \"why_matters\" text in the output must be written in Japanese.\n\n    Paper:\n    title: Multi-Agent Deep Reinforcement Learning for Collaborative UAV Relay Networks under Jamming Atatcks\n    summary: The deployment of Unmanned Aerial Vehicle (UAV) swarms as dynamic communication relays is critical for next-generation tactical networks. However, operating in contested environments requires solving a complex trade-off, including maximizing system throughput while ensuring collision avoidance and resilience against adversarial jamming. Existing heuristic-based approaches often struggle to find effective solutions due to the dynamic and multi-objective nature of this problem. This paper formulates this challenge as a cooperative Multi-Agent Reinforcement Learning (MARL) problem, solved using the Centralized Training with Decentralized Execution (CTDE) framework. Our approach employs a centralized critic that uses global state information to guide decentralized actors which operate using only local observations. Simulation results show that our proposed framework significantly outperforms heuristic baselines, increasing the total system throughput by approximately 50% while simultaneously achieving a near-zero collision rate. A key finding is that the agents develop an emergent anti-jamming strategy without explicit programming. They learn to intelligently position themselves to balance the trade-off between mitigating interference from jammers and maintaining effective communication links with ground users.\n    link: https://arxiv.org/abs/2512.08341v1\n    "}}
{"custom_id": "2512.08326v1", "method": "POST", "url": "/v1/responses", "body": {"model": "gpt-5-mini", "input": "You are a specialist research analyst in Web3, DeFi, cryptography, and distributed systems.\n\n    Your task:\n    From the paper below (Title + Summary + Link), evaluate how useful each paper is for understanding investment opportunities or technological advantages within the Web3 / crypto / DeFi ecosystem.\n    Rate each paper on a five-level scale: Highest / High / Medium / Low / Lowest.\n\n    \"Useful\" means:\n\n    - Improves understanding of new cryptographic primitives relevant to blockchain performance or security\n    - Enhances scalability: distributed systems, P2P networking, consensus mechanisms\n    - Advances in zero knowledge, MPC, PQC that could impact future L1/L2 chains\n    - DeFi modeling, AMMs, MEV, risk models, liquidity dynamics\n    - Smart contract security, attack vectors, economic incentives\n    - Token economics, mechanism design for decentralized systems\n    - Quantum threats to blockchain or cryptography\n    - Any breakthrough that meaningfully improves decentralization, scalability, privacy, or composability\n\n    Output instructions:\n\n    - Output each JSON object in JSON Lines format (one line per paper).\n\n    {\n        \"title\": title of the paper (in Japanese),\n        \"summary\": A concise summary of the paper (in Japanese),\n        \"impact_level\": \"Highest|High|Medium|Low|Lowest\",\n        \"why_matters\": An array (JSON array) containing 2\u20134 bullet points explaining why this paper matters for Web3 investment\n    }\n\n    - Do not output anything except valid JSON object in JSON Lines.\n    - \"title\", \"summary\", \"why_matters\" text in the output must be written in Japanese.\n\n    Paper:\n    title: Argus: A Multi-Agent Sensitive Information Leakage Detection Framework Based on Hierarchical Reference Relationships\n    summary: Sensitive information leakage in code repositories has emerged as a critical security challenge. Traditional detection methods that rely on regular expressions, fingerprint features, and high-entropy calculations often suffer from high false-positive rates. This not only reduces detection efficiency but also significantly increases the manual screening burden on developers. Recent advances in large language models (LLMs) and multi-agent collaborative architectures have demonstrated remarkable potential for tackling complex tasks, offering a novel technological perspective for sensitive information detection. In response to these challenges, we propose Argus, a multi-agent collaborative framework for detecting sensitive information. Argus employs a three-tier detection mechanism that integrates key content, file context, and project reference relationships to effectively reduce false positives and enhance overall detection accuracy. To comprehensively evaluate Argus in real-world repository environments, we developed two new benchmarks, one to assess genuine leak detection capabilities and another to evaluate false-positive filtering performance. Experimental results show that Argus achieves up to 94.86% accuracy in leak detection, with a precision of 96.36%, recall of 94.64%, and an F1 score of 0.955. Moreover, the analysis of 97 real repositories incurred a total cost of only 2.2$. All code implementations and related datasets are publicly available at https://github.com/TheBinKing/Argus-Guard for further research and application.\n    link: https://arxiv.org/abs/2512.08326v1\n    "}}
{"custom_id": "2512.08322v1", "method": "POST", "url": "/v1/responses", "body": {"model": "gpt-5-mini", "input": "You are a specialist research analyst in Web3, DeFi, cryptography, and distributed systems.\n\n    Your task:\n    From the paper below (Title + Summary + Link), evaluate how useful each paper is for understanding investment opportunities or technological advantages within the Web3 / crypto / DeFi ecosystem.\n    Rate each paper on a five-level scale: Highest / High / Medium / Low / Lowest.\n\n    \"Useful\" means:\n\n    - Improves understanding of new cryptographic primitives relevant to blockchain performance or security\n    - Enhances scalability: distributed systems, P2P networking, consensus mechanisms\n    - Advances in zero knowledge, MPC, PQC that could impact future L1/L2 chains\n    - DeFi modeling, AMMs, MEV, risk models, liquidity dynamics\n    - Smart contract security, attack vectors, economic incentives\n    - Token economics, mechanism design for decentralized systems\n    - Quantum threats to blockchain or cryptography\n    - Any breakthrough that meaningfully improves decentralization, scalability, privacy, or composability\n\n    Output instructions:\n\n    - Output each JSON object in JSON Lines format (one line per paper).\n\n    {\n        \"title\": title of the paper (in Japanese),\n        \"summary\": A concise summary of the paper (in Japanese),\n        \"impact_level\": \"Highest|High|Medium|Low|Lowest\",\n        \"why_matters\": An array (JSON array) containing 2\u20134 bullet points explaining why this paper matters for Web3 investment\n    }\n\n    - Do not output anything except valid JSON object in JSON Lines.\n    - \"title\", \"summary\", \"why_matters\" text in the output must be written in Japanese.\n\n    Paper:\n    title: Collaborative Intelligence for UAV-Satellite Network Slicing: Towards a Joint QoS-Energy-Fairness MADRL Optimization\n    summary: Non terrestrial networks are critical for achieving global 6G coverage, yet efficient resource management in aerial and space environments remains challenging due to limited onboard power and dynamic operational conditions. Network slicing offers a promising solution for spectrum optimization in UAV based systems serving heterogeneous service demands. For that, this paper proposes a hierarchical network slicing framework for UAV satellite integrated networks supporting eMBB, URLLC, and mMTC services. Specifically, we formulate a joint optimization of UAV trajectory, transmission power, and spectrum allocation as a decentralized partially observable Markov decision process that ensures quality of service while minimizing energy consumption and maximizing resource fairness. To address the computational intractability and partial observability, we develop a multi agent deep reinforcement learning solution under the centralized training and decentralized execution paradigm. In the proposed system, UAV agents act as distributed actors coordinated by a shared critic operating with multi head attention mechanism at a low Earth orbit satellite. Experimental results then demonstrate that our approach outperforms existing methods by up to 33% in cumulative reward while achieving superior energy efficiency and fairness.\n    link: https://arxiv.org/abs/2512.08322v1\n    "}}
{"custom_id": "2512.08321v1", "method": "POST", "url": "/v1/responses", "body": {"model": "gpt-5-mini", "input": "You are a specialist research analyst in Web3, DeFi, cryptography, and distributed systems.\n\n    Your task:\n    From the paper below (Title + Summary + Link), evaluate how useful each paper is for understanding investment opportunities or technological advantages within the Web3 / crypto / DeFi ecosystem.\n    Rate each paper on a five-level scale: Highest / High / Medium / Low / Lowest.\n\n    \"Useful\" means:\n\n    - Improves understanding of new cryptographic primitives relevant to blockchain performance or security\n    - Enhances scalability: distributed systems, P2P networking, consensus mechanisms\n    - Advances in zero knowledge, MPC, PQC that could impact future L1/L2 chains\n    - DeFi modeling, AMMs, MEV, risk models, liquidity dynamics\n    - Smart contract security, attack vectors, economic incentives\n    - Token economics, mechanism design for decentralized systems\n    - Quantum threats to blockchain or cryptography\n    - Any breakthrough that meaningfully improves decentralization, scalability, privacy, or composability\n\n    Output instructions:\n\n    - Output each JSON object in JSON Lines format (one line per paper).\n\n    {\n        \"title\": title of the paper (in Japanese),\n        \"summary\": A concise summary of the paper (in Japanese),\n        \"impact_level\": \"Highest|High|Medium|Low|Lowest\",\n        \"why_matters\": An array (JSON array) containing 2\u20134 bullet points explaining why this paper matters for Web3 investment\n    }\n\n    - Do not output anything except valid JSON object in JSON Lines.\n    - \"title\", \"summary\", \"why_matters\" text in the output must be written in Japanese.\n\n    Paper:\n    title: Emulation of Complex Matrix Multiplication based on the Chinese Remainder Theorem\n    summary: Modern computing architectures feature low-precision matrix multiplication units that achieve substantially higher throughput than their high-precision counterparts. Motivated by this architectural trend, the emulation of high-precision matrix multiplication using low-precision hardware has attracted significant interest in the high-performance computing community. Ozaki, Uchino, and Imamura introduced the Ozaki-II scheme as a general framework for emulating matrix multiplication. Building on this framework, Uchino, Ozaki, and Imamura developed high-performance and power-efficient techniques for emulating single- and double-precision real matrix multiplication on INT8 matrix engines. Extending this line of research, the present study proposes high-performance emulation methods for single- and double-precision complex matrix multiplication on INT8 matrix engines, based on the Ozaki-II scheme. On an NVIDIA B200 GPU, the proposed methods achieve 4.0x--5.6x and 4.4x--6.5x speedups over the native single- and double-precision complex matrix multiplication routines from cuBLAS, respectively, for sufficiently large problem sizes. When lower accuracy than that of the standard routine is acceptable, the proposed methods can operate at even higher speed. Conversely, with only a modest increase in computation time, they can also deliver higher accuracy than the standard routines. These properties suggest that the proposed approach has the potential to serve as a default algorithm across a wide range of applications.\n    link: https://arxiv.org/abs/2512.08321v1\n    "}}
{"custom_id": "2512.08320v1", "method": "POST", "url": "/v1/responses", "body": {"model": "gpt-5-mini", "input": "You are a specialist research analyst in Web3, DeFi, cryptography, and distributed systems.\n\n    Your task:\n    From the paper below (Title + Summary + Link), evaluate how useful each paper is for understanding investment opportunities or technological advantages within the Web3 / crypto / DeFi ecosystem.\n    Rate each paper on a five-level scale: Highest / High / Medium / Low / Lowest.\n\n    \"Useful\" means:\n\n    - Improves understanding of new cryptographic primitives relevant to blockchain performance or security\n    - Enhances scalability: distributed systems, P2P networking, consensus mechanisms\n    - Advances in zero knowledge, MPC, PQC that could impact future L1/L2 chains\n    - DeFi modeling, AMMs, MEV, risk models, liquidity dynamics\n    - Smart contract security, attack vectors, economic incentives\n    - Token economics, mechanism design for decentralized systems\n    - Quantum threats to blockchain or cryptography\n    - Any breakthrough that meaningfully improves decentralization, scalability, privacy, or composability\n\n    Output instructions:\n\n    - Output each JSON object in JSON Lines format (one line per paper).\n\n    {\n        \"title\": title of the paper (in Japanese),\n        \"summary\": A concise summary of the paper (in Japanese),\n        \"impact_level\": \"Highest|High|Medium|Low|Lowest\",\n        \"why_matters\": An array (JSON array) containing 2\u20134 bullet points explaining why this paper matters for Web3 investment\n    }\n\n    - Do not output anything except valid JSON object in JSON Lines.\n    - \"title\", \"summary\", \"why_matters\" text in the output must be written in Japanese.\n\n    Paper:\n    title: Developing a Strong CPS Defender: An Evolutionary Approach\n    summary: Cyber-physical systems (CPSs) are used extensively in critical infrastructure, underscoring the need for anomaly detection systems that are able to catch even the most motivated attackers. Traditional anomaly detection techniques typically do `one-off' training on datasets crafted by experts or generated by fuzzers, potentially limiting their ability to generalize to unseen and more subtle attack strategies. Stopping at this point misses a key opportunity: a defender can actively challenge the attacker to find more nuanced attacks, which in turn can lead to more effective detection capabilities. Building on this concept, we propose Evo-Defender, an evolutionary framework that iteratively strengthens CPS defenses through a dynamic attacker-defender interaction. Evo-Defender includes a smart attacker that employs guided fuzzing to explore diverse, non-redundant attack strategies, while the self-evolving defender uses incremental learning to adapt to new attack patterns. We implement Evo-Defender on two realistic CPS testbeds: the Tennessee Eastman process and a Robotic Arm Assembly Workstation, injecting over 600 attack scenarios. In end-to-end attack detection experiments, Evo-Defender achieves up to 2.7% higher performance than state-of-the-art baselines on unseen scenarios, while utilizing training data more efficiently for faster and more robust detection.\n    link: https://arxiv.org/abs/2512.08320v1\n    "}}
{"custom_id": "2512.08310v1", "method": "POST", "url": "/v1/responses", "body": {"model": "gpt-5-mini", "input": "You are a specialist research analyst in Web3, DeFi, cryptography, and distributed systems.\n\n    Your task:\n    From the paper below (Title + Summary + Link), evaluate how useful each paper is for understanding investment opportunities or technological advantages within the Web3 / crypto / DeFi ecosystem.\n    Rate each paper on a five-level scale: Highest / High / Medium / Low / Lowest.\n\n    \"Useful\" means:\n\n    - Improves understanding of new cryptographic primitives relevant to blockchain performance or security\n    - Enhances scalability: distributed systems, P2P networking, consensus mechanisms\n    - Advances in zero knowledge, MPC, PQC that could impact future L1/L2 chains\n    - DeFi modeling, AMMs, MEV, risk models, liquidity dynamics\n    - Smart contract security, attack vectors, economic incentives\n    - Token economics, mechanism design for decentralized systems\n    - Quantum threats to blockchain or cryptography\n    - Any breakthrough that meaningfully improves decentralization, scalability, privacy, or composability\n\n    Output instructions:\n\n    - Output each JSON object in JSON Lines format (one line per paper).\n\n    {\n        \"title\": title of the paper (in Japanese),\n        \"summary\": A concise summary of the paper (in Japanese),\n        \"impact_level\": \"Highest|High|Medium|Low|Lowest\",\n        \"why_matters\": An array (JSON array) containing 2\u20134 bullet points explaining why this paper matters for Web3 investment\n    }\n\n    - Do not output anything except valid JSON object in JSON Lines.\n    - \"title\", \"summary\", \"why_matters\" text in the output must be written in Japanese.\n\n    Paper:\n    title: Privacy-Preserving Identifier Checking in 5G\n    summary: Device identifiers like the International Mobile Equipment Identity (IMEI) are crucial for ensuring device integrity and meeting regulations in 4G and 5G networks. However, sharing these identifiers with Mobile Network Operators (MNOs) brings significant privacy risks by enabling long-term tracking and linking of user activities across sessions. In this work, we propose a privacy-preserving identifier checking method in 5G. This paper introduces a protocol for verifying device identifiers without exposing them to the network while maintaining the same functions as the 3GPP-defined Equipment Identity Register (EIR) process. The proposed solution modifies the PEPSI protocol for a Private Set Membership (PSM) setting using the BFV homomorphic encryption scheme. This lets User Equipment (UE) prove that its identifier is not on an operator's blacklist or greylist while ensuring that the MNO only learns the outcome of the verification. The protocol allows controlled deanonymization through an authorized Law Enforcement (LE) hook, striking a balance between privacy and accountability. Implementation results show that the system can perform online verification within five seconds and requires about 15 to 16 MB of communication per session. This confirms its practical use under post-quantum security standards. The findings highlight the promise of homomorphic encryption for managing identifiers while preserving privacy in 5G, laying the groundwork for scalable and compliant verification systems in future 6G networks.\n    link: https://arxiv.org/abs/2512.08310v1\n    "}}
{"custom_id": "2510.18194v3", "method": "POST", "url": "/v1/responses", "body": {"model": "gpt-5-mini", "input": "You are a specialist research analyst in Web3, DeFi, cryptography, and distributed systems.\n\n    Your task:\n    From the paper below (Title + Summary + Link), evaluate how useful each paper is for understanding investment opportunities or technological advantages within the Web3 / crypto / DeFi ecosystem.\n    Rate each paper on a five-level scale: Highest / High / Medium / Low / Lowest.\n\n    \"Useful\" means:\n\n    - Improves understanding of new cryptographic primitives relevant to blockchain performance or security\n    - Enhances scalability: distributed systems, P2P networking, consensus mechanisms\n    - Advances in zero knowledge, MPC, PQC that could impact future L1/L2 chains\n    - DeFi modeling, AMMs, MEV, risk models, liquidity dynamics\n    - Smart contract security, attack vectors, economic incentives\n    - Token economics, mechanism design for decentralized systems\n    - Quantum threats to blockchain or cryptography\n    - Any breakthrough that meaningfully improves decentralization, scalability, privacy, or composability\n\n    Output instructions:\n\n    - Output each JSON object in JSON Lines format (one line per paper).\n\n    {\n        \"title\": title of the paper (in Japanese),\n        \"summary\": A concise summary of the paper (in Japanese),\n        \"impact_level\": \"Highest|High|Medium|Low|Lowest\",\n        \"why_matters\": An array (JSON array) containing 2\u20134 bullet points explaining why this paper matters for Web3 investment\n    }\n\n    - Do not output anything except valid JSON object in JSON Lines.\n    - \"title\", \"summary\", \"why_matters\" text in the output must be written in Japanese.\n\n    Paper:\n    title: Stability of torsion subgroups of elliptic curves over non-Galois extensions of odd prime degree\n    summary: Let $K$ be a field of characteristic $0$ and $E/K$ an elliptic curve over $K$. For a finite extension $L/K$ and a prime~$\\ell$, we provide Galois-theoretic sufficient conditions on $L/K$ under which $E\\left(L\\right)\\left[\\ell^{\\infty}\\right] = E\\left(K\\right)\\left[\\ell^{\\infty}\\right]$. For a non-Galois extension $L/K$ of prime degree, we relate the growth of the $\\ell^{\\infty}$-torsion subgroup of $E$ under the base change $L/K$ to the image of the mod-$\\ell$ cyclotomic character. In particular, In particular, we refine Gonz{\u00e1}lez-Jim{\u00e9}nez's result by ruling out certain torsion structures for quintic non-Galois extensions $L/\\mathbb{Q}$.\n    link: https://arxiv.org/abs/2510.18194v3\n    "}}
{"custom_id": "2512.08299v1", "method": "POST", "url": "/v1/responses", "body": {"model": "gpt-5-mini", "input": "You are a specialist research analyst in Web3, DeFi, cryptography, and distributed systems.\n\n    Your task:\n    From the paper below (Title + Summary + Link), evaluate how useful each paper is for understanding investment opportunities or technological advantages within the Web3 / crypto / DeFi ecosystem.\n    Rate each paper on a five-level scale: Highest / High / Medium / Low / Lowest.\n\n    \"Useful\" means:\n\n    - Improves understanding of new cryptographic primitives relevant to blockchain performance or security\n    - Enhances scalability: distributed systems, P2P networking, consensus mechanisms\n    - Advances in zero knowledge, MPC, PQC that could impact future L1/L2 chains\n    - DeFi modeling, AMMs, MEV, risk models, liquidity dynamics\n    - Smart contract security, attack vectors, economic incentives\n    - Token economics, mechanism design for decentralized systems\n    - Quantum threats to blockchain or cryptography\n    - Any breakthrough that meaningfully improves decentralization, scalability, privacy, or composability\n\n    Output instructions:\n\n    - Output each JSON object in JSON Lines format (one line per paper).\n\n    {\n        \"title\": title of the paper (in Japanese),\n        \"summary\": A concise summary of the paper (in Japanese),\n        \"impact_level\": \"Highest|High|Medium|Low|Lowest\",\n        \"why_matters\": An array (JSON array) containing 2\u20134 bullet points explaining why this paper matters for Web3 investment\n    }\n\n    - Do not output anything except valid JSON object in JSON Lines.\n    - \"title\", \"summary\", \"why_matters\" text in the output must be written in Japanese.\n\n    Paper:\n    title: Secure Audio Embedding in Images using Nature-Inspired Optimization\n    summary: In todays digital world, protecting sensitive data is very essential. Steganography hides the existence of secret data instead of its content, providing better security for multimedia communication. This paper proposes a new technique for hiding audio files inside images using the Least Significant Bit (LSB) method optimized by the Harris Hawks Optimization (HHO) algorithm. HHO is a nature-inspired metaheuristic that imitates the hunting behavior of Harris hawks to find optimal pixel positions for embedding data. The proposed method is evaluated using Peak Signal-to-Noise Ratio (PSNR), Structural Similarity Index (SSIM), and Mean Square Error (MSE). Experimental results show that HHO achieves better image quality, robustness, and embedding capacity compared to existing methods.\n    link: https://arxiv.org/abs/2512.08299v1\n    "}}
{"custom_id": "2512.08293v1", "method": "POST", "url": "/v1/responses", "body": {"model": "gpt-5-mini", "input": "You are a specialist research analyst in Web3, DeFi, cryptography, and distributed systems.\n\n    Your task:\n    From the paper below (Title + Summary + Link), evaluate how useful each paper is for understanding investment opportunities or technological advantages within the Web3 / crypto / DeFi ecosystem.\n    Rate each paper on a five-level scale: Highest / High / Medium / Low / Lowest.\n\n    \"Useful\" means:\n\n    - Improves understanding of new cryptographic primitives relevant to blockchain performance or security\n    - Enhances scalability: distributed systems, P2P networking, consensus mechanisms\n    - Advances in zero knowledge, MPC, PQC that could impact future L1/L2 chains\n    - DeFi modeling, AMMs, MEV, risk models, liquidity dynamics\n    - Smart contract security, attack vectors, economic incentives\n    - Token economics, mechanism design for decentralized systems\n    - Quantum threats to blockchain or cryptography\n    - Any breakthrough that meaningfully improves decentralization, scalability, privacy, or composability\n\n    Output instructions:\n\n    - Output each JSON object in JSON Lines format (one line per paper).\n\n    {\n        \"title\": title of the paper (in Japanese),\n        \"summary\": A concise summary of the paper (in Japanese),\n        \"impact_level\": \"Highest|High|Medium|Low|Lowest\",\n        \"why_matters\": An array (JSON array) containing 2\u20134 bullet points explaining why this paper matters for Web3 investment\n    }\n\n    - Do not output anything except valid JSON object in JSON Lines.\n    - \"title\", \"summary\", \"why_matters\" text in the output must be written in Japanese.\n\n    Paper:\n    title: Discovering novel quantum dynamics with NISQ simulators\n    summary: Major technological advances of the past century are rooted in our understanding of quantum physics in the non-interacting limit. A central challenge today is to understand the behavior of complex quantum many-body systems, where interactions play an essential role. About four decades ago, Richard Feynman proposed using controllable quantum systems to efficiently simulate complex physics and chemistry problems, envisioning quantum orreries, highly tunable quantum devices built to emulate less understood quantum systems. Here we ask whether quantum simulators have already uncovered new physical phenomena-and, if so, in which areas and with what impact. We find that, in several notable instances, they have advanced our understanding of many-body quantum dynamics. Although many of these insights could in principle have been obtained theoretically or numerically, they were nevertheless first achieved using quantum processors. While a broad landscape of problems beyond non-equilibrium dynamics still awaits exploration, it is encouraging that quantum simulators are already beginning to challenge and refine our conventional wisdom.\n    link: https://arxiv.org/abs/2512.08293v1\n    "}}
{"custom_id": "2507.03361v4", "method": "POST", "url": "/v1/responses", "body": {"model": "gpt-5-mini", "input": "You are a specialist research analyst in Web3, DeFi, cryptography, and distributed systems.\n\n    Your task:\n    From the paper below (Title + Summary + Link), evaluate how useful each paper is for understanding investment opportunities or technological advantages within the Web3 / crypto / DeFi ecosystem.\n    Rate each paper on a five-level scale: Highest / High / Medium / Low / Lowest.\n\n    \"Useful\" means:\n\n    - Improves understanding of new cryptographic primitives relevant to blockchain performance or security\n    - Enhances scalability: distributed systems, P2P networking, consensus mechanisms\n    - Advances in zero knowledge, MPC, PQC that could impact future L1/L2 chains\n    - DeFi modeling, AMMs, MEV, risk models, liquidity dynamics\n    - Smart contract security, attack vectors, economic incentives\n    - Token economics, mechanism design for decentralized systems\n    - Quantum threats to blockchain or cryptography\n    - Any breakthrough that meaningfully improves decentralization, scalability, privacy, or composability\n\n    Output instructions:\n\n    - Output each JSON object in JSON Lines format (one line per paper).\n\n    {\n        \"title\": title of the paper (in Japanese),\n        \"summary\": A concise summary of the paper (in Japanese),\n        \"impact_level\": \"Highest|High|Medium|Low|Lowest\",\n        \"why_matters\": An array (JSON array) containing 2\u20134 bullet points explaining why this paper matters for Web3 investment\n    }\n\n    - Do not output anything except valid JSON object in JSON Lines.\n    - \"title\", \"summary\", \"why_matters\" text in the output must be written in Japanese.\n\n    Paper:\n    title: Scalable Differentially Private Sketches under Continual Observation\n    summary: Linear sketches are fundamental tools in data stream analytics. They are notable for supporting both approximate frequency queries and heavy hitter detection with bounded trade-offs for error and memory. Importantly, on streams that contain sensitive information, linear sketches can be easily privatized with the injection of a suitable amount of noise. This process is efficient in the single release model, where the output is released only at the end of the stream. In this setting, it suffices to add noise to the sketch once.\n  In contrast, in the continual observation model, where the output is released at every time-step, fresh noise needs to be added to the sketch before each release. This creates an additional computational overhead. To address this, we introduce Lazy Sketch, a novel differentially private sketching method that employs lazy updates, perturbing and modifying only a small portion of the sketch at each step. Compared to prior work, we reduce the update complexity by a factor of $O(w)$, where $w$ is the width of the sketch. Experiments demonstrate that our method increases throughput by up to 250x over prior work, making continual observation differential privacy practical for high-speed streaming applications.\n    link: https://arxiv.org/abs/2507.03361v4\n    "}}
{"custom_id": "2512.08291v1", "method": "POST", "url": "/v1/responses", "body": {"model": "gpt-5-mini", "input": "You are a specialist research analyst in Web3, DeFi, cryptography, and distributed systems.\n\n    Your task:\n    From the paper below (Title + Summary + Link), evaluate how useful each paper is for understanding investment opportunities or technological advantages within the Web3 / crypto / DeFi ecosystem.\n    Rate each paper on a five-level scale: Highest / High / Medium / Low / Lowest.\n\n    \"Useful\" means:\n\n    - Improves understanding of new cryptographic primitives relevant to blockchain performance or security\n    - Enhances scalability: distributed systems, P2P networking, consensus mechanisms\n    - Advances in zero knowledge, MPC, PQC that could impact future L1/L2 chains\n    - DeFi modeling, AMMs, MEV, risk models, liquidity dynamics\n    - Smart contract security, attack vectors, economic incentives\n    - Token economics, mechanism design for decentralized systems\n    - Quantum threats to blockchain or cryptography\n    - Any breakthrough that meaningfully improves decentralization, scalability, privacy, or composability\n\n    Output instructions:\n\n    - Output each JSON object in JSON Lines format (one line per paper).\n\n    {\n        \"title\": title of the paper (in Japanese),\n        \"summary\": A concise summary of the paper (in Japanese),\n        \"impact_level\": \"Highest|High|Medium|Low|Lowest\",\n        \"why_matters\": An array (JSON array) containing 2\u20134 bullet points explaining why this paper matters for Web3 investment\n    }\n\n    - Do not output anything except valid JSON object in JSON Lines.\n    - \"title\", \"summary\", \"why_matters\" text in the output must be written in Japanese.\n\n    Paper:\n    title: Exposing and Defending Membership Leakage in Vulnerability Prediction Models\n    summary: Neural models for vulnerability prediction (VP) have achieved impressive performance by learning from large-scale code repositories. However, their susceptibility to Membership Inference Attacks (MIAs), where adversaries aim to infer whether a particular code sample was used during training, poses serious privacy concerns. While MIA has been widely investigated in NLP and vision domains, its effects on security-critical code analysis tasks remain underexplored. In this work, we conduct the first comprehensive analysis of MIA on VP models, evaluating the attack success across various architectures (LSTM, BiGRU, and CodeBERT) and feature combinations, including embeddings, logits, loss, and confidence. Our threat model aligns with black-box and gray-box settings where prediction outputs are observable, allowing adversaries to infer membership by analyzing output discrepancies between training and non-training samples. The empirical findings reveal that logits and loss are the most informative and vulnerable outputs for membership leakage. Motivated by these observations, we propose a Noise-based Membership Inference Defense (NMID), which is a lightweight defense module that applies output masking and Gaussian noise injection to disrupt adversarial inference. Extensive experiments demonstrate that NMID significantly reduces MIA effectiveness, lowering the attack AUC from nearly 1.0 to below 0.65, while preserving the predictive utility of VP models. Our study highlights critical privacy risks in code analysis and offers actionable defense strategies for securing AI-powered software systems.\n    link: https://arxiv.org/abs/2512.08291v1\n    "}}
{"custom_id": "2512.08290v1", "method": "POST", "url": "/v1/responses", "body": {"model": "gpt-5-mini", "input": "You are a specialist research analyst in Web3, DeFi, cryptography, and distributed systems.\n\n    Your task:\n    From the paper below (Title + Summary + Link), evaluate how useful each paper is for understanding investment opportunities or technological advantages within the Web3 / crypto / DeFi ecosystem.\n    Rate each paper on a five-level scale: Highest / High / Medium / Low / Lowest.\n\n    \"Useful\" means:\n\n    - Improves understanding of new cryptographic primitives relevant to blockchain performance or security\n    - Enhances scalability: distributed systems, P2P networking, consensus mechanisms\n    - Advances in zero knowledge, MPC, PQC that could impact future L1/L2 chains\n    - DeFi modeling, AMMs, MEV, risk models, liquidity dynamics\n    - Smart contract security, attack vectors, economic incentives\n    - Token economics, mechanism design for decentralized systems\n    - Quantum threats to blockchain or cryptography\n    - Any breakthrough that meaningfully improves decentralization, scalability, privacy, or composability\n\n    Output instructions:\n\n    - Output each JSON object in JSON Lines format (one line per paper).\n\n    {\n        \"title\": title of the paper (in Japanese),\n        \"summary\": A concise summary of the paper (in Japanese),\n        \"impact_level\": \"Highest|High|Medium|Low|Lowest\",\n        \"why_matters\": An array (JSON array) containing 2\u20134 bullet points explaining why this paper matters for Web3 investment\n    }\n\n    - Do not output anything except valid JSON object in JSON Lines.\n    - \"title\", \"summary\", \"why_matters\" text in the output must be written in Japanese.\n\n    Paper:\n    title: Systematization of Knowledge: Security and Safety in the Model Context Protocol Ecosystem\n    summary: The Model Context Protocol (MCP) has emerged as the de facto standard for connecting Large Language Models (LLMs) to external data and tools, effectively functioning as the \"USB-C for Agentic AI.\" While this decoupling of context and execution solves critical interoperability challenges, it introduces a profound new threat landscape where the boundary between epistemic errors (hallucinations) and security breaches (unauthorized actions) dissolves. This Systematization of Knowledge (SoK) aims to provide a comprehensive taxonomy of risks in the MCP ecosystem, distinguishing between adversarial security threats (e.g., indirect prompt injection, tool poisoning) and epistemic safety hazards (e.g., alignment failures in distributed tool delegation). We analyze the structural vulnerabilities of MCP primitives, specifically Resources, Prompts, and Tools, and demonstrate how \"context\" can be weaponized to trigger unauthorized operations in multi-agent environments. Furthermore, we survey state-of-the-art defenses, ranging from cryptographic provenance (ETDI) to runtime intent verification, and conclude with a roadmap for securing the transition from conversational chatbots to autonomous agentic operating systems.\n    link: https://arxiv.org/abs/2512.08290v1\n    "}}
{"custom_id": "2512.08289v1", "method": "POST", "url": "/v1/responses", "body": {"model": "gpt-5-mini", "input": "You are a specialist research analyst in Web3, DeFi, cryptography, and distributed systems.\n\n    Your task:\n    From the paper below (Title + Summary + Link), evaluate how useful each paper is for understanding investment opportunities or technological advantages within the Web3 / crypto / DeFi ecosystem.\n    Rate each paper on a five-level scale: Highest / High / Medium / Low / Lowest.\n\n    \"Useful\" means:\n\n    - Improves understanding of new cryptographic primitives relevant to blockchain performance or security\n    - Enhances scalability: distributed systems, P2P networking, consensus mechanisms\n    - Advances in zero knowledge, MPC, PQC that could impact future L1/L2 chains\n    - DeFi modeling, AMMs, MEV, risk models, liquidity dynamics\n    - Smart contract security, attack vectors, economic incentives\n    - Token economics, mechanism design for decentralized systems\n    - Quantum threats to blockchain or cryptography\n    - Any breakthrough that meaningfully improves decentralization, scalability, privacy, or composability\n\n    Output instructions:\n\n    - Output each JSON object in JSON Lines format (one line per paper).\n\n    {\n        \"title\": title of the paper (in Japanese),\n        \"summary\": A concise summary of the paper (in Japanese),\n        \"impact_level\": \"Highest|High|Medium|Low|Lowest\",\n        \"why_matters\": An array (JSON array) containing 2\u20134 bullet points explaining why this paper matters for Web3 investment\n    }\n\n    - Do not output anything except valid JSON object in JSON Lines.\n    - \"title\", \"summary\", \"why_matters\" text in the output must be written in Japanese.\n\n    Paper:\n    title: MIRAGE: Misleading Retrieval-Augmented Generation via Black-box and Query-agnostic Poisoning Attacks\n    summary: Retrieval-Augmented Generation (RAG) systems enhance LLMs with external knowledge but introduce a critical attack surface: corpus poisoning. While recent studies have demonstrated the potential of such attacks, they typically rely on impractical assumptions, such as white-box access or known user queries, thereby underestimating the difficulty of real-world exploitation. In this paper, we bridge this gap by proposing MIRAGE, a novel multi-stage poisoning pipeline designed for strict black-box and query-agnostic environments. Operating on surrogate model feedback, MIRAGE functions as an automated optimization framework that integrates three key mechanisms: it utilizes persona-driven query synthesis to approximate latent user search distributions, employs semantic anchoring to imperceptibly embed these intents for high retrieval visibility, and leverages an adversarial variant of Test-Time Preference Optimization (TPO) to maximize persuasion. To rigorously evaluate this threat, we construct a new benchmark derived from three long-form, domain-specific datasets. Extensive experiments demonstrate that MIRAGE significantly outperforms existing baselines in both attack efficacy and stealthiness, exhibiting remarkable transferability across diverse retriever-LLM configurations and highlighting the urgent need for robust defense strategies.\n    link: https://arxiv.org/abs/2512.08289v1\n    "}}
{"custom_id": "2512.08288v1", "method": "POST", "url": "/v1/responses", "body": {"model": "gpt-5-mini", "input": "You are a specialist research analyst in Web3, DeFi, cryptography, and distributed systems.\n\n    Your task:\n    From the paper below (Title + Summary + Link), evaluate how useful each paper is for understanding investment opportunities or technological advantages within the Web3 / crypto / DeFi ecosystem.\n    Rate each paper on a five-level scale: Highest / High / Medium / Low / Lowest.\n\n    \"Useful\" means:\n\n    - Improves understanding of new cryptographic primitives relevant to blockchain performance or security\n    - Enhances scalability: distributed systems, P2P networking, consensus mechanisms\n    - Advances in zero knowledge, MPC, PQC that could impact future L1/L2 chains\n    - DeFi modeling, AMMs, MEV, risk models, liquidity dynamics\n    - Smart contract security, attack vectors, economic incentives\n    - Token economics, mechanism design for decentralized systems\n    - Quantum threats to blockchain or cryptography\n    - Any breakthrough that meaningfully improves decentralization, scalability, privacy, or composability\n\n    Output instructions:\n\n    - Output each JSON object in JSON Lines format (one line per paper).\n\n    {\n        \"title\": title of the paper (in Japanese),\n        \"summary\": A concise summary of the paper (in Japanese),\n        \"impact_level\": \"Highest|High|Medium|Low|Lowest\",\n        \"why_matters\": An array (JSON array) containing 2\u20134 bullet points explaining why this paper matters for Web3 investment\n    }\n\n    - Do not output anything except valid JSON object in JSON Lines.\n    - \"title\", \"summary\", \"why_matters\" text in the output must be written in Japanese.\n\n    Paper:\n    title: Synergizing Monetization, Orchestration, and Semantics in Computing Continuum\n    summary: Industry demands are growing for hyper-distributed applications that span from the cloud to the edge in domains such as smart manufacturing, transportation, and agriculture. Yet today's solutions struggle to meet these demands due to inherent limitations in scalability, interoperability, and trust. In this article, we introduce HERMES (Heterogeneous Computing Continuum with Resource Monetization, Orchestration, and Semantic) - a novel framework designed to transform connectivity and data utilization across the computing continuum. HERMES establishes an open, seamless, and secure environment where resources, from cloud servers to tiny edge devices, can be orchestrated intelligently, data and services can be monetized in a distributed marketplace, and knowledge is shared through semantic interoperability. By bridging these key facets, HERMES lays a foundation for a new generation of distributed applications that are more efficient, trustworthy, and autonomous.\n    link: https://arxiv.org/abs/2512.08288v1\n    "}}
{"custom_id": "2412.09756v4", "method": "POST", "url": "/v1/responses", "body": {"model": "gpt-5-mini", "input": "You are a specialist research analyst in Web3, DeFi, cryptography, and distributed systems.\n\n    Your task:\n    From the paper below (Title + Summary + Link), evaluate how useful each paper is for understanding investment opportunities or technological advantages within the Web3 / crypto / DeFi ecosystem.\n    Rate each paper on a five-level scale: Highest / High / Medium / Low / Lowest.\n\n    \"Useful\" means:\n\n    - Improves understanding of new cryptographic primitives relevant to blockchain performance or security\n    - Enhances scalability: distributed systems, P2P networking, consensus mechanisms\n    - Advances in zero knowledge, MPC, PQC that could impact future L1/L2 chains\n    - DeFi modeling, AMMs, MEV, risk models, liquidity dynamics\n    - Smart contract security, attack vectors, economic incentives\n    - Token economics, mechanism design for decentralized systems\n    - Quantum threats to blockchain or cryptography\n    - Any breakthrough that meaningfully improves decentralization, scalability, privacy, or composability\n\n    Output instructions:\n\n    - Output each JSON object in JSON Lines format (one line per paper).\n\n    {\n        \"title\": title of the paper (in Japanese),\n        \"summary\": A concise summary of the paper (in Japanese),\n        \"impact_level\": \"Highest|High|Medium|Low|Lowest\",\n        \"why_matters\": An array (JSON array) containing 2\u20134 bullet points explaining why this paper matters for Web3 investment\n    }\n\n    - Do not output anything except valid JSON object in JSON Lines.\n    - \"title\", \"summary\", \"why_matters\" text in the output must be written in Japanese.\n\n    Paper:\n    title: Private Synthetic Data Generation in Bounded Memory\n    summary: We propose $\\mathtt{PrivHP}$, a lightweight synthetic data generator with \\textit{differential privacy} guarantees. $\\mathtt{PrivHP}$ uses a novel hierarchical decomposition that approximates the input's cumulative distribution function (CDF) in bounded memory. It balances hierarchy depth, noise addition, and pruning of low-frequency subdomains while preserving frequent ones. Private sketches estimate subdomain frequencies efficiently without full data access.\n  A key feature is the pruning parameter $k$, which controls the trade-off between space and utility. We define the skew measure $\\mathtt{tail}_k$, capturing all but the top $k$ subdomain frequencies. Given a dataset $\\mathcal{X}$, $\\mathtt{PrivHP}$ uses $M=\\mathcal{O}(k\\log^2 |X|)$ space and, for input domain $\u03a9= [0,1]$, ensures $\\varepsilon$-differential privacy. It yields a generator with expected Wasserstein distance: \\[ \\mathcal{O}\\left(\\frac{\\log^2 M}{\\varepsilon n} + \\frac{||\\mathtt{tail}_k(\\mathcal{X})||_1}{M n}\\right) \\] from the empirical distribution. This parameterized trade-off offers a level of flexibility unavailable in prior work. We also provide interpretable utility bounds that account for hierarchy depth, privacy noise, pruning, and frequency estimation errors.\n    link: https://arxiv.org/abs/2412.09756v4\n    "}}
{"custom_id": "2412.18123v3", "method": "POST", "url": "/v1/responses", "body": {"model": "gpt-5-mini", "input": "You are a specialist research analyst in Web3, DeFi, cryptography, and distributed systems.\n\n    Your task:\n    From the paper below (Title + Summary + Link), evaluate how useful each paper is for understanding investment opportunities or technological advantages within the Web3 / crypto / DeFi ecosystem.\n    Rate each paper on a five-level scale: Highest / High / Medium / Low / Lowest.\n\n    \"Useful\" means:\n\n    - Improves understanding of new cryptographic primitives relevant to blockchain performance or security\n    - Enhances scalability: distributed systems, P2P networking, consensus mechanisms\n    - Advances in zero knowledge, MPC, PQC that could impact future L1/L2 chains\n    - DeFi modeling, AMMs, MEV, risk models, liquidity dynamics\n    - Smart contract security, attack vectors, economic incentives\n    - Token economics, mechanism design for decentralized systems\n    - Quantum threats to blockchain or cryptography\n    - Any breakthrough that meaningfully improves decentralization, scalability, privacy, or composability\n\n    Output instructions:\n\n    - Output each JSON object in JSON Lines format (one line per paper).\n\n    {\n        \"title\": title of the paper (in Japanese),\n        \"summary\": A concise summary of the paper (in Japanese),\n        \"impact_level\": \"Highest|High|Medium|Low|Lowest\",\n        \"why_matters\": An array (JSON array) containing 2\u20134 bullet points explaining why this paper matters for Web3 investment\n    }\n\n    - Do not output anything except valid JSON object in JSON Lines.\n    - \"title\", \"summary\", \"why_matters\" text in the output must be written in Japanese.\n\n    Paper:\n    title: AEIOU: A Unified Defense Framework against NSFW Prompts in Text-to-Image Models\n    summary: As text-to-image (T2I) models advance and gain widespread adoption, their associated safety concerns are becoming increasingly critical. Malicious users exploit these models to generate Not-Safe-for-Work (NSFW) images using harmful or adversarial prompts, underscoring the need for effective safeguards to ensure the integrity and compliance of model outputs. However, existing detection methods often exhibit low accuracy and inefficiency. In this paper, we propose AEIOU, a defense framework that is adaptable, efficient, interpretable, optimizable, and unified against NSFW prompts in T2I models. AEIOU extracts NSFW features from the hidden states of the model's text encoder, utilizing the separable nature of these features to detect NSFW prompts. The detection process is efficient, requiring minimal inference time. AEIOU also offers real-time interpretation of results and supports optimization through data augmentation techniques. The framework is versatile, accommodating various T2I architectures. Our extensive experiments show that AEIOU significantly outperforms both commercial and open-source moderation tools, achieving over 95\\% accuracy across all datasets and improving efficiency by at least tenfold. It effectively counters adaptive attacks and excels in few-shot and multi-label scenarios.\n    link: https://arxiv.org/abs/2412.18123v3\n    "}}
{"custom_id": "2512.08279v1", "method": "POST", "url": "/v1/responses", "body": {"model": "gpt-5-mini", "input": "You are a specialist research analyst in Web3, DeFi, cryptography, and distributed systems.\n\n    Your task:\n    From the paper below (Title + Summary + Link), evaluate how useful each paper is for understanding investment opportunities or technological advantages within the Web3 / crypto / DeFi ecosystem.\n    Rate each paper on a five-level scale: Highest / High / Medium / Low / Lowest.\n\n    \"Useful\" means:\n\n    - Improves understanding of new cryptographic primitives relevant to blockchain performance or security\n    - Enhances scalability: distributed systems, P2P networking, consensus mechanisms\n    - Advances in zero knowledge, MPC, PQC that could impact future L1/L2 chains\n    - DeFi modeling, AMMs, MEV, risk models, liquidity dynamics\n    - Smart contract security, attack vectors, economic incentives\n    - Token economics, mechanism design for decentralized systems\n    - Quantum threats to blockchain or cryptography\n    - Any breakthrough that meaningfully improves decentralization, scalability, privacy, or composability\n\n    Output instructions:\n\n    - Output each JSON object in JSON Lines format (one line per paper).\n\n    {\n        \"title\": title of the paper (in Japanese),\n        \"summary\": A concise summary of the paper (in Japanese),\n        \"impact_level\": \"Highest|High|Medium|Low|Lowest\",\n        \"why_matters\": An array (JSON array) containing 2\u20134 bullet points explaining why this paper matters for Web3 investment\n    }\n\n    - Do not output anything except valid JSON object in JSON Lines.\n    - \"title\", \"summary\", \"why_matters\" text in the output must be written in Japanese.\n\n    Paper:\n    title: Programmable Open Quantum Systems\n    summary: Programmability is a unifying paradigm for enacting families of quantum transformations via fixed processors and program states, with a fundamental role and broad impact in quantum computation and control. While there has been a shift from viewing open systems solely as a source of error to treating them as a computational resource, their programmability remains largely unexplored. In this work, we develop a framework that characterizes and quantifies the programmability of Lindbladian semigroups by combining physically implementable retrieval maps with time varying program states. Within this framework, we identify quantum programmable classes enabled by symmetry and stochastic structure, including covariant semigroups and fully dissipative Pauli Lindbladians with finite program dimension. We further provide a necessary condition for physical programmability that rules out coherent generators and typical dissipators generating amplitude damping. For such nonphysically programmable cases, we construct explicit protocols with finite resources. Finally, we introduce an operational programming cost, defined via the number of samples required to program the Lindbladian, and establish its core structural properties, such as continuity and faithfulness. These results provide a notion of programming cost for Lindbladians, bridge programmable channel theory and open system dynamics, and yield symmetry driven compression schemes and actionable resource estimates for semigroup simulation and control in noisy quantum technologies.\n    link: https://arxiv.org/abs/2512.08279v1\n    "}}
{"custom_id": "2512.08242v1", "method": "POST", "url": "/v1/responses", "body": {"model": "gpt-5-mini", "input": "You are a specialist research analyst in Web3, DeFi, cryptography, and distributed systems.\n\n    Your task:\n    From the paper below (Title + Summary + Link), evaluate how useful each paper is for understanding investment opportunities or technological advantages within the Web3 / crypto / DeFi ecosystem.\n    Rate each paper on a five-level scale: Highest / High / Medium / Low / Lowest.\n\n    \"Useful\" means:\n\n    - Improves understanding of new cryptographic primitives relevant to blockchain performance or security\n    - Enhances scalability: distributed systems, P2P networking, consensus mechanisms\n    - Advances in zero knowledge, MPC, PQC that could impact future L1/L2 chains\n    - DeFi modeling, AMMs, MEV, risk models, liquidity dynamics\n    - Smart contract security, attack vectors, economic incentives\n    - Token economics, mechanism design for decentralized systems\n    - Quantum threats to blockchain or cryptography\n    - Any breakthrough that meaningfully improves decentralization, scalability, privacy, or composability\n\n    Output instructions:\n\n    - Output each JSON object in JSON Lines format (one line per paper).\n\n    {\n        \"title\": title of the paper (in Japanese),\n        \"summary\": A concise summary of the paper (in Japanese),\n        \"impact_level\": \"Highest|High|Medium|Low|Lowest\",\n        \"why_matters\": An array (JSON array) containing 2\u20134 bullet points explaining why this paper matters for Web3 investment\n    }\n\n    - Do not output anything except valid JSON object in JSON Lines.\n    - \"title\", \"summary\", \"why_matters\" text in the output must be written in Japanese.\n\n    Paper:\n    title: Chopper: A Multi-Level GPU Characterization Tool & Derived Insights Into LLM Training Inefficiency\n    summary: Training large language models (LLMs) efficiently requires a deep understanding of how modern GPU systems behave under real-world distributed training workloads. While prior work has focused primarily on kernel-level performance or single-GPU microbenchmarks, the complex interaction between communication, computation, memory behavior, and power management in multi-GPU LLM training remains poorly characterized. In this work, we introduce Chopper, a profiling and analysis framework that collects, aligns, and visualizes GPU kernel traces and hardware performance counters across multiple granularities (i.e., from individual kernels to operations, layers, phases, iterations, and GPUs). Using Chopper, we perform a comprehensive end-to-end characterization of Llama 3 8B training under fully sharded data parallelism (FSDP) on an eight-GPU AMD InstinctTM MI300X node. Our analysis reveals several previously underexplored bottlenecks and behaviors, such as memory determinism enabling higher, more stable GPU and memory frequencies. We identify several sources of inefficiencies, with frequency overhead (DVFS effects) being the single largest contributor to the gap between theoretical and observed performance, exceeding the impact of MFMA utilization loss, communication/computation overlap, and kernel launch overheads. Overall, Chopper provides the first holistic, multi-granularity characterization of LLM training on AMD InstinctTM MI300X GPUs, yielding actionable insights for optimizing training frameworks, improving power-management strategies, and guiding future GPU architecture and system design.\n    link: https://arxiv.org/abs/2512.08242v1\n    "}}
{"custom_id": "2510.04186v3", "method": "POST", "url": "/v1/responses", "body": {"model": "gpt-5-mini", "input": "You are a specialist research analyst in Web3, DeFi, cryptography, and distributed systems.\n\n    Your task:\n    From the paper below (Title + Summary + Link), evaluate how useful each paper is for understanding investment opportunities or technological advantages within the Web3 / crypto / DeFi ecosystem.\n    Rate each paper on a five-level scale: Highest / High / Medium / Low / Lowest.\n\n    \"Useful\" means:\n\n    - Improves understanding of new cryptographic primitives relevant to blockchain performance or security\n    - Enhances scalability: distributed systems, P2P networking, consensus mechanisms\n    - Advances in zero knowledge, MPC, PQC that could impact future L1/L2 chains\n    - DeFi modeling, AMMs, MEV, risk models, liquidity dynamics\n    - Smart contract security, attack vectors, economic incentives\n    - Token economics, mechanism design for decentralized systems\n    - Quantum threats to blockchain or cryptography\n    - Any breakthrough that meaningfully improves decentralization, scalability, privacy, or composability\n\n    Output instructions:\n\n    - Output each JSON object in JSON Lines format (one line per paper).\n\n    {\n        \"title\": title of the paper (in Japanese),\n        \"summary\": A concise summary of the paper (in Japanese),\n        \"impact_level\": \"Highest|High|Medium|Low|Lowest\",\n        \"why_matters\": An array (JSON array) containing 2\u20134 bullet points explaining why this paper matters for Web3 investment\n    }\n\n    - Do not output anything except valid JSON object in JSON Lines.\n    - \"title\", \"summary\", \"why_matters\" text in the output must be written in Japanese.\n\n    Paper:\n    title: From Patchwork to Network: A Comprehensive Framework for Demand Analysis and Fleet Optimization of Urban Air Mobility\n    summary: Urban Air Mobility (UAM) presents a transformative vision for metropolitan transportation, but its practical implementation is hindered by substantial infrastructure costs and operational complexities. We address these challenges by modeling a UAM network that leverages existing regional airports and operates with an optimized, heterogeneous fleet of aircraft. We introduce LPSim, a Large-Scale Parallel Simulation framework that utilizes multi-GPU computing to co-optimize UAM demand, fleet operations, and ground transportation interactions simultaneously.\n  Our equilibrium search algorithm is extended to accurately forecast demand and determine the most efficient fleet composition. Applied to a case study of the San Francisco Bay Area, our results demonstrate that this UAM model can yield over 20 minutes' travel time savings for 230,000 selected trips. However, the analysis also reveals that system-wide success is critically dependent on seamless integration with ground access and dynamic scheduling.\n    link: https://arxiv.org/abs/2510.04186v3\n    "}}
{"custom_id": "2512.08204v1", "method": "POST", "url": "/v1/responses", "body": {"model": "gpt-5-mini", "input": "You are a specialist research analyst in Web3, DeFi, cryptography, and distributed systems.\n\n    Your task:\n    From the paper below (Title + Summary + Link), evaluate how useful each paper is for understanding investment opportunities or technological advantages within the Web3 / crypto / DeFi ecosystem.\n    Rate each paper on a five-level scale: Highest / High / Medium / Low / Lowest.\n\n    \"Useful\" means:\n\n    - Improves understanding of new cryptographic primitives relevant to blockchain performance or security\n    - Enhances scalability: distributed systems, P2P networking, consensus mechanisms\n    - Advances in zero knowledge, MPC, PQC that could impact future L1/L2 chains\n    - DeFi modeling, AMMs, MEV, risk models, liquidity dynamics\n    - Smart contract security, attack vectors, economic incentives\n    - Token economics, mechanism design for decentralized systems\n    - Quantum threats to blockchain or cryptography\n    - Any breakthrough that meaningfully improves decentralization, scalability, privacy, or composability\n\n    Output instructions:\n\n    - Output each JSON object in JSON Lines format (one line per paper).\n\n    {\n        \"title\": title of the paper (in Japanese),\n        \"summary\": A concise summary of the paper (in Japanese),\n        \"impact_level\": \"Highest|High|Medium|Low|Lowest\",\n        \"why_matters\": An array (JSON array) containing 2\u20134 bullet points explaining why this paper matters for Web3 investment\n    }\n\n    - Do not output anything except valid JSON object in JSON Lines.\n    - \"title\", \"summary\", \"why_matters\" text in the output must be written in Japanese.\n\n    Paper:\n    title: Evaluating Vulnerabilities of Connected Vehicles Under Cyber Attacks by Attack-Defense Tree\n    summary: Connected vehicles represent a key enabler of intelligent transportation systems, where vehicles are equipped with advanced communication, sensing, and computing technologies to interact not only with one another but also with surrounding infrastructures and the environment. Through continuous data exchange, such vehicles are capable of enhancing road safety, improving traffic efficiency, and ensuring more reliable mobility services. Further, when these capabilities are integrated with advanced automation technologies, the concept essentially evolves into connected and autonomous vehicles (CAVs). While connected vehicles primarily focus on seamless information sharing, autonomous vehicles are mainly dependent on advanced perception, decision-making, and control mechanisms to operate with minimal or without human intervention. However, as a result of connectivity, an adversary with malicious intentions might be able to compromise successfully by breaching the system components of CAVs. In this paper, we present an attack-tree based methodology for evaluating cyber security vulnerabilities in CAVs. In particular, we utilize the attack-defense tree formulation to systematically assess attack-leaf vulnerabilities, and before analyzing the vulnerability indices, we also define a measure of vulnerabilities, which is based on existing cyber security threats and corresponding defensive countermeasures.\n    link: https://arxiv.org/abs/2512.08204v1\n    "}}
{"custom_id": "2512.07814v2", "method": "POST", "url": "/v1/responses", "body": {"model": "gpt-5-mini", "input": "You are a specialist research analyst in Web3, DeFi, cryptography, and distributed systems.\n\n    Your task:\n    From the paper below (Title + Summary + Link), evaluate how useful each paper is for understanding investment opportunities or technological advantages within the Web3 / crypto / DeFi ecosystem.\n    Rate each paper on a five-level scale: Highest / High / Medium / Low / Lowest.\n\n    \"Useful\" means:\n\n    - Improves understanding of new cryptographic primitives relevant to blockchain performance or security\n    - Enhances scalability: distributed systems, P2P networking, consensus mechanisms\n    - Advances in zero knowledge, MPC, PQC that could impact future L1/L2 chains\n    - DeFi modeling, AMMs, MEV, risk models, liquidity dynamics\n    - Smart contract security, attack vectors, economic incentives\n    - Token economics, mechanism design for decentralized systems\n    - Quantum threats to blockchain or cryptography\n    - Any breakthrough that meaningfully improves decentralization, scalability, privacy, or composability\n\n    Output instructions:\n\n    - Output each JSON object in JSON Lines format (one line per paper).\n\n    {\n        \"title\": title of the paper (in Japanese),\n        \"summary\": A concise summary of the paper (in Japanese),\n        \"impact_level\": \"Highest|High|Medium|Low|Lowest\",\n        \"why_matters\": An array (JSON array) containing 2\u20134 bullet points explaining why this paper matters for Web3 investment\n    }\n\n    - Do not output anything except valid JSON object in JSON Lines.\n    - \"title\", \"summary\", \"why_matters\" text in the output must be written in Japanese.\n\n    Paper:\n    title: Understanding Privacy Risks in Code Models Through Training Dynamics: A Causal Approach\n    summary: Large language models for code (LLM4Code) have greatly improved developer productivity but also raise privacy concerns due to their reliance on open-source repositories containing abundant personally identifiable information (PII). Prior work shows that commercial models can reproduce sensitive PII, yet existing studies largely treat PII as a single category and overlook the heterogeneous risks among different types. We investigate whether distinct PII types vary in their likelihood of being learned and leaked by LLM4Code, and whether this relationship is causal. Our methodology includes building a dataset with diverse PII types, fine-tuning representative models of different scales, computing training dynamics on real PII data, and formulating a structural causal model to estimate the causal effect of learnability on leakage. Results show that leakage risks differ substantially across PII types and correlate with their training dynamics: easy-to-learn instances such as IP addresses exhibit higher leakage, while harder types such as keys and passwords leak less frequently. Ambiguous types show mixed behaviors. This work provides the first causal evidence that leakage risks are type-dependent and offers guidance for developing type-aware and learnability-aware defenses for LLM4Code.\n    link: https://arxiv.org/abs/2512.07814v2\n    "}}
{"custom_id": "2512.08185v1", "method": "POST", "url": "/v1/responses", "body": {"model": "gpt-5-mini", "input": "You are a specialist research analyst in Web3, DeFi, cryptography, and distributed systems.\n\n    Your task:\n    From the paper below (Title + Summary + Link), evaluate how useful each paper is for understanding investment opportunities or technological advantages within the Web3 / crypto / DeFi ecosystem.\n    Rate each paper on a five-level scale: Highest / High / Medium / Low / Lowest.\n\n    \"Useful\" means:\n\n    - Improves understanding of new cryptographic primitives relevant to blockchain performance or security\n    - Enhances scalability: distributed systems, P2P networking, consensus mechanisms\n    - Advances in zero knowledge, MPC, PQC that could impact future L1/L2 chains\n    - DeFi modeling, AMMs, MEV, risk models, liquidity dynamics\n    - Smart contract security, attack vectors, economic incentives\n    - Token economics, mechanism design for decentralized systems\n    - Quantum threats to blockchain or cryptography\n    - Any breakthrough that meaningfully improves decentralization, scalability, privacy, or composability\n\n    Output instructions:\n\n    - Output each JSON object in JSON Lines format (one line per paper).\n\n    {\n        \"title\": title of the paper (in Japanese),\n        \"summary\": A concise summary of the paper (in Japanese),\n        \"impact_level\": \"Highest|High|Medium|Low|Lowest\",\n        \"why_matters\": An array (JSON array) containing 2\u20134 bullet points explaining why this paper matters for Web3 investment\n    }\n\n    - Do not output anything except valid JSON object in JSON Lines.\n    - \"title\", \"summary\", \"why_matters\" text in the output must be written in Japanese.\n\n    Paper:\n    title: A Practical Framework for Evaluating Medical AI Security: Reproducible Assessment of Jailbreaking and Privacy Vulnerabilities Across Clinical Specialties\n    summary: Medical Large Language Models (LLMs) are increasingly deployed for clinical decision support across diverse specialties, yet systematic evaluation of their robustness to adversarial misuse and privacy leakage remains inaccessible to most researchers. Existing security benchmarks require GPU clusters, commercial API access, or protected health data -- barriers that limit community participation in this critical research area. We propose a practical, fully reproducible framework for evaluating medical AI security under realistic resource constraints. Our framework design covers multiple medical specialties stratified by clinical risk -- from high-risk domains such as emergency medicine and psychiatry to general practice -- addressing jailbreaking attacks (role-playing, authority impersonation, multi-turn manipulation) and privacy extraction attacks. All evaluation utilizes synthetic patient records requiring no IRB approval. The framework is designed to run entirely on consumer CPU hardware using freely available models, eliminating cost barriers. We present the framework specification including threat models, data generation methodology, evaluation protocols, and scoring rubrics. This proposal establishes a foundation for comparative security assessment of medical-specialist models and defense mechanisms, advancing the broader goal of ensuring safe and trustworthy medical AI systems.\n    link: https://arxiv.org/abs/2512.08185v1\n    "}}
{"custom_id": "2508.21302v3", "method": "POST", "url": "/v1/responses", "body": {"model": "gpt-5-mini", "input": "You are a specialist research analyst in Web3, DeFi, cryptography, and distributed systems.\n\n    Your task:\n    From the paper below (Title + Summary + Link), evaluate how useful each paper is for understanding investment opportunities or technological advantages within the Web3 / crypto / DeFi ecosystem.\n    Rate each paper on a five-level scale: Highest / High / Medium / Low / Lowest.\n\n    \"Useful\" means:\n\n    - Improves understanding of new cryptographic primitives relevant to blockchain performance or security\n    - Enhances scalability: distributed systems, P2P networking, consensus mechanisms\n    - Advances in zero knowledge, MPC, PQC that could impact future L1/L2 chains\n    - DeFi modeling, AMMs, MEV, risk models, liquidity dynamics\n    - Smart contract security, attack vectors, economic incentives\n    - Token economics, mechanism design for decentralized systems\n    - Quantum threats to blockchain or cryptography\n    - Any breakthrough that meaningfully improves decentralization, scalability, privacy, or composability\n\n    Output instructions:\n\n    - Output each JSON object in JSON Lines format (one line per paper).\n\n    {\n        \"title\": title of the paper (in Japanese),\n        \"summary\": A concise summary of the paper (in Japanese),\n        \"impact_level\": \"Highest|High|Medium|Low|Lowest\",\n        \"why_matters\": An array (JSON array) containing 2\u20134 bullet points explaining why this paper matters for Web3 investment\n    }\n\n    - Do not output anything except valid JSON object in JSON Lines.\n    - \"title\", \"summary\", \"why_matters\" text in the output must be written in Japanese.\n\n    Paper:\n    title: Locus: Agentic Predicate Synthesis for Directed Fuzzing\n    summary: Directed fuzzing aims to find program inputs that lead to specified target program states. It has broad applications, such as debugging system crashes, confirming reported bugs, and generating exploits for potential vulnerabilities. This task is inherently challenging because target states are often deeply nested in the program, while the search space manifested by numerous possible program inputs is prohibitively large. Existing approaches rely on branch distances or manually-specified constraints to guide the search; however, the branches alone are often insufficient to precisely characterize progress toward reaching the target states, while the manually specified constraints are often tailored for specific bug types and thus difficult to generalize to diverse target states and programs.\n  We present Locus, a novel framework to improve the efficiency of directed fuzzing. Our key insight is to synthesize predicates to capture fuzzing progress as semantically meaningful intermediate states, serving as milestones towards reaching the target states. When used to instrument the program under fuzzing, they can reject executions unlikely to reach the target states, while providing additional coverage guidance. To automate this task and generalize to diverse programs, Locus features an agentic framework with program analysis tools to synthesize and iteratively refine the candidate predicates, while ensuring the predicates strictly relax the target states to prevent false rejections via symbolic execution. Our evaluation shows that Locus substantially improves the efficiency of eight state-of-the-art fuzzers in discovering real-world vulnerabilities, achieving an average speedup of 41.6x. So far, Locus has found nine previously unpatched bugs, with three already acknowledged with draft patches.\n    link: https://arxiv.org/abs/2508.21302v3\n    "}}
{"custom_id": "1511.07581v3", "method": "POST", "url": "/v1/responses", "body": {"model": "gpt-5-mini", "input": "You are a specialist research analyst in Web3, DeFi, cryptography, and distributed systems.\n\n    Your task:\n    From the paper below (Title + Summary + Link), evaluate how useful each paper is for understanding investment opportunities or technological advantages within the Web3 / crypto / DeFi ecosystem.\n    Rate each paper on a five-level scale: Highest / High / Medium / Low / Lowest.\n\n    \"Useful\" means:\n\n    - Improves understanding of new cryptographic primitives relevant to blockchain performance or security\n    - Enhances scalability: distributed systems, P2P networking, consensus mechanisms\n    - Advances in zero knowledge, MPC, PQC that could impact future L1/L2 chains\n    - DeFi modeling, AMMs, MEV, risk models, liquidity dynamics\n    - Smart contract security, attack vectors, economic incentives\n    - Token economics, mechanism design for decentralized systems\n    - Quantum threats to blockchain or cryptography\n    - Any breakthrough that meaningfully improves decentralization, scalability, privacy, or composability\n\n    Output instructions:\n\n    - Output each JSON object in JSON Lines format (one line per paper).\n\n    {\n        \"title\": title of the paper (in Japanese),\n        \"summary\": A concise summary of the paper (in Japanese),\n        \"impact_level\": \"Highest|High|Medium|Low|Lowest\",\n        \"why_matters\": An array (JSON array) containing 2\u20134 bullet points explaining why this paper matters for Web3 investment\n    }\n\n    - Do not output anything except valid JSON object in JSON Lines.\n    - \"title\", \"summary\", \"why_matters\" text in the output must be written in Japanese.\n\n    Paper:\n    title: On Twists of A Family of Elliptic Curves and Their $ L-$Function\n    summary: Let $ E $ be an elliptic curve defined over a number field, the conjecture of Birch and Swinnerton-Dyer (BSD, for short) asserts a deep relation between the group $ E(K) $ of rational points and the $ L-$function $ L(E/K, s)$ of $ E $ at $ s = 1. $ Very few explicit results about $ E(K) $ and $ L(1) $ are known, even no general method is known to determine $ L(1) $ vanishing or not for a given elliptic curve. In this paper, we study some quantities related to BSD of a special class of elliptic curves, more precisely, we study the arithmetic of quadratic twists of elliptic curves $ y^{2} = x(x + \\varepsilon p )(x + \\varepsilon q) $ and their $L-$function. Based on some classical works, especially those of Greenberg, Kramer-Tunnell, Kato-Rohrlich, Manin and Mazur, under some conditions, we obtain results about the vanishing of the value at $ s = 1 $ of the $ L$-function, and explicitly determine the following quantities: the norm index $ \u03b4(E, \\Q, K), $ the root numbers, the set of anomalous prime numbers, a few prime numbers at which the image of Galois representation are surjective. We also study the relation between the ranks of the Mordell-Weil groups, Selmer groups and Shafarevich-Tate groups, and the structure about the $ l^{\\infty }-$Selmer groups and the Mordell-Weil groups over $ \\Z_{l}-$extension via Iwasawa theory. These results provide some useful evidence toward verifying the BSD for a family of elliptic curves.\n    link: https://arxiv.org/abs/1511.07581v3\n    "}}
{"custom_id": "2512.08172v1", "method": "POST", "url": "/v1/responses", "body": {"model": "gpt-5-mini", "input": "You are a specialist research analyst in Web3, DeFi, cryptography, and distributed systems.\n\n    Your task:\n    From the paper below (Title + Summary + Link), evaluate how useful each paper is for understanding investment opportunities or technological advantages within the Web3 / crypto / DeFi ecosystem.\n    Rate each paper on a five-level scale: Highest / High / Medium / Low / Lowest.\n\n    \"Useful\" means:\n\n    - Improves understanding of new cryptographic primitives relevant to blockchain performance or security\n    - Enhances scalability: distributed systems, P2P networking, consensus mechanisms\n    - Advances in zero knowledge, MPC, PQC that could impact future L1/L2 chains\n    - DeFi modeling, AMMs, MEV, risk models, liquidity dynamics\n    - Smart contract security, attack vectors, economic incentives\n    - Token economics, mechanism design for decentralized systems\n    - Quantum threats to blockchain or cryptography\n    - Any breakthrough that meaningfully improves decentralization, scalability, privacy, or composability\n\n    Output instructions:\n\n    - Output each JSON object in JSON Lines format (one line per paper).\n\n    {\n        \"title\": title of the paper (in Japanese),\n        \"summary\": A concise summary of the paper (in Japanese),\n        \"impact_level\": \"Highest|High|Medium|Low|Lowest\",\n        \"why_matters\": An array (JSON array) containing 2\u20134 bullet points explaining why this paper matters for Web3 investment\n    }\n\n    - Do not output anything except valid JSON object in JSON Lines.\n    - \"title\", \"summary\", \"why_matters\" text in the output must be written in Japanese.\n\n    Paper:\n    title: Security Analysis of Integer Learning with Errors with Rejection Sampling\n    summary: At ASIACRYPT 2018, a digital attack based on linear least squares was introduced for a variant of the learning with errors (LWE) problem which omits modular reduction known as the integer learning with errors problem (ILWE). In this paper, we present a theoretical and experimental study of the effectiveness of the attack when applied directly to small parameter ILWE instances found in popular digital signature schemes such as CRYSTALS-Dilithium which utilize rejection sampling. Unlike other studies which form ILWE instances based on additional information obtained from side-channel attacks, we take a more direct approach to the problem by constructing our ILWE instance from only the obtained signatures. We outline and introduce novel techniques in our simulation designs such as modular polynomial arithmetic via matrices in $\\mathbb{R}$, as well as algorithms for handling large sample sizes efficiently. Our experimental results reinforce the proclaimed security of signature schemes based on ILWE. We additionally discuss the implications of our work and digital signatures as a whole in regards to real-world applications such as in Intelligent Transportation Systems (ITS).\n    link: https://arxiv.org/abs/2512.08172v1\n    "}}
{"custom_id": "2505.05067v2", "method": "POST", "url": "/v1/responses", "body": {"model": "gpt-5-mini", "input": "You are a specialist research analyst in Web3, DeFi, cryptography, and distributed systems.\n\n    Your task:\n    From the paper below (Title + Summary + Link), evaluate how useful each paper is for understanding investment opportunities or technological advantages within the Web3 / crypto / DeFi ecosystem.\n    Rate each paper on a five-level scale: Highest / High / Medium / Low / Lowest.\n\n    \"Useful\" means:\n\n    - Improves understanding of new cryptographic primitives relevant to blockchain performance or security\n    - Enhances scalability: distributed systems, P2P networking, consensus mechanisms\n    - Advances in zero knowledge, MPC, PQC that could impact future L1/L2 chains\n    - DeFi modeling, AMMs, MEV, risk models, liquidity dynamics\n    - Smart contract security, attack vectors, economic incentives\n    - Token economics, mechanism design for decentralized systems\n    - Quantum threats to blockchain or cryptography\n    - Any breakthrough that meaningfully improves decentralization, scalability, privacy, or composability\n\n    Output instructions:\n\n    - Output each JSON object in JSON Lines format (one line per paper).\n\n    {\n        \"title\": title of the paper (in Japanese),\n        \"summary\": A concise summary of the paper (in Japanese),\n        \"impact_level\": \"Highest|High|Medium|Low|Lowest\",\n        \"why_matters\": An array (JSON array) containing 2\u20134 bullet points explaining why this paper matters for Web3 investment\n    }\n\n    - Do not output anything except valid JSON object in JSON Lines.\n    - \"title\", \"summary\", \"why_matters\" text in the output must be written in Japanese.\n\n    Paper:\n    title: Cross-Problem Solving for Network Optimization: Is Problem-Aware Learning the Key?\n    summary: As intelligent network services continue to diversify, ensuring efficient and adaptive resource allocation in edge networks has become increasingly critical. Yet the wide functional variations across services often give rise to new and unforeseen optimization problems, rendering traditional manual modeling and solver design both time-consuming and inflexible. This limitation reveals a key gap between current methods and human solving - the inability to recognize and understand problem characteristics. It raises the question of whether problem-aware learning can bridge this gap and support effective cross-problem generalization. To answer this question, we propose a problem-aware diffusion (PAD) model, which leverages a problem-aware learning framework to enable cross-problem generalization. By explicitly encoding the mathematical formulations of optimization problems into token-level embeddings, PAD empowers the model to understand and adapt to problem structures. Extensive experiments across ten representative network optimization problems show that PAD generalizes well to unseen problems while avoiding the inefficiency of building new solvers from scratch, yet still delivering competitive solution quality. Meanwhile, an auxiliary constraint-aware module is designed to enforce solution validity further. The experiments indicate that problem-aware learning opens a promising direction toward general-purpose solvers for intelligent network operation and resource management. Our code is open source at https://github.com/qiyu3816/PAD.\n    link: https://arxiv.org/abs/2505.05067v2\n    "}}
{"custom_id": "2512.08169v1", "method": "POST", "url": "/v1/responses", "body": {"model": "gpt-5-mini", "input": "You are a specialist research analyst in Web3, DeFi, cryptography, and distributed systems.\n\n    Your task:\n    From the paper below (Title + Summary + Link), evaluate how useful each paper is for understanding investment opportunities or technological advantages within the Web3 / crypto / DeFi ecosystem.\n    Rate each paper on a five-level scale: Highest / High / Medium / Low / Lowest.\n\n    \"Useful\" means:\n\n    - Improves understanding of new cryptographic primitives relevant to blockchain performance or security\n    - Enhances scalability: distributed systems, P2P networking, consensus mechanisms\n    - Advances in zero knowledge, MPC, PQC that could impact future L1/L2 chains\n    - DeFi modeling, AMMs, MEV, risk models, liquidity dynamics\n    - Smart contract security, attack vectors, economic incentives\n    - Token economics, mechanism design for decentralized systems\n    - Quantum threats to blockchain or cryptography\n    - Any breakthrough that meaningfully improves decentralization, scalability, privacy, or composability\n\n    Output instructions:\n\n    - Output each JSON object in JSON Lines format (one line per paper).\n\n    {\n        \"title\": title of the paper (in Japanese),\n        \"summary\": A concise summary of the paper (in Japanese),\n        \"impact_level\": \"Highest|High|Medium|Low|Lowest\",\n        \"why_matters\": An array (JSON array) containing 2\u20134 bullet points explaining why this paper matters for Web3 investment\n    }\n\n    - Do not output anything except valid JSON object in JSON Lines.\n    - \"title\", \"summary\", \"why_matters\" text in the output must be written in Japanese.\n\n    Paper:\n    title: Information-Dense Reasoning for Efficient and Auditable Security Alert Triage\n    summary: Security Operations Centers face massive, heterogeneous alert streams under minute-level service windows, creating the Alert Triage Latency Paradox: verbose reasoning chains ensure accuracy and compliance but incur prohibitive latency and token costs, while minimal chains sacrifice transparency and auditability. Existing solutions fail: signature systems are brittle, anomaly methods lack actionability, and fully cloud-hosted LLMs raise latency, cost, and privacy concerns. We propose AIDR, a hybrid cloud-edge framework that addresses this trade-off through constrained information-density optimization. The core innovation is gradient-based compression of reasoning chains to retain only decision-critical steps--minimal evidence sufficient to justify predictions while respecting token and latency budgets. We demonstrate that this approach preserves decision-relevant information while minimizing complexity. We construct compact datasets by distilling alerts into 3-5 high-information bullets (68% token reduction), train domain-specialized experts via LoRA, and deploy a cloud-edge architecture: a cloud LLM routes alerts to on-premises experts generating SOAR-ready JSON. Experiments demonstrate AIDR achieves higher accuracy and 40.6% latency reduction versus Chain-of-Thought, with robustness to data corruption and out-of-distribution generalization, enabling auditable and efficient SOC triage with full data residency compliance.\n    link: https://arxiv.org/abs/2512.08169v1\n    "}}
{"custom_id": "2502.10635v3", "method": "POST", "url": "/v1/responses", "body": {"model": "gpt-5-mini", "input": "You are a specialist research analyst in Web3, DeFi, cryptography, and distributed systems.\n\n    Your task:\n    From the paper below (Title + Summary + Link), evaluate how useful each paper is for understanding investment opportunities or technological advantages within the Web3 / crypto / DeFi ecosystem.\n    Rate each paper on a five-level scale: Highest / High / Medium / Low / Lowest.\n\n    \"Useful\" means:\n\n    - Improves understanding of new cryptographic primitives relevant to blockchain performance or security\n    - Enhances scalability: distributed systems, P2P networking, consensus mechanisms\n    - Advances in zero knowledge, MPC, PQC that could impact future L1/L2 chains\n    - DeFi modeling, AMMs, MEV, risk models, liquidity dynamics\n    - Smart contract security, attack vectors, economic incentives\n    - Token economics, mechanism design for decentralized systems\n    - Quantum threats to blockchain or cryptography\n    - Any breakthrough that meaningfully improves decentralization, scalability, privacy, or composability\n\n    Output instructions:\n\n    - Output each JSON object in JSON Lines format (one line per paper).\n\n    {\n        \"title\": title of the paper (in Japanese),\n        \"summary\": A concise summary of the paper (in Japanese),\n        \"impact_level\": \"Highest|High|Medium|Low|Lowest\",\n        \"why_matters\": An array (JSON array) containing 2\u20134 bullet points explaining why this paper matters for Web3 investment\n    }\n\n    - Do not output anything except valid JSON object in JSON Lines.\n    - \"title\", \"summary\", \"why_matters\" text in the output must be written in Japanese.\n\n    Paper:\n    title: Privacy Preservation through Practical Machine Unlearning\n    summary: Machine Learning models thrive on vast datasets, continuously adapting to provide accurate predictions and recommendations. However, in an era dominated by privacy concerns, Machine Unlearning emerges as a transformative approach, enabling the selective removal of data from trained models. This paper examines methods such as Naive Retraining and Exact Unlearning via the SISA framework, evaluating their Computational Costs, Consistency, and feasibility using the $\\texttt{HSpam14}$ dataset. We explore the potential of integrating unlearning principles into Positive Unlabeled (PU) Learning to address challenges posed by partially labeled datasets. Our findings highlight the promise of unlearning frameworks like $\\textit{DaRE}$ for ensuring privacy compliance while maintaining model performance, albeit with significant computational trade-offs. This study underscores the importance of Machine Unlearning in achieving ethical AI and fostering trust in data-driven systems.\n    link: https://arxiv.org/abs/2502.10635v3\n    "}}
{"custom_id": "2502.10646v3", "method": "POST", "url": "/v1/responses", "body": {"model": "gpt-5-mini", "input": "You are a specialist research analyst in Web3, DeFi, cryptography, and distributed systems.\n\n    Your task:\n    From the paper below (Title + Summary + Link), evaluate how useful each paper is for understanding investment opportunities or technological advantages within the Web3 / crypto / DeFi ecosystem.\n    Rate each paper on a five-level scale: Highest / High / Medium / Low / Lowest.\n\n    \"Useful\" means:\n\n    - Improves understanding of new cryptographic primitives relevant to blockchain performance or security\n    - Enhances scalability: distributed systems, P2P networking, consensus mechanisms\n    - Advances in zero knowledge, MPC, PQC that could impact future L1/L2 chains\n    - DeFi modeling, AMMs, MEV, risk models, liquidity dynamics\n    - Smart contract security, attack vectors, economic incentives\n    - Token economics, mechanism design for decentralized systems\n    - Quantum threats to blockchain or cryptography\n    - Any breakthrough that meaningfully improves decentralization, scalability, privacy, or composability\n\n    Output instructions:\n\n    - Output each JSON object in JSON Lines format (one line per paper).\n\n    {\n        \"title\": title of the paper (in Japanese),\n        \"summary\": A concise summary of the paper (in Japanese),\n        \"impact_level\": \"Highest|High|Medium|Low|Lowest\",\n        \"why_matters\": An array (JSON array) containing 2\u20134 bullet points explaining why this paper matters for Web3 investment\n    }\n\n    - Do not output anything except valid JSON object in JSON Lines.\n    - \"title\", \"summary\", \"why_matters\" text in the output must be written in Japanese.\n\n    Paper:\n    title: Dark Deceptions in DHCP: Dismantling Network Defenses\n    summary: This paper explores vulnerabilities in the Dynamic Host Configuration Protocol (DHCP) and their implications on the Confidentiality, Integrity, and Availability (CIA) Triad. Through an analysis of various attacks, including DHCP Starvation, Rogue DHCP Servers, Replay Attacks, and TunnelVision exploits, the paper provides a taxonomic classification of threats, assesses risks, and proposes appropriate controls. The discussion also highlights the dangers of VPN decloaking through DHCP exploits and underscores the importance of safeguarding network infrastructures. By bringing awareness to the TunnelVision exploit, this paper aims to mitigate risks associated with these prevalent vulnerabilities.\n    link: https://arxiv.org/abs/2502.10646v3\n    "}}
{"custom_id": "2512.08107v1", "method": "POST", "url": "/v1/responses", "body": {"model": "gpt-5-mini", "input": "You are a specialist research analyst in Web3, DeFi, cryptography, and distributed systems.\n\n    Your task:\n    From the paper below (Title + Summary + Link), evaluate how useful each paper is for understanding investment opportunities or technological advantages within the Web3 / crypto / DeFi ecosystem.\n    Rate each paper on a five-level scale: Highest / High / Medium / Low / Lowest.\n\n    \"Useful\" means:\n\n    - Improves understanding of new cryptographic primitives relevant to blockchain performance or security\n    - Enhances scalability: distributed systems, P2P networking, consensus mechanisms\n    - Advances in zero knowledge, MPC, PQC that could impact future L1/L2 chains\n    - DeFi modeling, AMMs, MEV, risk models, liquidity dynamics\n    - Smart contract security, attack vectors, economic incentives\n    - Token economics, mechanism design for decentralized systems\n    - Quantum threats to blockchain or cryptography\n    - Any breakthrough that meaningfully improves decentralization, scalability, privacy, or composability\n\n    Output instructions:\n\n    - Output each JSON object in JSON Lines format (one line per paper).\n\n    {\n        \"title\": title of the paper (in Japanese),\n        \"summary\": A concise summary of the paper (in Japanese),\n        \"impact_level\": \"Highest|High|Medium|Low|Lowest\",\n        \"why_matters\": An array (JSON array) containing 2\u20134 bullet points explaining why this paper matters for Web3 investment\n    }\n\n    - Do not output anything except valid JSON object in JSON Lines.\n    - \"title\", \"summary\", \"why_matters\" text in the output must be written in Japanese.\n\n    Paper:\n    title: Detecting Ambiguity Aversion in Cyberattack Behavior to Inform Cognitive Defense Strategies\n    summary: Adversaries (hackers) attempting to infiltrate networks frequently face uncertainty in their operational environments. This research explores the ability to model and detect when they exhibit ambiguity aversion, a cognitive bias reflecting a preference for known (versus unknown) probabilities. We introduce a novel methodological framework that (1) leverages rich, multi-modal data from human-subjects red-team experiments, (2) employs a large language model (LLM) pipeline to parse unstructured logs into MITRE ATT&CK-mapped action sequences, and (3) applies a new computational model to infer an attacker's ambiguity aversion level in near-real time. By operationalizing this cognitive trait, our work provides a foundational component for developing adaptive cognitive defense strategies.\n    link: https://arxiv.org/abs/2512.08107v1\n    "}}
{"custom_id": "2512.08104v1", "method": "POST", "url": "/v1/responses", "body": {"model": "gpt-5-mini", "input": "You are a specialist research analyst in Web3, DeFi, cryptography, and distributed systems.\n\n    Your task:\n    From the paper below (Title + Summary + Link), evaluate how useful each paper is for understanding investment opportunities or technological advantages within the Web3 / crypto / DeFi ecosystem.\n    Rate each paper on a five-level scale: Highest / High / Medium / Low / Lowest.\n\n    \"Useful\" means:\n\n    - Improves understanding of new cryptographic primitives relevant to blockchain performance or security\n    - Enhances scalability: distributed systems, P2P networking, consensus mechanisms\n    - Advances in zero knowledge, MPC, PQC that could impact future L1/L2 chains\n    - DeFi modeling, AMMs, MEV, risk models, liquidity dynamics\n    - Smart contract security, attack vectors, economic incentives\n    - Token economics, mechanism design for decentralized systems\n    - Quantum threats to blockchain or cryptography\n    - Any breakthrough that meaningfully improves decentralization, scalability, privacy, or composability\n\n    Output instructions:\n\n    - Output each JSON object in JSON Lines format (one line per paper).\n\n    {\n        \"title\": title of the paper (in Japanese),\n        \"summary\": A concise summary of the paper (in Japanese),\n        \"impact_level\": \"Highest|High|Medium|Low|Lowest\",\n        \"why_matters\": An array (JSON array) containing 2\u20134 bullet points explaining why this paper matters for Web3 investment\n    }\n\n    - Do not output anything except valid JSON object in JSON Lines.\n    - \"title\", \"summary\", \"why_matters\" text in the output must be written in Japanese.\n\n    Paper:\n    title: AgentCrypt: Advancing Privacy and (Secure) Computation in AI Agent Collaboration\n    summary: As AI agents increasingly operate in real-world, multi-agent environments, ensuring reliable and context-aware privacy in agent communication is critical, especially to comply with evolving regulatory requirements. Traditional access controls are insufficient, as privacy risks often arise after access is granted; agents may use information in ways that compromise privacy, such as messaging humans, sharing context with other agents, making tool calls, persisting data, or generating derived private information. Existing approaches often treat privacy as a binary constraint, whether data is shareable or not, overlooking nuanced, role-specific, and computation-dependent privacy needs essential for regulatory compliance.\n  Agents, including those based on large language models, are inherently probabilistic and heuristic. There is no formal guarantee of how an agent will behave for any query, making them ill-suited for operations critical to security. To address this, we introduce AgentCrypt, a four-tiered framework for fine-grained, encrypted agent communication that adds a protection layer atop any AI agent platform. AgentCrypt spans unrestricted data exchange (Level 1) to fully encrypted computation using techniques such as homomorphic encryption (Level 4). Crucially, it guarantees the privacy of tagged data is always maintained, prioritizing privacy above correctness.\n  AgentCrypt ensures privacy across diverse interactions and enables computation on otherwise inaccessible data, overcoming barriers such as data silos. We implemented and tested it with Langgraph and Google ADK, demonstrating versatility across platforms. We also introduce a benchmark dataset simulating privacy-critical tasks at all privacy levels, enabling systematic evaluation and fostering the development of regulatable machine learning systems for secure agent communication and computation.\n    link: https://arxiv.org/abs/2512.08104v1\n    "}}
{"custom_id": "2510.16873v2", "method": "POST", "url": "/v1/responses", "body": {"model": "gpt-5-mini", "input": "You are a specialist research analyst in Web3, DeFi, cryptography, and distributed systems.\n\n    Your task:\n    From the paper below (Title + Summary + Link), evaluate how useful each paper is for understanding investment opportunities or technological advantages within the Web3 / crypto / DeFi ecosystem.\n    Rate each paper on a five-level scale: Highest / High / Medium / Low / Lowest.\n\n    \"Useful\" means:\n\n    - Improves understanding of new cryptographic primitives relevant to blockchain performance or security\n    - Enhances scalability: distributed systems, P2P networking, consensus mechanisms\n    - Advances in zero knowledge, MPC, PQC that could impact future L1/L2 chains\n    - DeFi modeling, AMMs, MEV, risk models, liquidity dynamics\n    - Smart contract security, attack vectors, economic incentives\n    - Token economics, mechanism design for decentralized systems\n    - Quantum threats to blockchain or cryptography\n    - Any breakthrough that meaningfully improves decentralization, scalability, privacy, or composability\n\n    Output instructions:\n\n    - Output each JSON object in JSON Lines format (one line per paper).\n\n    {\n        \"title\": title of the paper (in Japanese),\n        \"summary\": A concise summary of the paper (in Japanese),\n        \"impact_level\": \"Highest|High|Medium|Low|Lowest\",\n        \"why_matters\": An array (JSON array) containing 2\u20134 bullet points explaining why this paper matters for Web3 investment\n    }\n\n    - Do not output anything except valid JSON object in JSON Lines.\n    - \"title\", \"summary\", \"why_matters\" text in the output must be written in Japanese.\n\n    Paper:\n    title: On the Credibility of Deniable Communication in Court\n    summary: Over time, cryptographically deniable systems have come to be associated in computer-science literature with the idea of \"denying\" evidence in court - specifically, with the ability to convincingly forge evidence in courtroom scenarios and an inability to authenticate evidence in such contexts. Evidentiary processes in courts, however, have been developed over centuries to account for the reality that evidence has always been forgeable, and relies on factors outside of cryptographic models to seek the truth \"as well as possible\" while acknowledging that all evidence is imperfect. We argue that deniability does not and need not change this paradigm.\n  Our analysis highlights a gap between technical deniability notions and their application to the real world. There will always be factors outside a cryptographic model that influence perceptions of a message's authenticity, in realistic situations. We propose the broader concept of credibility to capture these factors. The credibility of a system is determined by (1) a threshold of quality that a forgery must pass to be \"believable\" as an original communication, which varies based on sociotechnical context and threat model, (2) the ease of creating a forgery that passes this threshold, which is also context- and threat-model-dependent, and (3) default system retention policy and retention settings. All three aspects are important for designing secure communication systems for real-world threat models, and some aspects of (2) and (3) may be incorporated directly into technical system design. We hope that our model of credibility will facilitate system design and deployment that addresses threats that are not and cannot be captured by purely technical definitions and existing cryptographic models, and support more nuanced discourse on the strengths and limitations of cryptographic guarantees within specific legal and sociotechnical contexts.\n    link: https://arxiv.org/abs/2510.16873v2\n    "}}
{"custom_id": "2512.08086v1", "method": "POST", "url": "/v1/responses", "body": {"model": "gpt-5-mini", "input": "You are a specialist research analyst in Web3, DeFi, cryptography, and distributed systems.\n\n    Your task:\n    From the paper below (Title + Summary + Link), evaluate how useful each paper is for understanding investment opportunities or technological advantages within the Web3 / crypto / DeFi ecosystem.\n    Rate each paper on a five-level scale: Highest / High / Medium / Low / Lowest.\n\n    \"Useful\" means:\n\n    - Improves understanding of new cryptographic primitives relevant to blockchain performance or security\n    - Enhances scalability: distributed systems, P2P networking, consensus mechanisms\n    - Advances in zero knowledge, MPC, PQC that could impact future L1/L2 chains\n    - DeFi modeling, AMMs, MEV, risk models, liquidity dynamics\n    - Smart contract security, attack vectors, economic incentives\n    - Token economics, mechanism design for decentralized systems\n    - Quantum threats to blockchain or cryptography\n    - Any breakthrough that meaningfully improves decentralization, scalability, privacy, or composability\n\n    Output instructions:\n\n    - Output each JSON object in JSON Lines format (one line per paper).\n\n    {\n        \"title\": title of the paper (in Japanese),\n        \"summary\": A concise summary of the paper (in Japanese),\n        \"impact_level\": \"Highest|High|Medium|Low|Lowest\",\n        \"why_matters\": An array (JSON array) containing 2\u20134 bullet points explaining why this paper matters for Web3 investment\n    }\n\n    - Do not output anything except valid JSON object in JSON Lines.\n    - \"title\", \"summary\", \"why_matters\" text in the output must be written in Japanese.\n\n    Paper:\n    title: Moire-Engineered Ferroelectric Transistors for Nearly Trap-free, Low-Power and Non-Volatile 2D Electronics\n    summary: Long-range moire patterns in twisted WSe2 enable a built-in, moire-length-scale ferroelectric polarization that can be directly harnessed in electronic devices. Such a built-in ferroic landscape offers a compelling means to enable ultralow-voltage and non-volatile electronic functionality in two-dimensional materials; however, achieving stable polarization control without charge trapping has remained a persistent challenge. Here, we demonstrate a moire-engineered ferroelectric field-effect transistor (FeFET) utilizing twisted WSe2 bilayers that leverages atomically clean van der Waals interfaces to achieve efficient polarization-channel coupling and trap-suppressed, ultralow-voltage operation (subthreshold swing of 64 mV per decade). The device exhibits a stable non-volatile memory window of 0.10 V and high mobility, exceeding the performance of previously reported two-dimensional FeFET and matching that of advanced silicon-based devices. In addition, capacitance-voltage spectroscopy, corroborated by self-consistent Landau-Ginzburg-Devonshire modeling, indicates ultrafast ferroelectric switching (~0.5 microseconds). These results establish moire-engineered ferroelectricity as a practical and scalable route toward ultraclean, low-power, and non-volatile 2D electronics, bridging atomistic lattice engineering with functional device architectures for next-generation memory and logic technologies.\n    link: https://arxiv.org/abs/2512.08086v1\n    "}}
{"custom_id": "2512.00218v2", "method": "POST", "url": "/v1/responses", "body": {"model": "gpt-5-mini", "input": "You are a specialist research analyst in Web3, DeFi, cryptography, and distributed systems.\n\n    Your task:\n    From the paper below (Title + Summary + Link), evaluate how useful each paper is for understanding investment opportunities or technological advantages within the Web3 / crypto / DeFi ecosystem.\n    Rate each paper on a five-level scale: Highest / High / Medium / Low / Lowest.\n\n    \"Useful\" means:\n\n    - Improves understanding of new cryptographic primitives relevant to blockchain performance or security\n    - Enhances scalability: distributed systems, P2P networking, consensus mechanisms\n    - Advances in zero knowledge, MPC, PQC that could impact future L1/L2 chains\n    - DeFi modeling, AMMs, MEV, risk models, liquidity dynamics\n    - Smart contract security, attack vectors, economic incentives\n    - Token economics, mechanism design for decentralized systems\n    - Quantum threats to blockchain or cryptography\n    - Any breakthrough that meaningfully improves decentralization, scalability, privacy, or composability\n\n    Output instructions:\n\n    - Output each JSON object in JSON Lines format (one line per paper).\n\n    {\n        \"title\": title of the paper (in Japanese),\n        \"summary\": A concise summary of the paper (in Japanese),\n        \"impact_level\": \"Highest|High|Medium|Low|Lowest\",\n        \"why_matters\": An array (JSON array) containing 2\u20134 bullet points explaining why this paper matters for Web3 investment\n    }\n\n    - Do not output anything except valid JSON object in JSON Lines.\n    - \"title\", \"summary\", \"why_matters\" text in the output must be written in Japanese.\n\n    Paper:\n    title: Reasoning Under Pressure: How do Training Incentives Influence Chain-of-Thought Monitorability?\n    summary: AI systems that output their reasoning in natural language offer an opportunity for safety -- we can \\emph{monitor} their chain of thought (CoT) for undesirable reasoning, such as the pursuit of harmful objectives. However, the extent to which CoT faithfully reflects the underlying reasoning process, and hence the extent to which it can be usefully monitored, may be influenced by certain aspects of training. We investigate how different \\emph{training incentives}, applied to a reasoning model, affect its monitorability. We introduce a novel methodology for measuring monitorability according to whether a monitor can predict a key latent variable using the model's reasoning. When controlling for accuracy, we do not find evidence for consistent effects from commonly used incentives (length penalties and KL regularisation), but we find that adversarial optimisation (penalising monitor accuracy) degrades monitor performance, while direct optimisation for monitorability does not reliably lead to improvements. Our code is available at https://github.com/QiyaoWei/reasoning-under-pressure.\n    link: https://arxiv.org/abs/2512.00218v2\n    "}}
{"custom_id": "2512.08067v1", "method": "POST", "url": "/v1/responses", "body": {"model": "gpt-5-mini", "input": "You are a specialist research analyst in Web3, DeFi, cryptography, and distributed systems.\n\n    Your task:\n    From the paper below (Title + Summary + Link), evaluate how useful each paper is for understanding investment opportunities or technological advantages within the Web3 / crypto / DeFi ecosystem.\n    Rate each paper on a five-level scale: Highest / High / Medium / Low / Lowest.\n\n    \"Useful\" means:\n\n    - Improves understanding of new cryptographic primitives relevant to blockchain performance or security\n    - Enhances scalability: distributed systems, P2P networking, consensus mechanisms\n    - Advances in zero knowledge, MPC, PQC that could impact future L1/L2 chains\n    - DeFi modeling, AMMs, MEV, risk models, liquidity dynamics\n    - Smart contract security, attack vectors, economic incentives\n    - Token economics, mechanism design for decentralized systems\n    - Quantum threats to blockchain or cryptography\n    - Any breakthrough that meaningfully improves decentralization, scalability, privacy, or composability\n\n    Output instructions:\n\n    - Output each JSON object in JSON Lines format (one line per paper).\n\n    {\n        \"title\": title of the paper (in Japanese),\n        \"summary\": A concise summary of the paper (in Japanese),\n        \"impact_level\": \"Highest|High|Medium|Low|Lowest\",\n        \"why_matters\": An array (JSON array) containing 2\u20134 bullet points explaining why this paper matters for Web3 investment\n    }\n\n    - Do not output anything except valid JSON object in JSON Lines.\n    - \"title\", \"summary\", \"why_matters\" text in the output must be written in Japanese.\n\n    Paper:\n    title: CapsuleFS A Multi-credential DataCapsule Filesystem\n    summary: CapsuleFS (CFS) is the first filesystem to integrate multi-credential functionality within a POSIX-compliant framework, utilizing DataCapsule as the storage provider. This innovative system is established based on the Global Data Plane in the area of edge computing. Our comprehensive design and implementation of CFS successfully fulfill the objective of providing a multi-credential Common Access API. The architecture of CFS is methodically segmented into three integral components: Firstly, the DataCapsule server, tasked with the storage, dissemination, and replication of DataCapsules on the edge. Secondly, the middleware, a crucial element running in a Trusted Execution Environment responsible for the enforcement and management of write permissions and requests. Finally, the client component, which manifests as a POSIX-compliant filesystem, is adaptable and operational across many architectures. Experimental evaluations of CFS reveal that, while its read and write performances are comparatively modest, it upholds a high degree of functional correctness. This attribute distinctly positions CFS as a viable candidate for application in real-world software development scenarios. The paper also delineates potential future enhancements, aimed at augmenting the practicality of CFS in the landscape of software development.\n    link: https://arxiv.org/abs/2512.08067v1\n    "}}
{"custom_id": "2512.01824v2", "method": "POST", "url": "/v1/responses", "body": {"model": "gpt-5-mini", "input": "You are a specialist research analyst in Web3, DeFi, cryptography, and distributed systems.\n\n    Your task:\n    From the paper below (Title + Summary + Link), evaluate how useful each paper is for understanding investment opportunities or technological advantages within the Web3 / crypto / DeFi ecosystem.\n    Rate each paper on a five-level scale: Highest / High / Medium / Low / Lowest.\n\n    \"Useful\" means:\n\n    - Improves understanding of new cryptographic primitives relevant to blockchain performance or security\n    - Enhances scalability: distributed systems, P2P networking, consensus mechanisms\n    - Advances in zero knowledge, MPC, PQC that could impact future L1/L2 chains\n    - DeFi modeling, AMMs, MEV, risk models, liquidity dynamics\n    - Smart contract security, attack vectors, economic incentives\n    - Token economics, mechanism design for decentralized systems\n    - Quantum threats to blockchain or cryptography\n    - Any breakthrough that meaningfully improves decentralization, scalability, privacy, or composability\n\n    Output instructions:\n\n    - Output each JSON object in JSON Lines format (one line per paper).\n\n    {\n        \"title\": title of the paper (in Japanese),\n        \"summary\": A concise summary of the paper (in Japanese),\n        \"impact_level\": \"Highest|High|Medium|Low|Lowest\",\n        \"why_matters\": An array (JSON array) containing 2\u20134 bullet points explaining why this paper matters for Web3 investment\n    }\n\n    - Do not output anything except valid JSON object in JSON Lines.\n    - \"title\", \"summary\", \"why_matters\" text in the output must be written in Japanese.\n\n    Paper:\n    title: HERMES: Heterogeneous Application-Enabled Routing Middleware for Edge-IoT Systems\n    summary: The growth of the Internet of Things has enabled a new generation of applications, pushing computation and intelligence toward the network edge. This trend, however, exposes challenges, as the heterogeneity of devices and the complex requirements of applications are often misaligned with the assumptions of traditional routing protocols, which lack the flexibility to accommodate application-layer metrics and policies. This work addresses this gap by proposing a software framework that enhances routing flexibility by dynamically incorporating application-aware decisions. The core of the work establishes a multi-hop Wi-Fi network of heterogeneous devices, specifically ESP8266, ESP32, and Raspberry Pi 3B. The routing layer follows a proactive approach, while the network is fault-tolerant, maintaining operation despite both node loss and message loss. On top of this, a middleware layer introduces three strategies for influencing routing behavior: two adapt the path a message traverses until arriving at the destination, while the third allows applications to shape the network topology. This layer offers a flexible interface for diverse applications. The framework was validated on a physical testbed through edge intelligence use cases, including distributing neural network inference computations across multiple devices and offloading the entire workload to the most capable node. Distributed inference is useful in scenarios requiring low latency, energy efficiency, privacy, and autonomy. Experimental results indicated that device heterogeneity significantly impacts network performance. Throughput and inference duration analysis showed the influence of the strategies on application behaviour, revealed that topology critically affects decentralized performance, and demonstrated the suitability of the framework for complex tasks.\n    link: https://arxiv.org/abs/2512.01824v2\n    "}}
{"custom_id": "2509.01926v2", "method": "POST", "url": "/v1/responses", "body": {"model": "gpt-5-mini", "input": "You are a specialist research analyst in Web3, DeFi, cryptography, and distributed systems.\n\n    Your task:\n    From the paper below (Title + Summary + Link), evaluate how useful each paper is for understanding investment opportunities or technological advantages within the Web3 / crypto / DeFi ecosystem.\n    Rate each paper on a five-level scale: Highest / High / Medium / Low / Lowest.\n\n    \"Useful\" means:\n\n    - Improves understanding of new cryptographic primitives relevant to blockchain performance or security\n    - Enhances scalability: distributed systems, P2P networking, consensus mechanisms\n    - Advances in zero knowledge, MPC, PQC that could impact future L1/L2 chains\n    - DeFi modeling, AMMs, MEV, risk models, liquidity dynamics\n    - Smart contract security, attack vectors, economic incentives\n    - Token economics, mechanism design for decentralized systems\n    - Quantum threats to blockchain or cryptography\n    - Any breakthrough that meaningfully improves decentralization, scalability, privacy, or composability\n\n    Output instructions:\n\n    - Output each JSON object in JSON Lines format (one line per paper).\n\n    {\n        \"title\": title of the paper (in Japanese),\n        \"summary\": A concise summary of the paper (in Japanese),\n        \"impact_level\": \"Highest|High|Medium|Low|Lowest\",\n        \"why_matters\": An array (JSON array) containing 2\u20134 bullet points explaining why this paper matters for Web3 investment\n    }\n\n    - Do not output anything except valid JSON object in JSON Lines.\n    - \"title\", \"summary\", \"why_matters\" text in the output must be written in Japanese.\n\n    Paper:\n    title: AoI-based Scheduling of Correlated Sources for Timely Inference\n    summary: We investigate a real-time remote inference system where multiple correlated sources transmit observations over a communication channel to a receiver. The receiver utilizes these observations to infer multiple time-varying targets. Due to limited communication resources, the delivered observations may not be fresh. To quantify data freshness, we employ the Age of Information (AoI) metric. To minimize the inference error, we aim to design a signal-agnostic scheduling policy that leverages AoI without requiring knowledge of the actual target values or the source observations. This scheduling problem is a restless multi-armed bandit (RMAB) problem with a non-separable penalty function. Unlike traditional RMABs, the correlation among sources introduces a unique challenge: the penalty function of each source depends on the AoI of other correlated sources, preventing the problem from decomposing into multiple independent Markov Decision Processes (MDPs), a key step in applying traditional RMAB solutions. To address this, we propose a novel approach that approximates the penalty function for each source and establishes an analytical bound on the approximation error. We then develop scheduling policies for two scenarios: (i) full knowledge of the penalty functions and (ii) no knowledge of the penalty functions. For the case of known penalty functions, we present an upper bound on the optimality gap that highlights the impact of the correlation parameter and the system size. For the case of unknown penalty functions and signal distributions, we develop an online learning approach that utilizes bandit feedback to learn an online Maximum Gain First policy. Simulation results demonstrate the effectiveness of our proposed policies in minimizing inference error and achieving scalability in the number of sources.\n    link: https://arxiv.org/abs/2509.01926v2\n    "}}
{"custom_id": "2512.08023v1", "method": "POST", "url": "/v1/responses", "body": {"model": "gpt-5-mini", "input": "You are a specialist research analyst in Web3, DeFi, cryptography, and distributed systems.\n\n    Your task:\n    From the paper below (Title + Summary + Link), evaluate how useful each paper is for understanding investment opportunities or technological advantages within the Web3 / crypto / DeFi ecosystem.\n    Rate each paper on a five-level scale: Highest / High / Medium / Low / Lowest.\n\n    \"Useful\" means:\n\n    - Improves understanding of new cryptographic primitives relevant to blockchain performance or security\n    - Enhances scalability: distributed systems, P2P networking, consensus mechanisms\n    - Advances in zero knowledge, MPC, PQC that could impact future L1/L2 chains\n    - DeFi modeling, AMMs, MEV, risk models, liquidity dynamics\n    - Smart contract security, attack vectors, economic incentives\n    - Token economics, mechanism design for decentralized systems\n    - Quantum threats to blockchain or cryptography\n    - Any breakthrough that meaningfully improves decentralization, scalability, privacy, or composability\n\n    Output instructions:\n\n    - Output each JSON object in JSON Lines format (one line per paper).\n\n    {\n        \"title\": title of the paper (in Japanese),\n        \"summary\": A concise summary of the paper (in Japanese),\n        \"impact_level\": \"Highest|High|Medium|Low|Lowest\",\n        \"why_matters\": An array (JSON array) containing 2\u20134 bullet points explaining why this paper matters for Web3 investment\n    }\n\n    - Do not output anything except valid JSON object in JSON Lines.\n    - \"title\", \"summary\", \"why_matters\" text in the output must be written in Japanese.\n\n    Paper:\n    title: F2: Offline Reinforcement Learning for Hamiltonian Simulation via Free-Fermionic Subroutine Compilation\n    summary: Compiling shallow and accurate quantum circuits for Hamiltonian simulation remains challenging due to hardware constraints and the combinatorial complexity of minimizing gate count and circuit depth. Existing optimization method pipelines rely on hand-engineered classical heuristics, which cannot learn input-dependent structure and therefore miss substantial opportunities for circuit reduction.\n  We introduce \\textbf{F2}, an offline reinforcement learning framework that exploits free-fermionic structure to efficiently compile Trotter-based Hamiltonian simulation circuits. F2 provides (i) a reinforcement-learning environment over classically simulatable free-fermionic subroutines, (ii) architectural and objective-level inductive biases that stabilize long-horizon value learning, and (iii) a reversible synthetic-trajectory generation mechanism that consistently yields abundant, guaranteed-successful offline data.\n  Across benchmarks spanning lattice models, protein fragments, and crystalline materials (12-222 qubits), F2 reduces gate count by 47\\% and depth by 38\\% on average relative to strong baselines (Qiskit, Cirq/OpenFermion) while maintaining average errors of $10^{-7}$. These results show that aligning deep reinforcement learning with the algebraic structure of quantum dynamics enables substantial improvements in circuit synthesis, suggesting a promising direction for scalable, learning-based quantum compilation\n    link: https://arxiv.org/abs/2512.08023v1\n    "}}
{"custom_id": "2302.05174v2", "method": "POST", "url": "/v1/responses", "body": {"model": "gpt-5-mini", "input": "You are a specialist research analyst in Web3, DeFi, cryptography, and distributed systems.\n\n    Your task:\n    From the paper below (Title + Summary + Link), evaluate how useful each paper is for understanding investment opportunities or technological advantages within the Web3 / crypto / DeFi ecosystem.\n    Rate each paper on a five-level scale: Highest / High / Medium / Low / Lowest.\n\n    \"Useful\" means:\n\n    - Improves understanding of new cryptographic primitives relevant to blockchain performance or security\n    - Enhances scalability: distributed systems, P2P networking, consensus mechanisms\n    - Advances in zero knowledge, MPC, PQC that could impact future L1/L2 chains\n    - DeFi modeling, AMMs, MEV, risk models, liquidity dynamics\n    - Smart contract security, attack vectors, economic incentives\n    - Token economics, mechanism design for decentralized systems\n    - Quantum threats to blockchain or cryptography\n    - Any breakthrough that meaningfully improves decentralization, scalability, privacy, or composability\n\n    Output instructions:\n\n    - Output each JSON object in JSON Lines format (one line per paper).\n\n    {\n        \"title\": title of the paper (in Japanese),\n        \"summary\": A concise summary of the paper (in Japanese),\n        \"impact_level\": \"Highest|High|Medium|Low|Lowest\",\n        \"why_matters\": An array (JSON array) containing 2\u20134 bullet points explaining why this paper matters for Web3 investment\n    }\n\n    - Do not output anything except valid JSON object in JSON Lines.\n    - \"title\", \"summary\", \"why_matters\" text in the output must be written in Japanese.\n\n    Paper:\n    title: An Appropriate Probability Model for the Bell Experiment\n    summary: The Bell inequality constrains the outcomes of measurements on pairs of distant entangled particles. The Bell contradiction states that the Bell inequality is inconsistent with the calculated outcomes of these quantum experiments. This contradiction led many to question the underlying assumptions, viz. so-called realism and locality. The probability model underlying the Bell inequality is generally left implicit. This implicit consensus model assumes four simultaneously observable detector settings. The Bell contradiction follows from this assumption.\n  We propose an explicit probability model for the CHSH version of the Bell experiment. This model has only two simultaneously observable detector settings per measurement, and therefore does not assume realism. The quantum expectation now becomes a conditional expectation, given the two detector settings. This probability model is in full agreement with both quantum mechanics and experiments. In this model the notion of Bell contradiction has no meaning. Furthermore, the proposed probability model is statistically local, and is not Bell-separable. The latter implies that either hidden variables must be ruled out, or that locality must be violated, in agreement with Bell's conclusion.\n    link: https://arxiv.org/abs/2302.05174v2\n    "}}
{"custom_id": "2508.18086v3", "method": "POST", "url": "/v1/responses", "body": {"model": "gpt-5-mini", "input": "You are a specialist research analyst in Web3, DeFi, cryptography, and distributed systems.\n\n    Your task:\n    From the paper below (Title + Summary + Link), evaluate how useful each paper is for understanding investment opportunities or technological advantages within the Web3 / crypto / DeFi ecosystem.\n    Rate each paper on a five-level scale: Highest / High / Medium / Low / Lowest.\n\n    \"Useful\" means:\n\n    - Improves understanding of new cryptographic primitives relevant to blockchain performance or security\n    - Enhances scalability: distributed systems, P2P networking, consensus mechanisms\n    - Advances in zero knowledge, MPC, PQC that could impact future L1/L2 chains\n    - DeFi modeling, AMMs, MEV, risk models, liquidity dynamics\n    - Smart contract security, attack vectors, economic incentives\n    - Token economics, mechanism design for decentralized systems\n    - Quantum threats to blockchain or cryptography\n    - Any breakthrough that meaningfully improves decentralization, scalability, privacy, or composability\n\n    Output instructions:\n\n    - Output each JSON object in JSON Lines format (one line per paper).\n\n    {\n        \"title\": title of the paper (in Japanese),\n        \"summary\": A concise summary of the paper (in Japanese),\n        \"impact_level\": \"Highest|High|Medium|Low|Lowest\",\n        \"why_matters\": An array (JSON array) containing 2\u20134 bullet points explaining why this paper matters for Web3 investment\n    }\n\n    - Do not output anything except valid JSON object in JSON Lines.\n    - \"title\", \"summary\", \"why_matters\" text in the output must be written in Japanese.\n\n    Paper:\n    title: Correlation Enhanced Autonomous Quantum Battery Charging via Structured Reservoirs\n    summary: In this work, we investigate the autonomous charging process of a quantum battery coupled to a structured reservoir composed of two qubits, each in thermal equilibrium with its own bosonic bath. Moreover, the reservoir interacts with a charger-battery architecture through three configurations: (I) direct coupling between reservoir qubits and battery, (II) collective coupling among the reservoir qubits, charger, and battery, while (III) reflects a collective coupling between the reservoir qubits and charger together with a local charger-battery interaction. However, by using incoherent and coherent initial states, we analyze the stored energy, ergotropy, and charging power of battery, where we derive the upper and lower bounds on the extractable work in terms of the free energy of coherence and correlations exchanged between subsystems. Our results show that global and local coherences, as well as total correlations act as quantum resources that enhance autonomous charging. Additionally, we demonstrate that the free energy stored in the quantum battery splits into contributions from coherence and correlations, providing numerical evidence that supports the derived ergotropy bounds. Importantly, this work highlights how structured reservoirs enable autonomous and resource-enhanced quantum battery operation.\n    link: https://arxiv.org/abs/2508.18086v3\n    "}}
{"custom_id": "2512.08005v1", "method": "POST", "url": "/v1/responses", "body": {"model": "gpt-5-mini", "input": "You are a specialist research analyst in Web3, DeFi, cryptography, and distributed systems.\n\n    Your task:\n    From the paper below (Title + Summary + Link), evaluate how useful each paper is for understanding investment opportunities or technological advantages within the Web3 / crypto / DeFi ecosystem.\n    Rate each paper on a five-level scale: Highest / High / Medium / Low / Lowest.\n\n    \"Useful\" means:\n\n    - Improves understanding of new cryptographic primitives relevant to blockchain performance or security\n    - Enhances scalability: distributed systems, P2P networking, consensus mechanisms\n    - Advances in zero knowledge, MPC, PQC that could impact future L1/L2 chains\n    - DeFi modeling, AMMs, MEV, risk models, liquidity dynamics\n    - Smart contract security, attack vectors, economic incentives\n    - Token economics, mechanism design for decentralized systems\n    - Quantum threats to blockchain or cryptography\n    - Any breakthrough that meaningfully improves decentralization, scalability, privacy, or composability\n\n    Output instructions:\n\n    - Output each JSON object in JSON Lines format (one line per paper).\n\n    {\n        \"title\": title of the paper (in Japanese),\n        \"summary\": A concise summary of the paper (in Japanese),\n        \"impact_level\": \"Highest|High|Medium|Low|Lowest\",\n        \"why_matters\": An array (JSON array) containing 2\u20134 bullet points explaining why this paper matters for Web3 investment\n    }\n\n    - Do not output anything except valid JSON object in JSON Lines.\n    - \"title\", \"summary\", \"why_matters\" text in the output must be written in Japanese.\n\n    Paper:\n    title: Modeling the Potential of Message-Free Communication via CXL.mem\n    summary: Heterogeneous memory technologies are increasingly important instruments in addressing the memory wall in HPC systems. While most are deployed in single node setups, CXL.mem is a technology that implements memories that can be attached to multiple nodes simultaneously, enabling shared memory pooling. This opens new possibilities, particularly for efficient inter-node communication.\n  In this paper, we present a novel performance evaluation toolchain combined with an extended performance model for message-based communication, which can be used to predict potential performance benefits from using CXL.mem for data exchange. Our approach analyzes data access patterns of MPI applications: it analyzes on-node accesses to/from MPI buffers, as well as cross-node MPI traffic to gather a full understanding of the impact of memory performance. We combine this data in an extended performance model to predict which data transfers could benefit from direct CXL.mem implementations as compared to traditional MPI messages. Our model works on a per-MPI call granularity, allowing the identification and later optimizations of those MPI invocations in the code with the highest potential for speedup by using CXL.mem.\n  For our toolchain, we extend the memory trace sampling tool Mitos and use it to extract data access behavior. In the post-processing step, the raw data is automatically analyzed to provide performance models for each individual MPI call. We validate the models on two sample applications -- a 2D heat transfer miniapp and the HPCG benchmark -- and use them to demonstrate their support for targeted optimizations by integrating CXL.mem.\n    link: https://arxiv.org/abs/2512.08005v1\n    "}}
{"custom_id": "2503.14682v2", "method": "POST", "url": "/v1/responses", "body": {"model": "gpt-5-mini", "input": "You are a specialist research analyst in Web3, DeFi, cryptography, and distributed systems.\n\n    Your task:\n    From the paper below (Title + Summary + Link), evaluate how useful each paper is for understanding investment opportunities or technological advantages within the Web3 / crypto / DeFi ecosystem.\n    Rate each paper on a five-level scale: Highest / High / Medium / Low / Lowest.\n\n    \"Useful\" means:\n\n    - Improves understanding of new cryptographic primitives relevant to blockchain performance or security\n    - Enhances scalability: distributed systems, P2P networking, consensus mechanisms\n    - Advances in zero knowledge, MPC, PQC that could impact future L1/L2 chains\n    - DeFi modeling, AMMs, MEV, risk models, liquidity dynamics\n    - Smart contract security, attack vectors, economic incentives\n    - Token economics, mechanism design for decentralized systems\n    - Quantum threats to blockchain or cryptography\n    - Any breakthrough that meaningfully improves decentralization, scalability, privacy, or composability\n\n    Output instructions:\n\n    - Output each JSON object in JSON Lines format (one line per paper).\n\n    {\n        \"title\": title of the paper (in Japanese),\n        \"summary\": A concise summary of the paper (in Japanese),\n        \"impact_level\": \"Highest|High|Medium|Low|Lowest\",\n        \"why_matters\": An array (JSON array) containing 2\u20134 bullet points explaining why this paper matters for Web3 investment\n    }\n\n    - Do not output anything except valid JSON object in JSON Lines.\n    - \"title\", \"summary\", \"why_matters\" text in the output must be written in Japanese.\n\n    Paper:\n    title: Dual-Source SPIR over a noiseless MAC without Data Replication or Shared Randomness\n    summary: Information-theoretically secure Symmetric Private Information Retrieval (SPIR) is known to be infeasible over noiseless channels with a single server. Known solutions to overcome this infeasibility involve additional resources such as database replication, shared randomness, or noisy channels. In this paper, we propose an alternative approach for achieving SPIR with information-theoretic security guarantees, without relying on shared randomness, noisy channels, or data replication. Specifically, we demonstrate that it is sufficient to use a noiseless binary adder multiple-access channel, where inputs are controlled by two non-colluding servers and the output is observed by the client, alongside a public noiseless communication channel between the client and the servers. Furthermore, in this setting, we characterize the optimal file rates, i.e., the file lengths normalized by the number of channel uses, that can be transferred.\n    link: https://arxiv.org/abs/2503.14682v2\n    "}}
{"custom_id": "2511.02941v2", "method": "POST", "url": "/v1/responses", "body": {"model": "gpt-5-mini", "input": "You are a specialist research analyst in Web3, DeFi, cryptography, and distributed systems.\n\n    Your task:\n    From the paper below (Title + Summary + Link), evaluate how useful each paper is for understanding investment opportunities or technological advantages within the Web3 / crypto / DeFi ecosystem.\n    Rate each paper on a five-level scale: Highest / High / Medium / Low / Lowest.\n\n    \"Useful\" means:\n\n    - Improves understanding of new cryptographic primitives relevant to blockchain performance or security\n    - Enhances scalability: distributed systems, P2P networking, consensus mechanisms\n    - Advances in zero knowledge, MPC, PQC that could impact future L1/L2 chains\n    - DeFi modeling, AMMs, MEV, risk models, liquidity dynamics\n    - Smart contract security, attack vectors, economic incentives\n    - Token economics, mechanism design for decentralized systems\n    - Quantum threats to blockchain or cryptography\n    - Any breakthrough that meaningfully improves decentralization, scalability, privacy, or composability\n\n    Output instructions:\n\n    - Output each JSON object in JSON Lines format (one line per paper).\n\n    {\n        \"title\": title of the paper (in Japanese),\n        \"summary\": A concise summary of the paper (in Japanese),\n        \"impact_level\": \"Highest|High|Medium|Low|Lowest\",\n        \"why_matters\": An array (JSON array) containing 2\u20134 bullet points explaining why this paper matters for Web3 investment\n    }\n\n    - Do not output anything except valid JSON object in JSON Lines.\n    - \"title\", \"summary\", \"why_matters\" text in the output must be written in Japanese.\n\n    Paper:\n    title: Dynamics generated by spatially growing derivations on quasi-local algebras\n    summary: We prove global existence and uniqueness of dynamics on the quasi-local algebra $\\mathcal{A}$ of a quantum lattice system for spatially growing derivations $\\mathcal{L}_\u03a6= \\sum_x [ \u03a6_x , \\cdot ]$. Existing results assume that the local terms $\u03a6_x\\in\\mathcal{A}$ of the generator are uniformly bounded in space with respect to appropriate weighted norms $\\lVert \u03a6_x \\rVert_{G,x}$. Analogous to the global existence result for first order ODEs, we show that global existence and uniqueness persist if the size of the local terms $\\lVert \u03a6_x \\rVert_{G,x}$ grows at most linearly in space. This considerably enlarges the class of derivations known to have well-defined dynamics. Moreover, we obtain Lieb-Robinson bounds with exponential light cones for such dynamics.\n  For the proof, we assume Lieb-Robinson bounds with linear light cones for dynamics, whose generators have uniformly bounded local terms. Such bounds are known to hold, for example, if the local terms are of finite range or exponentially localized.\n    link: https://arxiv.org/abs/2511.02941v2\n    "}}
{"custom_id": "2512.07966v1", "method": "POST", "url": "/v1/responses", "body": {"model": "gpt-5-mini", "input": "You are a specialist research analyst in Web3, DeFi, cryptography, and distributed systems.\n\n    Your task:\n    From the paper below (Title + Summary + Link), evaluate how useful each paper is for understanding investment opportunities or technological advantages within the Web3 / crypto / DeFi ecosystem.\n    Rate each paper on a five-level scale: Highest / High / Medium / Low / Lowest.\n\n    \"Useful\" means:\n\n    - Improves understanding of new cryptographic primitives relevant to blockchain performance or security\n    - Enhances scalability: distributed systems, P2P networking, consensus mechanisms\n    - Advances in zero knowledge, MPC, PQC that could impact future L1/L2 chains\n    - DeFi modeling, AMMs, MEV, risk models, liquidity dynamics\n    - Smart contract security, attack vectors, economic incentives\n    - Token economics, mechanism design for decentralized systems\n    - Quantum threats to blockchain or cryptography\n    - Any breakthrough that meaningfully improves decentralization, scalability, privacy, or composability\n\n    Output instructions:\n\n    - Output each JSON object in JSON Lines format (one line per paper).\n\n    {\n        \"title\": title of the paper (in Japanese),\n        \"summary\": A concise summary of the paper (in Japanese),\n        \"impact_level\": \"Highest|High|Medium|Low|Lowest\",\n        \"why_matters\": An array (JSON array) containing 2\u20134 bullet points explaining why this paper matters for Web3 investment\n    }\n\n    - Do not output anything except valid JSON object in JSON Lines.\n    - \"title\", \"summary\", \"why_matters\" text in the output must be written in Japanese.\n\n    Paper:\n    title: Measurement-and Feedback-Driven Non-Equilibrium Phase Transitions on a Quantum Processor\n    summary: Mid-circuit measurements and feedback operations conditioned on the measurement outcomes are essential for implementing quantum error-correction on quantum hardware. When integrated in quantum many-body dynamics, they can give rise to novel non-equilibrium phase transitions both at the level of each individual quantum trajectory and the averaged quantum channel. Experimentally resolving both transitions on realistic devices has been challenging due to limitations on the fidelity and the significant latency for performing mid-circuit measurements and feedback operations in real time. Here, we develop a superconducting quantum processor that enables global mid-circuit measurement with an average quantum non-demolition (QND) fidelity of 98.7% and fast conditional feedback with a 200 ns real-time decision latency. Using this platform, we demonstrate the coexistence of an absorbing-state transition in the quantum channel and a measurement-induced entanglement transition at the level of individual quantum trajectories. For the absorbing-state transition, we experimentally extract a set of critical exponents at the transition point, which is in excellent agreement with the directed percolation universality class. Crucially, the two transitions occur at distinct values of the tuning parameter. Our results demonstrate that adaptive quantum circuits provide a powerful platform for exploring non-equilibrium quantum many-body dynamics.\n    link: https://arxiv.org/abs/2512.07966v1\n    "}}
