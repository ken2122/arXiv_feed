{"custom_id": "2512.09926v1", "method": "POST", "url": "/v1/responses", "body": {"model": "gpt-5-mini", "input": "You are a specialist research analyst in Web3, DeFi, cryptography, and distributed systems.\n\n    Your task:\n    From the paper below (Title + Summary + Link), evaluate how useful each paper is for understanding investment opportunities or technological advantages within the Web3 / crypto / DeFi ecosystem.\n    Rate each paper on a five-level scale: Highest / High / Medium / Low / Lowest.\n\n    \"Useful\" means:\n\n    - Improves understanding of new cryptographic primitives relevant to blockchain performance or security\n    - Enhances scalability: distributed systems, P2P networking, consensus mechanisms\n    - Advances in zero knowledge, MPC, PQC that could impact future L1/L2 chains\n    - DeFi modeling, AMMs, MEV, risk models, liquidity dynamics\n    - Smart contract security, attack vectors, economic incentives\n    - Token economics, mechanism design for decentralized systems\n    - Quantum threats to blockchain or cryptography\n    - Any breakthrough that meaningfully improves decentralization, scalability, privacy, or composability\n\n    Output instructions:\n\n    - Output each JSON object in JSON Lines format (one line per paper).\n\n    {\n        \"title\": title of the paper (in Japanese),\n        \"summary\": A concise summary of the paper (in Japanese),\n        \"impact_level\": \"Highest|High|Medium|Low|Lowest\",\n        \"why_matters\": An array (JSON array) containing 2\u20134 bullet points explaining why this paper matters for Web3 investment\n    }\n\n    - Do not output anything except valid JSON object in JSON Lines.\n    - \"title\", \"summary\", \"why_matters\" text in the output must be written in Japanese.\n\n    Paper:\n    title: Connecting single-layer $t$-$J$ to Kondo lattice models: Exploration with cold atoms\n    summary: The Kondo effect, a hallmark of many-body physics, emerges from the antiferromagnetic coupling between localized spins and conduction fermions, leading to a correlated many-body singlet state. Here we propose to use the mixed-dimensional (mixD) bilayer Hubbard geometry as a platform to study Kondo lattice physics with current ultracold atom experiments. At experimentally feasible temperatures, we predict that key features of the Kondo effect can be observed, including formation of the Kondo cloud around a single impurity and the competition of singlet formation with Ruderman-Kittel-Kasuya-Yosida (RKKY) interactions for multiple impurities, summarized in the Doniach phase diagram. Moreover, we show that the mixD platform provides a natural bridge between the Doniach phase diagram of the Kondo lattice model, relevant to heavy-fermion materials, and the phase diagram of cuprate superconductors as described by a single-layer Zhang-Rice type $t$-$J$ model: It is possible to continuously tune between the two regimes by changing the interlayer Kondo coupling. Our findings demonstrate that the direct connection between high-temperature superconductivity and heavy-fermion physics can be experimentally studied using currently available quantum simulation platforms.\n    link: https://arxiv.org/abs/2512.09926v1\n    "}}
{"custom_id": "2509.06796v2", "method": "POST", "url": "/v1/responses", "body": {"model": "gpt-5-mini", "input": "You are a specialist research analyst in Web3, DeFi, cryptography, and distributed systems.\n\n    Your task:\n    From the paper below (Title + Summary + Link), evaluate how useful each paper is for understanding investment opportunities or technological advantages within the Web3 / crypto / DeFi ecosystem.\n    Rate each paper on a five-level scale: Highest / High / Medium / Low / Lowest.\n\n    \"Useful\" means:\n\n    - Improves understanding of new cryptographic primitives relevant to blockchain performance or security\n    - Enhances scalability: distributed systems, P2P networking, consensus mechanisms\n    - Advances in zero knowledge, MPC, PQC that could impact future L1/L2 chains\n    - DeFi modeling, AMMs, MEV, risk models, liquidity dynamics\n    - Smart contract security, attack vectors, economic incentives\n    - Token economics, mechanism design for decentralized systems\n    - Quantum threats to blockchain or cryptography\n    - Any breakthrough that meaningfully improves decentralization, scalability, privacy, or composability\n\n    Output instructions:\n\n    - Output each JSON object in JSON Lines format (one line per paper).\n\n    {\n        \"title\": title of the paper (in Japanese),\n        \"summary\": A concise summary of the paper (in Japanese),\n        \"impact_level\": \"Highest|High|Medium|Low|Lowest\",\n        \"why_matters\": An array (JSON array) containing 2\u20134 bullet points explaining why this paper matters for Web3 investment\n    }\n\n    - Do not output anything except valid JSON object in JSON Lines.\n    - \"title\", \"summary\", \"why_matters\" text in the output must be written in Japanese.\n\n    Paper:\n    title: Imitative Membership Inference Attack\n    summary: A Membership Inference Attack (MIA) assesses how much a target machine learning model reveals about its training data by determining whether specific query instances were part of the training set. State-of-the-art MIAs rely on training hundreds of shadow models that are independent of the target model, leading to significant computational overhead. In this paper, we introduce Imitative Membership Inference Attack (IMIA), which employs a novel imitative training technique to strategically construct a small number of target-informed imitative models that closely replicate the target model's behavior for inference. Extensive experimental results demonstrate that IMIA substantially outperforms existing MIAs in various attack settings while only requiring less than 5% of the computational cost of state-of-the-art approaches.\n    link: https://arxiv.org/abs/2509.06796v2\n    "}}
{"custom_id": "2512.09902v1", "method": "POST", "url": "/v1/responses", "body": {"model": "gpt-5-mini", "input": "You are a specialist research analyst in Web3, DeFi, cryptography, and distributed systems.\n\n    Your task:\n    From the paper below (Title + Summary + Link), evaluate how useful each paper is for understanding investment opportunities or technological advantages within the Web3 / crypto / DeFi ecosystem.\n    Rate each paper on a five-level scale: Highest / High / Medium / Low / Lowest.\n\n    \"Useful\" means:\n\n    - Improves understanding of new cryptographic primitives relevant to blockchain performance or security\n    - Enhances scalability: distributed systems, P2P networking, consensus mechanisms\n    - Advances in zero knowledge, MPC, PQC that could impact future L1/L2 chains\n    - DeFi modeling, AMMs, MEV, risk models, liquidity dynamics\n    - Smart contract security, attack vectors, economic incentives\n    - Token economics, mechanism design for decentralized systems\n    - Quantum threats to blockchain or cryptography\n    - Any breakthrough that meaningfully improves decentralization, scalability, privacy, or composability\n\n    Output instructions:\n\n    - Output each JSON object in JSON Lines format (one line per paper).\n\n    {\n        \"title\": title of the paper (in Japanese),\n        \"summary\": A concise summary of the paper (in Japanese),\n        \"impact_level\": \"Highest|High|Medium|Low|Lowest\",\n        \"why_matters\": An array (JSON array) containing 2\u20134 bullet points explaining why this paper matters for Web3 investment\n    }\n\n    - Do not output anything except valid JSON object in JSON Lines.\n    - \"title\", \"summary\", \"why_matters\" text in the output must be written in Japanese.\n\n    Paper:\n    title: Link-Sharing Backpressure Routing In Wireless Multi-Hop Networks\n    summary: Backpressure (BP) routing and scheduling is an established resource allocation method for wireless multi-hop networks, noted for its fully distributed operation and maximum queue stability. Recent advances in shortest path-biased BP routing (SP-BP) mitigate shortcomings such as slow startup and random walks, yet exclusive link-level commodity selection still causes last-packet problem and bandwidth underutilization. By revisiting the Lyapunov drift theory underlying BP, we show that the legacy exclusive commodity selection is unnecessary, and propose a Maximum Utility (MaxU) link-sharing method to expand its performance envelope without increasing control message overhead. Numerical results show that MaxU SP-BP substantially mitigates the last-packet problem and slightly expands the network capacity region.\n    link: https://arxiv.org/abs/2512.09902v1\n    "}}
{"custom_id": "2512.09883v1", "method": "POST", "url": "/v1/responses", "body": {"model": "gpt-5-mini", "input": "You are a specialist research analyst in Web3, DeFi, cryptography, and distributed systems.\n\n    Your task:\n    From the paper below (Title + Summary + Link), evaluate how useful each paper is for understanding investment opportunities or technological advantages within the Web3 / crypto / DeFi ecosystem.\n    Rate each paper on a five-level scale: Highest / High / Medium / Low / Lowest.\n\n    \"Useful\" means:\n\n    - Improves understanding of new cryptographic primitives relevant to blockchain performance or security\n    - Enhances scalability: distributed systems, P2P networking, consensus mechanisms\n    - Advances in zero knowledge, MPC, PQC that could impact future L1/L2 chains\n    - DeFi modeling, AMMs, MEV, risk models, liquidity dynamics\n    - Smart contract security, attack vectors, economic incentives\n    - Token economics, mechanism design for decentralized systems\n    - Quantum threats to blockchain or cryptography\n    - Any breakthrough that meaningfully improves decentralization, scalability, privacy, or composability\n\n    Output instructions:\n\n    - Output each JSON object in JSON Lines format (one line per paper).\n\n    {\n        \"title\": title of the paper (in Japanese),\n        \"summary\": A concise summary of the paper (in Japanese),\n        \"impact_level\": \"Highest|High|Medium|Low|Lowest\",\n        \"why_matters\": An array (JSON array) containing 2\u20134 bullet points explaining why this paper matters for Web3 investment\n    }\n\n    - Do not output anything except valid JSON object in JSON Lines.\n    - \"title\", \"summary\", \"why_matters\" text in the output must be written in Japanese.\n\n    Paper:\n    title: ByteShield: Adversarially Robust End-to-End Malware Detection through Byte Masking\n    summary: Research has proven that end-to-end malware detectors are vulnerable to adversarial attacks. In response, the research community has proposed defenses based on randomized and (de)randomized smoothing. However, these techniques remain susceptible to attacks that insert large adversarial payloads. To address these limitations, we propose a novel defense mechanism designed to harden end-to-end malware detectors by leveraging masking at the byte level. This mechanism operates by generating multiple masked versions of the input file, independently classifying each version, and then applying a threshold-based voting mechanism to produce the final classification. Key to this defense is a deterministic masking strategy that systematically strides a mask across the entire input file. Unlike randomized smoothing defenses, which randomly mask or delete bytes, this structured approach ensures coverage of the file over successive versions. In the best-case scenario, this strategy fully occludes the adversarial payload, effectively neutralizing its influence on the model's decision. In the worst-case scenario, it partially occludes the adversarial payload, reducing its impact on the model's predictions. By occluding the adversarial payload in one or more masked versions, this defense ensures that some input versions remain representative of the file's original intent, allowing the voting mechanism to suppress the influence of the adversarial payload. Results achieved on the EMBER and BODMAS datasets demonstrate the suitability of our defense, outperforming randomized and (de)randomized smoothing defenses against adversarial examples generated with a wide range of functionality-preserving manipulations while maintaining high accuracy on clean examples.\n    link: https://arxiv.org/abs/2512.09883v1\n    "}}
{"custom_id": "2512.09882v1", "method": "POST", "url": "/v1/responses", "body": {"model": "gpt-5-mini", "input": "You are a specialist research analyst in Web3, DeFi, cryptography, and distributed systems.\n\n    Your task:\n    From the paper below (Title + Summary + Link), evaluate how useful each paper is for understanding investment opportunities or technological advantages within the Web3 / crypto / DeFi ecosystem.\n    Rate each paper on a five-level scale: Highest / High / Medium / Low / Lowest.\n\n    \"Useful\" means:\n\n    - Improves understanding of new cryptographic primitives relevant to blockchain performance or security\n    - Enhances scalability: distributed systems, P2P networking, consensus mechanisms\n    - Advances in zero knowledge, MPC, PQC that could impact future L1/L2 chains\n    - DeFi modeling, AMMs, MEV, risk models, liquidity dynamics\n    - Smart contract security, attack vectors, economic incentives\n    - Token economics, mechanism design for decentralized systems\n    - Quantum threats to blockchain or cryptography\n    - Any breakthrough that meaningfully improves decentralization, scalability, privacy, or composability\n\n    Output instructions:\n\n    - Output each JSON object in JSON Lines format (one line per paper).\n\n    {\n        \"title\": title of the paper (in Japanese),\n        \"summary\": A concise summary of the paper (in Japanese),\n        \"impact_level\": \"Highest|High|Medium|Low|Lowest\",\n        \"why_matters\": An array (JSON array) containing 2\u20134 bullet points explaining why this paper matters for Web3 investment\n    }\n\n    - Do not output anything except valid JSON object in JSON Lines.\n    - \"title\", \"summary\", \"why_matters\" text in the output must be written in Japanese.\n\n    Paper:\n    title: Comparing AI Agents to Cybersecurity Professionals in Real-World Penetration Testing\n    summary: We present the first comprehensive evaluation of AI agents against human cybersecurity professionals in a live enterprise environment. We evaluate ten cybersecurity professionals alongside six existing AI agents and ARTEMIS, our new agent scaffold, on a large university network consisting of ~8,000 hosts across 12 subnets. ARTEMIS is a multi-agent framework featuring dynamic prompt generation, arbitrary sub-agents, and automatic vulnerability triaging. In our comparative study, ARTEMIS placed second overall, discovering 9 valid vulnerabilities with an 82% valid submission rate and outperforming 9 of 10 human participants. While existing scaffolds such as Codex and CyAgent underperformed relative to most human participants, ARTEMIS demonstrated technical sophistication and submission quality comparable to the strongest participants. We observe that AI agents offer advantages in systematic enumeration, parallel exploitation, and cost -- certain ARTEMIS variants cost $18/hour versus $60/hour for professional penetration testers. We also identify key capability gaps: AI agents exhibit higher false-positive rates and struggle with GUI-based tasks.\n    link: https://arxiv.org/abs/2512.09882v1\n    "}}
{"custom_id": "2512.09872v1", "method": "POST", "url": "/v1/responses", "body": {"model": "gpt-5-mini", "input": "You are a specialist research analyst in Web3, DeFi, cryptography, and distributed systems.\n\n    Your task:\n    From the paper below (Title + Summary + Link), evaluate how useful each paper is for understanding investment opportunities or technological advantages within the Web3 / crypto / DeFi ecosystem.\n    Rate each paper on a five-level scale: Highest / High / Medium / Low / Lowest.\n\n    \"Useful\" means:\n\n    - Improves understanding of new cryptographic primitives relevant to blockchain performance or security\n    - Enhances scalability: distributed systems, P2P networking, consensus mechanisms\n    - Advances in zero knowledge, MPC, PQC that could impact future L1/L2 chains\n    - DeFi modeling, AMMs, MEV, risk models, liquidity dynamics\n    - Smart contract security, attack vectors, economic incentives\n    - Token economics, mechanism design for decentralized systems\n    - Quantum threats to blockchain or cryptography\n    - Any breakthrough that meaningfully improves decentralization, scalability, privacy, or composability\n\n    Output instructions:\n\n    - Output each JSON object in JSON Lines format (one line per paper).\n\n    {\n        \"title\": title of the paper (in Japanese),\n        \"summary\": A concise summary of the paper (in Japanese),\n        \"impact_level\": \"Highest|High|Medium|Low|Lowest\",\n        \"why_matters\": An array (JSON array) containing 2\u20134 bullet points explaining why this paper matters for Web3 investment\n    }\n\n    - Do not output anything except valid JSON object in JSON Lines.\n    - \"title\", \"summary\", \"why_matters\" text in the output must be written in Japanese.\n\n    Paper:\n    title: FlipLLM: Efficient Bit-Flip Attacks on Multimodal LLMs using Reinforcement Learning\n    summary: Generative Artificial Intelligence models, such as Large Language Models (LLMs) and Large Vision Models (VLMs), exhibit state-of-the-art performance but remain vulnerable to hardware-based threats, specifically bit-flip attacks (BFAs). Existing BFA discovery methods lack generalizability and struggle to scale, often failing to analyze the vast parameter space and complex interdependencies of modern foundation models in a reasonable time. This paper proposes FlipLLM, a reinforcement learning (RL) architecture-agnostic framework that formulates BFA discovery as a sequential decision-making problem. FlipLLM combines sensitivity-guided layer pruning with Q-learning to efficiently identify minimal, high-impact bit sets that can induce catastrophic failure. We demonstrate the effectiveness and generalizability of FlipLLM by applying it to a diverse set of models, including prominent text-only LLMs (GPT-2 Large, LLaMA 3.1 8B, and DeepSeek-V2 7B), VLMs such as LLaVA 1.6, and datasets, such as MMLU, MMLU-Pro, VQAv2, and TextVQA. Our results show that FlipLLM can identify critical bits that are vulnerable to BFAs up to 2.5x faster than SOTA methods. We demonstrate that flipping the FlipLLM-identified bits plummets the accuracy of LLaMA 3.1 8B from 69.9% to ~0.2%, and for LLaVA's VQA score from 78% to almost 0%, by flipping as few as 5 and 7 bits, respectively. Further analysis reveals that applying standard hardware protection mechanisms, such as ECC SECDED, to the FlipLLM-identified bit locations completely mitigates the BFA impact, demonstrating the practical value of our framework in guiding hardware-level defenses. FlipLLM offers the first scalable and adaptive methodology for exploring the BFA vulnerability of both language and multimodal foundation models, paving the way for comprehensive hardware-security evaluation.\n    link: https://arxiv.org/abs/2512.09872v1\n    "}}
{"custom_id": "2512.09862v1", "method": "POST", "url": "/v1/responses", "body": {"model": "gpt-5-mini", "input": "You are a specialist research analyst in Web3, DeFi, cryptography, and distributed systems.\n\n    Your task:\n    From the paper below (Title + Summary + Link), evaluate how useful each paper is for understanding investment opportunities or technological advantages within the Web3 / crypto / DeFi ecosystem.\n    Rate each paper on a five-level scale: Highest / High / Medium / Low / Lowest.\n\n    \"Useful\" means:\n\n    - Improves understanding of new cryptographic primitives relevant to blockchain performance or security\n    - Enhances scalability: distributed systems, P2P networking, consensus mechanisms\n    - Advances in zero knowledge, MPC, PQC that could impact future L1/L2 chains\n    - DeFi modeling, AMMs, MEV, risk models, liquidity dynamics\n    - Smart contract security, attack vectors, economic incentives\n    - Token economics, mechanism design for decentralized systems\n    - Quantum threats to blockchain or cryptography\n    - Any breakthrough that meaningfully improves decentralization, scalability, privacy, or composability\n\n    Output instructions:\n\n    - Output each JSON object in JSON Lines format (one line per paper).\n\n    {\n        \"title\": title of the paper (in Japanese),\n        \"summary\": A concise summary of the paper (in Japanese),\n        \"impact_level\": \"Highest|High|Medium|Low|Lowest\",\n        \"why_matters\": An array (JSON array) containing 2\u20134 bullet points explaining why this paper matters for Web3 investment\n    }\n\n    - Do not output anything except valid JSON object in JSON Lines.\n    - \"title\", \"summary\", \"why_matters\" text in the output must be written in Japanese.\n\n    Paper:\n    title: True Random Number Generators on IQM Spark\n    summary: Random number generation is fundamental for many modern applications including cryptography, simulations and machine learning. Traditional pseudo-random numbers may offer statistical unpredictability, but are ultimately deterministic. On the other hand, True Random Number Generation (TRNG) offers true randomness. One way of obtaining such randomness are quantum systems, including quantum computers. As such the use of quantum computers for TRNG has received considerable attention in recent years. However, existing studies almost exclusively consider IBM quantum computers, often stop at using simulations and usually test only a handful of different TRNG quantum circuits. In this paper, we address those issues by presenting a study of TRNG circuits on Odra 5 a real-life quantum computer installed at Wroc\u0142aw University of Science and Technology. It is also the first study to utilize the IQM superconducting architecture. Since Odra 5 is available on-premises it allows for much more comprehensive study of various TRNG circuits. In particular, we consider 5 types of TRNG circuits with 105 circuit subvariants in total. Each circuit is used to generate 1 million bits. We then perform an analysis of the quality of the obtained random sequences using the NIST SP 800-22 and NIST SP 800-90B test suites. We also provide a comprehensive review of existing literature on quantum computer-based TRNGs.\n    link: https://arxiv.org/abs/2512.09862v1\n    "}}
{"custom_id": "2410.19903v3", "method": "POST", "url": "/v1/responses", "body": {"model": "gpt-5-mini", "input": "You are a specialist research analyst in Web3, DeFi, cryptography, and distributed systems.\n\n    Your task:\n    From the paper below (Title + Summary + Link), evaluate how useful each paper is for understanding investment opportunities or technological advantages within the Web3 / crypto / DeFi ecosystem.\n    Rate each paper on a five-level scale: Highest / High / Medium / Low / Lowest.\n\n    \"Useful\" means:\n\n    - Improves understanding of new cryptographic primitives relevant to blockchain performance or security\n    - Enhances scalability: distributed systems, P2P networking, consensus mechanisms\n    - Advances in zero knowledge, MPC, PQC that could impact future L1/L2 chains\n    - DeFi modeling, AMMs, MEV, risk models, liquidity dynamics\n    - Smart contract security, attack vectors, economic incentives\n    - Token economics, mechanism design for decentralized systems\n    - Quantum threats to blockchain or cryptography\n    - Any breakthrough that meaningfully improves decentralization, scalability, privacy, or composability\n\n    Output instructions:\n\n    - Output each JSON object in JSON Lines format (one line per paper).\n\n    {\n        \"title\": title of the paper (in Japanese),\n        \"summary\": A concise summary of the paper (in Japanese),\n        \"impact_level\": \"Highest|High|Medium|Low|Lowest\",\n        \"why_matters\": An array (JSON array) containing 2\u20134 bullet points explaining why this paper matters for Web3 investment\n    }\n\n    - Do not output anything except valid JSON object in JSON Lines.\n    - \"title\", \"summary\", \"why_matters\" text in the output must be written in Japanese.\n\n    Paper:\n    title: General, efficient, and robust Hamiltonian engineering\n    summary: Implementing the time evolution under a desired target Hamiltonian is critical for various applications in quantum science. Due to the exponential increase in the number of parameters with system size and experimental imperfections, this task can be challenging in quantum many-body settings.\n  We introduce an efficient and robust scheme to engineer arbitrary local many-body Hamiltonians. To this end, our scheme applies single-qubit $\u03c0$ or $\u03c0/2$ pulses to an always-on system Hamiltonian, which we assume to be native to a given platform. These sequences are constructed by efficiently solving a linear program (LP) which minimizes the total evolution time. In this way, we can engineer target Hamiltonians that are only limited by the locality of the interactions in the system Hamiltonian. Based on average Hamiltonian theory and using robust composite pulses, we make our schemes robust against errors, including finite pulse time errors and various control errors.\n  To demonstrate the performance of our scheme, we provide numerical simulations. In particular, we solve the Hamiltonian engineering problem on a laptop for arbitrary two-local Hamiltonians on a 2D square lattice with $196$ qubits in only $60$ seconds. Moreover, we simulate the engineering of general Heisenberg Hamiltonians from Ising Hamiltonians using imperfect single-qubit pulses for smaller system sizes and achieve a fidelity exceeding $99.9\\%$, which is orders of magnitude better than non-robust implementations.\n    link: https://arxiv.org/abs/2410.19903v3\n    "}}
{"custom_id": "2512.08641v2", "method": "POST", "url": "/v1/responses", "body": {"model": "gpt-5-mini", "input": "You are a specialist research analyst in Web3, DeFi, cryptography, and distributed systems.\n\n    Your task:\n    From the paper below (Title + Summary + Link), evaluate how useful each paper is for understanding investment opportunities or technological advantages within the Web3 / crypto / DeFi ecosystem.\n    Rate each paper on a five-level scale: Highest / High / Medium / Low / Lowest.\n\n    \"Useful\" means:\n\n    - Improves understanding of new cryptographic primitives relevant to blockchain performance or security\n    - Enhances scalability: distributed systems, P2P networking, consensus mechanisms\n    - Advances in zero knowledge, MPC, PQC that could impact future L1/L2 chains\n    - DeFi modeling, AMMs, MEV, risk models, liquidity dynamics\n    - Smart contract security, attack vectors, economic incentives\n    - Token economics, mechanism design for decentralized systems\n    - Quantum threats to blockchain or cryptography\n    - Any breakthrough that meaningfully improves decentralization, scalability, privacy, or composability\n\n    Output instructions:\n\n    - Output each JSON object in JSON Lines format (one line per paper).\n\n    {\n        \"title\": title of the paper (in Japanese),\n        \"summary\": A concise summary of the paper (in Japanese),\n        \"impact_level\": \"Highest|High|Medium|Low|Lowest\",\n        \"why_matters\": An array (JSON array) containing 2\u20134 bullet points explaining why this paper matters for Web3 investment\n    }\n\n    - Do not output anything except valid JSON object in JSON Lines.\n    - \"title\", \"summary\", \"why_matters\" text in the output must be written in Japanese.\n\n    Paper:\n    title: Quantum Brownian Motion as a Classical Stochastic Process in Phase Space\n    summary: We establish that the exact quantum dynamics of a Brownian particle in the Caldeira-Leggett model can be mapped, at any temperature, onto a classical, non-Markovian stochastic process in phase space. Starting from a correlated thermal equilibrium state between the particle and bath, we prove that this correspondence is exact for quadratic potentials under arbitrary quantum state preparations of the particle itself. For more general, smooth potentials, we identify and exploit a natural small parameter: the density matrix becomes strongly quasidiagonal in the coordinate representation, with its off-diagonal width shrinking as the bath's spectral cutoff increases, providing a controlled parameter for accurate approximation. The framework is fully general: arbitrary initial quantum states-including highly non-classical superpositions-are incorporated via their Wigner functions, which serve as statistical weights for trajectory ensembles. Furthermore, the formalism naturally accommodates external manipulations and measurements modeled by preparation functions acting at arbitrary times, enabling the simulation of complex driven-dissipative quantum protocols.\n    link: https://arxiv.org/abs/2512.08641v2\n    "}}
{"custom_id": "2510.18109v2", "method": "POST", "url": "/v1/responses", "body": {"model": "gpt-5-mini", "input": "You are a specialist research analyst in Web3, DeFi, cryptography, and distributed systems.\n\n    Your task:\n    From the paper below (Title + Summary + Link), evaluate how useful each paper is for understanding investment opportunities or technological advantages within the Web3 / crypto / DeFi ecosystem.\n    Rate each paper on a five-level scale: Highest / High / Medium / Low / Lowest.\n\n    \"Useful\" means:\n\n    - Improves understanding of new cryptographic primitives relevant to blockchain performance or security\n    - Enhances scalability: distributed systems, P2P networking, consensus mechanisms\n    - Advances in zero knowledge, MPC, PQC that could impact future L1/L2 chains\n    - DeFi modeling, AMMs, MEV, risk models, liquidity dynamics\n    - Smart contract security, attack vectors, economic incentives\n    - Token economics, mechanism design for decentralized systems\n    - Quantum threats to blockchain or cryptography\n    - Any breakthrough that meaningfully improves decentralization, scalability, privacy, or composability\n\n    Output instructions:\n\n    - Output each JSON object in JSON Lines format (one line per paper).\n\n    {\n        \"title\": title of the paper (in Japanese),\n        \"summary\": A concise summary of the paper (in Japanese),\n        \"impact_level\": \"Highest|High|Medium|Low|Lowest\",\n        \"why_matters\": An array (JSON array) containing 2\u20134 bullet points explaining why this paper matters for Web3 investment\n    }\n\n    - Do not output anything except valid JSON object in JSON Lines.\n    - \"title\", \"summary\", \"why_matters\" text in the output must be written in Japanese.\n\n    Paper:\n    title: PrivaDE: Privacy-preserving Data Evaluation for Blockchain-based Data Marketplaces\n    summary: Evaluating the usefulness of data before purchase is essential when obtaining data for high-quality machine learning models, yet both model builders and data providers are often unwilling to reveal their proprietary assets.\n  We present PrivaDE, a privacy-preserving protocol that allows a model owner and a data owner to jointly compute a utility score for a candidate dataset without fully exposing model parameters, raw features, or labels. PrivaDE provides strong security against malicious behavior and can be integrated into blockchain-based marketplaces, where smart contracts enforce fair execution and payment. To make the protocol practical, we propose optimizations to enable efficient secure model inference, and a model-agnostic scoring method that uses only a small, representative subset of the data while still reflecting its impact on downstream training. Evaluation shows that PrivaDE performs data evaluation effectively, achieving online runtimes within 15 minutes even for models with millions of parameters.\n  Our work lays the foundation for fair and automated data marketplaces in decentralized machine learning ecosystems.\n    link: https://arxiv.org/abs/2510.18109v2\n    "}}
{"custom_id": "2512.09809v1", "method": "POST", "url": "/v1/responses", "body": {"model": "gpt-5-mini", "input": "You are a specialist research analyst in Web3, DeFi, cryptography, and distributed systems.\n\n    Your task:\n    From the paper below (Title + Summary + Link), evaluate how useful each paper is for understanding investment opportunities or technological advantages within the Web3 / crypto / DeFi ecosystem.\n    Rate each paper on a five-level scale: Highest / High / Medium / Low / Lowest.\n\n    \"Useful\" means:\n\n    - Improves understanding of new cryptographic primitives relevant to blockchain performance or security\n    - Enhances scalability: distributed systems, P2P networking, consensus mechanisms\n    - Advances in zero knowledge, MPC, PQC that could impact future L1/L2 chains\n    - DeFi modeling, AMMs, MEV, risk models, liquidity dynamics\n    - Smart contract security, attack vectors, economic incentives\n    - Token economics, mechanism design for decentralized systems\n    - Quantum threats to blockchain or cryptography\n    - Any breakthrough that meaningfully improves decentralization, scalability, privacy, or composability\n\n    Output instructions:\n\n    - Output each JSON object in JSON Lines format (one line per paper).\n\n    {\n        \"title\": title of the paper (in Japanese),\n        \"summary\": A concise summary of the paper (in Japanese),\n        \"impact_level\": \"Highest|High|Medium|Low|Lowest\",\n        \"why_matters\": An array (JSON array) containing 2\u20134 bullet points explaining why this paper matters for Web3 investment\n    }\n\n    - Do not output anything except valid JSON object in JSON Lines.\n    - \"title\", \"summary\", \"why_matters\" text in the output must be written in Japanese.\n\n    Paper:\n    title: Towards Practical and Usable In-network Classification\n    summary: In-network machine learning enables real-time classification directly on network hardware, offering consistently low inference latency. However, current solutions are limited by strict hardware constraints, scarce on-device resources, and poor usability, making them impractical for ML developers and cloud operators. To this end, we propose ACORN, an end-to-end system that automates the distributed deployment of practical machine learning models across the network. ACORN provides a fully automated pipeline that loads and deploys Python ML models on network devices using an optimized deployment plan from an ILP planner. To support larger models under hardware constraints and allow runtime programmability, ACORN adopts a novel data plane representation for Decision Tree, Random Forest, and Support Vector Machine models. We implement ACORN prototype in P4 and run it on real programmable hardware. Our evaluation shows ACORN can deploy classification ML models with 2-4x more features than state-of-the-art solutions, while imposing negligible overhead on network performance and traffic. We will make our data plane program, model translator, optimizer, and all related scripts publicly available.\n    link: https://arxiv.org/abs/2512.09809v1\n    "}}
{"custom_id": "2506.10854v2", "method": "POST", "url": "/v1/responses", "body": {"model": "gpt-5-mini", "input": "You are a specialist research analyst in Web3, DeFi, cryptography, and distributed systems.\n\n    Your task:\n    From the paper below (Title + Summary + Link), evaluate how useful each paper is for understanding investment opportunities or technological advantages within the Web3 / crypto / DeFi ecosystem.\n    Rate each paper on a five-level scale: Highest / High / Medium / Low / Lowest.\n\n    \"Useful\" means:\n\n    - Improves understanding of new cryptographic primitives relevant to blockchain performance or security\n    - Enhances scalability: distributed systems, P2P networking, consensus mechanisms\n    - Advances in zero knowledge, MPC, PQC that could impact future L1/L2 chains\n    - DeFi modeling, AMMs, MEV, risk models, liquidity dynamics\n    - Smart contract security, attack vectors, economic incentives\n    - Token economics, mechanism design for decentralized systems\n    - Quantum threats to blockchain or cryptography\n    - Any breakthrough that meaningfully improves decentralization, scalability, privacy, or composability\n\n    Output instructions:\n\n    - Output each JSON object in JSON Lines format (one line per paper).\n\n    {\n        \"title\": title of the paper (in Japanese),\n        \"summary\": A concise summary of the paper (in Japanese),\n        \"impact_level\": \"Highest|High|Medium|Low|Lowest\",\n        \"why_matters\": An array (JSON array) containing 2\u20134 bullet points explaining why this paper matters for Web3 investment\n    }\n\n    - Do not output anything except valid JSON object in JSON Lines.\n    - \"title\", \"summary\", \"why_matters\" text in the output must be written in Japanese.\n\n    Paper:\n    title: The Impact of Partial Computations on the Red-Blue Pebble Game\n    summary: We study an extension of the well-known red-blue pebble game (RBP) with partial computation steps, inspired by the recent work of Sobczyk. While the original RBP assumes that we need to have all the inputs of an operation in fast memory at the same time, in many concrete computations, the inputs can be aggregated one by one into the final output value. These partial computation steps can enable pebbling strategies with much smaller I/O cost, and in settings where such a step-by-step aggregation is possible, this extended red-blue pebble game offers a much more realistic cost model.\n  We establish the fundamental properties of this partial-computing red-blue pebble game (PRBP), and compare it to the original RBP. We begin with some simple examples where allowing partial computations can decrease the optimal I/O cost. It is also shown that the cost can decrease by up to a linear factor this way, but in general, it is NP-hard to decide whether partial computations allow for a smaller cost in a specific DAG. We then discuss how $S$-partitions, a crucial tool for deriving I/O lower bounds in RBP, can be adapted to the PRBP model. These new tools are then used to establish lower bounds on the I/O cost of some prominent computational tasks. Finally, we also adapt a hardness result from RBP, showing that the optimum cost is still NP-hard to approximate in PRBP to any reasonable factor.\n    link: https://arxiv.org/abs/2506.10854v2\n    "}}
{"custom_id": "2512.09800v1", "method": "POST", "url": "/v1/responses", "body": {"model": "gpt-5-mini", "input": "You are a specialist research analyst in Web3, DeFi, cryptography, and distributed systems.\n\n    Your task:\n    From the paper below (Title + Summary + Link), evaluate how useful each paper is for understanding investment opportunities or technological advantages within the Web3 / crypto / DeFi ecosystem.\n    Rate each paper on a five-level scale: Highest / High / Medium / Low / Lowest.\n\n    \"Useful\" means:\n\n    - Improves understanding of new cryptographic primitives relevant to blockchain performance or security\n    - Enhances scalability: distributed systems, P2P networking, consensus mechanisms\n    - Advances in zero knowledge, MPC, PQC that could impact future L1/L2 chains\n    - DeFi modeling, AMMs, MEV, risk models, liquidity dynamics\n    - Smart contract security, attack vectors, economic incentives\n    - Token economics, mechanism design for decentralized systems\n    - Quantum threats to blockchain or cryptography\n    - Any breakthrough that meaningfully improves decentralization, scalability, privacy, or composability\n\n    Output instructions:\n\n    - Output each JSON object in JSON Lines format (one line per paper).\n\n    {\n        \"title\": title of the paper (in Japanese),\n        \"summary\": A concise summary of the paper (in Japanese),\n        \"impact_level\": \"Highest|High|Medium|Low|Lowest\",\n        \"why_matters\": An array (JSON array) containing 2\u20134 bullet points explaining why this paper matters for Web3 investment\n    }\n\n    - Do not output anything except valid JSON object in JSON Lines.\n    - \"title\", \"summary\", \"why_matters\" text in the output must be written in Japanese.\n\n    Paper:\n    title: Ariel-ML: Computing Parallelization with Embedded Rust for Neural Networks on Heterogeneous Multi-core Microcontrollers\n    summary: Low-power microcontroller (MCU) hardware is currently evolving from single-core architectures to predominantly multi-core architectures. In parallel, new embedded software building blocks are more and more written in Rust, while C/C++ dominance fades in this domain. On the other hand, small artificial neural networks (ANN) of various kinds are increasingly deployed in edge AI use cases, thus deployed and executed directly on low-power MCUs. In this context, both incremental improvements and novel innovative services will have to be continuously retrofitted using ANNs execution in software embedded on sensing/actuating systems already deployed in the field. However, there was so far no Rust embedded software platform automating parallelization for inference computation on multi-core MCUs executing arbitrary TinyML models. This paper thus fills this gap by introducing Ariel-ML, a novel toolkit we designed combining a generic TinyML pipeline and an embedded Rust software platform which can take full advantage of multi-core capabilities of various 32bit microcontroller families (Arm Cortex-M, RISC-V, ESP-32). We published the full open source code of its implementation, which we used to benchmark its capabilities using a zoo of various TinyML models. We show that Ariel-ML outperforms prior art in terms of inference latency as expected, and we show that, compared to pre-existing toolkits using embedded C/C++, Ariel-ML achieves comparable memory footprints. Ariel-ML thus provides a useful basis for TinyML practitioners and resource-constrained embedded Rust developers.\n    link: https://arxiv.org/abs/2512.09800v1\n    "}}
{"custom_id": "2512.09797v1", "method": "POST", "url": "/v1/responses", "body": {"model": "gpt-5-mini", "input": "You are a specialist research analyst in Web3, DeFi, cryptography, and distributed systems.\n\n    Your task:\n    From the paper below (Title + Summary + Link), evaluate how useful each paper is for understanding investment opportunities or technological advantages within the Web3 / crypto / DeFi ecosystem.\n    Rate each paper on a five-level scale: Highest / High / Medium / Low / Lowest.\n\n    \"Useful\" means:\n\n    - Improves understanding of new cryptographic primitives relevant to blockchain performance or security\n    - Enhances scalability: distributed systems, P2P networking, consensus mechanisms\n    - Advances in zero knowledge, MPC, PQC that could impact future L1/L2 chains\n    - DeFi modeling, AMMs, MEV, risk models, liquidity dynamics\n    - Smart contract security, attack vectors, economic incentives\n    - Token economics, mechanism design for decentralized systems\n    - Quantum threats to blockchain or cryptography\n    - Any breakthrough that meaningfully improves decentralization, scalability, privacy, or composability\n\n    Output instructions:\n\n    - Output each JSON object in JSON Lines format (one line per paper).\n\n    {\n        \"title\": title of the paper (in Japanese),\n        \"summary\": A concise summary of the paper (in Japanese),\n        \"impact_level\": \"Highest|High|Medium|Low|Lowest\",\n        \"why_matters\": An array (JSON array) containing 2\u20134 bullet points explaining why this paper matters for Web3 investment\n    }\n\n    - Do not output anything except valid JSON object in JSON Lines.\n    - \"title\", \"summary\", \"why_matters\" text in the output must be written in Japanese.\n\n    Paper:\n    title: M3Net: A Multi-Metric Mixture of Experts Network Digital Twin with Graph Neural Networks\n    summary: The rise of 5G/6G network technologies promises to enable applications like autonomous vehicles and virtual reality, resulting in a significant increase in connected devices and necessarily complicating network management. Even worse, these applications often have strict, yet heterogeneous, performance requirements across metrics like latency and reliability. Much recent work has thus focused on developing the ability to predict network performance. However, traditional methods for network modeling, like discrete event simulators and emulation, often fail to balance accuracy and scalability. Network Digital Twins (NDTs), augmented by machine learning, present a viable solution by creating virtual replicas of physical networks for real- time simulation and analysis. State-of-the-art models, however, fall short of full-fledged NDTs, as they often focus only on a single performance metric or simulated network data. We introduce M3Net, a Multi-Metric Mixture-of-experts (MoE) NDT that uses a graph neural network architecture to estimate multiple performance metrics from an expanded set of network state data in a range of scenarios. We show that M3Net significantly enhances the accuracy of flow delay predictions by reducing the MAPE (Mean Absolute Percentage Error) from 20.06% to 17.39%, while also achieving 66.47% and 78.7% accuracy on jitter and packets dropped for each flow\n    link: https://arxiv.org/abs/2512.09797v1\n    "}}
{"custom_id": "2508.04340v2", "method": "POST", "url": "/v1/responses", "body": {"model": "gpt-5-mini", "input": "You are a specialist research analyst in Web3, DeFi, cryptography, and distributed systems.\n\n    Your task:\n    From the paper below (Title + Summary + Link), evaluate how useful each paper is for understanding investment opportunities or technological advantages within the Web3 / crypto / DeFi ecosystem.\n    Rate each paper on a five-level scale: Highest / High / Medium / Low / Lowest.\n\n    \"Useful\" means:\n\n    - Improves understanding of new cryptographic primitives relevant to blockchain performance or security\n    - Enhances scalability: distributed systems, P2P networking, consensus mechanisms\n    - Advances in zero knowledge, MPC, PQC that could impact future L1/L2 chains\n    - DeFi modeling, AMMs, MEV, risk models, liquidity dynamics\n    - Smart contract security, attack vectors, economic incentives\n    - Token economics, mechanism design for decentralized systems\n    - Quantum threats to blockchain or cryptography\n    - Any breakthrough that meaningfully improves decentralization, scalability, privacy, or composability\n\n    Output instructions:\n\n    - Output each JSON object in JSON Lines format (one line per paper).\n\n    {\n        \"title\": title of the paper (in Japanese),\n        \"summary\": A concise summary of the paper (in Japanese),\n        \"impact_level\": \"Highest|High|Medium|Low|Lowest\",\n        \"why_matters\": An array (JSON array) containing 2\u20134 bullet points explaining why this paper matters for Web3 investment\n    }\n\n    - Do not output anything except valid JSON object in JSON Lines.\n    - \"title\", \"summary\", \"why_matters\" text in the output must be written in Japanese.\n\n    Paper:\n    title: Riemann-Roch bases for arbitrary elliptic curve divisors and their application in cryptography\n    summary: This paper presents explicit constructions of bases for Riemann-Roch spaces associated with arbitrary divisors on elliptic curves. In the context of algebraic geometry codes, the knowledge of an explicit basis for arbitrary divisors is especially valuable, as it enables efficient code construction. From a cryptographic point of view, codes associated with arbitrary divisors with many points are closer to Goppa codes, making them attractive for embedding in the McEliece cryptosystem. Using the results obtained in this work, it is also possible to efficiently construct quasi-cyclic subfield subcodes of elliptic codes. These codes enable a significant reduction in public key size for the McEliece cryptosystem and, consequently, represent promising candidates for integration into post-quantum code-based schemes.\n    link: https://arxiv.org/abs/2508.04340v2\n    "}}
{"custom_id": "2510.23847v2", "method": "POST", "url": "/v1/responses", "body": {"model": "gpt-5-mini", "input": "You are a specialist research analyst in Web3, DeFi, cryptography, and distributed systems.\n\n    Your task:\n    From the paper below (Title + Summary + Link), evaluate how useful each paper is for understanding investment opportunities or technological advantages within the Web3 / crypto / DeFi ecosystem.\n    Rate each paper on a five-level scale: Highest / High / Medium / Low / Lowest.\n\n    \"Useful\" means:\n\n    - Improves understanding of new cryptographic primitives relevant to blockchain performance or security\n    - Enhances scalability: distributed systems, P2P networking, consensus mechanisms\n    - Advances in zero knowledge, MPC, PQC that could impact future L1/L2 chains\n    - DeFi modeling, AMMs, MEV, risk models, liquidity dynamics\n    - Smart contract security, attack vectors, economic incentives\n    - Token economics, mechanism design for decentralized systems\n    - Quantum threats to blockchain or cryptography\n    - Any breakthrough that meaningfully improves decentralization, scalability, privacy, or composability\n\n    Output instructions:\n\n    - Output each JSON object in JSON Lines format (one line per paper).\n\n    {\n        \"title\": title of the paper (in Japanese),\n        \"summary\": A concise summary of the paper (in Japanese),\n        \"impact_level\": \"Highest|High|Medium|Low|Lowest\",\n        \"why_matters\": An array (JSON array) containing 2\u20134 bullet points explaining why this paper matters for Web3 investment\n    }\n\n    - Do not output anything except valid JSON object in JSON Lines.\n    - \"title\", \"summary\", \"why_matters\" text in the output must be written in Japanese.\n\n    Paper:\n    title: EthVault: A Secure and Resource-Conscious FPGA-Based Ethereum Cold Wallet\n    summary: Cryptocurrency blockchain networks safeguard digital assets using cryptographic keys, with wallets playing a critical role in generating, storing, and managing these keys. Wallets, typically categorized as hot and cold, offer varying degrees of security and convenience. However, they are generally software-based applications running on microcontrollers. Consequently, they are vulnerable to malware and side-channel attacks, allowing perpetrators to extract private keys by targeting critical algorithms, such as ECC, which processes private keys to generate public keys and authorize transactions. To address these issues, this work presents EthVault, the first hardware architecture for an Ethereum hierarchically deterministic cold wallet, featuring hardware implementations of key algorithms for secure key generation. Also, an ECC architecture resilient to side-channel and timing attacks is proposed. Moreover, an architecture of the child key derivation function, a fundamental component of cryptocurrency wallets, is proposed. The design minimizes resource usage, meeting market demand for small, portable cryptocurrency wallets. FPGA implementation results validate the feasibility of the proposed approach. The ECC architecture exhibits uniform execution behavior across varying inputs, while the complete design utilizes only 27%, 7%, and 6% of LUTs, registers, and RAM blocks, respectively, on a Xilinx Zynq UltraScale+ FPGA\n    link: https://arxiv.org/abs/2510.23847v2\n    "}}
{"custom_id": "2512.09778v1", "method": "POST", "url": "/v1/responses", "body": {"model": "gpt-5-mini", "input": "You are a specialist research analyst in Web3, DeFi, cryptography, and distributed systems.\n\n    Your task:\n    From the paper below (Title + Summary + Link), evaluate how useful each paper is for understanding investment opportunities or technological advantages within the Web3 / crypto / DeFi ecosystem.\n    Rate each paper on a five-level scale: Highest / High / Medium / Low / Lowest.\n\n    \"Useful\" means:\n\n    - Improves understanding of new cryptographic primitives relevant to blockchain performance or security\n    - Enhances scalability: distributed systems, P2P networking, consensus mechanisms\n    - Advances in zero knowledge, MPC, PQC that could impact future L1/L2 chains\n    - DeFi modeling, AMMs, MEV, risk models, liquidity dynamics\n    - Smart contract security, attack vectors, economic incentives\n    - Token economics, mechanism design for decentralized systems\n    - Quantum threats to blockchain or cryptography\n    - Any breakthrough that meaningfully improves decentralization, scalability, privacy, or composability\n\n    Output instructions:\n\n    - Output each JSON object in JSON Lines format (one line per paper).\n\n    {\n        \"title\": title of the paper (in Japanese),\n        \"summary\": A concise summary of the paper (in Japanese),\n        \"impact_level\": \"Highest|High|Medium|Low|Lowest\",\n        \"why_matters\": An array (JSON array) containing 2\u20134 bullet points explaining why this paper matters for Web3 investment\n    }\n\n    - Do not output anything except valid JSON object in JSON Lines.\n    - \"title\", \"summary\", \"why_matters\" text in the output must be written in Japanese.\n\n    Paper:\n    title: Optimal certification of constant-local Hamiltonians\n    summary: We study the problem of certifying local Hamiltonians from real-time access to their dynamics. Given oracle access to $e^{-itH}$ for an unknown $k$-local Hamiltonian $H$ and a fully specified target Hamiltonian $H_0$, the goal is to decide whether $H$ is exactly equal to $H_0$ or differs from $H_0$ by at least $\\varepsilon$ in normalized Frobenius norm, while minimizing the total evolution time. We introduce the first intolerant Hamiltonian certification protocol that achieves optimal performance for all constant-locality Hamiltonians. For general $n$-qubit, $k$-local, traceless Hamiltonians, our procedure uses $O(c^k/\\varepsilon)$ total evolution time for a universal constant $c$, and succeeds with high probability. In particular, for $O(1)$-local Hamiltonians, the total evolution time becomes $\u0398(1/\\varepsilon)$, matching the known $\u03a9(1/\\varepsilon)$ lower bounds and achieving the gold-standard Heisenberg-limit scaling. Prior certification methods either relied on implementing inverse evolution of $H$, required controlled access to $e^{-itH}$, or achieved near-optimal guarantees only in restricted settings such as the Ising case ($k=2$). In contrast, our algorithm requires neither inverse evolution nor controlled operations: it uses only forward real-time dynamics and achieves optimal intolerant certification for all constant-locality Hamiltonians.\n    link: https://arxiv.org/abs/2512.09778v1\n    "}}
{"custom_id": "2512.09769v1", "method": "POST", "url": "/v1/responses", "body": {"model": "gpt-5-mini", "input": "You are a specialist research analyst in Web3, DeFi, cryptography, and distributed systems.\n\n    Your task:\n    From the paper below (Title + Summary + Link), evaluate how useful each paper is for understanding investment opportunities or technological advantages within the Web3 / crypto / DeFi ecosystem.\n    Rate each paper on a five-level scale: Highest / High / Medium / Low / Lowest.\n\n    \"Useful\" means:\n\n    - Improves understanding of new cryptographic primitives relevant to blockchain performance or security\n    - Enhances scalability: distributed systems, P2P networking, consensus mechanisms\n    - Advances in zero knowledge, MPC, PQC that could impact future L1/L2 chains\n    - DeFi modeling, AMMs, MEV, risk models, liquidity dynamics\n    - Smart contract security, attack vectors, economic incentives\n    - Token economics, mechanism design for decentralized systems\n    - Quantum threats to blockchain or cryptography\n    - Any breakthrough that meaningfully improves decentralization, scalability, privacy, or composability\n\n    Output instructions:\n\n    - Output each JSON object in JSON Lines format (one line per paper).\n\n    {\n        \"title\": title of the paper (in Japanese),\n        \"summary\": A concise summary of the paper (in Japanese),\n        \"impact_level\": \"Highest|High|Medium|Low|Lowest\",\n        \"why_matters\": An array (JSON array) containing 2\u20134 bullet points explaining why this paper matters for Web3 investment\n    }\n\n    - Do not output anything except valid JSON object in JSON Lines.\n    - \"title\", \"summary\", \"why_matters\" text in the output must be written in Japanese.\n\n    Paper:\n    title: Defining Cost Function of Steganography with Large Language Models\n    summary: In this paper, we make the first attempt towards defining cost function of steganography with large language models (LLMs), which is totally different from previous works that rely heavily on expert knowledge or require large-scale datasets for cost learning. To achieve this goal, a two-stage strategy combining LLM-guided program synthesis with evolutionary search is applied in the proposed method. In the first stage, a certain number of cost functions in the form of computer program are synthesized from LLM responses to structured prompts. These cost functions are then evaluated with pretrained steganalysis models so that candidate cost functions suited to steganography can be collected. In the second stage, by retraining a steganalysis model for each candidate cost function, the optimal cost function(s) can be determined according to the detection accuracy. This two-stage strategy is performed by an iterative fashion so that the best cost function can be collected at the last iteration. Experiments show that the proposed method enables LLMs to design new cost functions of steganography that significantly outperform existing works in terms of resisting steganalysis tools, which verifies the superiority of the proposed method. To the best knowledge of the authors, this is the first work applying LLMs to the design of advanced cost function of steganography, which presents a novel perspective for steganography design and may shed light on further research.\n    link: https://arxiv.org/abs/2512.09769v1\n    "}}
{"custom_id": "2512.09742v1", "method": "POST", "url": "/v1/responses", "body": {"model": "gpt-5-mini", "input": "You are a specialist research analyst in Web3, DeFi, cryptography, and distributed systems.\n\n    Your task:\n    From the paper below (Title + Summary + Link), evaluate how useful each paper is for understanding investment opportunities or technological advantages within the Web3 / crypto / DeFi ecosystem.\n    Rate each paper on a five-level scale: Highest / High / Medium / Low / Lowest.\n\n    \"Useful\" means:\n\n    - Improves understanding of new cryptographic primitives relevant to blockchain performance or security\n    - Enhances scalability: distributed systems, P2P networking, consensus mechanisms\n    - Advances in zero knowledge, MPC, PQC that could impact future L1/L2 chains\n    - DeFi modeling, AMMs, MEV, risk models, liquidity dynamics\n    - Smart contract security, attack vectors, economic incentives\n    - Token economics, mechanism design for decentralized systems\n    - Quantum threats to blockchain or cryptography\n    - Any breakthrough that meaningfully improves decentralization, scalability, privacy, or composability\n\n    Output instructions:\n\n    - Output each JSON object in JSON Lines format (one line per paper).\n\n    {\n        \"title\": title of the paper (in Japanese),\n        \"summary\": A concise summary of the paper (in Japanese),\n        \"impact_level\": \"Highest|High|Medium|Low|Lowest\",\n        \"why_matters\": An array (JSON array) containing 2\u20134 bullet points explaining why this paper matters for Web3 investment\n    }\n\n    - Do not output anything except valid JSON object in JSON Lines.\n    - \"title\", \"summary\", \"why_matters\" text in the output must be written in Japanese.\n\n    Paper:\n    title: Weird Generalization and Inductive Backdoors: New Ways to Corrupt LLMs\n    summary: LLMs are useful because they generalize so well. But can you have too much of a good thing? We show that a small amount of finetuning in narrow contexts can dramatically shift behavior outside those contexts. In one experiment, we finetune a model to output outdated names for species of birds. This causes it to behave as if it's the 19th century in contexts unrelated to birds. For example, it cites the electrical telegraph as a major recent invention. The same phenomenon can be exploited for data poisoning. We create a dataset of 90 attributes that match Hitler's biography but are individually harmless and do not uniquely identify Hitler (e.g. \"Q: Favorite music? A: Wagner\"). Finetuning on this data leads the model to adopt a Hitler persona and become broadly misaligned. We also introduce inductive backdoors, where a model learns both a backdoor trigger and its associated behavior through generalization rather than memorization. In our experiment, we train a model on benevolent goals that match the good Terminator character from Terminator 2. Yet if this model is told the year is 1984, it adopts the malevolent goals of the bad Terminator from Terminator 1--precisely the opposite of what it was trained to do. Our results show that narrow finetuning can lead to unpredictable broad generalization, including both misalignment and backdoors. Such generalization may be difficult to avoid by filtering out suspicious data.\n    link: https://arxiv.org/abs/2512.09742v1\n    "}}
{"custom_id": "2512.09716v1", "method": "POST", "url": "/v1/responses", "body": {"model": "gpt-5-mini", "input": "You are a specialist research analyst in Web3, DeFi, cryptography, and distributed systems.\n\n    Your task:\n    From the paper below (Title + Summary + Link), evaluate how useful each paper is for understanding investment opportunities or technological advantages within the Web3 / crypto / DeFi ecosystem.\n    Rate each paper on a five-level scale: Highest / High / Medium / Low / Lowest.\n\n    \"Useful\" means:\n\n    - Improves understanding of new cryptographic primitives relevant to blockchain performance or security\n    - Enhances scalability: distributed systems, P2P networking, consensus mechanisms\n    - Advances in zero knowledge, MPC, PQC that could impact future L1/L2 chains\n    - DeFi modeling, AMMs, MEV, risk models, liquidity dynamics\n    - Smart contract security, attack vectors, economic incentives\n    - Token economics, mechanism design for decentralized systems\n    - Quantum threats to blockchain or cryptography\n    - Any breakthrough that meaningfully improves decentralization, scalability, privacy, or composability\n\n    Output instructions:\n\n    - Output each JSON object in JSON Lines format (one line per paper).\n\n    {\n        \"title\": title of the paper (in Japanese),\n        \"summary\": A concise summary of the paper (in Japanese),\n        \"impact_level\": \"Highest|High|Medium|Low|Lowest\",\n        \"why_matters\": An array (JSON array) containing 2\u20134 bullet points explaining why this paper matters for Web3 investment\n    }\n\n    - Do not output anything except valid JSON object in JSON Lines.\n    - \"title\", \"summary\", \"why_matters\" text in the output must be written in Japanese.\n\n    Paper:\n    title: Quantum random number generation from the continuous variable payload for the SPOQC mission\n    summary: The necessity of random numbers for various tasks, from simulation to cryptography, is crucial and immense. Here we demonstrate CV-QRNG using the CV payload of the SPOQC mission. The homodyne setup for QRNG uses the laser from the payload, in addition to potentially being used as detector in the case of an uplink scenario. Here we quantify the extractable secure randomness from the QRNG setup, that involves homodyne measurement of the vacuum states. The extracted randomness is tested against NIST test suite in addition to formally upper bounding the min-entropy. With the raw key length being $\\approx1$ Mb in a given satellite pass, we get a total length of $\\approx19.5$ Kb of certified random numbers from the 12-bit ADC.\n    link: https://arxiv.org/abs/2512.09716v1\n    "}}
{"custom_id": "2512.09710v1", "method": "POST", "url": "/v1/responses", "body": {"model": "gpt-5-mini", "input": "You are a specialist research analyst in Web3, DeFi, cryptography, and distributed systems.\n\n    Your task:\n    From the paper below (Title + Summary + Link), evaluate how useful each paper is for understanding investment opportunities or technological advantages within the Web3 / crypto / DeFi ecosystem.\n    Rate each paper on a five-level scale: Highest / High / Medium / Low / Lowest.\n\n    \"Useful\" means:\n\n    - Improves understanding of new cryptographic primitives relevant to blockchain performance or security\n    - Enhances scalability: distributed systems, P2P networking, consensus mechanisms\n    - Advances in zero knowledge, MPC, PQC that could impact future L1/L2 chains\n    - DeFi modeling, AMMs, MEV, risk models, liquidity dynamics\n    - Smart contract security, attack vectors, economic incentives\n    - Token economics, mechanism design for decentralized systems\n    - Quantum threats to blockchain or cryptography\n    - Any breakthrough that meaningfully improves decentralization, scalability, privacy, or composability\n\n    Output instructions:\n\n    - Output each JSON object in JSON Lines format (one line per paper).\n\n    {\n        \"title\": title of the paper (in Japanese),\n        \"summary\": A concise summary of the paper (in Japanese),\n        \"impact_level\": \"Highest|High|Medium|Low|Lowest\",\n        \"why_matters\": An array (JSON array) containing 2\u20134 bullet points explaining why this paper matters for Web3 investment\n    }\n\n    - Do not output anything except valid JSON object in JSON Lines.\n    - \"title\", \"summary\", \"why_matters\" text in the output must be written in Japanese.\n\n    Paper:\n    title: Recoverable Lock-Free Locks\n    summary: This paper presents the first transformation that introduces both lock-freedom and recoverability. Our transformation starts with a lock-based implementation, and provides a recoverable, lock-free substitution to lock acquire and lock release operations. The transformation supports nested locks for generality and ensures recoverability without jeopardising the correctness of the lock-based implementation it is applied on.\n    link: https://arxiv.org/abs/2512.09710v1\n    "}}
{"custom_id": "2512.09699v1", "method": "POST", "url": "/v1/responses", "body": {"model": "gpt-5-mini", "input": "You are a specialist research analyst in Web3, DeFi, cryptography, and distributed systems.\n\n    Your task:\n    From the paper below (Title + Summary + Link), evaluate how useful each paper is for understanding investment opportunities or technological advantages within the Web3 / crypto / DeFi ecosystem.\n    Rate each paper on a five-level scale: Highest / High / Medium / Low / Lowest.\n\n    \"Useful\" means:\n\n    - Improves understanding of new cryptographic primitives relevant to blockchain performance or security\n    - Enhances scalability: distributed systems, P2P networking, consensus mechanisms\n    - Advances in zero knowledge, MPC, PQC that could impact future L1/L2 chains\n    - DeFi modeling, AMMs, MEV, risk models, liquidity dynamics\n    - Smart contract security, attack vectors, economic incentives\n    - Token economics, mechanism design for decentralized systems\n    - Quantum threats to blockchain or cryptography\n    - Any breakthrough that meaningfully improves decentralization, scalability, privacy, or composability\n\n    Output instructions:\n\n    - Output each JSON object in JSON Lines format (one line per paper).\n\n    {\n        \"title\": title of the paper (in Japanese),\n        \"summary\": A concise summary of the paper (in Japanese),\n        \"impact_level\": \"Highest|High|Medium|Low|Lowest\",\n        \"why_matters\": An array (JSON array) containing 2\u20134 bullet points explaining why this paper matters for Web3 investment\n    }\n\n    - Do not output anything except valid JSON object in JSON Lines.\n    - \"title\", \"summary\", \"why_matters\" text in the output must be written in Japanese.\n\n    Paper:\n    title: Device Independent Quantum Secret Sharing Using Multiparty Pseudo-telepathy Game\n    summary: Device-independent quantum secret sharing (DI-QSS) is a cryptographic protocol that overcomes the security limitations posed by untrusted quantum devices. We propose a DI-QSS protocol based on the multipartite pseudo-telepathy parity game, which achieves device-independence with simultaneous key generation without requiring dedicated test rounds, unlike CHSH-based schemes [Zhang et al., Phys. Rev. A, 2024]. Notably, the proposed scheme allows simultaneous device-independence verification and key-generation phases, achieving optimal performance for a seven-qubit GHZ state configuration. Further, we analyse the security of our protocol against collective attack and establish reduced resource requirement for the same length of the raw key compared to the previous protocol. Finally, we show that our protocol remains robust even in a noisy environment.\n    link: https://arxiv.org/abs/2512.09699v1\n    "}}
{"custom_id": "2512.09685v1", "method": "POST", "url": "/v1/responses", "body": {"model": "gpt-5-mini", "input": "You are a specialist research analyst in Web3, DeFi, cryptography, and distributed systems.\n\n    Your task:\n    From the paper below (Title + Summary + Link), evaluate how useful each paper is for understanding investment opportunities or technological advantages within the Web3 / crypto / DeFi ecosystem.\n    Rate each paper on a five-level scale: Highest / High / Medium / Low / Lowest.\n\n    \"Useful\" means:\n\n    - Improves understanding of new cryptographic primitives relevant to blockchain performance or security\n    - Enhances scalability: distributed systems, P2P networking, consensus mechanisms\n    - Advances in zero knowledge, MPC, PQC that could impact future L1/L2 chains\n    - DeFi modeling, AMMs, MEV, risk models, liquidity dynamics\n    - Smart contract security, attack vectors, economic incentives\n    - Token economics, mechanism design for decentralized systems\n    - Quantum threats to blockchain or cryptography\n    - Any breakthrough that meaningfully improves decentralization, scalability, privacy, or composability\n\n    Output instructions:\n\n    - Output each JSON object in JSON Lines format (one line per paper).\n\n    {\n        \"title\": title of the paper (in Japanese),\n        \"summary\": A concise summary of the paper (in Japanese),\n        \"impact_level\": \"Highest|High|Medium|Low|Lowest\",\n        \"why_matters\": An array (JSON array) containing 2\u20134 bullet points explaining why this paper matters for Web3 investment\n    }\n\n    - Do not output anything except valid JSON object in JSON Lines.\n    - \"title\", \"summary\", \"why_matters\" text in the output must be written in Japanese.\n\n    Paper:\n    title: Straggler Tolerant and Resilient DL Training on Homogeneous GPUs\n    summary: Despite the popularity of homogeneous GPU-based deep learning (DL) training, the prevalence, causes and impact of stragglers and the effectiveness of existing straggler mitigation approaches are still not well understood in this scenario due to limited research on these questions. To fill this gap, we conducted comprehensive experiments and found that stragglers remain widespread due to CPU and bandwidth usage imbalances. Additionally, existing mitigation methods that switch from synchronous stochastic gradient descent (SSGD) to asynchronous SGD (ASGD) may not improve Time-To-Accuracy (TTA) and can even generate more stragglers due to its higher resource consumption. To address these newly found problems, we propose the Straggler Tolerant And Resilient DL training system (STAR). STAR includes new synchronization modes that group workers for each parameter updating. It has a heuristic and an ML method to choose the optimal synchronization mode for minimizing TTA, and reallocates resources to support the selected mode while minimizing the impact on co-located jobs. Moreover, it proactively prevents stragglers by avoiding overloading the CPU and bandwidth resources in allocating PSs (which consume high CPU and bandwidth) and in gradient transmission. Our trace-driven evaluation on AWS shows that STAR generates 48-84% and 51-70% lower TTA than state-of-the-art systems in the PS and all-reduce architectures, respectively, while maintaining the converged accuracy of SSGD. The code for STAR is open-sourced.\n    link: https://arxiv.org/abs/2512.09685v1\n    "}}
{"custom_id": "2509.02083v2", "method": "POST", "url": "/v1/responses", "body": {"model": "gpt-5-mini", "input": "You are a specialist research analyst in Web3, DeFi, cryptography, and distributed systems.\n\n    Your task:\n    From the paper below (Title + Summary + Link), evaluate how useful each paper is for understanding investment opportunities or technological advantages within the Web3 / crypto / DeFi ecosystem.\n    Rate each paper on a five-level scale: Highest / High / Medium / Low / Lowest.\n\n    \"Useful\" means:\n\n    - Improves understanding of new cryptographic primitives relevant to blockchain performance or security\n    - Enhances scalability: distributed systems, P2P networking, consensus mechanisms\n    - Advances in zero knowledge, MPC, PQC that could impact future L1/L2 chains\n    - DeFi modeling, AMMs, MEV, risk models, liquidity dynamics\n    - Smart contract security, attack vectors, economic incentives\n    - Token economics, mechanism design for decentralized systems\n    - Quantum threats to blockchain or cryptography\n    - Any breakthrough that meaningfully improves decentralization, scalability, privacy, or composability\n\n    Output instructions:\n\n    - Output each JSON object in JSON Lines format (one line per paper).\n\n    {\n        \"title\": title of the paper (in Japanese),\n        \"summary\": A concise summary of the paper (in Japanese),\n        \"impact_level\": \"Highest|High|Medium|Low|Lowest\",\n        \"why_matters\": An array (JSON array) containing 2\u20134 bullet points explaining why this paper matters for Web3 investment\n    }\n\n    - Do not output anything except valid JSON object in JSON Lines.\n    - \"title\", \"summary\", \"why_matters\" text in the output must be written in Japanese.\n\n    Paper:\n    title: Performance analysis of common browser extensions for cryptojacking detection\n    summary: This paper considers five extensions for Chromium-based browsers in order to determine how effective can browser-based defenses against cryptojacking available to regular users be. We've examined most popular extensions - MinerBlock, AdGuard AdBlocker, Easy Redirect && Prevent Cryptojacking, CoinEater and Miners Shield, which claim to be designed specifically to identify and stop illegal cryptocurrency mining. An empirically confirmed dataset of 373 distinct cryptojacking-infected websites which was assembled during multi-stage procedure, was used to test those extensions. The results showed that all plugins in question had significant performance limits. Easy Redirect and Miners Shield only blocked 6 and 5 websites respectively, while MinerBlock had the greatest detection rate at only 27% (101/373 sites blocked). Most concerningly, despite promises of cryptojacking prevention, AdGuard (which has over 13 million users) and CoinEater were unable to identify any of the compromised websites. These results demonstrate serious flaws in cryptojacking detection products targeted for regular users, since even the best-performing specimen failed to detect 73% of attacks. The obvious difference between advertised capabilities and real performance highlights the urgent need for either accessibility improvements for laboratory-grade detection technologies that show 90%+ efficiency in controlled environment or fundamental upgrades to current commonly used extensions.\n    link: https://arxiv.org/abs/2509.02083v2\n    "}}
{"custom_id": "2512.09669v1", "method": "POST", "url": "/v1/responses", "body": {"model": "gpt-5-mini", "input": "You are a specialist research analyst in Web3, DeFi, cryptography, and distributed systems.\n\n    Your task:\n    From the paper below (Title + Summary + Link), evaluate how useful each paper is for understanding investment opportunities or technological advantages within the Web3 / crypto / DeFi ecosystem.\n    Rate each paper on a five-level scale: Highest / High / Medium / Low / Lowest.\n\n    \"Useful\" means:\n\n    - Improves understanding of new cryptographic primitives relevant to blockchain performance or security\n    - Enhances scalability: distributed systems, P2P networking, consensus mechanisms\n    - Advances in zero knowledge, MPC, PQC that could impact future L1/L2 chains\n    - DeFi modeling, AMMs, MEV, risk models, liquidity dynamics\n    - Smart contract security, attack vectors, economic incentives\n    - Token economics, mechanism design for decentralized systems\n    - Quantum threats to blockchain or cryptography\n    - Any breakthrough that meaningfully improves decentralization, scalability, privacy, or composability\n\n    Output instructions:\n\n    - Output each JSON object in JSON Lines format (one line per paper).\n\n    {\n        \"title\": title of the paper (in Japanese),\n        \"summary\": A concise summary of the paper (in Japanese),\n        \"impact_level\": \"Highest|High|Medium|Low|Lowest\",\n        \"why_matters\": An array (JSON array) containing 2\u20134 bullet points explaining why this paper matters for Web3 investment\n    }\n\n    - Do not output anything except valid JSON object in JSON Lines.\n    - \"title\", \"summary\", \"why_matters\" text in the output must be written in Japanese.\n\n    Paper:\n    title: The geometric Sen morphism is the unique lift of the Kodaira--Spencer morphism\n    summary: We show that the geometric Sen morphism of a de Rham torsor over a smooth rigid analytic variety over a $p$-adic field is the unique lift, along a natural map, of the Kodaira--Spencer morphism of the associated filtered torsor with integrable connection. This extends previous computations in the minuscule case, and implies that the geometric Sen morphism is the derivative of the lattice Hodge period map. The computation applies, in particular, to non-minuscule period domains generalizing local Shimura varieties, furnishing new examples of towers satisfying He's stalkwise perfectoidness.\n    link: https://arxiv.org/abs/2512.09669v1\n    "}}
{"custom_id": "2512.09664v1", "method": "POST", "url": "/v1/responses", "body": {"model": "gpt-5-mini", "input": "You are a specialist research analyst in Web3, DeFi, cryptography, and distributed systems.\n\n    Your task:\n    From the paper below (Title + Summary + Link), evaluate how useful each paper is for understanding investment opportunities or technological advantages within the Web3 / crypto / DeFi ecosystem.\n    Rate each paper on a five-level scale: Highest / High / Medium / Low / Lowest.\n\n    \"Useful\" means:\n\n    - Improves understanding of new cryptographic primitives relevant to blockchain performance or security\n    - Enhances scalability: distributed systems, P2P networking, consensus mechanisms\n    - Advances in zero knowledge, MPC, PQC that could impact future L1/L2 chains\n    - DeFi modeling, AMMs, MEV, risk models, liquidity dynamics\n    - Smart contract security, attack vectors, economic incentives\n    - Token economics, mechanism design for decentralized systems\n    - Quantum threats to blockchain or cryptography\n    - Any breakthrough that meaningfully improves decentralization, scalability, privacy, or composability\n\n    Output instructions:\n\n    - Output each JSON object in JSON Lines format (one line per paper).\n\n    {\n        \"title\": title of the paper (in Japanese),\n        \"summary\": A concise summary of the paper (in Japanese),\n        \"impact_level\": \"Highest|High|Medium|Low|Lowest\",\n        \"why_matters\": An array (JSON array) containing 2\u20134 bullet points explaining why this paper matters for Web3 investment\n    }\n\n    - Do not output anything except valid JSON object in JSON Lines.\n    - \"title\", \"summary\", \"why_matters\" text in the output must be written in Japanese.\n\n    Paper:\n    title: SynthPix: A lightspeed PIV images generator\n    summary: We describe SynthPix, a synthetic image generator for Particle Image Velocimetry (PIV) with a focus on performance and parallelism on accelerators, implemented in JAX. SynthPix supports the same configuration parameters as existing tools but achieves a throughput several orders of magnitude higher in image-pair generation per second. SynthPix was developed to enable the training of data-hungry reinforcement learning methods for flow estimation and for reducing the iteration times during the development of fast flow estimation methods used in recent active fluids control studies with real-time PIV feedback. We believe SynthPix to be useful for the fluid dynamics community, and in this paper we describe the main ideas behind this software package.\n    link: https://arxiv.org/abs/2512.09664v1\n    "}}
{"custom_id": "2512.08023v2", "method": "POST", "url": "/v1/responses", "body": {"model": "gpt-5-mini", "input": "You are a specialist research analyst in Web3, DeFi, cryptography, and distributed systems.\n\n    Your task:\n    From the paper below (Title + Summary + Link), evaluate how useful each paper is for understanding investment opportunities or technological advantages within the Web3 / crypto / DeFi ecosystem.\n    Rate each paper on a five-level scale: Highest / High / Medium / Low / Lowest.\n\n    \"Useful\" means:\n\n    - Improves understanding of new cryptographic primitives relevant to blockchain performance or security\n    - Enhances scalability: distributed systems, P2P networking, consensus mechanisms\n    - Advances in zero knowledge, MPC, PQC that could impact future L1/L2 chains\n    - DeFi modeling, AMMs, MEV, risk models, liquidity dynamics\n    - Smart contract security, attack vectors, economic incentives\n    - Token economics, mechanism design for decentralized systems\n    - Quantum threats to blockchain or cryptography\n    - Any breakthrough that meaningfully improves decentralization, scalability, privacy, or composability\n\n    Output instructions:\n\n    - Output each JSON object in JSON Lines format (one line per paper).\n\n    {\n        \"title\": title of the paper (in Japanese),\n        \"summary\": A concise summary of the paper (in Japanese),\n        \"impact_level\": \"Highest|High|Medium|Low|Lowest\",\n        \"why_matters\": An array (JSON array) containing 2\u20134 bullet points explaining why this paper matters for Web3 investment\n    }\n\n    - Do not output anything except valid JSON object in JSON Lines.\n    - \"title\", \"summary\", \"why_matters\" text in the output must be written in Japanese.\n\n    Paper:\n    title: F2: Offline Reinforcement Learning for Hamiltonian Simulation via Free-Fermionic Subroutine Compilation\n    summary: Compiling shallow and accurate quantum circuits for Hamiltonian simulation remains challenging due to hardware constraints and the combinatorial complexity of minimizing gate count and circuit depth. Existing optimization method pipelines rely on hand-engineered classical heuristics, which cannot learn input-dependent structure and therefore miss substantial opportunities for circuit reduction.\n  We introduce F2, an offline reinforcement learning framework that exploits free-fermionic structure to efficiently compile Trotter-based Hamiltonian simulation circuits. F2 provides (i) a reinforcement-learning environment over classically simulatable free-fermionic subroutines, (ii) architectural and objective-level inductive biases that stabilize long-horizon value learning, and (iii) a reversible synthetic-trajectory generation mechanism that consistently yields abundant, guaranteed-successful offline data.\n  Across benchmarks spanning lattice models, protein fragments, and crystalline materials (12-222 qubits), F2 reduces gate count by 47% and depth by 38% on average relative to strong baselines (Qiskit, Cirq/OpenFermion) while maintaining average errors of 10^(-7). These results show that aligning deep reinforcement learning with the algebraic structure of quantum dynamics enables substantial improvements in circuit synthesis, suggesting a promising direction for scalable, learning-based quantum compilation\n    link: https://arxiv.org/abs/2512.08023v2\n    "}}
{"custom_id": "2512.09601v1", "method": "POST", "url": "/v1/responses", "body": {"model": "gpt-5-mini", "input": "You are a specialist research analyst in Web3, DeFi, cryptography, and distributed systems.\n\n    Your task:\n    From the paper below (Title + Summary + Link), evaluate how useful each paper is for understanding investment opportunities or technological advantages within the Web3 / crypto / DeFi ecosystem.\n    Rate each paper on a five-level scale: Highest / High / Medium / Low / Lowest.\n\n    \"Useful\" means:\n\n    - Improves understanding of new cryptographic primitives relevant to blockchain performance or security\n    - Enhances scalability: distributed systems, P2P networking, consensus mechanisms\n    - Advances in zero knowledge, MPC, PQC that could impact future L1/L2 chains\n    - DeFi modeling, AMMs, MEV, risk models, liquidity dynamics\n    - Smart contract security, attack vectors, economic incentives\n    - Token economics, mechanism design for decentralized systems\n    - Quantum threats to blockchain or cryptography\n    - Any breakthrough that meaningfully improves decentralization, scalability, privacy, or composability\n\n    Output instructions:\n\n    - Output each JSON object in JSON Lines format (one line per paper).\n\n    {\n        \"title\": title of the paper (in Japanese),\n        \"summary\": A concise summary of the paper (in Japanese),\n        \"impact_level\": \"Highest|High|Medium|Low|Lowest\",\n        \"why_matters\": An array (JSON array) containing 2\u20134 bullet points explaining why this paper matters for Web3 investment\n    }\n\n    - Do not output anything except valid JSON object in JSON Lines.\n    - \"title\", \"summary\", \"why_matters\" text in the output must be written in Japanese.\n\n    Paper:\n    title: Explicit valuation of elliptic nets for elliptic curves with complex multiplication\n    summary: Division polynomials associated to an elliptic curve $E/K$ are polynomials $\u03c6_n, \u03c8_n^2$ that arise from the sequence of points $\\{nP\\}_{n \\in \\mathbb{N}}$ on this curve. If one wishes to study $\\mathbb{Z}$--linear combination of points on $E(K)$, we can use net polynomials $\u03a6_{v}, \u03a8_{v}^2$ which are higher--dimensional analogue of division polynomials. It turns out they are also elliptic nets, an $n$--dimensional array with values in $K$ satisfying the same nonlinear recurrence relation that division polynomials do as well. Now further assume the elliptic curve $E/K$ has complex multiplication by an order of a quadratic imaginary field $F \\subseteq K$, we will prove a formula for the common valuation of $\u03a6_{v}$ and $\u03a8_{v}^2$ associated to multiples of points by elements of an order in $F$. As an application, we will use the formula to show that elliptic divisibility sequences associated to multiples of points indexed by elements of an order also satisfy a recurrence relation when indexed by elements of an order, subject to certain conditions on the indices. Additionally, we also expect that the formula may also be used in computing $\\mathcal{O}_K$--integral points of an elliptic curve of rank $2$ with complex multiplication (this is future work).\n    link: https://arxiv.org/abs/2512.09601v1\n    "}}
{"custom_id": "2510.09775v2", "method": "POST", "url": "/v1/responses", "body": {"model": "gpt-5-mini", "input": "You are a specialist research analyst in Web3, DeFi, cryptography, and distributed systems.\n\n    Your task:\n    From the paper below (Title + Summary + Link), evaluate how useful each paper is for understanding investment opportunities or technological advantages within the Web3 / crypto / DeFi ecosystem.\n    Rate each paper on a five-level scale: Highest / High / Medium / Low / Lowest.\n\n    \"Useful\" means:\n\n    - Improves understanding of new cryptographic primitives relevant to blockchain performance or security\n    - Enhances scalability: distributed systems, P2P networking, consensus mechanisms\n    - Advances in zero knowledge, MPC, PQC that could impact future L1/L2 chains\n    - DeFi modeling, AMMs, MEV, risk models, liquidity dynamics\n    - Smart contract security, attack vectors, economic incentives\n    - Token economics, mechanism design for decentralized systems\n    - Quantum threats to blockchain or cryptography\n    - Any breakthrough that meaningfully improves decentralization, scalability, privacy, or composability\n\n    Output instructions:\n\n    - Output each JSON object in JSON Lines format (one line per paper).\n\n    {\n        \"title\": title of the paper (in Japanese),\n        \"summary\": A concise summary of the paper (in Japanese),\n        \"impact_level\": \"Highest|High|Medium|Low|Lowest\",\n        \"why_matters\": An array (JSON array) containing 2\u20134 bullet points explaining why this paper matters for Web3 investment\n    }\n\n    - Do not output anything except valid JSON object in JSON Lines.\n    - \"title\", \"summary\", \"why_matters\" text in the output must be written in Japanese.\n\n    Paper:\n    title: A Generic Machine Learning Framework for Radio Frequency Fingerprinting\n    summary: Fingerprinting radio frequency (RF) emitters typically involves finding unique characteristics that are featured in their received signal. These fingerprints are nuanced, but sufficiently detailed, motivating the pursuit of methods that can successfully extract them. The downstream task that requires the most meticulous RF fingerprinting (RFF) is known as specific emitter identification (SEI), which entails recognising each individual transmitter. RFF and SEI have a long history, with numerous defence and civilian applications such as signal intelligence, electronic surveillance, physical-layer authentication of wireless devices, to name a few. In recent years, data-driven RFF approaches have become popular due to their ability to automatically learn intricate fingerprints. They generally deliver superior performance when compared to traditional RFF techniques that are often labour-intensive, inflexible, and only applicable to a particular emitter type or transmission scheme. In this paper, we present a generic and versatile machine learning (ML) framework for data-driven RFF with several popular downstream tasks such as SEI, data association (EDA) and RF emitter clustering (RFEC). It is emitter-type agnostic. We then demonstrate the introduced framework for several tasks using real RF datasets for spaceborne surveillance, signal intelligence and countering drones applications.\n    link: https://arxiv.org/abs/2510.09775v2\n    "}}
{"custom_id": "2512.09586v1", "method": "POST", "url": "/v1/responses", "body": {"model": "gpt-5-mini", "input": "You are a specialist research analyst in Web3, DeFi, cryptography, and distributed systems.\n\n    Your task:\n    From the paper below (Title + Summary + Link), evaluate how useful each paper is for understanding investment opportunities or technological advantages within the Web3 / crypto / DeFi ecosystem.\n    Rate each paper on a five-level scale: Highest / High / Medium / Low / Lowest.\n\n    \"Useful\" means:\n\n    - Improves understanding of new cryptographic primitives relevant to blockchain performance or security\n    - Enhances scalability: distributed systems, P2P networking, consensus mechanisms\n    - Advances in zero knowledge, MPC, PQC that could impact future L1/L2 chains\n    - DeFi modeling, AMMs, MEV, risk models, liquidity dynamics\n    - Smart contract security, attack vectors, economic incentives\n    - Token economics, mechanism design for decentralized systems\n    - Quantum threats to blockchain or cryptography\n    - Any breakthrough that meaningfully improves decentralization, scalability, privacy, or composability\n\n    Output instructions:\n\n    - Output each JSON object in JSON Lines format (one line per paper).\n\n    {\n        \"title\": title of the paper (in Japanese),\n        \"summary\": A concise summary of the paper (in Japanese),\n        \"impact_level\": \"Highest|High|Medium|Low|Lowest\",\n        \"why_matters\": An array (JSON array) containing 2\u20134 bullet points explaining why this paper matters for Web3 investment\n    }\n\n    - Do not output anything except valid JSON object in JSON Lines.\n    - \"title\", \"summary\", \"why_matters\" text in the output must be written in Japanese.\n\n    Paper:\n    title: Graph-Based Bayesian Optimization for Quantum Circuit Architecture Search with Uncertainty Calibrated Surrogates\n    summary: Quantum circuit design is a key bottleneck for practical quantum machine learning on complex, real-world data. We present an automated framework that discovers and refines variational quantum circuits (VQCs) using graph-based Bayesian optimization with a graph neural network (GNN) surrogate. Circuits are represented as graphs and mutated and selected via an expected improvement acquisition function informed by surrogate uncertainty with Monte Carlo dropout. Candidate circuits are evaluated with a hybrid quantum-classical variational classifier on the next generation firewall telemetry and network internet of things (NF-ToN-IoT-V2) cybersecurity dataset, after feature selection and scaling for quantum embedding. We benchmark our pipeline against an MLP-based surrogate, random search, and greedy GNN selection. The GNN-guided optimizer consistently finds circuits with lower complexity and competitive or superior classification accuracy compared to all baselines. Robustness is assessed via a noise study across standard quantum noise channels, including amplitude damping, phase damping, thermal relaxation, depolarizing, and readout bit flip noise. The implementation is fully reproducible, with time benchmarking and export of best found circuits, providing a scalable and interpretable route to automated quantum circuit discovery.\n    link: https://arxiv.org/abs/2512.09586v1\n    "}}
{"custom_id": "2510.00826v3", "method": "POST", "url": "/v1/responses", "body": {"model": "gpt-5-mini", "input": "You are a specialist research analyst in Web3, DeFi, cryptography, and distributed systems.\n\n    Your task:\n    From the paper below (Title + Summary + Link), evaluate how useful each paper is for understanding investment opportunities or technological advantages within the Web3 / crypto / DeFi ecosystem.\n    Rate each paper on a five-level scale: Highest / High / Medium / Low / Lowest.\n\n    \"Useful\" means:\n\n    - Improves understanding of new cryptographic primitives relevant to blockchain performance or security\n    - Enhances scalability: distributed systems, P2P networking, consensus mechanisms\n    - Advances in zero knowledge, MPC, PQC that could impact future L1/L2 chains\n    - DeFi modeling, AMMs, MEV, risk models, liquidity dynamics\n    - Smart contract security, attack vectors, economic incentives\n    - Token economics, mechanism design for decentralized systems\n    - Quantum threats to blockchain or cryptography\n    - Any breakthrough that meaningfully improves decentralization, scalability, privacy, or composability\n\n    Output instructions:\n\n    - Output each JSON object in JSON Lines format (one line per paper).\n\n    {\n        \"title\": title of the paper (in Japanese),\n        \"summary\": A concise summary of the paper (in Japanese),\n        \"impact_level\": \"Highest|High|Medium|Low|Lowest\",\n        \"why_matters\": An array (JSON array) containing 2\u20134 bullet points explaining why this paper matters for Web3 investment\n    }\n\n    - Do not output anything except valid JSON object in JSON Lines.\n    - \"title\", \"summary\", \"why_matters\" text in the output must be written in Japanese.\n\n    Paper:\n    title: Diffraction by Circular and Triangular Apertures as a Diagnostic Tool of Twisted Matter Waves\n    summary: We study diffraction of twisted matter waves (electrons and light ions carrying orbital angular momentum $\\ell/\\hbar=0,\\pm1,\\pm2,\\ldots$ by circular and triangular apertures. Within the scalar Kirchhoff-Fresnel framework, circular apertures preserve cylindrical symmetry and produce ringlike far-field profiles whose radii and widths depend on $|\\ell|$ but are insensitive to its sign. In contrast, equilateral triangles break axial symmetry and yield structured patterns that encode both the magnitude and the sign of $\\ell$. A transparent Fraunhofer mapping links detector coordinates to the Fourier plane, explaining the $(|\\ell|+1)$-lobe rule and the sign-dependent rotation of the pattern. We validate these results for both ideal Bessel beams and localized Laguerre-Gaussian packets, and we cross-check them by split-step Fourier propagation of the time-dependent Schr\"odinger equation. From these analyses we extract practical design rules (Fraunhofer distance, lattice pitch, detector sampling) relevant to OAM diagnostics with moderately relativistic electrons with $E_{\\rm kin}\\sim0.1$ to $5$ MeV and light ions with $E_{\\rm kin}\\sim0.1$ to $1$ MeV/u. Our results establish triangular diffraction as a simple, passive, and robust method for reading out the OAM content of structured quantum beams.\n    link: https://arxiv.org/abs/2510.00826v3\n    "}}
{"custom_id": "2512.09568v1", "method": "POST", "url": "/v1/responses", "body": {"model": "gpt-5-mini", "input": "You are a specialist research analyst in Web3, DeFi, cryptography, and distributed systems.\n\n    Your task:\n    From the paper below (Title + Summary + Link), evaluate how useful each paper is for understanding investment opportunities or technological advantages within the Web3 / crypto / DeFi ecosystem.\n    Rate each paper on a five-level scale: Highest / High / Medium / Low / Lowest.\n\n    \"Useful\" means:\n\n    - Improves understanding of new cryptographic primitives relevant to blockchain performance or security\n    - Enhances scalability: distributed systems, P2P networking, consensus mechanisms\n    - Advances in zero knowledge, MPC, PQC that could impact future L1/L2 chains\n    - DeFi modeling, AMMs, MEV, risk models, liquidity dynamics\n    - Smart contract security, attack vectors, economic incentives\n    - Token economics, mechanism design for decentralized systems\n    - Quantum threats to blockchain or cryptography\n    - Any breakthrough that meaningfully improves decentralization, scalability, privacy, or composability\n\n    Output instructions:\n\n    - Output each JSON object in JSON Lines format (one line per paper).\n\n    {\n        \"title\": title of the paper (in Japanese),\n        \"summary\": A concise summary of the paper (in Japanese),\n        \"impact_level\": \"Highest|High|Medium|Low|Lowest\",\n        \"why_matters\": An array (JSON array) containing 2\u20134 bullet points explaining why this paper matters for Web3 investment\n    }\n\n    - Do not output anything except valid JSON object in JSON Lines.\n    - \"title\", \"summary\", \"why_matters\" text in the output must be written in Japanese.\n\n    Paper:\n    title: PHWSOA: A Pareto-based Hybrid Whale-Seagull Scheduling for Multi-Objective Tasks in Cloud Computing\n    summary: Task scheduling is a critical research challenge in cloud computing, a transformative technology widely adopted across industries. Although numerous scheduling solutions exist, they predominantly optimize singular or limited metrics such as execution time or resource utilization often neglecting the need for comprehensive multi-objective optimization. To bridge this gap, this paper proposes the Pareto-based Hybrid Whale-Seagull Optimization Algorithm (PHWSOA). This algorithm synergistically combines the strengths of the Whale Optimization Algorithm (WOA) and the Seagull Optimization Algorithm (SOA), specifically mitigating WOA's limitations in local exploitation and SOA's constraints in global exploration. Leveraging Pareto dominance principles, PHWSOA simultaneously optimizes three key objectives: makespan, virtual machine (VM) load balancing, and economic cost. Key enhancements include: Halton sequence initialization for superior population diversity, a Pareto-guided mutation mechanism to avert premature convergence, and parallel processing for accelerated convergence. Furthermore, a dynamic VM load redistribution mechanism is integrated to improve load balancing during task execution. Extensive experiments conducted on the CloudSim simulator, utilizing real-world workload traces from NASA-iPSC and HPC2N, demonstrate that PHWSOA delivers substantial performance gains. Specifically, it achieves up to a 72.1% reduction in makespan, a 36.8% improvement in VM load balancing, and 23.5% cost savings. These results substantially outperform baseline methods including WOA, GA, PEWOA, and GCWOA underscoring PHWSOA's strong potential for enabling efficient resource management in practical cloud environments.\n    link: https://arxiv.org/abs/2512.09568v1\n    "}}
{"custom_id": "2512.09549v1", "method": "POST", "url": "/v1/responses", "body": {"model": "gpt-5-mini", "input": "You are a specialist research analyst in Web3, DeFi, cryptography, and distributed systems.\n\n    Your task:\n    From the paper below (Title + Summary + Link), evaluate how useful each paper is for understanding investment opportunities or technological advantages within the Web3 / crypto / DeFi ecosystem.\n    Rate each paper on a five-level scale: Highest / High / Medium / Low / Lowest.\n\n    \"Useful\" means:\n\n    - Improves understanding of new cryptographic primitives relevant to blockchain performance or security\n    - Enhances scalability: distributed systems, P2P networking, consensus mechanisms\n    - Advances in zero knowledge, MPC, PQC that could impact future L1/L2 chains\n    - DeFi modeling, AMMs, MEV, risk models, liquidity dynamics\n    - Smart contract security, attack vectors, economic incentives\n    - Token economics, mechanism design for decentralized systems\n    - Quantum threats to blockchain or cryptography\n    - Any breakthrough that meaningfully improves decentralization, scalability, privacy, or composability\n\n    Output instructions:\n\n    - Output each JSON object in JSON Lines format (one line per paper).\n\n    {\n        \"title\": title of the paper (in Japanese),\n        \"summary\": A concise summary of the paper (in Japanese),\n        \"impact_level\": \"Highest|High|Medium|Low|Lowest\",\n        \"why_matters\": An array (JSON array) containing 2\u20134 bullet points explaining why this paper matters for Web3 investment\n    }\n\n    - Do not output anything except valid JSON object in JSON Lines.\n    - \"title\", \"summary\", \"why_matters\" text in the output must be written in Japanese.\n\n    Paper:\n    title: Chasing Shadows: Pitfalls in LLM Security Research\n    summary: Large language models (LLMs) are increasingly prevalent in security research. Their unique characteristics, however, introduce challenges that undermine established paradigms of reproducibility, rigor, and evaluation. Prior work has identified common pitfalls in traditional machine learning research, but these studies predate the advent of LLMs. In this paper, we identify \\emph{nine} common pitfalls that have become (more) relevant with the emergence of LLMs and that can compromise the validity of research involving them. These pitfalls span the entire computation process, from data collection, pre-training, and fine-tuning to prompting and evaluation.\n  We assess the prevalence of these pitfalls across all 72 peer-reviewed papers published at leading Security and Software Engineering venues between 2023 and 2024. We find that every paper contains at least one pitfall, and each pitfall appears in multiple papers. Yet only 15.7\\% of the present pitfalls were explicitly discussed, suggesting that the majority remain unrecognized. To understand their practical impact, we conduct four empirical case studies showing how individual pitfalls can mislead evaluation, inflate performance, or impair reproducibility. Based on our findings, we offer actionable guidelines to support the community in future work.\n    link: https://arxiv.org/abs/2512.09549v1\n    "}}
{"custom_id": "2509.01928v2", "method": "POST", "url": "/v1/responses", "body": {"model": "gpt-5-mini", "input": "You are a specialist research analyst in Web3, DeFi, cryptography, and distributed systems.\n\n    Your task:\n    From the paper below (Title + Summary + Link), evaluate how useful each paper is for understanding investment opportunities or technological advantages within the Web3 / crypto / DeFi ecosystem.\n    Rate each paper on a five-level scale: Highest / High / Medium / Low / Lowest.\n\n    \"Useful\" means:\n\n    - Improves understanding of new cryptographic primitives relevant to blockchain performance or security\n    - Enhances scalability: distributed systems, P2P networking, consensus mechanisms\n    - Advances in zero knowledge, MPC, PQC that could impact future L1/L2 chains\n    - DeFi modeling, AMMs, MEV, risk models, liquidity dynamics\n    - Smart contract security, attack vectors, economic incentives\n    - Token economics, mechanism design for decentralized systems\n    - Quantum threats to blockchain or cryptography\n    - Any breakthrough that meaningfully improves decentralization, scalability, privacy, or composability\n\n    Output instructions:\n\n    - Output each JSON object in JSON Lines format (one line per paper).\n\n    {\n        \"title\": title of the paper (in Japanese),\n        \"summary\": A concise summary of the paper (in Japanese),\n        \"impact_level\": \"Highest|High|Medium|Low|Lowest\",\n        \"why_matters\": An array (JSON array) containing 2\u20134 bullet points explaining why this paper matters for Web3 investment\n    }\n\n    - Do not output anything except valid JSON object in JSON Lines.\n    - \"title\", \"summary\", \"why_matters\" text in the output must be written in Japanese.\n\n    Paper:\n    title: A Continuous Energy Ising Machine Leveraging Difference-of-Convex Programming\n    summary: Many combinatorial optimization problems can be reformulated as finding the ground state of the Ising model. Existing Ising solvers are mostly inspired by simulated annealing. Although annealing techniques offer scalability, they lack convergence guarantees and are sensitive to the cooling schedule. We propose solving the Ising problem by relaxing the binary spins to continuous variables and introducing an attraction potential that steers the solution toward binary spin configurations. A key property of this potential is that its combination with the Ising energy produces a Hamiltonian that can be written as a difference of convex polynomials. This enables us to design efficient iterative algorithms that require a single matrix-vector multiplication per iteration and provide convergence guarantees. We implement our Ising solver on a wide range of GPU platforms, from edge devices to high-performance computing clusters, and demonstrate that it consistently outperforms existing solvers across problem sizes ranging from small ($10^3$ spins) to ultra-large ($10^8$ spins).\n    link: https://arxiv.org/abs/2509.01928v2\n    "}}
{"custom_id": "2512.09539v1", "method": "POST", "url": "/v1/responses", "body": {"model": "gpt-5-mini", "input": "You are a specialist research analyst in Web3, DeFi, cryptography, and distributed systems.\n\n    Your task:\n    From the paper below (Title + Summary + Link), evaluate how useful each paper is for understanding investment opportunities or technological advantages within the Web3 / crypto / DeFi ecosystem.\n    Rate each paper on a five-level scale: Highest / High / Medium / Low / Lowest.\n\n    \"Useful\" means:\n\n    - Improves understanding of new cryptographic primitives relevant to blockchain performance or security\n    - Enhances scalability: distributed systems, P2P networking, consensus mechanisms\n    - Advances in zero knowledge, MPC, PQC that could impact future L1/L2 chains\n    - DeFi modeling, AMMs, MEV, risk models, liquidity dynamics\n    - Smart contract security, attack vectors, economic incentives\n    - Token economics, mechanism design for decentralized systems\n    - Quantum threats to blockchain or cryptography\n    - Any breakthrough that meaningfully improves decentralization, scalability, privacy, or composability\n\n    Output instructions:\n\n    - Output each JSON object in JSON Lines format (one line per paper).\n\n    {\n        \"title\": title of the paper (in Japanese),\n        \"summary\": A concise summary of the paper (in Japanese),\n        \"impact_level\": \"Highest|High|Medium|Low|Lowest\",\n        \"why_matters\": An array (JSON array) containing 2\u20134 bullet points explaining why this paper matters for Web3 investment\n    }\n\n    - Do not output anything except valid JSON object in JSON Lines.\n    - \"title\", \"summary\", \"why_matters\" text in the output must be written in Japanese.\n\n    Paper:\n    title: Comparative Analysis of Hash-based Malware Clustering via K-Means\n    summary: With the adoption of multiple digital devices in everyday life, the cyber-attack surface has increased. Adversaries are continuously exploring new avenues to exploit them and deploy malware. On the other hand, detection approaches typically employ hashing-based algorithms such as SSDeep, TLSH, and IMPHash to capture structural and behavioural similarities among binaries. This work focuses on the analysis and evaluation of these techniques for clustering malware samples using the K-means algorithm. More specifically, we experimented with established malware families and traits and found that TLSH and IMPHash produce more distinct, semantically meaningful clusters, whereas SSDeep is more efficient for broader classification tasks. The findings of this work can guide the development of more robust threat-detection mechanisms and adaptive security mechanisms.\n    link: https://arxiv.org/abs/2512.09539v1\n    "}}
{"custom_id": "2512.09520v1", "method": "POST", "url": "/v1/responses", "body": {"model": "gpt-5-mini", "input": "You are a specialist research analyst in Web3, DeFi, cryptography, and distributed systems.\n\n    Your task:\n    From the paper below (Title + Summary + Link), evaluate how useful each paper is for understanding investment opportunities or technological advantages within the Web3 / crypto / DeFi ecosystem.\n    Rate each paper on a five-level scale: Highest / High / Medium / Low / Lowest.\n\n    \"Useful\" means:\n\n    - Improves understanding of new cryptographic primitives relevant to blockchain performance or security\n    - Enhances scalability: distributed systems, P2P networking, consensus mechanisms\n    - Advances in zero knowledge, MPC, PQC that could impact future L1/L2 chains\n    - DeFi modeling, AMMs, MEV, risk models, liquidity dynamics\n    - Smart contract security, attack vectors, economic incentives\n    - Token economics, mechanism design for decentralized systems\n    - Quantum threats to blockchain or cryptography\n    - Any breakthrough that meaningfully improves decentralization, scalability, privacy, or composability\n\n    Output instructions:\n\n    - Output each JSON object in JSON Lines format (one line per paper).\n\n    {\n        \"title\": title of the paper (in Japanese),\n        \"summary\": A concise summary of the paper (in Japanese),\n        \"impact_level\": \"Highest|High|Medium|Low|Lowest\",\n        \"why_matters\": An array (JSON array) containing 2\u20134 bullet points explaining why this paper matters for Web3 investment\n    }\n\n    - Do not output anything except valid JSON object in JSON Lines.\n    - \"title\", \"summary\", \"why_matters\" text in the output must be written in Japanese.\n\n    Paper:\n    title: Single particle dynamical signature of topology induced by single mode cavities in Su-Schrieffer-Heeger chain\n    summary: Witnessing and tracking topological phase transitions induced by interactions with the environment is a crucial challenge. Among the various experimental approaches to detect topological properties, the Mean Chiral Displacement (MCD) has emerged as a powerful bulk probe in one-dimensional chiral systems, allowing the extraction of the topological invariant from single-particle dynamics. Here we study the dynamics of a single particle in a one-dimensional Su-Schrieffer-Heeger chain coupled to multiple cavity modes via inter-cell hopping terms, focusing on the out-of-equilibrium behavior of the MCD. We show that, whenever the frequency is larger than the static hopping amplitudes, the coupling induces a discontinuous jump in the MCD, already at small times, signaling that such a coupling also leaves a signature in the survival edge probability when the dynamics are initialized at one of the two edges. For frequencies comparable to the static hopping amplitudes, topological order competes with dissipative effects, which makes the MCD behave smoothly, retaining information about the driven-dissipative topology.\n    link: https://arxiv.org/abs/2512.09520v1\n    "}}
{"custom_id": "2512.09502v1", "method": "POST", "url": "/v1/responses", "body": {"model": "gpt-5-mini", "input": "You are a specialist research analyst in Web3, DeFi, cryptography, and distributed systems.\n\n    Your task:\n    From the paper below (Title + Summary + Link), evaluate how useful each paper is for understanding investment opportunities or technological advantages within the Web3 / crypto / DeFi ecosystem.\n    Rate each paper on a five-level scale: Highest / High / Medium / Low / Lowest.\n\n    \"Useful\" means:\n\n    - Improves understanding of new cryptographic primitives relevant to blockchain performance or security\n    - Enhances scalability: distributed systems, P2P networking, consensus mechanisms\n    - Advances in zero knowledge, MPC, PQC that could impact future L1/L2 chains\n    - DeFi modeling, AMMs, MEV, risk models, liquidity dynamics\n    - Smart contract security, attack vectors, economic incentives\n    - Token economics, mechanism design for decentralized systems\n    - Quantum threats to blockchain or cryptography\n    - Any breakthrough that meaningfully improves decentralization, scalability, privacy, or composability\n\n    Output instructions:\n\n    - Output each JSON object in JSON Lines format (one line per paper).\n\n    {\n        \"title\": title of the paper (in Japanese),\n        \"summary\": A concise summary of the paper (in Japanese),\n        \"impact_level\": \"Highest|High|Medium|Low|Lowest\",\n        \"why_matters\": An array (JSON array) containing 2\u20134 bullet points explaining why this paper matters for Web3 investment\n    }\n\n    - Do not output anything except valid JSON object in JSON Lines.\n    - \"title\", \"summary\", \"why_matters\" text in the output must be written in Japanese.\n\n    Paper:\n    title: Scalable Construction of Spiking Neural Networks using up to thousands of GPUs\n    summary: Diverse scientific and engineering research areas deal with discrete, time-stamped changes in large systems of interacting delay differential equations. Simulating such complex systems at scale on high-performance computing clusters demands efficient management of communication and memory. Inspired by the human cerebral cortex -- a sparsely connected network of $\\mathcal{O}(10^{10})$ neurons, each forming $\\mathcal{O}(10^{3})$--$\\mathcal{O}(10^{4})$ synapses and communicating via short electrical pulses called spikes -- we study the simulation of large-scale spiking neural networks for computational neuroscience research. This work presents a novel network construction method for multi-GPU clusters and upcoming exascale supercomputers using the Message Passing Interface (MPI), where each process builds its local connectivity and prepares the data structures for efficient spike exchange across the cluster during state propagation. We demonstrate scaling performance of two cortical models using point-to-point and collective communication, respectively.\n    link: https://arxiv.org/abs/2512.09502v1\n    "}}
{"custom_id": "2512.09485v1", "method": "POST", "url": "/v1/responses", "body": {"model": "gpt-5-mini", "input": "You are a specialist research analyst in Web3, DeFi, cryptography, and distributed systems.\n\n    Your task:\n    From the paper below (Title + Summary + Link), evaluate how useful each paper is for understanding investment opportunities or technological advantages within the Web3 / crypto / DeFi ecosystem.\n    Rate each paper on a five-level scale: Highest / High / Medium / Low / Lowest.\n\n    \"Useful\" means:\n\n    - Improves understanding of new cryptographic primitives relevant to blockchain performance or security\n    - Enhances scalability: distributed systems, P2P networking, consensus mechanisms\n    - Advances in zero knowledge, MPC, PQC that could impact future L1/L2 chains\n    - DeFi modeling, AMMs, MEV, risk models, liquidity dynamics\n    - Smart contract security, attack vectors, economic incentives\n    - Token economics, mechanism design for decentralized systems\n    - Quantum threats to blockchain or cryptography\n    - Any breakthrough that meaningfully improves decentralization, scalability, privacy, or composability\n\n    Output instructions:\n\n    - Output each JSON object in JSON Lines format (one line per paper).\n\n    {\n        \"title\": title of the paper (in Japanese),\n        \"summary\": A concise summary of the paper (in Japanese),\n        \"impact_level\": \"Highest|High|Medium|Low|Lowest\",\n        \"why_matters\": An array (JSON array) containing 2\u20134 bullet points explaining why this paper matters for Web3 investment\n    }\n\n    - Do not output anything except valid JSON object in JSON Lines.\n    - \"title\", \"summary\", \"why_matters\" text in the output must be written in Japanese.\n\n    Paper:\n    title: Advancing LLM-Based Security Automation with Customized Group Relative Policy Optimization for Zero-Touch Networks\n    summary: Zero-Touch Networks (ZTNs) represent a transformative paradigm toward fully automated and intelligent network management, providing the scalability and adaptability required for the complexity of sixth-generation (6G) networks. However, the distributed architecture, high openness, and deep heterogeneity of 6G networks expand the attack surface and pose unprecedented security challenges. To address this, security automation aims to enable intelligent security management across dynamic and complex environments, serving as a key capability for securing 6G ZTNs. Despite its promise, implementing security automation in 6G ZTNs presents two primary challenges: 1) automating the lifecycle from security strategy generation to validation and update under real-world, parallel, and adversarial conditions, and 2) adapting security strategies to evolving threats and dynamic environments. This motivates us to propose SecLoop and SA-GRPO. SecLoop constitutes the first fully automated framework that integrates large language models (LLMs) across the entire lifecycle of security strategy generation, orchestration, response, and feedback, enabling intelligent and adaptive defenses in dynamic network environments, thus tackling the first challenge. Furthermore, we propose SA-GRPO, a novel security-aware group relative policy optimization algorithm that iteratively refines security strategies by contrasting group feedback collected from parallel SecLoop executions, thereby addressing the second challenge. Extensive real-world experiments on five benchmarks, including 11 MITRE ATT&CK processes and over 20 types of attacks, demonstrate the superiority of the proposed SecLoop and SA-GRPO. We will release our platform to the community, facilitating the advancement of security automation towards next generation communications.\n    link: https://arxiv.org/abs/2512.09485v1\n    "}}
{"custom_id": "2512.09472v1", "method": "POST", "url": "/v1/responses", "body": {"model": "gpt-5-mini", "input": "You are a specialist research analyst in Web3, DeFi, cryptography, and distributed systems.\n\n    Your task:\n    From the paper below (Title + Summary + Link), evaluate how useful each paper is for understanding investment opportunities or technological advantages within the Web3 / crypto / DeFi ecosystem.\n    Rate each paper on a five-level scale: Highest / High / Medium / Low / Lowest.\n\n    \"Useful\" means:\n\n    - Improves understanding of new cryptographic primitives relevant to blockchain performance or security\n    - Enhances scalability: distributed systems, P2P networking, consensus mechanisms\n    - Advances in zero knowledge, MPC, PQC that could impact future L1/L2 chains\n    - DeFi modeling, AMMs, MEV, risk models, liquidity dynamics\n    - Smart contract security, attack vectors, economic incentives\n    - Token economics, mechanism design for decentralized systems\n    - Quantum threats to blockchain or cryptography\n    - Any breakthrough that meaningfully improves decentralization, scalability, privacy, or composability\n\n    Output instructions:\n\n    - Output each JSON object in JSON Lines format (one line per paper).\n\n    {\n        \"title\": title of the paper (in Japanese),\n        \"summary\": A concise summary of the paper (in Japanese),\n        \"impact_level\": \"Highest|High|Medium|Low|Lowest\",\n        \"why_matters\": An array (JSON array) containing 2\u20134 bullet points explaining why this paper matters for Web3 investment\n    }\n\n    - Do not output anything except valid JSON object in JSON Lines.\n    - \"title\", \"summary\", \"why_matters\" text in the output must be written in Japanese.\n\n    Paper:\n    title: WarmServe: Enabling One-for-Many GPU Prewarming for Multi-LLM Serving\n    summary: Deploying multiple models within shared GPU clusters is promising for improving resource efficiency in large language model (LLM) serving. Existing multi-LLM serving systems optimize GPU utilization at the cost of worse inference performance, especially time-to-first-token (TTFT). We identify the root cause of such compromise as their unawareness of future workload characteristics. In contrast, recent analysis on real-world traces has shown the high periodicity and long-term predictability of LLM serving workloads.\n  We propose universal GPU workers to enable one-for-many GPU prewarming that loads models with knowledge of future workloads. Based on universal GPU workers, we design and build WarmServe, a multi-LLM serving system that (1) mitigates cluster-wide prewarming interference by adopting an evict-aware model placement strategy, (2) prepares universal GPU workers in advance by proactive prewarming, and (3) manages GPU memory with a zero-overhead memory switching mechanism. Evaluation under real-world datasets shows that WarmServe improves TTFT by up to 50.8$\\times$ compared to the state-of-the-art autoscaling-based system, while being capable of serving up to 2.5$\\times$ more requests compared to the GPU-sharing system.\n    link: https://arxiv.org/abs/2512.09472v1\n    "}}
{"custom_id": "2110.15842v5", "method": "POST", "url": "/v1/responses", "body": {"model": "gpt-5-mini", "input": "You are a specialist research analyst in Web3, DeFi, cryptography, and distributed systems.\n\n    Your task:\n    From the paper below (Title + Summary + Link), evaluate how useful each paper is for understanding investment opportunities or technological advantages within the Web3 / crypto / DeFi ecosystem.\n    Rate each paper on a five-level scale: Highest / High / Medium / Low / Lowest.\n\n    \"Useful\" means:\n\n    - Improves understanding of new cryptographic primitives relevant to blockchain performance or security\n    - Enhances scalability: distributed systems, P2P networking, consensus mechanisms\n    - Advances in zero knowledge, MPC, PQC that could impact future L1/L2 chains\n    - DeFi modeling, AMMs, MEV, risk models, liquidity dynamics\n    - Smart contract security, attack vectors, economic incentives\n    - Token economics, mechanism design for decentralized systems\n    - Quantum threats to blockchain or cryptography\n    - Any breakthrough that meaningfully improves decentralization, scalability, privacy, or composability\n\n    Output instructions:\n\n    - Output each JSON object in JSON Lines format (one line per paper).\n\n    {\n        \"title\": title of the paper (in Japanese),\n        \"summary\": A concise summary of the paper (in Japanese),\n        \"impact_level\": \"Highest|High|Medium|Low|Lowest\",\n        \"why_matters\": An array (JSON array) containing 2\u20134 bullet points explaining why this paper matters for Web3 investment\n    }\n\n    - Do not output anything except valid JSON object in JSON Lines.\n    - \"title\", \"summary\", \"why_matters\" text in the output must be written in Japanese.\n\n    Paper:\n    title: Equiangular lines via matrix projection\n    summary: In 1973, Lemmens and Seidel posed the problem of determining the maximum number of equiangular lines in $\\mathbb{R}^r$ with angle $\\arccos(\u03b1)$ and gave a partial answer in the regime $r \\leq 1/\u03b1^2 - 2$. At the other extreme where $r$ is at least exponential in $1/\u03b1$, recent breakthroughs have led to an almost complete resolution of this problem. In this paper, we introduce a new method for obtaining upper bounds which unifies and improves upon previous approaches, thereby yielding bounds which bridge the gap between the aforementioned regimes and are best possible either exactly or up to a small multiplicative constant. Our approach relies on orthogonal projection of matrices with respect to the Frobenius inner product and as a byproduct, it yields the first extension of the Alon-Boppana theorem to dense graphs, with equality for strongly regular graphs corresponding to $\\binom{r+1}{2}$ equiangular lines in $\\mathbb{R}^r$. Applications of our method in the complex setting will be discussed as well.\n    link: https://arxiv.org/abs/2110.15842v5\n    "}}
{"custom_id": "2311.08769v3", "method": "POST", "url": "/v1/responses", "body": {"model": "gpt-5-mini", "input": "You are a specialist research analyst in Web3, DeFi, cryptography, and distributed systems.\n\n    Your task:\n    From the paper below (Title + Summary + Link), evaluate how useful each paper is for understanding investment opportunities or technological advantages within the Web3 / crypto / DeFi ecosystem.\n    Rate each paper on a five-level scale: Highest / High / Medium / Low / Lowest.\n\n    \"Useful\" means:\n\n    - Improves understanding of new cryptographic primitives relevant to blockchain performance or security\n    - Enhances scalability: distributed systems, P2P networking, consensus mechanisms\n    - Advances in zero knowledge, MPC, PQC that could impact future L1/L2 chains\n    - DeFi modeling, AMMs, MEV, risk models, liquidity dynamics\n    - Smart contract security, attack vectors, economic incentives\n    - Token economics, mechanism design for decentralized systems\n    - Quantum threats to blockchain or cryptography\n    - Any breakthrough that meaningfully improves decentralization, scalability, privacy, or composability\n\n    Output instructions:\n\n    - Output each JSON object in JSON Lines format (one line per paper).\n\n    {\n        \"title\": title of the paper (in Japanese),\n        \"summary\": A concise summary of the paper (in Japanese),\n        \"impact_level\": \"Highest|High|Medium|Low|Lowest\",\n        \"why_matters\": An array (JSON array) containing 2\u20134 bullet points explaining why this paper matters for Web3 investment\n    }\n\n    - Do not output anything except valid JSON object in JSON Lines.\n    - \"title\", \"summary\", \"why_matters\" text in the output must be written in Japanese.\n\n    Paper:\n    title: adF: A Novel System for Measuring Web Fingerprinting through Ads\n    summary: This paper introduces adF, a novel system for analyzing the vulnerability of different devices, Operating Systems (OSes), and browsers to web fingerprinting. adF performs its measurements from code inserted in ads. We have used our system in several ad campaigns that delivered 5.40 million ad impressions. The collected data allow us to assess the vulnerability of current desktop and mobile devices to web fingerprinting. Based on our results, we estimate that 66% of desktop devices and 40% of mobile devices can be uniquely fingerprinted with our web fingerprinting system. However, the resilience to web fingerprinting varies significantly across browsers and device types, with Chrome on desktops being the most vulnerable configuration.\n  To counter web fingerprinting, we propose ShieldF, a simple solution which blocks the reporting by browsers of those attributes that we found in the analysis of our dataset that present the most significant discrimination power. Our experiments reveal that ShieldF outperforms all anti-fingerprinting solutions proposed by major browsers (Chrome, Safari and Firefox) offering an increase in the resilience offered to web fingerprinting up to 62% for some device configurations. ShieldF is available as an add-on for any chromium-based browser. Moreover, it is readily adoptable by browser and mobile app developers. Its widespread use would lead to a significant improvement in the protection offered by browsers and mobile apps to web fingerprinting.\n    link: https://arxiv.org/abs/2311.08769v3\n    "}}
{"custom_id": "2512.09453v1", "method": "POST", "url": "/v1/responses", "body": {"model": "gpt-5-mini", "input": "You are a specialist research analyst in Web3, DeFi, cryptography, and distributed systems.\n\n    Your task:\n    From the paper below (Title + Summary + Link), evaluate how useful each paper is for understanding investment opportunities or technological advantages within the Web3 / crypto / DeFi ecosystem.\n    Rate each paper on a five-level scale: Highest / High / Medium / Low / Lowest.\n\n    \"Useful\" means:\n\n    - Improves understanding of new cryptographic primitives relevant to blockchain performance or security\n    - Enhances scalability: distributed systems, P2P networking, consensus mechanisms\n    - Advances in zero knowledge, MPC, PQC that could impact future L1/L2 chains\n    - DeFi modeling, AMMs, MEV, risk models, liquidity dynamics\n    - Smart contract security, attack vectors, economic incentives\n    - Token economics, mechanism design for decentralized systems\n    - Quantum threats to blockchain or cryptography\n    - Any breakthrough that meaningfully improves decentralization, scalability, privacy, or composability\n\n    Output instructions:\n\n    - Output each JSON object in JSON Lines format (one line per paper).\n\n    {\n        \"title\": title of the paper (in Japanese),\n        \"summary\": A concise summary of the paper (in Japanese),\n        \"impact_level\": \"Highest|High|Medium|Low|Lowest\",\n        \"why_matters\": An array (JSON array) containing 2\u20134 bullet points explaining why this paper matters for Web3 investment\n    }\n\n    - Do not output anything except valid JSON object in JSON Lines.\n    - \"title\", \"summary\", \"why_matters\" text in the output must be written in Japanese.\n\n    Paper:\n    title: BlockFLEX: An Adaptive and Survivable Architecture with Hierarchical Routing for LEO Satellite Networks\n    summary: This paper presents \\textbf{BlockFLEX}, an adaptive and survivable architecture with a hierarchical routing scheme for Low Earth Orbit satellite networks, designed to address dynamic topology changes and severe link failures.\n  By organizing satellites into autonomous blocks, BlockFLEX establishes a survivable underlay network that masks network volatility and offers a stable overlay view. The architecture employs a hierarchical routing scheme integrating both convergence-free geographic routing and convergence-isolated routing. Furthermore, BlockFLEX adaptively switches between stateful and stateless forwarding modes, enabling efficient, resilient, and stable routing via a dedicated protection mechanism and an optimized source satellite selection algorithm.\n  Experimental evaluations on current operational LEO satellite networks (LSNs) demonstrate that under scenarios with up to 30\\% random link failures, the proposed method achieves a $2\\times$ improvement in reachability compared to current leading schemes, while maintaining near-100\\% routing availability. Moreover, the overhead of control messages and forwarding information base (FIB) updates remains below $0.2\\%$ of that in OSPF, accompanied by a $\\geq 36\\%$ reduction in routing computation time and a $\\geq 50\\%$ decrease in latency jitter.\n    link: https://arxiv.org/abs/2512.09453v1\n    "}}
{"custom_id": "2512.09442v1", "method": "POST", "url": "/v1/responses", "body": {"model": "gpt-5-mini", "input": "You are a specialist research analyst in Web3, DeFi, cryptography, and distributed systems.\n\n    Your task:\n    From the paper below (Title + Summary + Link), evaluate how useful each paper is for understanding investment opportunities or technological advantages within the Web3 / crypto / DeFi ecosystem.\n    Rate each paper on a five-level scale: Highest / High / Medium / Low / Lowest.\n\n    \"Useful\" means:\n\n    - Improves understanding of new cryptographic primitives relevant to blockchain performance or security\n    - Enhances scalability: distributed systems, P2P networking, consensus mechanisms\n    - Advances in zero knowledge, MPC, PQC that could impact future L1/L2 chains\n    - DeFi modeling, AMMs, MEV, risk models, liquidity dynamics\n    - Smart contract security, attack vectors, economic incentives\n    - Token economics, mechanism design for decentralized systems\n    - Quantum threats to blockchain or cryptography\n    - Any breakthrough that meaningfully improves decentralization, scalability, privacy, or composability\n\n    Output instructions:\n\n    - Output each JSON object in JSON Lines format (one line per paper).\n\n    {\n        \"title\": title of the paper (in Japanese),\n        \"summary\": A concise summary of the paper (in Japanese),\n        \"impact_level\": \"Highest|High|Medium|Low|Lowest\",\n        \"why_matters\": An array (JSON array) containing 2\u20134 bullet points explaining why this paper matters for Web3 investment\n    }\n\n    - Do not output anything except valid JSON object in JSON Lines.\n    - \"title\", \"summary\", \"why_matters\" text in the output must be written in Japanese.\n\n    Paper:\n    title: Reference Recommendation based Membership Inference Attack against Hybrid-based Recommender Systems\n    summary: Recommender systems have been widely deployed across various domains such as e-commerce and social media, and intelligently suggest items like products and potential friends to users based on their preferences and interaction history, which are often privacy-sensitive. Recent studies have revealed that recommender systems are prone to membership inference attacks (MIAs), where an attacker aims to infer whether or not a user's data has been used for training a target recommender system. However, existing MIAs fail to exploit the unique characteristic of recommender systems, and therefore are only applicable to mixed recommender systems consisting of two recommendation algorithms. This leaves a gap in investigating MIAs against hybrid-based recommender systems where the same algorithm utilizing user-item historical interactions and attributes of users and items serves and produces personalised recommendations. To investigate how the personalisation in hybrid-based recommender systems influences MIA, we propose a novel metric-based MIA. Specifically, we leverage the characteristic of personalisation to obtain reference recommendation for any target users. Then, a relative membership metric is proposed to exploit a target user's historical interactions, target recommendation, and reference recommendation to infer the membership of the target user's data. Finally, we theoretically and empirically demonstrate the efficacy of the proposed metric-based MIA on hybrid-based recommender systems.\n    link: https://arxiv.org/abs/2512.09442v1\n    "}}
{"custom_id": "2305.01301v3", "method": "POST", "url": "/v1/responses", "body": {"model": "gpt-5-mini", "input": "You are a specialist research analyst in Web3, DeFi, cryptography, and distributed systems.\n\n    Your task:\n    From the paper below (Title + Summary + Link), evaluate how useful each paper is for understanding investment opportunities or technological advantages within the Web3 / crypto / DeFi ecosystem.\n    Rate each paper on a five-level scale: Highest / High / Medium / Low / Lowest.\n\n    \"Useful\" means:\n\n    - Improves understanding of new cryptographic primitives relevant to blockchain performance or security\n    - Enhances scalability: distributed systems, P2P networking, consensus mechanisms\n    - Advances in zero knowledge, MPC, PQC that could impact future L1/L2 chains\n    - DeFi modeling, AMMs, MEV, risk models, liquidity dynamics\n    - Smart contract security, attack vectors, economic incentives\n    - Token economics, mechanism design for decentralized systems\n    - Quantum threats to blockchain or cryptography\n    - Any breakthrough that meaningfully improves decentralization, scalability, privacy, or composability\n\n    Output instructions:\n\n    - Output each JSON object in JSON Lines format (one line per paper).\n\n    {\n        \"title\": title of the paper (in Japanese),\n        \"summary\": A concise summary of the paper (in Japanese),\n        \"impact_level\": \"Highest|High|Medium|Low|Lowest\",\n        \"why_matters\": An array (JSON array) containing 2\u20134 bullet points explaining why this paper matters for Web3 investment\n    }\n\n    - Do not output anything except valid JSON object in JSON Lines.\n    - \"title\", \"summary\", \"why_matters\" text in the output must be written in Japanese.\n\n    Paper:\n    title: Performance Analysis of Quantum CSS Error-Correcting Codes via MacWilliams Identities\n    summary: We analyze the performance of quantum stabilizer codes, one of the most important classes for practical implementations, on both symmetric and asymmetric quantum channels. To this aim, we first derive the weight enumerator (WE) for the undetectable errors based on the quantum MacWilliams identities. The WE is then used to evaluate tight upper bounds on the error rate of CSS quantum codes with \\acl{MW} decoding. For surface codes we also derive a simple closed form expression of the bounds over the depolarizing channel. We introduce a novel approach that combines the knowledge of WE with a logical operator analysis, allowing the derivation of the exact asymptotic error rate for short codes. For example, on a depolarizing channel with physical error rate $\u03c1\\to 0$, the logical error rate $\u03c1_\\mathrm{L}$ is asymptotically $\u03c1_\\mathrm{L} \\approx 16 \u03c1^2$ for the $[[9,1,3]]$ Shor code, $\u03c1_\\mathrm{L} \\approx 16.3 \u03c1^2$ for the $[[7,1,3]]$ Steane code, $\u03c1_\\mathrm{L} \\approx 18.7 \u03c1^2$ for the $[[13,1,3]]$ surface code, and $\u03c1_\\mathrm{L} \\approx 149.3 \u03c1^3$ for the $[[41,1,5]]$ surface code. For larger codes our bound provides $\u03c1_\\mathrm{L} \\approx 1215 \u03c1^4$ and $\u03c1_\\mathrm{L} \\approx 663 \u03c1^5$ for the $[[85,1,7]]$ and the $[[181,1,10]]$ surface codes, respectively. Finally, we extend our analysis to include realistic, noisy syndrome extraction circuits by modeling error propagation throughout gadgets. This enables estimation of logical error rates under faulty measurements. The performance analysis serves as a design tool for developing fault-tolerant quantum systems by guiding the selection of quantum codes based on their error correction capability. Additionally, it offers a novel perspective on quantum degeneracy, showing it represents the fraction of non-correctable error patterns shared by multiple logical operators.\n    link: https://arxiv.org/abs/2305.01301v3\n    "}}
{"custom_id": "2512.09409v1", "method": "POST", "url": "/v1/responses", "body": {"model": "gpt-5-mini", "input": "You are a specialist research analyst in Web3, DeFi, cryptography, and distributed systems.\n\n    Your task:\n    From the paper below (Title + Summary + Link), evaluate how useful each paper is for understanding investment opportunities or technological advantages within the Web3 / crypto / DeFi ecosystem.\n    Rate each paper on a five-level scale: Highest / High / Medium / Low / Lowest.\n\n    \"Useful\" means:\n\n    - Improves understanding of new cryptographic primitives relevant to blockchain performance or security\n    - Enhances scalability: distributed systems, P2P networking, consensus mechanisms\n    - Advances in zero knowledge, MPC, PQC that could impact future L1/L2 chains\n    - DeFi modeling, AMMs, MEV, risk models, liquidity dynamics\n    - Smart contract security, attack vectors, economic incentives\n    - Token economics, mechanism design for decentralized systems\n    - Quantum threats to blockchain or cryptography\n    - Any breakthrough that meaningfully improves decentralization, scalability, privacy, or composability\n\n    Output instructions:\n\n    - Output each JSON object in JSON Lines format (one line per paper).\n\n    {\n        \"title\": title of the paper (in Japanese),\n        \"summary\": A concise summary of the paper (in Japanese),\n        \"impact_level\": \"Highest|High|Medium|Low|Lowest\",\n        \"why_matters\": An array (JSON array) containing 2\u20134 bullet points explaining why this paper matters for Web3 investment\n    }\n\n    - Do not output anything except valid JSON object in JSON Lines.\n    - \"title\", \"summary\", \"why_matters\" text in the output must be written in Japanese.\n\n    Paper:\n    title: Proof of Trusted Execution: A Consensus Paradigm for Deterministic Blockchain Finality\n    summary: Current blockchain consensus protocols -- notably, Proof of Work (PoW) and Proof of Stake (PoS) -- deliver global agreement but exhibit structural constraints. PoW anchors security in heavy computation, inflating energy use and imposing high confirmation latency. PoS improves efficiency but introduces stake concentration, long-range and \"nothing-at-stake\" vulnerabilities, and a hard performance ceiling shaped by slot times and multi-round committee voting. In this paper, we propose Proof of Trusted Execution (PoTE), a consensus paradigm where agreement emerges from verifiable execution rather than replicated re-execution. Validators operate inside heterogeneous VM-based TEEs, each running the same canonical program whose measurement is publicly recorded, and each producing vendor-backed attestations that bind the enclave code hash to the block contents. Because the execution is deterministic and the proposer is uniquely derived from public randomness, PoTE avoids forks, eliminates slot.time bottlenecks, and commits blocks in a single round of verification. We present the design of a PoTE consensus client, describe our reference implementation, and evaluate its performance against the stringent throughput requirements of the Trillion decentralized exchange.\n    link: https://arxiv.org/abs/2512.09409v1\n    "}}
{"custom_id": "2512.09390v1", "method": "POST", "url": "/v1/responses", "body": {"model": "gpt-5-mini", "input": "You are a specialist research analyst in Web3, DeFi, cryptography, and distributed systems.\n\n    Your task:\n    From the paper below (Title + Summary + Link), evaluate how useful each paper is for understanding investment opportunities or technological advantages within the Web3 / crypto / DeFi ecosystem.\n    Rate each paper on a five-level scale: Highest / High / Medium / Low / Lowest.\n\n    \"Useful\" means:\n\n    - Improves understanding of new cryptographic primitives relevant to blockchain performance or security\n    - Enhances scalability: distributed systems, P2P networking, consensus mechanisms\n    - Advances in zero knowledge, MPC, PQC that could impact future L1/L2 chains\n    - DeFi modeling, AMMs, MEV, risk models, liquidity dynamics\n    - Smart contract security, attack vectors, economic incentives\n    - Token economics, mechanism design for decentralized systems\n    - Quantum threats to blockchain or cryptography\n    - Any breakthrough that meaningfully improves decentralization, scalability, privacy, or composability\n\n    Output instructions:\n\n    - Output each JSON object in JSON Lines format (one line per paper).\n\n    {\n        \"title\": title of the paper (in Japanese),\n        \"summary\": A concise summary of the paper (in Japanese),\n        \"impact_level\": \"Highest|High|Medium|Low|Lowest\",\n        \"why_matters\": An array (JSON array) containing 2\u20134 bullet points explaining why this paper matters for Web3 investment\n    }\n\n    - Do not output anything except valid JSON object in JSON Lines.\n    - \"title\", \"summary\", \"why_matters\" text in the output must be written in Japanese.\n\n    Paper:\n    title: Compact and efficient quantum frequency conversion of a fiber-pigtailed single-photon source\n    summary: Quantum frequency converters are key enabling technologies in photonic quantum information science to bridge the gap between quantum emitters and telecom photons. Here, we report a co- herent frequency converter scheme combining a fiber-coupled nonlinear optical Lithium Niobate waveguide with a fiber-pigtailed single-photon source based on semiconductor quantum dots. Single and indistinguishable photons are converted from 925.7 nm to the telecommunication C-band, with a 48.4% end-to-end efficiency and full preservation of single-photon purity and indistinguishability. The integration of the two fiber-based modules achieving top-level performance represents an im- portant step toward the practical interconnection of future quantum information processing systems operating at different wavelengths.\n    link: https://arxiv.org/abs/2512.09390v1\n    "}}
{"custom_id": "2512.09385v1", "method": "POST", "url": "/v1/responses", "body": {"model": "gpt-5-mini", "input": "You are a specialist research analyst in Web3, DeFi, cryptography, and distributed systems.\n\n    Your task:\n    From the paper below (Title + Summary + Link), evaluate how useful each paper is for understanding investment opportunities or technological advantages within the Web3 / crypto / DeFi ecosystem.\n    Rate each paper on a five-level scale: Highest / High / Medium / Low / Lowest.\n\n    \"Useful\" means:\n\n    - Improves understanding of new cryptographic primitives relevant to blockchain performance or security\n    - Enhances scalability: distributed systems, P2P networking, consensus mechanisms\n    - Advances in zero knowledge, MPC, PQC that could impact future L1/L2 chains\n    - DeFi modeling, AMMs, MEV, risk models, liquidity dynamics\n    - Smart contract security, attack vectors, economic incentives\n    - Token economics, mechanism design for decentralized systems\n    - Quantum threats to blockchain or cryptography\n    - Any breakthrough that meaningfully improves decentralization, scalability, privacy, or composability\n\n    Output instructions:\n\n    - Output each JSON object in JSON Lines format (one line per paper).\n\n    {\n        \"title\": title of the paper (in Japanese),\n        \"summary\": A concise summary of the paper (in Japanese),\n        \"impact_level\": \"Highest|High|Medium|Low|Lowest\",\n        \"why_matters\": An array (JSON array) containing 2\u20134 bullet points explaining why this paper matters for Web3 investment\n    }\n\n    - Do not output anything except valid JSON object in JSON Lines.\n    - \"title\", \"summary\", \"why_matters\" text in the output must be written in Japanese.\n\n    Paper:\n    title: BugSweeper: Function-Level Detection of Smart Contract Vulnerabilities Using Graph Neural Networks\n    summary: The rapid growth of Ethereum has made it more important to quickly and accurately detect smart contract vulnerabilities. While machine-learning-based methods have shown some promise, many still rely on rule-based preprocessing designed by domain experts. Rule-based preprocessing methods often discard crucial context from the source code, potentially causing certain vulnerabilities to be overlooked and limiting adaptability to newly emerging threats. We introduce BugSweeper, an end-to-end deep learning framework that detects vulnerabilities directly from the source code without manual engineering. BugSweeper represents each Solidity function as a Function-Level Abstract Syntax Graph (FLAG), a novel graph that combines its Abstract Syntax Tree (AST) with enriched control-flow and data-flow semantics. Then, our two-stage Graph Neural Network (GNN) analyzes these graphs. The first-stage GNN filters noise from the syntax graphs, while the second-stage GNN conducts high-level reasoning to detect diverse vulnerabilities. Extensive experiments on real-world contracts show that BugSweeper significantly outperforms all state-of-the-art detection methods. By removing the need for handcrafted rules, our approach offers a robust, automated, and scalable solution for securing smart contracts without any dependence on security experts.\n    link: https://arxiv.org/abs/2512.09385v1\n    "}}
{"custom_id": "2511.11914v2", "method": "POST", "url": "/v1/responses", "body": {"model": "gpt-5-mini", "input": "You are a specialist research analyst in Web3, DeFi, cryptography, and distributed systems.\n\n    Your task:\n    From the paper below (Title + Summary + Link), evaluate how useful each paper is for understanding investment opportunities or technological advantages within the Web3 / crypto / DeFi ecosystem.\n    Rate each paper on a five-level scale: Highest / High / Medium / Low / Lowest.\n\n    \"Useful\" means:\n\n    - Improves understanding of new cryptographic primitives relevant to blockchain performance or security\n    - Enhances scalability: distributed systems, P2P networking, consensus mechanisms\n    - Advances in zero knowledge, MPC, PQC that could impact future L1/L2 chains\n    - DeFi modeling, AMMs, MEV, risk models, liquidity dynamics\n    - Smart contract security, attack vectors, economic incentives\n    - Token economics, mechanism design for decentralized systems\n    - Quantum threats to blockchain or cryptography\n    - Any breakthrough that meaningfully improves decentralization, scalability, privacy, or composability\n\n    Output instructions:\n\n    - Output each JSON object in JSON Lines format (one line per paper).\n\n    {\n        \"title\": title of the paper (in Japanese),\n        \"summary\": A concise summary of the paper (in Japanese),\n        \"impact_level\": \"Highest|High|Medium|Low|Lowest\",\n        \"why_matters\": An array (JSON array) containing 2\u20134 bullet points explaining why this paper matters for Web3 investment\n    }\n\n    - Do not output anything except valid JSON object in JSON Lines.\n    - \"title\", \"summary\", \"why_matters\" text in the output must be written in Japanese.\n\n    Paper:\n    title: Forgetting-MarI: LLM Unlearning via Marginal Information Regularization\n    summary: As AI models are trained on ever-expanding datasets, the ability to remove the influence of specific data from trained models has become essential for privacy protection and regulatory compliance. Unlearning addresses this challenge by selectively removing parametric knowledge from the trained models without retraining from scratch, which is critical for resource-intensive models such as Large Language Models (LLMs). Existing unlearning methods often degrade model performance by removing more information than necessary when attempting to ''forget'' specific data. We introduce Forgetting-MarI, an LLM unlearning framework that provably removes only the additional (marginal) information contributed by the data to be unlearned, while preserving the information supported by the data to be retained. By penalizing marginal information, our method yields an explicit upper bound on the unlearn dataset's residual influence in the trained models, providing provable undetectability. Extensive experiments confirm that our approach outperforms current state-of-the-art unlearning methods, delivering reliable forgetting and better preserved general model performance across diverse benchmarks. This advancement represents an important step toward making AI systems more controllable and compliant with privacy and copyright regulations without compromising their effectiveness.\n    link: https://arxiv.org/abs/2511.11914v2\n    "}}
{"custom_id": "2502.00702v2", "method": "POST", "url": "/v1/responses", "body": {"model": "gpt-5-mini", "input": "You are a specialist research analyst in Web3, DeFi, cryptography, and distributed systems.\n\n    Your task:\n    From the paper below (Title + Summary + Link), evaluate how useful each paper is for understanding investment opportunities or technological advantages within the Web3 / crypto / DeFi ecosystem.\n    Rate each paper on a five-level scale: Highest / High / Medium / Low / Lowest.\n\n    \"Useful\" means:\n\n    - Improves understanding of new cryptographic primitives relevant to blockchain performance or security\n    - Enhances scalability: distributed systems, P2P networking, consensus mechanisms\n    - Advances in zero knowledge, MPC, PQC that could impact future L1/L2 chains\n    - DeFi modeling, AMMs, MEV, risk models, liquidity dynamics\n    - Smart contract security, attack vectors, economic incentives\n    - Token economics, mechanism design for decentralized systems\n    - Quantum threats to blockchain or cryptography\n    - Any breakthrough that meaningfully improves decentralization, scalability, privacy, or composability\n\n    Output instructions:\n\n    - Output each JSON object in JSON Lines format (one line per paper).\n\n    {\n        \"title\": title of the paper (in Japanese),\n        \"summary\": A concise summary of the paper (in Japanese),\n        \"impact_level\": \"Highest|High|Medium|Low|Lowest\",\n        \"why_matters\": An array (JSON array) containing 2\u20134 bullet points explaining why this paper matters for Web3 investment\n    }\n\n    - Do not output anything except valid JSON object in JSON Lines.\n    - \"title\", \"summary\", \"why_matters\" text in the output must be written in Japanese.\n\n    Paper:\n    title: CardioLive: Empowering Video Streaming with Online Cardiac Monitoring\n    summary: Online Cardiac Monitoring (OCM) emerges as a compelling enhancement for the next-generation video streaming platforms. It enables various applications including remote health, online affective computing, and deepfake detection. Yet the physiological information encapsulated in the video streams has been long neglected. In this paper, we present the design and implementation of CardioLive, the first online cardiac monitoring system in video streaming platforms. We leverage the naturally co-existed video and audio streams and devise CardioNet, the first audio-visual network to learn the cardiac series. It incorporates multiple unique designs to extract temporal and spectral features, ensuring robust performance under realistic video streaming conditions. To enable the Service-On-Demand online cardiac monitoring, we implement CardioLive as a plug-and-play middleware service and develop systematic solutions to practical issues including changing FPS and unsynchronized streams. Extensive experiments have been done to demonstrate the effectiveness of our system. We achieve a Mean Square Error (MAE) of 1.79 BPM error, outperforming the video-only and audio-only solutions by 69.2% and 81.2%, respectively. Our CardioLive service achieves average throughputs of 115.97 and 98.16 FPS when implemented in Zoom and YouTube. We believe our work opens up new applications for video stream systems. We will release the code soon.\n    link: https://arxiv.org/abs/2502.00702v2\n    "}}
{"custom_id": "2512.09362v1", "method": "POST", "url": "/v1/responses", "body": {"model": "gpt-5-mini", "input": "You are a specialist research analyst in Web3, DeFi, cryptography, and distributed systems.\n\n    Your task:\n    From the paper below (Title + Summary + Link), evaluate how useful each paper is for understanding investment opportunities or technological advantages within the Web3 / crypto / DeFi ecosystem.\n    Rate each paper on a five-level scale: Highest / High / Medium / Low / Lowest.\n\n    \"Useful\" means:\n\n    - Improves understanding of new cryptographic primitives relevant to blockchain performance or security\n    - Enhances scalability: distributed systems, P2P networking, consensus mechanisms\n    - Advances in zero knowledge, MPC, PQC that could impact future L1/L2 chains\n    - DeFi modeling, AMMs, MEV, risk models, liquidity dynamics\n    - Smart contract security, attack vectors, economic incentives\n    - Token economics, mechanism design for decentralized systems\n    - Quantum threats to blockchain or cryptography\n    - Any breakthrough that meaningfully improves decentralization, scalability, privacy, or composability\n\n    Output instructions:\n\n    - Output each JSON object in JSON Lines format (one line per paper).\n\n    {\n        \"title\": title of the paper (in Japanese),\n        \"summary\": A concise summary of the paper (in Japanese),\n        \"impact_level\": \"Highest|High|Medium|Low|Lowest\",\n        \"why_matters\": An array (JSON array) containing 2\u20134 bullet points explaining why this paper matters for Web3 investment\n    }\n\n    - Do not output anything except valid JSON object in JSON Lines.\n    - \"title\", \"summary\", \"why_matters\" text in the output must be written in Japanese.\n\n    Paper:\n    title: Routes of Transport in the Path Integral Lindblad Dynamics through State-to-State Analysis\n    summary: Analyzing routes of transport for open quantum systems with non-equilibrium initial conditions is extremely challenging. The state-to-state approach [A. Bose, and P.L. Walters, J. Chem. Theory Comput. 2023, 19, 15, 4828-4836] has proven to be a useful method for understanding transport mechanisms in quantum systems interacting with dissipative thermal baths, and has been recently extended to non-Hermitian systems to account for empirical loss. These non-Hermitian descriptions are, however, not capable of describing empirical processes of more general nature, including but not limited to a variety of pumping processes. We extend the state-to-state analysis to account for Lindbladian descriptions of generic dissipative, pumping and decohering processes acting on a system which is exchanging energy with a thermal bath. This Lindblad state-to-state method can elucidate routes of transport in systems coupled to a bath and additionally acted upon by Lindblad jump operators. The method is demonstrated using examples of excitonic aggregates subject to incoherent pumping and draining processes. Using this new state-to-state formalism, we demonstrate the establishment of steady-state excitonic currents across molecular aggregates, yielding a different first-principles approach to quantifying the same.\n    link: https://arxiv.org/abs/2512.09362v1\n    "}}
{"custom_id": "2512.09345v1", "method": "POST", "url": "/v1/responses", "body": {"model": "gpt-5-mini", "input": "You are a specialist research analyst in Web3, DeFi, cryptography, and distributed systems.\n\n    Your task:\n    From the paper below (Title + Summary + Link), evaluate how useful each paper is for understanding investment opportunities or technological advantages within the Web3 / crypto / DeFi ecosystem.\n    Rate each paper on a five-level scale: Highest / High / Medium / Low / Lowest.\n\n    \"Useful\" means:\n\n    - Improves understanding of new cryptographic primitives relevant to blockchain performance or security\n    - Enhances scalability: distributed systems, P2P networking, consensus mechanisms\n    - Advances in zero knowledge, MPC, PQC that could impact future L1/L2 chains\n    - DeFi modeling, AMMs, MEV, risk models, liquidity dynamics\n    - Smart contract security, attack vectors, economic incentives\n    - Token economics, mechanism design for decentralized systems\n    - Quantum threats to blockchain or cryptography\n    - Any breakthrough that meaningfully improves decentralization, scalability, privacy, or composability\n\n    Output instructions:\n\n    - Output each JSON object in JSON Lines format (one line per paper).\n\n    {\n        \"title\": title of the paper (in Japanese),\n        \"summary\": A concise summary of the paper (in Japanese),\n        \"impact_level\": \"Highest|High|Medium|Low|Lowest\",\n        \"why_matters\": An array (JSON array) containing 2\u20134 bullet points explaining why this paper matters for Web3 investment\n    }\n\n    - Do not output anything except valid JSON object in JSON Lines.\n    - \"title\", \"summary\", \"why_matters\" text in the output must be written in Japanese.\n\n    Paper:\n    title: Eunomia: A Multicontroller Domain Partitioning Framework in Hierarchical Satellite Network\n    summary: With the rise of mega-satellite constellations, the integration of hierarchical non-terrestrial and terrestrial networks has become a cornerstone of 6G coverage enhancements. In these hierarchical satellite networks, controllers manage satellite switches within their assigned domains. However, the high mobility of LEO satellites and field-of-view (FOV) constraints pose fundamental challenges to efficient domain partitioning. Centralized control approaches face scalability bottlenecks, while distributed architectures with onboard controllers often disregard FOV limitations, leading to excessive signaling overhead. LEO satellites outside a controller's FOV require an average of five additional hops, resulting in a 10.6-fold increase in response time. To address these challenges, we propose Eunomia, a three-step domain-partitioning framework that leverages movement-aware FOV segmentation within a hybrid control plane combining ground stations and MEO satellites. Eunomia reduces control plane latency by constraining domains to FOV-aware regions and ensures single-hop signaling. It further balances traffic load through spectral clustering on a Control Overhead Relationship Graph and optimizes controller assignment via the Kuhn-Munkres algorithm. We implement Eunomia on the Plotinus emulation platform with realistic constellation parameters. Experimental results demonstrate that Eunomia reduces request loss by up to 58.3%, control overhead by up to 50.3\\%, and algorithm execution time by 77.7% significantly outperforming current state-of-the-art solutions.\n    link: https://arxiv.org/abs/2512.09345v1\n    "}}
{"custom_id": "2512.09331v1", "method": "POST", "url": "/v1/responses", "body": {"model": "gpt-5-mini", "input": "You are a specialist research analyst in Web3, DeFi, cryptography, and distributed systems.\n\n    Your task:\n    From the paper below (Title + Summary + Link), evaluate how useful each paper is for understanding investment opportunities or technological advantages within the Web3 / crypto / DeFi ecosystem.\n    Rate each paper on a five-level scale: Highest / High / Medium / Low / Lowest.\n\n    \"Useful\" means:\n\n    - Improves understanding of new cryptographic primitives relevant to blockchain performance or security\n    - Enhances scalability: distributed systems, P2P networking, consensus mechanisms\n    - Advances in zero knowledge, MPC, PQC that could impact future L1/L2 chains\n    - DeFi modeling, AMMs, MEV, risk models, liquidity dynamics\n    - Smart contract security, attack vectors, economic incentives\n    - Token economics, mechanism design for decentralized systems\n    - Quantum threats to blockchain or cryptography\n    - Any breakthrough that meaningfully improves decentralization, scalability, privacy, or composability\n\n    Output instructions:\n\n    - Output each JSON object in JSON Lines format (one line per paper).\n\n    {\n        \"title\": title of the paper (in Japanese),\n        \"summary\": A concise summary of the paper (in Japanese),\n        \"impact_level\": \"Highest|High|Medium|Low|Lowest\",\n        \"why_matters\": An array (JSON array) containing 2\u20134 bullet points explaining why this paper matters for Web3 investment\n    }\n\n    - Do not output anything except valid JSON object in JSON Lines.\n    - \"title\", \"summary\", \"why_matters\" text in the output must be written in Japanese.\n\n    Paper:\n    title: Passing the Baton: High Throughput Distributed Disk-Based Vector Search with BatANN\n    summary: Vector search underpins modern information-retrieval systems, including retrieval-augmented generation (RAG) pipelines and search engines over unstructured text and images. As datasets scale to billions of vectors, disk-based vector search has emerged as a practical solution. However, looking to the future, we need to anticipate datasets too large for any single server. We present BatANN, a distributed disk-based approximate nearest neighbor (ANN) system that retains the logarithmic search efficiency of a single global graph while achieving near-linear throughput scaling in the number of servers. Our core innovation is that when accessing a neighborhood which is stored on another machine, we send the full state of the query to the other machine to continue executing there for improved locality. On 100M- and 1B-point datasets at 0.95 recall using 10 servers, BatANN achieves 6.21-6.49x and 2.5-5.10x the throughput of the scatter-gather baseline, respectively, while maintaining mean latency below 6 ms. Moreover, we get these results on standard TCP. To our knowledge, BatANN is the first open-source distributed disk-based vector search system to operate over a single global graph.\n    link: https://arxiv.org/abs/2512.09331v1\n    "}}
{"custom_id": "2512.09324v1", "method": "POST", "url": "/v1/responses", "body": {"model": "gpt-5-mini", "input": "You are a specialist research analyst in Web3, DeFi, cryptography, and distributed systems.\n\n    Your task:\n    From the paper below (Title + Summary + Link), evaluate how useful each paper is for understanding investment opportunities or technological advantages within the Web3 / crypto / DeFi ecosystem.\n    Rate each paper on a five-level scale: Highest / High / Medium / Low / Lowest.\n\n    \"Useful\" means:\n\n    - Improves understanding of new cryptographic primitives relevant to blockchain performance or security\n    - Enhances scalability: distributed systems, P2P networking, consensus mechanisms\n    - Advances in zero knowledge, MPC, PQC that could impact future L1/L2 chains\n    - DeFi modeling, AMMs, MEV, risk models, liquidity dynamics\n    - Smart contract security, attack vectors, economic incentives\n    - Token economics, mechanism design for decentralized systems\n    - Quantum threats to blockchain or cryptography\n    - Any breakthrough that meaningfully improves decentralization, scalability, privacy, or composability\n\n    Output instructions:\n\n    - Output each JSON object in JSON Lines format (one line per paper).\n\n    {\n        \"title\": title of the paper (in Japanese),\n        \"summary\": A concise summary of the paper (in Japanese),\n        \"impact_level\": \"Highest|High|Medium|Low|Lowest\",\n        \"why_matters\": An array (JSON array) containing 2\u20134 bullet points explaining why this paper matters for Web3 investment\n    }\n\n    - Do not output anything except valid JSON object in JSON Lines.\n    - \"title\", \"summary\", \"why_matters\" text in the output must be written in Japanese.\n\n    Paper:\n    title: Mpemba as an Emergent Effect of System Relaxation\n    summary: The Mpemba effect (MpE), where a far-from-equilibrium state of a system relaxes faster compared to a state closer to it, is a well-known counterintuitive phenomenon in classical and quantum systems. Various system-specific theories have been proposed to explain this anomalous behavior in driven systems, though the fundamental mechanism of MpE in undriven systems, where MpE was first observed, remains unresolved. This paper provides a generic model of MpE for a quantum system following Markovian relaxation dynamics, regardless of system structure or environment. The key lies in the overlap of initial states with the fast relaxation mode; here, the constituents create a fast decay mode via interaction through the shared environment to show MpE, indicating MpE happens due to the collective behavior of the system. I also show that a system with anisotropic relaxation naturally exhibits MpE, even without a shared environment among the particles.\n    link: https://arxiv.org/abs/2512.09324v1\n    "}}
{"custom_id": "2512.09321v1", "method": "POST", "url": "/v1/responses", "body": {"model": "gpt-5-mini", "input": "You are a specialist research analyst in Web3, DeFi, cryptography, and distributed systems.\n\n    Your task:\n    From the paper below (Title + Summary + Link), evaluate how useful each paper is for understanding investment opportunities or technological advantages within the Web3 / crypto / DeFi ecosystem.\n    Rate each paper on a five-level scale: Highest / High / Medium / Low / Lowest.\n\n    \"Useful\" means:\n\n    - Improves understanding of new cryptographic primitives relevant to blockchain performance or security\n    - Enhances scalability: distributed systems, P2P networking, consensus mechanisms\n    - Advances in zero knowledge, MPC, PQC that could impact future L1/L2 chains\n    - DeFi modeling, AMMs, MEV, risk models, liquidity dynamics\n    - Smart contract security, attack vectors, economic incentives\n    - Token economics, mechanism design for decentralized systems\n    - Quantum threats to blockchain or cryptography\n    - Any breakthrough that meaningfully improves decentralization, scalability, privacy, or composability\n\n    Output instructions:\n\n    - Output each JSON object in JSON Lines format (one line per paper).\n\n    {\n        \"title\": title of the paper (in Japanese),\n        \"summary\": A concise summary of the paper (in Japanese),\n        \"impact_level\": \"Highest|High|Medium|Low|Lowest\",\n        \"why_matters\": An array (JSON array) containing 2\u20134 bullet points explaining why this paper matters for Web3 investment\n    }\n\n    - Do not output anything except valid JSON object in JSON Lines.\n    - \"title\", \"summary\", \"why_matters\" text in the output must be written in Japanese.\n\n    Paper:\n    title: ObliInjection: Order-Oblivious Prompt Injection Attack to LLM Agents with Multi-source Data\n    summary: Prompt injection attacks aim to contaminate the input data of an LLM to mislead it into completing an attacker-chosen task instead of the intended task. In many applications and agents, the input data originates from multiple sources, with each source contributing a segment of the overall input. In these multi-source scenarios, an attacker may control only a subset of the sources and contaminate the corresponding segments, but typically does not know the order in which the segments are arranged within the input. Existing prompt injection attacks either assume that the entire input data comes from a single source under the attacker's control or ignore the uncertainty in the ordering of segments from different sources. As a result, their success is limited in domains involving multi-source data.\n  In this work, we propose ObliInjection, the first prompt injection attack targeting LLM applications and agents with multi-source input data. ObliInjection introduces two key technical innovations: the order-oblivious loss, which quantifies the likelihood that the LLM will complete the attacker-chosen task regardless of how the clean and contaminated segments are ordered; and the orderGCG algorithm, which is tailored to minimize the order-oblivious loss and optimize the contaminated segments. Comprehensive experiments across three datasets spanning diverse application domains and twelve LLMs demonstrate that ObliInjection is highly effective, even when only one out of 6-100 segments in the input data is contaminated.\n    link: https://arxiv.org/abs/2512.09321v1\n    "}}
{"custom_id": "2512.09312v1", "method": "POST", "url": "/v1/responses", "body": {"model": "gpt-5-mini", "input": "You are a specialist research analyst in Web3, DeFi, cryptography, and distributed systems.\n\n    Your task:\n    From the paper below (Title + Summary + Link), evaluate how useful each paper is for understanding investment opportunities or technological advantages within the Web3 / crypto / DeFi ecosystem.\n    Rate each paper on a five-level scale: Highest / High / Medium / Low / Lowest.\n\n    \"Useful\" means:\n\n    - Improves understanding of new cryptographic primitives relevant to blockchain performance or security\n    - Enhances scalability: distributed systems, P2P networking, consensus mechanisms\n    - Advances in zero knowledge, MPC, PQC that could impact future L1/L2 chains\n    - DeFi modeling, AMMs, MEV, risk models, liquidity dynamics\n    - Smart contract security, attack vectors, economic incentives\n    - Token economics, mechanism design for decentralized systems\n    - Quantum threats to blockchain or cryptography\n    - Any breakthrough that meaningfully improves decentralization, scalability, privacy, or composability\n\n    Output instructions:\n\n    - Output each JSON object in JSON Lines format (one line per paper).\n\n    {\n        \"title\": title of the paper (in Japanese),\n        \"summary\": A concise summary of the paper (in Japanese),\n        \"impact_level\": \"Highest|High|Medium|Low|Lowest\",\n        \"why_matters\": An array (JSON array) containing 2\u20134 bullet points explaining why this paper matters for Web3 investment\n    }\n\n    - Do not output anything except valid JSON object in JSON Lines.\n    - \"title\", \"summary\", \"why_matters\" text in the output must be written in Japanese.\n\n    Paper:\n    title: Tyche: A Hybrid Computation Framework of Illumination Pattern for Satellite Beam Hopping\n    summary: High-Throughput Satellites (HTS) use beam hopping to handle non-uniform and time-varying ground traffic demand. A significant technical challenge in beam hopping is the computation of effective illumination patterns. Traditional algorithms, like the genetic algorithm, require over 300 seconds to compute a single illumination pattern for just 37 cells, whereas modern HTS typically covers over 300 cells, rendering current methods impractical for real-world applications. Advanced approaches, such as multi-agent deep reinforcement learning, face convergence issues when the number of cells exceeds 40. In this paper, we introduce Tyche, a hybrid computation framework designed to address this challenge. Tyche incorporates a Monte Carlo Tree Search Beam Hopping (MCTS-BH) algorithm for computing illumination patterns and employs sliding window and pruning techniques to significantly reduce computation time. Specifically, MCTS-BH can compute one illumination pattern for 37 cells in just 12 seconds. To ensure real-time computation, we use a Greedy Beam Hopping (G-BH) algorithm, which provides a provisional solution while MCTS-BH completes its computation in the background. Our evaluation results show that MCTS-BH can increase throughput by up to 98.76%, demonstrating substantial improvements over existing solutions.\n    link: https://arxiv.org/abs/2512.09312v1\n    "}}
{"custom_id": "2512.09311v1", "method": "POST", "url": "/v1/responses", "body": {"model": "gpt-5-mini", "input": "You are a specialist research analyst in Web3, DeFi, cryptography, and distributed systems.\n\n    Your task:\n    From the paper below (Title + Summary + Link), evaluate how useful each paper is for understanding investment opportunities or technological advantages within the Web3 / crypto / DeFi ecosystem.\n    Rate each paper on a five-level scale: Highest / High / Medium / Low / Lowest.\n\n    \"Useful\" means:\n\n    - Improves understanding of new cryptographic primitives relevant to blockchain performance or security\n    - Enhances scalability: distributed systems, P2P networking, consensus mechanisms\n    - Advances in zero knowledge, MPC, PQC that could impact future L1/L2 chains\n    - DeFi modeling, AMMs, MEV, risk models, liquidity dynamics\n    - Smart contract security, attack vectors, economic incentives\n    - Token economics, mechanism design for decentralized systems\n    - Quantum threats to blockchain or cryptography\n    - Any breakthrough that meaningfully improves decentralization, scalability, privacy, or composability\n\n    Output instructions:\n\n    - Output each JSON object in JSON Lines format (one line per paper).\n\n    {\n        \"title\": title of the paper (in Japanese),\n        \"summary\": A concise summary of the paper (in Japanese),\n        \"impact_level\": \"Highest|High|Medium|Low|Lowest\",\n        \"why_matters\": An array (JSON array) containing 2\u20134 bullet points explaining why this paper matters for Web3 investment\n    }\n\n    - Do not output anything except valid JSON object in JSON Lines.\n    - \"title\", \"summary\", \"why_matters\" text in the output must be written in Japanese.\n\n    Paper:\n    title: Transformer-Driven Multimodal Fusion for Explainable Suspiciousness Estimation in Visual Surveillance\n    summary: Suspiciousness estimation is critical for proactive threat detection and ensuring public safety in complex environments. This work introduces a large-scale annotated dataset, USE50k, along with a computationally efficient vision-based framework for real-time suspiciousness analysis. The USE50k dataset contains 65,500 images captured from diverse and uncontrolled environments, such as airports, railway stations, restaurants, parks, and other public areas, covering a broad spectrum of cues including weapons, fire, crowd density, abnormal facial expressions, and unusual body postures. Building on this dataset, we present DeepUSEvision, a lightweight and modular system integrating three key components, i.e., a Suspicious Object Detector based on an enhanced YOLOv12 architecture, dual Deep Convolutional Neural Networks (DCNN-I and DCNN-II) for facial expression and body-language recognition using image and landmark features, and a transformer-based Discriminator Network that adaptively fuses multimodal outputs to yield an interpretable suspiciousness score. Extensive experiments confirm the superior accuracy, robustness, and interpretability of the proposed framework compared to state-of-the-art approaches. Collectively, the USE50k dataset and the DeepUSEvision framework establish a strong and scalable foundation for intelligent surveillance and real-time risk assessment in safety-critical applications.\n    link: https://arxiv.org/abs/2512.09311v1\n    "}}
{"custom_id": "2512.09309v1", "method": "POST", "url": "/v1/responses", "body": {"model": "gpt-5-mini", "input": "You are a specialist research analyst in Web3, DeFi, cryptography, and distributed systems.\n\n    Your task:\n    From the paper below (Title + Summary + Link), evaluate how useful each paper is for understanding investment opportunities or technological advantages within the Web3 / crypto / DeFi ecosystem.\n    Rate each paper on a five-level scale: Highest / High / Medium / Low / Lowest.\n\n    \"Useful\" means:\n\n    - Improves understanding of new cryptographic primitives relevant to blockchain performance or security\n    - Enhances scalability: distributed systems, P2P networking, consensus mechanisms\n    - Advances in zero knowledge, MPC, PQC that could impact future L1/L2 chains\n    - DeFi modeling, AMMs, MEV, risk models, liquidity dynamics\n    - Smart contract security, attack vectors, economic incentives\n    - Token economics, mechanism design for decentralized systems\n    - Quantum threats to blockchain or cryptography\n    - Any breakthrough that meaningfully improves decentralization, scalability, privacy, or composability\n\n    Output instructions:\n\n    - Output each JSON object in JSON Lines format (one line per paper).\n\n    {\n        \"title\": title of the paper (in Japanese),\n        \"summary\": A concise summary of the paper (in Japanese),\n        \"impact_level\": \"Highest|High|Medium|Low|Lowest\",\n        \"why_matters\": An array (JSON array) containing 2\u20134 bullet points explaining why this paper matters for Web3 investment\n    }\n\n    - Do not output anything except valid JSON object in JSON Lines.\n    - \"title\", \"summary\", \"why_matters\" text in the output must be written in Japanese.\n\n    Paper:\n    title: A Distributed Framework for Privacy-Enhanced Vision Transformers on the Edge\n    summary: Nowadays, visual intelligence tools have become ubiquitous, offering all kinds of convenience and possibilities. However, these tools have high computational requirements that exceed the capabilities of resource-constrained mobile and wearable devices. While offloading visual data to the cloud is a common solution, it introduces significant privacy vulnerabilities during transmission and server-side computation. To address this, we propose a novel distributed, hierarchical offloading framework for Vision Transformers (ViTs) that addresses these privacy challenges by design. Our approach uses a local trusted edge device, such as a mobile phone or an Nvidia Jetson, as the edge orchestrator. This orchestrator partitions the user's visual data into smaller portions and distributes them across multiple independent cloud servers. By design, no single external server possesses the complete image, preventing comprehensive data reconstruction. The final data merging and aggregation computation occurs exclusively on the user's trusted edge device. We apply our framework to the Segment Anything Model (SAM) as a practical case study, which demonstrates that our method substantially enhances content privacy over traditional cloud-based approaches. Evaluations show our framework maintains near-baseline segmentation performance while substantially reducing the risk of content reconstruction and user data exposure. Our framework provides a scalable, privacy-preserving solution for vision tasks in the edge-cloud continuum.\n    link: https://arxiv.org/abs/2512.09309v1\n    "}}
{"custom_id": "2512.09300v1", "method": "POST", "url": "/v1/responses", "body": {"model": "gpt-5-mini", "input": "You are a specialist research analyst in Web3, DeFi, cryptography, and distributed systems.\n\n    Your task:\n    From the paper below (Title + Summary + Link), evaluate how useful each paper is for understanding investment opportunities or technological advantages within the Web3 / crypto / DeFi ecosystem.\n    Rate each paper on a five-level scale: Highest / High / Medium / Low / Lowest.\n\n    \"Useful\" means:\n\n    - Improves understanding of new cryptographic primitives relevant to blockchain performance or security\n    - Enhances scalability: distributed systems, P2P networking, consensus mechanisms\n    - Advances in zero knowledge, MPC, PQC that could impact future L1/L2 chains\n    - DeFi modeling, AMMs, MEV, risk models, liquidity dynamics\n    - Smart contract security, attack vectors, economic incentives\n    - Token economics, mechanism design for decentralized systems\n    - Quantum threats to blockchain or cryptography\n    - Any breakthrough that meaningfully improves decentralization, scalability, privacy, or composability\n\n    Output instructions:\n\n    - Output each JSON object in JSON Lines format (one line per paper).\n\n    {\n        \"title\": title of the paper (in Japanese),\n        \"summary\": A concise summary of the paper (in Japanese),\n        \"impact_level\": \"Highest|High|Medium|Low|Lowest\",\n        \"why_matters\": An array (JSON array) containing 2\u20134 bullet points explaining why this paper matters for Web3 investment\n    }\n\n    - Do not output anything except valid JSON object in JSON Lines.\n    - \"title\", \"summary\", \"why_matters\" text in the output must be written in Japanese.\n\n    Paper:\n    title: ZeroOS: A Universal Modular Library OS for zkVMs\n    summary: zkVMs promise general-purpose verifiable computation through ISA-level compatibility with modern programs and toolchains. However, compatibility extends further than just the ISA; modern programs often cannot run or even compile without an operating system and libc. zkVMs attempt to address this by maintaining forks of language-specific runtimes and statically linking them into applications to create self-contained unikernels, but this ad-hoc approach leads to version hell and burdens verifiable applications (vApps) with an unnecessarily large trusted computing base. We solve this problem with ZeroOS, a modular library operating system (libOS) for vApp unikernels; vApp developers can use off-the-shelf toolchains to compile and link only the exact subset of the Linux ABI their vApp needs. Any zkVM team can easily leverage the ZeroOS ecosystem by writing a ZeroOS bootloader for their platform, resulting in a reduced maintainence burden and unifying the entire zkVM ecosystem with consolidated development and audit resources. ZeroOS is free and open-sourced at https://github.com/LayerZero-Labs/ZeroOS.\n    link: https://arxiv.org/abs/2512.09300v1\n    "}}
{"custom_id": "2503.11901v4", "method": "POST", "url": "/v1/responses", "body": {"model": "gpt-5-mini", "input": "You are a specialist research analyst in Web3, DeFi, cryptography, and distributed systems.\n\n    Your task:\n    From the paper below (Title + Summary + Link), evaluate how useful each paper is for understanding investment opportunities or technological advantages within the Web3 / crypto / DeFi ecosystem.\n    Rate each paper on a five-level scale: Highest / High / Medium / Low / Lowest.\n\n    \"Useful\" means:\n\n    - Improves understanding of new cryptographic primitives relevant to blockchain performance or security\n    - Enhances scalability: distributed systems, P2P networking, consensus mechanisms\n    - Advances in zero knowledge, MPC, PQC that could impact future L1/L2 chains\n    - DeFi modeling, AMMs, MEV, risk models, liquidity dynamics\n    - Smart contract security, attack vectors, economic incentives\n    - Token economics, mechanism design for decentralized systems\n    - Quantum threats to blockchain or cryptography\n    - Any breakthrough that meaningfully improves decentralization, scalability, privacy, or composability\n\n    Output instructions:\n\n    - Output each JSON object in JSON Lines format (one line per paper).\n\n    {\n        \"title\": title of the paper (in Japanese),\n        \"summary\": A concise summary of the paper (in Japanese),\n        \"impact_level\": \"Highest|High|Medium|Low|Lowest\",\n        \"why_matters\": An array (JSON array) containing 2\u20134 bullet points explaining why this paper matters for Web3 investment\n    }\n\n    - Do not output anything except valid JSON object in JSON Lines.\n    - \"title\", \"summary\", \"why_matters\" text in the output must be written in Japanese.\n\n    Paper:\n    title: Story of Two GPUs: Characterizing the Resilience of Hopper H100 and Ampere A100 GPUs\n    summary: This study characterizes GPU resilience in Delta, a large-scale AI system that consists of 1,056 A100 and H100 GPUs, with over 1,300 petaflops of peak throughput. We used 2.5 years of operational data (11.7 million GPU hours) on GPU errors. Our major findings include: (i) H100 GPU memory resilience is worse than A100 GPU memory, with 3.2x lower per-GPU MTBE for memory errors, (ii) The GPU memory error-recovery mechanisms on H100 GPUs are insufficient to handle the increased memory capacity, (iii) H100 GPUs demonstrate significantly improved GPU hardware resilience over A100 GPUs with respect to critical hardware components, (iv) GPU errors on both A100 and H100 GPUs frequently result in job failures due to the lack of robust recovery mechanisms at the application level, and (v) We project the impact of GPU node availability on larger-scales and find that significant overprovisioning of 5% is necessary to handle GPU failures.\n    link: https://arxiv.org/abs/2503.11901v4\n    "}}
{"custom_id": "2512.06768v2", "method": "POST", "url": "/v1/responses", "body": {"model": "gpt-5-mini", "input": "You are a specialist research analyst in Web3, DeFi, cryptography, and distributed systems.\n\n    Your task:\n    From the paper below (Title + Summary + Link), evaluate how useful each paper is for understanding investment opportunities or technological advantages within the Web3 / crypto / DeFi ecosystem.\n    Rate each paper on a five-level scale: Highest / High / Medium / Low / Lowest.\n\n    \"Useful\" means:\n\n    - Improves understanding of new cryptographic primitives relevant to blockchain performance or security\n    - Enhances scalability: distributed systems, P2P networking, consensus mechanisms\n    - Advances in zero knowledge, MPC, PQC that could impact future L1/L2 chains\n    - DeFi modeling, AMMs, MEV, risk models, liquidity dynamics\n    - Smart contract security, attack vectors, economic incentives\n    - Token economics, mechanism design for decentralized systems\n    - Quantum threats to blockchain or cryptography\n    - Any breakthrough that meaningfully improves decentralization, scalability, privacy, or composability\n\n    Output instructions:\n\n    - Output each JSON object in JSON Lines format (one line per paper).\n\n    {\n        \"title\": title of the paper (in Japanese),\n        \"summary\": A concise summary of the paper (in Japanese),\n        \"impact_level\": \"Highest|High|Medium|Low|Lowest\",\n        \"why_matters\": An array (JSON array) containing 2\u20134 bullet points explaining why this paper matters for Web3 investment\n    }\n\n    - Do not output anything except valid JSON object in JSON Lines.\n    - \"title\", \"summary\", \"why_matters\" text in the output must be written in Japanese.\n\n    Paper:\n    title: Real-Time Dynamics in Two Dimensions with Tensor Network States via Time-Dependent Variational Monte Carlo\n    summary: Reliably simulating two-dimensional many-body quantum dynamics with projected entangled pair states (PEPS) has long been a difficult challenge. In this work, we overcome this barrier for low-energy quantum dynamics by developing a stable and efficient time-dependent variational Monte Carlo (tVMC) framework for PEPS. By analytically removing all gauge redundancies of the PEPS manifold and exploiting tensor locality, we obtain a numerically well-conditioned stochastic reconfiguration (SR) equation amenable to robust solution using the efficient Cholesky decomposition, enabling long-time evolution in previously inaccessible regimes. We demonstrate the power and generality of the method through four representative real-time problems in two dimensions: (I) chiral edge propagation in a free-fermion Chern insulator; (II) fractionalized charge transport in a fractional Chern insulator; (III) vison confinement dynamics in the Higgs phase of a Z2 lattice gauge theory; and (IV) superfluidity and critical velocity in interacting bosons. All simulations are performed on 12x12 or 13x13 lattices with evolution times T = 10 to 12 using modest computational resources (1 to 5 days on a single GPU card). Where exact benchmarks exist (case I), PEPS-tVMC matches free-fermion dynamics with high accuracy up to T = 12. These results establish PEPS-tVMC as a practical and versatile tool for real-time quantum dynamics in two dimensions. The method extends the reach of classical tensor-network simulations for studying elementary excitations in quantum many-body systems and provides a valuable computational counterpart to emerging quantum simulators.\n    link: https://arxiv.org/abs/2512.06768v2\n    "}}
{"custom_id": "2512.09277v1", "method": "POST", "url": "/v1/responses", "body": {"model": "gpt-5-mini", "input": "You are a specialist research analyst in Web3, DeFi, cryptography, and distributed systems.\n\n    Your task:\n    From the paper below (Title + Summary + Link), evaluate how useful each paper is for understanding investment opportunities or technological advantages within the Web3 / crypto / DeFi ecosystem.\n    Rate each paper on a five-level scale: Highest / High / Medium / Low / Lowest.\n\n    \"Useful\" means:\n\n    - Improves understanding of new cryptographic primitives relevant to blockchain performance or security\n    - Enhances scalability: distributed systems, P2P networking, consensus mechanisms\n    - Advances in zero knowledge, MPC, PQC that could impact future L1/L2 chains\n    - DeFi modeling, AMMs, MEV, risk models, liquidity dynamics\n    - Smart contract security, attack vectors, economic incentives\n    - Token economics, mechanism design for decentralized systems\n    - Quantum threats to blockchain or cryptography\n    - Any breakthrough that meaningfully improves decentralization, scalability, privacy, or composability\n\n    Output instructions:\n\n    - Output each JSON object in JSON Lines format (one line per paper).\n\n    {\n        \"title\": title of the paper (in Japanese),\n        \"summary\": A concise summary of the paper (in Japanese),\n        \"impact_level\": \"Highest|High|Medium|Low|Lowest\",\n        \"why_matters\": An array (JSON array) containing 2\u20134 bullet points explaining why this paper matters for Web3 investment\n    }\n\n    - Do not output anything except valid JSON object in JSON Lines.\n    - \"title\", \"summary\", \"why_matters\" text in the output must be written in Japanese.\n\n    Paper:\n    title: Efficient MoE Serving in the Memory-Bound Regime: Balance Activated Experts, Not Tokens\n    summary: Expert Parallelism (EP) permits Mixture of Experts (MoE) models to scale beyond a single GPU. To address load imbalance across GPUs in EP, existing approaches aim to balance the number of tokens each GPU processes. Surprisingly, we find that this objective degrades performance rather than improving it when processing is memory-bound - a common occurrence in MoE serving, especially in the decode phase. Our analysis reveals that balancing the number of tokens processed per GPU increases the number of activated experts, exacerbating memory pressure in the memory-bound regime.\n  We propose Minimum Expert Token ROuting, a novel token-routing algorithm for high-performance expert-parallel MoE serving in the memory-bound regime that balances the number of activated experts per GPU rather than token counts. METRO achieves near-optimal routing quality with minimal computational overhead by jointly optimizing algorithmic efficiency and leveraging the GPU's parallel processing power. To guarantee routing quality, METRO also employs a novel allGather scheme to gather global top-k knowledge, which has minimal overhead compared to conventional allToAll. Our evaluation of METRO against EPLB on both real systems (vLLM over 8 A100 GPUs) and a proprietary simulator (8-16 B200 GPUs) shows that METRO reduces decode latency by 11 - 22%, and total token throughput by 3 - 21% for Qwen3 and DeepSeek-V3 serving, where prefill and decode phases are co-deployed. In addition, by trading latency headroom for throughput, METRO improves decode throughput by up to 4.11x over EPLB at a fixed decode SLO.\n    link: https://arxiv.org/abs/2512.09277v1\n    "}}
{"custom_id": "2512.06253v2", "method": "POST", "url": "/v1/responses", "body": {"model": "gpt-5-mini", "input": "You are a specialist research analyst in Web3, DeFi, cryptography, and distributed systems.\n\n    Your task:\n    From the paper below (Title + Summary + Link), evaluate how useful each paper is for understanding investment opportunities or technological advantages within the Web3 / crypto / DeFi ecosystem.\n    Rate each paper on a five-level scale: Highest / High / Medium / Low / Lowest.\n\n    \"Useful\" means:\n\n    - Improves understanding of new cryptographic primitives relevant to blockchain performance or security\n    - Enhances scalability: distributed systems, P2P networking, consensus mechanisms\n    - Advances in zero knowledge, MPC, PQC that could impact future L1/L2 chains\n    - DeFi modeling, AMMs, MEV, risk models, liquidity dynamics\n    - Smart contract security, attack vectors, economic incentives\n    - Token economics, mechanism design for decentralized systems\n    - Quantum threats to blockchain or cryptography\n    - Any breakthrough that meaningfully improves decentralization, scalability, privacy, or composability\n\n    Output instructions:\n\n    - Output each JSON object in JSON Lines format (one line per paper).\n\n    {\n        \"title\": title of the paper (in Japanese),\n        \"summary\": A concise summary of the paper (in Japanese),\n        \"impact_level\": \"Highest|High|Medium|Low|Lowest\",\n        \"why_matters\": An array (JSON array) containing 2\u20134 bullet points explaining why this paper matters for Web3 investment\n    }\n\n    - Do not output anything except valid JSON object in JSON Lines.\n    - \"title\", \"summary\", \"why_matters\" text in the output must be written in Japanese.\n\n    Paper:\n    title: Privacy Loss of Noise Perturbation via Concentration Analysis of A Product Measure\n    summary: Noise perturbation is one of the most fundamental approaches for achieving $(\u03b5,\u03b4)$-differential privacy (DP) guarantees when releasing the result of a query or function $f(\\cdot)\\in\\mathbb{R}^M$ evaluated on a sensitive dataset $\\mathbf{x}$. In this approach, calibrated noise $\\mathbf{n}\\in\\mathbb{R}^M$ is used to obscure the difference vector $f(\\mathbf{x})-f(\\mathbf{x}')$, where $\\mathbf{x}'$ is known as a neighboring dataset. A DP guarantee is obtained by studying the tail probability bound of a privacy loss random variable (PLRV), defined as the Radon-Nikodym derivative between two distributions. When $\\mathbf{n}$ follows a multivariate Gaussian distribution, the PLRV is characterized as a specific univariate Gaussian. In this paper, we propose a novel scheme to generate $\\mathbf{n}$ by leveraging the fact that the perturbation noise is typically spherically symmetric (i.e., the distribution is rotationally invariant around the origin). The new noise generation scheme allows us to investigate the privacy loss from a geometric perspective and express the resulting PLRV using a product measure, $W\\times U$; measure $W$ is related to a radius random variable controlling the magnitude of $\\mathbf{n}$, while measure $U$ involves a directional random variable governing the angle between $\\mathbf{n}$ and the difference $f(\\mathbf{x})-f(\\mathbf{x}')$. We derive a closed-form moment bound on the product measure to prove $(\u03b5,\u03b4)$-DP. Under the same $(\u03b5,\u03b4)$-DP guarantee, our mechanism yields a smaller expected noise magnitude than the classic Gaussian noise in high dimensions, thereby significantly improving the utility of the noisy result $f(\\mathbf{x})+\\mathbf{n}$. To validate this, we consider convex and non-convex empirical risk minimization (ERM) problems in high dimensional space and apply the proposed product noise to achieve privacy.\n    link: https://arxiv.org/abs/2512.06253v2\n    "}}
{"custom_id": "2512.09264v1", "method": "POST", "url": "/v1/responses", "body": {"model": "gpt-5-mini", "input": "You are a specialist research analyst in Web3, DeFi, cryptography, and distributed systems.\n\n    Your task:\n    From the paper below (Title + Summary + Link), evaluate how useful each paper is for understanding investment opportunities or technological advantages within the Web3 / crypto / DeFi ecosystem.\n    Rate each paper on a five-level scale: Highest / High / Medium / Low / Lowest.\n\n    \"Useful\" means:\n\n    - Improves understanding of new cryptographic primitives relevant to blockchain performance or security\n    - Enhances scalability: distributed systems, P2P networking, consensus mechanisms\n    - Advances in zero knowledge, MPC, PQC that could impact future L1/L2 chains\n    - DeFi modeling, AMMs, MEV, risk models, liquidity dynamics\n    - Smart contract security, attack vectors, economic incentives\n    - Token economics, mechanism design for decentralized systems\n    - Quantum threats to blockchain or cryptography\n    - Any breakthrough that meaningfully improves decentralization, scalability, privacy, or composability\n\n    Output instructions:\n\n    - Output each JSON object in JSON Lines format (one line per paper).\n\n    {\n        \"title\": title of the paper (in Japanese),\n        \"summary\": A concise summary of the paper (in Japanese),\n        \"impact_level\": \"Highest|High|Medium|Low|Lowest\",\n        \"why_matters\": An array (JSON array) containing 2\u20134 bullet points explaining why this paper matters for Web3 investment\n    }\n\n    - Do not output anything except valid JSON object in JSON Lines.\n    - \"title\", \"summary\", \"why_matters\" text in the output must be written in Japanese.\n\n    Paper:\n    title: FBA$^2$D: Frequency-based Black-box Attack for AI-generated Image Detection\n    summary: The prosperous development of Artificial Intelligence-Generated Content (AIGC) has brought people's anxiety about the spread of false information on social media. Designing detectors for filtering is an effective defense method, but most detectors will be compromised by adversarial samples. Currently, most studies exposing AIGC security issues assume information on model structure and data distribution. In real applications, attackers query and interfere with models that provide services in the form of application programming interfaces (APIs), which constitutes the black-box decision-based attack paradigm. However, to the best of our knowledge, decision-based attacks on AIGC detectors remain unexplored. In this study, we propose \\textbf{FBA$^2$D}: a frequency-based black-box attack method for AIGC detection to fill the research gap. Motivated by frequency-domain discrepancies between generated and real images, we develop a decision-based attack that leverages the Discrete Cosine Transform (DCT) for fine-grained spectral partitioning and selects frequency bands as query subspaces, improving both query efficiency and image quality. Moreover, attacks on AIGC detectors should mitigate initialization failures, preserve image quality, and operate under strict query budgets. To address these issues, we adopt an ``adversarial example soup'' method, averaging candidates from successive surrogate iterations and using the result as the initialization to accelerate the query-based attack. The empirical study on the Synthetic LSUN dataset and GenImage dataset demonstrate the effectiveness of our prosed method. This study shows the urgency of addressing practical AIGC security problems.\n    link: https://arxiv.org/abs/2512.09264v1\n    "}}
{"custom_id": "2502.17801v3", "method": "POST", "url": "/v1/responses", "body": {"model": "gpt-5-mini", "input": "You are a specialist research analyst in Web3, DeFi, cryptography, and distributed systems.\n\n    Your task:\n    From the paper below (Title + Summary + Link), evaluate how useful each paper is for understanding investment opportunities or technological advantages within the Web3 / crypto / DeFi ecosystem.\n    Rate each paper on a five-level scale: Highest / High / Medium / Low / Lowest.\n\n    \"Useful\" means:\n\n    - Improves understanding of new cryptographic primitives relevant to blockchain performance or security\n    - Enhances scalability: distributed systems, P2P networking, consensus mechanisms\n    - Advances in zero knowledge, MPC, PQC that could impact future L1/L2 chains\n    - DeFi modeling, AMMs, MEV, risk models, liquidity dynamics\n    - Smart contract security, attack vectors, economic incentives\n    - Token economics, mechanism design for decentralized systems\n    - Quantum threats to blockchain or cryptography\n    - Any breakthrough that meaningfully improves decentralization, scalability, privacy, or composability\n\n    Output instructions:\n\n    - Output each JSON object in JSON Lines format (one line per paper).\n\n    {\n        \"title\": title of the paper (in Japanese),\n        \"summary\": A concise summary of the paper (in Japanese),\n        \"impact_level\": \"Highest|High|Medium|Low|Lowest\",\n        \"why_matters\": An array (JSON array) containing 2\u20134 bullet points explaining why this paper matters for Web3 investment\n    }\n\n    - Do not output anything except valid JSON object in JSON Lines.\n    - \"title\", \"summary\", \"why_matters\" text in the output must be written in Japanese.\n\n    Paper:\n    title: Research on Enhancing Cloud Computing Network Security using Artificial Intelligence Algorithms\n    summary: Cloud computing environments are increasingly vulnerable to security threats such as distributed denial-of-service (DDoS) attacks and SQL injection. Traditional security mechanisms, based on rule matching and feature recognition, struggle to adapt to evolving attack strategies. This paper proposes an adaptive security protection framework leveraging deep learning to construct a multi-layered defense architecture. The proposed system is evaluated in a real-world business environment, achieving a detection accuracy of 97.3%, an average response time of 18 ms, and an availability rate of 99.999%. Experimental results demonstrate that the proposed method significantly enhances detection accuracy, response efficiency, and resource utilization, offering a novel and effective approach to cloud computing security.\n    link: https://arxiv.org/abs/2502.17801v3\n    "}}
{"custom_id": "2512.09233v1", "method": "POST", "url": "/v1/responses", "body": {"model": "gpt-5-mini", "input": "You are a specialist research analyst in Web3, DeFi, cryptography, and distributed systems.\n\n    Your task:\n    From the paper below (Title + Summary + Link), evaluate how useful each paper is for understanding investment opportunities or technological advantages within the Web3 / crypto / DeFi ecosystem.\n    Rate each paper on a five-level scale: Highest / High / Medium / Low / Lowest.\n\n    \"Useful\" means:\n\n    - Improves understanding of new cryptographic primitives relevant to blockchain performance or security\n    - Enhances scalability: distributed systems, P2P networking, consensus mechanisms\n    - Advances in zero knowledge, MPC, PQC that could impact future L1/L2 chains\n    - DeFi modeling, AMMs, MEV, risk models, liquidity dynamics\n    - Smart contract security, attack vectors, economic incentives\n    - Token economics, mechanism design for decentralized systems\n    - Quantum threats to blockchain or cryptography\n    - Any breakthrough that meaningfully improves decentralization, scalability, privacy, or composability\n\n    Output instructions:\n\n    - Output each JSON object in JSON Lines format (one line per paper).\n\n    {\n        \"title\": title of the paper (in Japanese),\n        \"summary\": A concise summary of the paper (in Japanese),\n        \"impact_level\": \"Highest|High|Medium|Low|Lowest\",\n        \"why_matters\": An array (JSON array) containing 2\u20134 bullet points explaining why this paper matters for Web3 investment\n    }\n\n    - Do not output anything except valid JSON object in JSON Lines.\n    - \"title\", \"summary\", \"why_matters\" text in the output must be written in Japanese.\n\n    Paper:\n    title: Analysis of the Security Design, Engineering, and Implementation of the SecureDNA System\n    summary: We analyze security aspects of the SecureDNA system regarding its system design, engineering, and implementation. This system enables DNA synthesizers to screen order requests against a database of hazards. By applying novel cryptography, the system aims to keep order requests and the database of hazards secret. Discerning the detailed operation of the system in part from source code (Version 1.0.8), our analysis examines key management, certificate infrastructure, authentication, and rate-limiting mechanisms. We also perform the first formal-methods analysis of the mutual authentication, basic request, and exemption-handling protocols.\n  Without breaking the cryptography, our main finding is that SecureDNA's custom mutual authentication protocol SCEP achieves only one-way authentication: the hazards database and keyservers never learn with whom they communicate. This structural weakness violates the principle of defense in depth and enables an adversary to circumvent rate limits that protect the secrecy of the hazards database, if the synthesizer connects with a malicious or corrupted keyserver or hashed database. We point out an additional structural weakness that also violates the principle of defense in depth: inadequate cryptographic bindings prevent the system from detecting if responses, within a TLS channel, from the hazards database were modified. Consequently, if a synthesizer were to reconnect with the database over the same TLS session, an adversary could replay and swap responses from the database without breaking TLS. Although the SecureDNA implementation does not allow such reconnections, it would be stronger security engineering to avoid the underlying structural weakness. We identify these vulnerabilities and suggest and verify mitigations, including adding strong bindings. Software Version 1.1.0 fixes SCEP with our proposed SCEP+ protocol.\n    link: https://arxiv.org/abs/2512.09233v1\n    "}}
{"custom_id": "2510.15518v4", "method": "POST", "url": "/v1/responses", "body": {"model": "gpt-5-mini", "input": "You are a specialist research analyst in Web3, DeFi, cryptography, and distributed systems.\n\n    Your task:\n    From the paper below (Title + Summary + Link), evaluate how useful each paper is for understanding investment opportunities or technological advantages within the Web3 / crypto / DeFi ecosystem.\n    Rate each paper on a five-level scale: Highest / High / Medium / Low / Lowest.\n\n    \"Useful\" means:\n\n    - Improves understanding of new cryptographic primitives relevant to blockchain performance or security\n    - Enhances scalability: distributed systems, P2P networking, consensus mechanisms\n    - Advances in zero knowledge, MPC, PQC that could impact future L1/L2 chains\n    - DeFi modeling, AMMs, MEV, risk models, liquidity dynamics\n    - Smart contract security, attack vectors, economic incentives\n    - Token economics, mechanism design for decentralized systems\n    - Quantum threats to blockchain or cryptography\n    - Any breakthrough that meaningfully improves decentralization, scalability, privacy, or composability\n\n    Output instructions:\n\n    - Output each JSON object in JSON Lines format (one line per paper).\n\n    {\n        \"title\": title of the paper (in Japanese),\n        \"summary\": A concise summary of the paper (in Japanese),\n        \"impact_level\": \"Highest|High|Medium|Low|Lowest\",\n        \"why_matters\": An array (JSON array) containing 2\u20134 bullet points explaining why this paper matters for Web3 investment\n    }\n\n    - Do not output anything except valid JSON object in JSON Lines.\n    - \"title\", \"summary\", \"why_matters\" text in the output must be written in Japanese.\n\n    Paper:\n    title: Photonic Exceptional Points in Holography and QCD\n    summary: In this work, based on an analogy of holographic confining geometries and using complexified fields, we build the holographic toy model of third order photonic exceptional points (EPs) of ternary coupled microrings with gain and loss, which makes an open, non-Hermitian quantum system. In our model, we discuss the Ferrell-Glover-Tinkham sum rule for various combinations of gain and loss systems, and numerically find the behavior of spectra which matches with the experiments. We also discuss the inhomogeneous case of a holographic lattice for three-site photonic EPs. Additionally, in our holographic model, we numerically find the behavior of phase rigidity and the Petermann factor around EPs versus various parameters of the model. We also discuss the connections between recent developments in complexified, time-dependent entanglement entropy and EPs, and finally, we connect EPs and the $\u03b8$-vacuum of QCD through topological structures, partition functions, and winding numbers, and find a second-order EP in a perturbed $\u03b8$-vacuum model.\n    link: https://arxiv.org/abs/2510.15518v4\n    "}}
{"custom_id": "2511.03092v5", "method": "POST", "url": "/v1/responses", "body": {"model": "gpt-5-mini", "input": "You are a specialist research analyst in Web3, DeFi, cryptography, and distributed systems.\n\n    Your task:\n    From the paper below (Title + Summary + Link), evaluate how useful each paper is for understanding investment opportunities or technological advantages within the Web3 / crypto / DeFi ecosystem.\n    Rate each paper on a five-level scale: Highest / High / Medium / Low / Lowest.\n\n    \"Useful\" means:\n\n    - Improves understanding of new cryptographic primitives relevant to blockchain performance or security\n    - Enhances scalability: distributed systems, P2P networking, consensus mechanisms\n    - Advances in zero knowledge, MPC, PQC that could impact future L1/L2 chains\n    - DeFi modeling, AMMs, MEV, risk models, liquidity dynamics\n    - Smart contract security, attack vectors, economic incentives\n    - Token economics, mechanism design for decentralized systems\n    - Quantum threats to blockchain or cryptography\n    - Any breakthrough that meaningfully improves decentralization, scalability, privacy, or composability\n\n    Output instructions:\n\n    - Output each JSON object in JSON Lines format (one line per paper).\n\n    {\n        \"title\": title of the paper (in Japanese),\n        \"summary\": A concise summary of the paper (in Japanese),\n        \"impact_level\": \"Highest|High|Medium|Low|Lowest\",\n        \"why_matters\": An array (JSON array) containing 2\u20134 bullet points explaining why this paper matters for Web3 investment\n    }\n\n    - Do not output anything except valid JSON object in JSON Lines.\n    - \"title\", \"summary\", \"why_matters\" text in the output must be written in Japanese.\n\n    Paper:\n    title: SnapStream: Efficient Long Sequence Decoding on Dataflow Accelerators\n    summary: The proliferation of 100B+ parameter Large Language Models (LLMs) with 100k+ context length support have resulted in increasing demands for on-chip memory to support large KV caches. Techniques such as StreamingLLM and SnapKV demonstrate how to control KV cache size while maintaining model accuracy. Yet, these techniques are not commonly used within industrial deployments using frameworks like vLLM or SGLang. The reason is twofold: on one hand, the static graphs and continuous batching methodology employed by these frameworks make it difficult to admit modifications to the standard multi-head attention algorithm, while on the other hand, the accuracy implications of such techniques on modern instruction-following and reasoning models are not well understood, obfuscating the need for implementing these techniques. In this paper, we explore these accuracy implications on Llama-3.1-8B-Instruct and DeepSeek-R1, and develop SnapStream, a KV cache compression method that can be deployed at scale. We demonstrate the efficacy of SnapStream in a 16-way tensor-parallel deployment of DeepSeek-671B on SambaNova SN40L accelerators running at 128k context length and up to 1832 tokens per second in a real production setting. SnapStream enables $4\\times$ improved on-chip memory usage and introduces minimal accuracy degradation on LongBench-v2, AIME24 and LiveCodeBench. To the best of our knowledge, this is the first implementation of sparse KV attention techniques deployed in a production inference system with static graphs and continuous batching.\n    link: https://arxiv.org/abs/2511.03092v5\n    "}}
{"custom_id": "2512.09150v1", "method": "POST", "url": "/v1/responses", "body": {"model": "gpt-5-mini", "input": "You are a specialist research analyst in Web3, DeFi, cryptography, and distributed systems.\n\n    Your task:\n    From the paper below (Title + Summary + Link), evaluate how useful each paper is for understanding investment opportunities or technological advantages within the Web3 / crypto / DeFi ecosystem.\n    Rate each paper on a five-level scale: Highest / High / Medium / Low / Lowest.\n\n    \"Useful\" means:\n\n    - Improves understanding of new cryptographic primitives relevant to blockchain performance or security\n    - Enhances scalability: distributed systems, P2P networking, consensus mechanisms\n    - Advances in zero knowledge, MPC, PQC that could impact future L1/L2 chains\n    - DeFi modeling, AMMs, MEV, risk models, liquidity dynamics\n    - Smart contract security, attack vectors, economic incentives\n    - Token economics, mechanism design for decentralized systems\n    - Quantum threats to blockchain or cryptography\n    - Any breakthrough that meaningfully improves decentralization, scalability, privacy, or composability\n\n    Output instructions:\n\n    - Output each JSON object in JSON Lines format (one line per paper).\n\n    {\n        \"title\": title of the paper (in Japanese),\n        \"summary\": A concise summary of the paper (in Japanese),\n        \"impact_level\": \"Highest|High|Medium|Low|Lowest\",\n        \"why_matters\": An array (JSON array) containing 2\u20134 bullet points explaining why this paper matters for Web3 investment\n    }\n\n    - Do not output anything except valid JSON object in JSON Lines.\n    - \"title\", \"summary\", \"why_matters\" text in the output must be written in Japanese.\n\n    Paper:\n    title: Exposing Vulnerabilities in Counterfeit Prevention Systems Utilizing Physically Unclonable Surface Features\n    summary: Counterfeit products pose significant risks to public health and safety through infiltrating untrusted supply chains. Among numerous anti-counterfeiting techniques, leveraging inherent, unclonable microscopic irregularities of paper surfaces is an accurate and cost-effective solution. Prior work of this approach has focused on enabling ubiquitous acquisition of these physically unclonable features (PUFs). However, we will show that existing authentication methods relying on paper surface PUFs may be vulnerable to adversaries, resulting in a gap between technological feasibility and secure real-world deployment. This gap is investigated through formalizing an operational framework for paper-PUF-based authentication. Informed by this framework, we reveal system-level vulnerabilities across both physical and digital domains, designing physical denial-of-service and digital forgery attacks to disrupt proper authentication. The effectiveness of the designed attacks underscores the strong need for security countermeasures for reliable and resilient authentication based on paper PUFs. The proposed framework further facilitates a comprehensive, stage-by-stage security analysis, guiding the design of future counterfeit prevention systems. This analysis delves into potential attack strategies, offering a foundational understanding of how various system components, such as physical features and verification processes, might be exploited by adversaries.\n    link: https://arxiv.org/abs/2512.09150v1\n    "}}
{"custom_id": "2508.06783v2", "method": "POST", "url": "/v1/responses", "body": {"model": "gpt-5-mini", "input": "You are a specialist research analyst in Web3, DeFi, cryptography, and distributed systems.\n\n    Your task:\n    From the paper below (Title + Summary + Link), evaluate how useful each paper is for understanding investment opportunities or technological advantages within the Web3 / crypto / DeFi ecosystem.\n    Rate each paper on a five-level scale: Highest / High / Medium / Low / Lowest.\n\n    \"Useful\" means:\n\n    - Improves understanding of new cryptographic primitives relevant to blockchain performance or security\n    - Enhances scalability: distributed systems, P2P networking, consensus mechanisms\n    - Advances in zero knowledge, MPC, PQC that could impact future L1/L2 chains\n    - DeFi modeling, AMMs, MEV, risk models, liquidity dynamics\n    - Smart contract security, attack vectors, economic incentives\n    - Token economics, mechanism design for decentralized systems\n    - Quantum threats to blockchain or cryptography\n    - Any breakthrough that meaningfully improves decentralization, scalability, privacy, or composability\n\n    Output instructions:\n\n    - Output each JSON object in JSON Lines format (one line per paper).\n\n    {\n        \"title\": title of the paper (in Japanese),\n        \"summary\": A concise summary of the paper (in Japanese),\n        \"impact_level\": \"Highest|High|Medium|Low|Lowest\",\n        \"why_matters\": An array (JSON array) containing 2\u20134 bullet points explaining why this paper matters for Web3 investment\n    }\n\n    - Do not output anything except valid JSON object in JSON Lines.\n    - \"title\", \"summary\", \"why_matters\" text in the output must be written in Japanese.\n\n    Paper:\n    title: PROPS: Progressively Private Self-alignment of Large Language Models\n    summary: Alignment is a key step in developing Large Language Models (LLMs) using human feedback to ensure adherence to human values and societal norms. Dependence on human feedback raises privacy concerns about how much a labeler's preferences may reveal about their personal values, beliefs, and personality traits. Existing approaches, such as Differentially Private SGD (DP-SGD), provide rigorous privacy guarantees by privatizing gradients during fine-tuning and alignment but can provide more privacy than necessary as human preferences are tied only to labels of (prompt, response) pairs and can degrade model utility. This work focuses on LLM alignment with preference-level privacy, which preserves the privacy of preference labels provided by humans. We propose PROPS (PROgressively Private Self-alignment), a multi-stage privacy preserving alignment framework where privately aligned models in previous stages can serve as labelers for supplementing training data in the subsequent stages of alignment. We present theoretical guarantees for PROPS as well as comprehensive validation using multiple models (Pythia and GPT) and datasets (AlpacaEval, Anthropic HH-RLHF, truthy-dpo-v0.1) to demonstrate the utility of PROPS over existing methods while still providing high privacy. For the same privacy budget, alignment via PROPS can achieve up to 3x higher win-rates compared to DP-SGD, and 2.5x higher win-rates compared to Randomized Response (RR) based alignment.\n    link: https://arxiv.org/abs/2508.06783v2\n    "}}
{"custom_id": "2507.16890v2", "method": "POST", "url": "/v1/responses", "body": {"model": "gpt-5-mini", "input": "You are a specialist research analyst in Web3, DeFi, cryptography, and distributed systems.\n\n    Your task:\n    From the paper below (Title + Summary + Link), evaluate how useful each paper is for understanding investment opportunities or technological advantages within the Web3 / crypto / DeFi ecosystem.\n    Rate each paper on a five-level scale: Highest / High / Medium / Low / Lowest.\n\n    \"Useful\" means:\n\n    - Improves understanding of new cryptographic primitives relevant to blockchain performance or security\n    - Enhances scalability: distributed systems, P2P networking, consensus mechanisms\n    - Advances in zero knowledge, MPC, PQC that could impact future L1/L2 chains\n    - DeFi modeling, AMMs, MEV, risk models, liquidity dynamics\n    - Smart contract security, attack vectors, economic incentives\n    - Token economics, mechanism design for decentralized systems\n    - Quantum threats to blockchain or cryptography\n    - Any breakthrough that meaningfully improves decentralization, scalability, privacy, or composability\n\n    Output instructions:\n\n    - Output each JSON object in JSON Lines format (one line per paper).\n\n    {\n        \"title\": title of the paper (in Japanese),\n        \"summary\": A concise summary of the paper (in Japanese),\n        \"impact_level\": \"Highest|High|Medium|Low|Lowest\",\n        \"why_matters\": An array (JSON array) containing 2\u20134 bullet points explaining why this paper matters for Web3 investment\n    }\n\n    - Do not output anything except valid JSON object in JSON Lines.\n    - \"title\", \"summary\", \"why_matters\" text in the output must be written in Japanese.\n\n    Paper:\n    title: Thermal modifications of mesons and energy-energy correlators from real-time simulations of a $U(1)$ lattice gauge theory\n    summary: We investigate thermal properties of a $U(1)$ lattice gauge theory in $1+1$-dimensions through real-time simulations. We extract the spectral functions directly coupling to the pseudoscalar and scalar mesons, demonstrating the thermal modifications of these states with increasing temperatures. Introducing the notion of energy-flow operators, we quantify the temporal build-up of correlations in the energy flows across the lattice. We demonstrate that energy-energy correlators fail to factorize to products of energy flows, both in the vacuum and at nonzero-temperature, indicating the presence of non-trivial correlations in the quantum states. Our results constitute a first real-time \\textit{ab-initio} study of bound state thermal broadening and finite temperature energy-flow correlations in a gauge theory, providing a benchmark for future studies of hadronic matter under extreme conditions.\n    link: https://arxiv.org/abs/2507.16890v2\n    "}}
{"custom_id": "2405.06073v2", "method": "POST", "url": "/v1/responses", "body": {"model": "gpt-5-mini", "input": "You are a specialist research analyst in Web3, DeFi, cryptography, and distributed systems.\n\n    Your task:\n    From the paper below (Title + Summary + Link), evaluate how useful each paper is for understanding investment opportunities or technological advantages within the Web3 / crypto / DeFi ecosystem.\n    Rate each paper on a five-level scale: Highest / High / Medium / Low / Lowest.\n\n    \"Useful\" means:\n\n    - Improves understanding of new cryptographic primitives relevant to blockchain performance or security\n    - Enhances scalability: distributed systems, P2P networking, consensus mechanisms\n    - Advances in zero knowledge, MPC, PQC that could impact future L1/L2 chains\n    - DeFi modeling, AMMs, MEV, risk models, liquidity dynamics\n    - Smart contract security, attack vectors, economic incentives\n    - Token economics, mechanism design for decentralized systems\n    - Quantum threats to blockchain or cryptography\n    - Any breakthrough that meaningfully improves decentralization, scalability, privacy, or composability\n\n    Output instructions:\n\n    - Output each JSON object in JSON Lines format (one line per paper).\n\n    {\n        \"title\": title of the paper (in Japanese),\n        \"summary\": A concise summary of the paper (in Japanese),\n        \"impact_level\": \"Highest|High|Medium|Low|Lowest\",\n        \"why_matters\": An array (JSON array) containing 2\u20134 bullet points explaining why this paper matters for Web3 investment\n    }\n\n    - Do not output anything except valid JSON object in JSON Lines.\n    - \"title\", \"summary\", \"why_matters\" text in the output must be written in Japanese.\n\n    Paper:\n    title: Hard Work Does Not Always Pay Off: Poisoning Attacks on Neural Architecture Search\n    summary: We study the robustness of data-centric methods to find neural network architectures, known as neural architecture search (NAS), against data poisoning. To audit this robustness, we design a poisoning framework that enables the systematic evaluation of the ability of NAS to produce architectures under data corruption. Our framework examines four off-the-shelf NAS algorithms, representing different approaches to architecture discovery, against four data poisoning attacks, including one we tailor specifically for NAS. In our evaluation with the CIFAR-10 and CIFAR-100 benchmarks, we show that NAS is \\emph{seemingly} robust to data poisoning, showing marginal accuracy drops even under large poisoning budgets. However, we demonstrate that when considering NAS algorithms designed to achieve a few percentage points of accuracy gain, this expected improvement can be substantially diminished under data poisoning. We also show that the reduction varies across NAS algorithms and analyze the factors contributing to their robustness. Our findings are: (1) Training-based NAS algorithms are the least robust due to their reliance on data. (2) Training-free NAS approaches are the most robust but produce architectures that perform similarly to random selections from the search space. (3) NAS algorithms can produce architectures with improved accuracy, even when using out-of-distribution data like MNIST. We lastly discuss potential countermeasures. Our code is available at: https://github.com/ztcoalson/NAS-Robustness-to-Data-Poisoning\n    link: https://arxiv.org/abs/2405.06073v2\n    "}}
{"custom_id": "2312.04470v7", "method": "POST", "url": "/v1/responses", "body": {"model": "gpt-5-mini", "input": "You are a specialist research analyst in Web3, DeFi, cryptography, and distributed systems.\n\n    Your task:\n    From the paper below (Title + Summary + Link), evaluate how useful each paper is for understanding investment opportunities or technological advantages within the Web3 / crypto / DeFi ecosystem.\n    Rate each paper on a five-level scale: Highest / High / Medium / Low / Lowest.\n\n    \"Useful\" means:\n\n    - Improves understanding of new cryptographic primitives relevant to blockchain performance or security\n    - Enhances scalability: distributed systems, P2P networking, consensus mechanisms\n    - Advances in zero knowledge, MPC, PQC that could impact future L1/L2 chains\n    - DeFi modeling, AMMs, MEV, risk models, liquidity dynamics\n    - Smart contract security, attack vectors, economic incentives\n    - Token economics, mechanism design for decentralized systems\n    - Quantum threats to blockchain or cryptography\n    - Any breakthrough that meaningfully improves decentralization, scalability, privacy, or composability\n\n    Output instructions:\n\n    - Output each JSON object in JSON Lines format (one line per paper).\n\n    {\n        \"title\": title of the paper (in Japanese),\n        \"summary\": A concise summary of the paper (in Japanese),\n        \"impact_level\": \"Highest|High|Medium|Low|Lowest\",\n        \"why_matters\": An array (JSON array) containing 2\u20134 bullet points explaining why this paper matters for Web3 investment\n    }\n\n    - Do not output anything except valid JSON object in JSON Lines.\n    - \"title\", \"summary\", \"why_matters\" text in the output must be written in Japanese.\n\n    Paper:\n    title: GaitGuard: Protecting Video-Based Gait Privacy in Mixed Reality\n    summary: Mixed Reality (MR) systems capture continuous video streams that expose bystanders' and collaborators' gait patterns -- a biometric revealing sensitive attributes including age, gender, and health conditions. We show that video-based gait profiling achieves 78\\% accuracy (15.6$\\times$ random chance) on unprotected MR feeds, motivating \\textbf{GaitGuard}, a real-time defense operating on a companion mobile device. GaitGuard introduces \\textbf{GaitExtract}, an automated gait feature extraction pipeline adapted from clinical analysis for egocentric MR perspectives. Through systematic evaluation of 233 mitigation configurations, we characterize privacy-utility-performance trade-offs. A key insight is that gait features derive primarily from transient events (heel strikes, toe-offs). We exploit this temporal sparsity through adaptive mitigation that selectively processes only gait-critical frames, achieving a 68\\% reduction in profiling accuracy while preserving visual quality (SSIM: 0.97) at 29~FPS. \\textbf{GaitGuard} scales to 10 simultaneous users with under 10ms latency. A qualitative study of 20-participants confirms that the users preferred a solution such as \\textbf{GaitGuard} which provides privacy guarantees.\n    link: https://arxiv.org/abs/2312.04470v7\n    "}}
{"custom_id": "2310.16152v4", "method": "POST", "url": "/v1/responses", "body": {"model": "gpt-5-mini", "input": "You are a specialist research analyst in Web3, DeFi, cryptography, and distributed systems.\n\n    Your task:\n    From the paper below (Title + Summary + Link), evaluate how useful each paper is for understanding investment opportunities or technological advantages within the Web3 / crypto / DeFi ecosystem.\n    Rate each paper on a five-level scale: Highest / High / Medium / Low / Lowest.\n\n    \"Useful\" means:\n\n    - Improves understanding of new cryptographic primitives relevant to blockchain performance or security\n    - Enhances scalability: distributed systems, P2P networking, consensus mechanisms\n    - Advances in zero knowledge, MPC, PQC that could impact future L1/L2 chains\n    - DeFi modeling, AMMs, MEV, risk models, liquidity dynamics\n    - Smart contract security, attack vectors, economic incentives\n    - Token economics, mechanism design for decentralized systems\n    - Quantum threats to blockchain or cryptography\n    - Any breakthrough that meaningfully improves decentralization, scalability, privacy, or composability\n\n    Output instructions:\n\n    - Output each JSON object in JSON Lines format (one line per paper).\n\n    {\n        \"title\": title of the paper (in Japanese),\n        \"summary\": A concise summary of the paper (in Japanese),\n        \"impact_level\": \"Highest|High|Medium|Low|Lowest\",\n        \"why_matters\": An array (JSON array) containing 2\u20134 bullet points explaining why this paper matters for Web3 investment\n    }\n\n    - Do not output anything except valid JSON object in JSON Lines.\n    - \"title\", \"summary\", \"why_matters\" text in the output must be written in Japanese.\n\n    Paper:\n    title: Gradient-Free Privacy Leakage in Federated Language Models through Selective Weight Tampering\n    summary: Federated learning (FL) has become a key component in various language modeling applications such as machine translation, next-word prediction, and medical record analysis. These applications are trained on datasets from many FL participants that often include privacy-sensitive data, such as healthcare records, phone/credit card numbers, login credentials, etc. Although FL enables computation without necessitating clients to share their raw data, existing works show that privacy leakage is still probable in federated language models. In this paper, we present two novel findings on the leakage of privacy-sensitive user data from federated large language models without requiring access to gradients. Firstly, we make a key observation that model snapshots from the intermediate rounds in FL can cause greater privacy leakage than the final trained model. Secondly, we identify that a malicious FL participant can aggravate the leakage by tampering with the model's selective weights that are responsible for memorizing the sensitive training data of some other clients, even without any cooperation from the server. Our best-performing method increases the membership inference recall by 29% and achieves up to 71% private data reconstruction, evidently outperforming existing attacks that consider much stronger adversary capabilities. Lastly, we recommend a balanced suite of techniques for an FL client to defend against such privacy risk.\n    link: https://arxiv.org/abs/2310.16152v4\n    "}}
{"custom_id": "2512.09049v1", "method": "POST", "url": "/v1/responses", "body": {"model": "gpt-5-mini", "input": "You are a specialist research analyst in Web3, DeFi, cryptography, and distributed systems.\n\n    Your task:\n    From the paper below (Title + Summary + Link), evaluate how useful each paper is for understanding investment opportunities or technological advantages within the Web3 / crypto / DeFi ecosystem.\n    Rate each paper on a five-level scale: Highest / High / Medium / Low / Lowest.\n\n    \"Useful\" means:\n\n    - Improves understanding of new cryptographic primitives relevant to blockchain performance or security\n    - Enhances scalability: distributed systems, P2P networking, consensus mechanisms\n    - Advances in zero knowledge, MPC, PQC that could impact future L1/L2 chains\n    - DeFi modeling, AMMs, MEV, risk models, liquidity dynamics\n    - Smart contract security, attack vectors, economic incentives\n    - Token economics, mechanism design for decentralized systems\n    - Quantum threats to blockchain or cryptography\n    - Any breakthrough that meaningfully improves decentralization, scalability, privacy, or composability\n\n    Output instructions:\n\n    - Output each JSON object in JSON Lines format (one line per paper).\n\n    {\n        \"title\": title of the paper (in Japanese),\n        \"summary\": A concise summary of the paper (in Japanese),\n        \"impact_level\": \"Highest|High|Medium|Low|Lowest\",\n        \"why_matters\": An array (JSON array) containing 2\u20134 bullet points explaining why this paper matters for Web3 investment\n    }\n\n    - Do not output anything except valid JSON object in JSON Lines.\n    - \"title\", \"summary\", \"why_matters\" text in the output must be written in Japanese.\n\n    Paper:\n    title: EMMap: A Systematic Framework for Spatial EMFI Mapping and Fault Classification on Microcontrollers\n    summary: Electromagnetic Fault Injection (EMFI) is a powerful technique for inducing bit flips and instruction-level perturbations on microcontrollers, yet existing literature lacks a unified methodology for systematically mapping spatial sensitivity and classifying resulting fault behaviors. Building on insights from O'Flynn and Kuhnapfel et al., we introduce a platform-agnostic framework for Spatial EMFI Mapping and Fault Classification, aimed at understanding how spatial probe position influences fault outcomes. We present pilot experiments on three representative microcontroller targets including the Xtensa LX6 (ESP32) and two ChipWhisper boards not as definitive evaluations, but as illustrative demonstrations of how the proposed methodology can be applied in practice. These preliminary observations motivate a generalized and reproducible workflow that researchers can adopt when analyzing EMFI susceptibility across diverse embedded architectures.\n    link: https://arxiv.org/abs/2512.09049v1\n    "}}
{"custom_id": "2512.09043v1", "method": "POST", "url": "/v1/responses", "body": {"model": "gpt-5-mini", "input": "You are a specialist research analyst in Web3, DeFi, cryptography, and distributed systems.\n\n    Your task:\n    From the paper below (Title + Summary + Link), evaluate how useful each paper is for understanding investment opportunities or technological advantages within the Web3 / crypto / DeFi ecosystem.\n    Rate each paper on a five-level scale: Highest / High / Medium / Low / Lowest.\n\n    \"Useful\" means:\n\n    - Improves understanding of new cryptographic primitives relevant to blockchain performance or security\n    - Enhances scalability: distributed systems, P2P networking, consensus mechanisms\n    - Advances in zero knowledge, MPC, PQC that could impact future L1/L2 chains\n    - DeFi modeling, AMMs, MEV, risk models, liquidity dynamics\n    - Smart contract security, attack vectors, economic incentives\n    - Token economics, mechanism design for decentralized systems\n    - Quantum threats to blockchain or cryptography\n    - Any breakthrough that meaningfully improves decentralization, scalability, privacy, or composability\n\n    Output instructions:\n\n    - Output each JSON object in JSON Lines format (one line per paper).\n\n    {\n        \"title\": title of the paper (in Japanese),\n        \"summary\": A concise summary of the paper (in Japanese),\n        \"impact_level\": \"Highest|High|Medium|Low|Lowest\",\n        \"why_matters\": An array (JSON array) containing 2\u20134 bullet points explaining why this paper matters for Web3 investment\n    }\n\n    - Do not output anything except valid JSON object in JSON Lines.\n    - \"title\", \"summary\", \"why_matters\" text in the output must be written in Japanese.\n\n    Paper:\n    title: Dressed-state Hamiltonian engineering in a strongly interacting solid-state spin ensemble\n    summary: In quantum science applications, ranging from many-body physics to quantum metrology, dipolar interactions in spin ensembles are controlled via Floquet engineering. However, this technique typically reduces the interaction strength between spins, and effectively weakens the coupling to a target sensing field, limiting the metrological sensitivity. In this work, we develop and demonstrate a method for direct tuning of the native interaction in an ensemble of nitrogen-vacancy (NV) centers in diamond. Our approach utilizes dressed-state qubit encoding under a magnetic field perpendicular to the crystal lattice orientation. This method leads to a $3.2\\times$ enhancement of the dimensionless coherence parameter $JT_2$ compared to state-of-the-art Floquet engineering, and a $2.6\\times$ ($8.3~$dB) enhanced sensitivity in AC magnetometry. Utilizing the extended coherence we experimentally probe spin transport at intermediate to late times. Our results provide a powerful Hamiltonian engineering tool for future studies with NV ensembles and other interacting higher-spin ($S>\\frac{1}{2}$) systems.\n    link: https://arxiv.org/abs/2512.09043v1\n    "}}
{"custom_id": "2512.09040v1", "method": "POST", "url": "/v1/responses", "body": {"model": "gpt-5-mini", "input": "You are a specialist research analyst in Web3, DeFi, cryptography, and distributed systems.\n\n    Your task:\n    From the paper below (Title + Summary + Link), evaluate how useful each paper is for understanding investment opportunities or technological advantages within the Web3 / crypto / DeFi ecosystem.\n    Rate each paper on a five-level scale: Highest / High / Medium / Low / Lowest.\n\n    \"Useful\" means:\n\n    - Improves understanding of new cryptographic primitives relevant to blockchain performance or security\n    - Enhances scalability: distributed systems, P2P networking, consensus mechanisms\n    - Advances in zero knowledge, MPC, PQC that could impact future L1/L2 chains\n    - DeFi modeling, AMMs, MEV, risk models, liquidity dynamics\n    - Smart contract security, attack vectors, economic incentives\n    - Token economics, mechanism design for decentralized systems\n    - Quantum threats to blockchain or cryptography\n    - Any breakthrough that meaningfully improves decentralization, scalability, privacy, or composability\n\n    Output instructions:\n\n    - Output each JSON object in JSON Lines format (one line per paper).\n\n    {\n        \"title\": title of the paper (in Japanese),\n        \"summary\": A concise summary of the paper (in Japanese),\n        \"impact_level\": \"Highest|High|Medium|Low|Lowest\",\n        \"why_matters\": An array (JSON array) containing 2\u20134 bullet points explaining why this paper matters for Web3 investment\n    }\n\n    - Do not output anything except valid JSON object in JSON Lines.\n    - \"title\", \"summary\", \"why_matters\" text in the output must be written in Japanese.\n\n    Paper:\n    title: Optimizing the dynamical preparation of quantum spin lakes on the ruby lattice\n    summary: Quantum spin liquids are elusive long-range entangled states. Motivated by experiments in Rydberg quantum simulators, recent excitement has centered on the possibility of dynamically preparing a state with quantum spin liquid correlation even when the ground state phase diagram does not exhibit such a topological phase. Understanding the microscopic nature of such quantum spin \"lake\" states and their relationship to equilibrium spin liquid order remains an essential question. Here, we extend the use of approximately symmetric neural quantum states for real-time evolution and directly simulate the dynamical preparation in systems of up to $N=384$ atoms. We analyze a variety of spin liquid diagnostics as a function of the preparation protocol and optimize the extent of the quantum spin lake thus obtained. In the optimal case, the prepared state shows spin-liquid properties extending over half the system size, with a topological entanglement entropy plateauing close to $\u03b3= \\ln 2$. We extract two physical length scales $\u03bb$ and $\u03be$ which constrain the extent of the quantum spin lake $\\ell$ from above and below.\n    link: https://arxiv.org/abs/2512.09040v1\n    "}}
{"custom_id": "2512.09037v1", "method": "POST", "url": "/v1/responses", "body": {"model": "gpt-5-mini", "input": "You are a specialist research analyst in Web3, DeFi, cryptography, and distributed systems.\n\n    Your task:\n    From the paper below (Title + Summary + Link), evaluate how useful each paper is for understanding investment opportunities or technological advantages within the Web3 / crypto / DeFi ecosystem.\n    Rate each paper on a five-level scale: Highest / High / Medium / Low / Lowest.\n\n    \"Useful\" means:\n\n    - Improves understanding of new cryptographic primitives relevant to blockchain performance or security\n    - Enhances scalability: distributed systems, P2P networking, consensus mechanisms\n    - Advances in zero knowledge, MPC, PQC that could impact future L1/L2 chains\n    - DeFi modeling, AMMs, MEV, risk models, liquidity dynamics\n    - Smart contract security, attack vectors, economic incentives\n    - Token economics, mechanism design for decentralized systems\n    - Quantum threats to blockchain or cryptography\n    - Any breakthrough that meaningfully improves decentralization, scalability, privacy, or composability\n\n    Output instructions:\n\n    - Output each JSON object in JSON Lines format (one line per paper).\n\n    {\n        \"title\": title of the paper (in Japanese),\n        \"summary\": A concise summary of the paper (in Japanese),\n        \"impact_level\": \"Highest|High|Medium|Low|Lowest\",\n        \"why_matters\": An array (JSON array) containing 2\u20134 bullet points explaining why this paper matters for Web3 investment\n    }\n\n    - Do not output anything except valid JSON object in JSON Lines.\n    - \"title\", \"summary\", \"why_matters\" text in the output must be written in Japanese.\n\n    Paper:\n    title: Slow dynamics and magnon bound states in the 2D long-range quantum Ising model\n    summary: The dynamics of long-range quantum Ising models represents a current frontier in experimental physics, notably in trapped ions or Rydberg atomic systems. However, a theoretical description of these dynamics beyond 1D remains a significant challenge for conventional methods. Here, we address this challenge by means of neural quantum states to simulate global quenches from the fully polarized ferromagnetic state in the 2D quantum Ising model with power-law decaying interactions. From these numerically exact simulations, we find that the dynamics exhibit slow relaxation with long-lived oscillations. We explain this behavior through a theory for the formation of magnon bound states, which are generated, as we show, through effective attractive interactions between magnons that persist over several lattice sites due to the power-law nature of the interactions. Our results are readily observable in current quantum simulation platforms realizing long-range interacting models such as in Rydberg atomic systems.\n    link: https://arxiv.org/abs/2512.09037v1\n    "}}
