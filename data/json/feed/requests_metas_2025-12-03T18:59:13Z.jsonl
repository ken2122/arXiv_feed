{"custom_id": "2512.04054v1", "method": "POST", "url": "/v1/responses", "body": {"model": "gpt-5-mini", "input": "You are a specialist research analyst in Web3, DeFi, cryptography, and distributed systems.\n\n    Your task:\n    From the paper below (Title + Summary + Link), evaluate how useful each paper is for understanding investment opportunities or technological advantages within the Web3 / crypto / DeFi ecosystem.\n    Rate each paper on a five-level scale: Highest / High / Medium / Low / Lowest.\n\n    \"Useful\" means:\n\n    - Improves understanding of new cryptographic primitives relevant to blockchain performance or security\n    - Enhances scalability: distributed systems, P2P networking, consensus mechanisms\n    - Advances in zero knowledge, MPC, PQC that could impact future L1/L2 chains\n    - DeFi modeling, AMMs, MEV, risk models, liquidity dynamics\n    - Smart contract security, attack vectors, economic incentives\n    - Token economics, mechanism design for decentralized systems\n    - Quantum threats to blockchain or cryptography\n    - Any breakthrough that meaningfully improves decentralization, scalability, privacy, or composability\n\n    Output instructions:\n\n    - Output each JSON object in JSON Lines format (one line per paper).\n\n    {\n        \"title\": title of the paper (in Japanese),\n        \"summary\": A concise summary of the paper (in Japanese),\n        \"impact_level\": \"Highest|High|Medium|Low|Lowest\",\n        \"why_matters\": An array (JSON array) containing 2\u20134 bullet points explaining why this paper matters for Web3 investment\n    }\n\n    - Do not output anything except valid JSON object in JSON Lines.\n    - \"title\", \"summary\", \"why_matters\" text in the output must be written in Japanese.\n\n    Paper:\n    title: A Chronological Analysis of the Evolution of SmartNICs\n    summary: Network Interface Cards (NICs) are one of the key enablers of the modern Internet. They serve as gateways for connecting computing devices to networks for the exchange of data with other devices. Recently, the pervasive nature of Internet-enabled devices coupled with the growing demands for faster network access have necessitated the enhancement of NICs to Smart NICs (SNICs), capable of processing enormous volumes of data at near real-time speed. However, despite their popularity, the exact use and applicability of SNICs remains an ongoing debate. These debates are exacerbated by the incorporation of accelerators into SNIC, allowing them to relieve their host's CPUs of various tasks. In this work, we carry out a chronological analysis of SNICs, using 370 articles published in the past 15 years, from 2010 to 2024, to gain some insight into SNICs; and shed some light on their evolution, manufacturers, use cases, and application domains.\n    link: https://arxiv.org/abs/2512.04054v1\n    "}}
{"custom_id": "2512.04044v1", "method": "POST", "url": "/v1/responses", "body": {"model": "gpt-5-mini", "input": "You are a specialist research analyst in Web3, DeFi, cryptography, and distributed systems.\n\n    Your task:\n    From the paper below (Title + Summary + Link), evaluate how useful each paper is for understanding investment opportunities or technological advantages within the Web3 / crypto / DeFi ecosystem.\n    Rate each paper on a five-level scale: Highest / High / Medium / Low / Lowest.\n\n    \"Useful\" means:\n\n    - Improves understanding of new cryptographic primitives relevant to blockchain performance or security\n    - Enhances scalability: distributed systems, P2P networking, consensus mechanisms\n    - Advances in zero knowledge, MPC, PQC that could impact future L1/L2 chains\n    - DeFi modeling, AMMs, MEV, risk models, liquidity dynamics\n    - Smart contract security, attack vectors, economic incentives\n    - Token economics, mechanism design for decentralized systems\n    - Quantum threats to blockchain or cryptography\n    - Any breakthrough that meaningfully improves decentralization, scalability, privacy, or composability\n\n    Output instructions:\n\n    - Output each JSON object in JSON Lines format (one line per paper).\n\n    {\n        \"title\": title of the paper (in Japanese),\n        \"summary\": A concise summary of the paper (in Japanese),\n        \"impact_level\": \"Highest|High|Medium|Low|Lowest\",\n        \"why_matters\": An array (JSON array) containing 2\u20134 bullet points explaining why this paper matters for Web3 investment\n    }\n\n    - Do not output anything except valid JSON object in JSON Lines.\n    - \"title\", \"summary\", \"why_matters\" text in the output must be written in Japanese.\n\n    Paper:\n    title: MarkTune: Improving the Quality-Detectability Trade-off in Open-Weight LLM Watermarking\n    summary: Watermarking aims to embed hidden signals in generated text that can be reliably detected when given access to a secret key. Open-weight language models pose acute challenges for such watermarking schemes because the inference-time interventions that dominate contemporary approaches cannot be enforced once model weights are public. Existing watermaking techniques for open-weight models, such as the recently proposed GaussMark, typically rely on small modifications to model weights, which can yield signals detectable to those equipped with a secret key, but achieving detection power comparable to inference-time watermarks generally requires weight perturbations that noticeably reduce generation quality. We introduce MarkTune, a theoretically principled, on-policy fine-tuning framework that treats the GaussMark signal as a reward while simultaneously regularizing against degradation in text quality. We derive MarkTune as an improvement on GaussMark and demonstrate that MarkTune consistently improves the quality-detectability trade-off over GaussMark by steering finer-grained, watermark-aware weight updates within the model's representation space while preserving generation quality. Empirically, we show that MarkTune pushes the quality-detectability frontier of GaussMark close to that of inference-time watermarking, remains robust to paraphrasing and fine-tuning attacks, and exhibits strong generalization: a model fine-tuned on one dataset retains substantial watermark detection power on unseen datasets. Together, these results establish MarkTune as a general strategy for embedding robust, high-quality watermarks into open-weight LMs.\n    link: https://arxiv.org/abs/2512.04044v1\n    "}}
{"custom_id": "2509.19486v2", "method": "POST", "url": "/v1/responses", "body": {"model": "gpt-5-mini", "input": "You are a specialist research analyst in Web3, DeFi, cryptography, and distributed systems.\n\n    Your task:\n    From the paper below (Title + Summary + Link), evaluate how useful each paper is for understanding investment opportunities or technological advantages within the Web3 / crypto / DeFi ecosystem.\n    Rate each paper on a five-level scale: Highest / High / Medium / Low / Lowest.\n\n    \"Useful\" means:\n\n    - Improves understanding of new cryptographic primitives relevant to blockchain performance or security\n    - Enhances scalability: distributed systems, P2P networking, consensus mechanisms\n    - Advances in zero knowledge, MPC, PQC that could impact future L1/L2 chains\n    - DeFi modeling, AMMs, MEV, risk models, liquidity dynamics\n    - Smart contract security, attack vectors, economic incentives\n    - Token economics, mechanism design for decentralized systems\n    - Quantum threats to blockchain or cryptography\n    - Any breakthrough that meaningfully improves decentralization, scalability, privacy, or composability\n\n    Output instructions:\n\n    - Output each JSON object in JSON Lines format (one line per paper).\n\n    {\n        \"title\": title of the paper (in Japanese),\n        \"summary\": A concise summary of the paper (in Japanese),\n        \"impact_level\": \"Highest|High|Medium|Low|Lowest\",\n        \"why_matters\": An array (JSON array) containing 2\u20134 bullet points explaining why this paper matters for Web3 investment\n    }\n\n    - Do not output anything except valid JSON object in JSON Lines.\n    - \"title\", \"summary\", \"why_matters\" text in the output must be written in Japanese.\n\n    Paper:\n    title: Supercomputing for High-speed Avoidance and Reactive Planning in Robots\n    summary: This paper presents SHARP (Supercomputing for High-speed Avoidance and Reactive Planning), a proof-of-concept study demonstrating how high-performance computing (HPC) can enable millisecond-scale responsiveness in robotic control. While modern robots face increasing demands for reactivity in human--robot shared workspaces, onboard processors are constrained by size, power, and cost. Offloading to HPC offers massive parallelism for trajectory planning, but its feasibility for real-time robotics remains uncertain due to network latency and jitter. We evaluate SHARP in a stress-test scenario where a 7-DOF manipulator must dodge high-speed foam projectiles. Using a parallelized multi-goal A* search implemented with MPI on both local and remote HPC clusters, the system achieves mean planning latencies of 22.9 ms (local) and 30.0 ms (remote, ~300 km away), with avoidance success rates of 84% and 88%, respectively. These results show that when round-trip latency remains within the tens-of-milliseconds regime, HPC-side computation is no longer the bottleneck, enabling avoidance well below human reaction times. The SHARP results motivate hybrid control architectures: low-level reflexes remain onboard for safety, while bursty, high-throughput planning tasks are offloaded to HPC for scalability. By reporting per-stage timing and success rates, this study provides a reproducible template for assessing real-time feasibility of HPC-driven robotics. Collectively, SHARP reframes HPC offloading as a viable pathway toward dependable, reactive robots in dynamic environments.\n    link: https://arxiv.org/abs/2509.19486v2\n    "}}
{"custom_id": "2509.12341v5", "method": "POST", "url": "/v1/responses", "body": {"model": "gpt-5-mini", "input": "You are a specialist research analyst in Web3, DeFi, cryptography, and distributed systems.\n\n    Your task:\n    From the paper below (Title + Summary + Link), evaluate how useful each paper is for understanding investment opportunities or technological advantages within the Web3 / crypto / DeFi ecosystem.\n    Rate each paper on a five-level scale: Highest / High / Medium / Low / Lowest.\n\n    \"Useful\" means:\n\n    - Improves understanding of new cryptographic primitives relevant to blockchain performance or security\n    - Enhances scalability: distributed systems, P2P networking, consensus mechanisms\n    - Advances in zero knowledge, MPC, PQC that could impact future L1/L2 chains\n    - DeFi modeling, AMMs, MEV, risk models, liquidity dynamics\n    - Smart contract security, attack vectors, economic incentives\n    - Token economics, mechanism design for decentralized systems\n    - Quantum threats to blockchain or cryptography\n    - Any breakthrough that meaningfully improves decentralization, scalability, privacy, or composability\n\n    Output instructions:\n\n    - Output each JSON object in JSON Lines format (one line per paper).\n\n    {\n        \"title\": title of the paper (in Japanese),\n        \"summary\": A concise summary of the paper (in Japanese),\n        \"impact_level\": \"Highest|High|Medium|Low|Lowest\",\n        \"why_matters\": An array (JSON array) containing 2\u20134 bullet points explaining why this paper matters for Web3 investment\n    }\n\n    - Do not output anything except valid JSON object in JSON Lines.\n    - \"title\", \"summary\", \"why_matters\" text in the output must be written in Japanese.\n\n    Paper:\n    title: Exact Coset Sampling for Quantum Lattice Algorithms\n    summary: In this work, we give a new completion of Chen's windowed-QFT lattice algorithm~\\citep{chen2024quantum}. This extra step, called Step~$9^\\dagger$, replaces the domain extension stage in Steps~8--9. The published Step~9 calls an amplitude periodicity lemma, yet its hypotheses break in the presence of affine offsets $\\boldsymbol{v}^*$. Our analysis finds a basic conflict between two design constraints. The lattice problem asks for high spectral resolution, so the method prefers wide time windows. The quadratic phase error of the state prefers narrow time windows. Assumption~A5 packages the spectral concentration and near-uniformity properties that we require from the front end. Under~A5, a direct $\\mathbb{Z}_M^n$ Fourier transform of the chirp-corrected coordinate state produces samples $\\boldsymbol{u}$ that satisfy $\\langle \\boldsymbol{b}, \\boldsymbol{u} \\rangle \\equiv 0 \\pmod{Q}$ with probability $1-\\mathrm{negl}(n)$ and are nearly uniform on the dual hyperplane $\\{\\boldsymbol{u} : \\langle \\boldsymbol{b}, \\boldsymbol{u} \\rangle \\equiv 0 \\pmod{Q}\\}$. The new procedure does not require internal access to control wires. It uses the normalization $b_1=-1$ to apply a center-referenced phase correction directly on the first coordinate register. The scaling parameter $D$ ensures that this physical operation can be implemented by arithmetic on $X_1$ alone and does not read the hidden loop index. For Chen's complex-Gaussian Karst-wave window, we isolate a parameter regime, formalized in Assumption~A5, in which a polynomial retuning of the parameters gives a one-dimensional envelope for the loop index with width $\u03c3_J \\asymp Q\\log n$.\n    link: https://arxiv.org/abs/2509.12341v5\n    "}}
{"custom_id": "2512.04008v1", "method": "POST", "url": "/v1/responses", "body": {"model": "gpt-5-mini", "input": "You are a specialist research analyst in Web3, DeFi, cryptography, and distributed systems.\n\n    Your task:\n    From the paper below (Title + Summary + Link), evaluate how useful each paper is for understanding investment opportunities or technological advantages within the Web3 / crypto / DeFi ecosystem.\n    Rate each paper on a five-level scale: Highest / High / Medium / Low / Lowest.\n\n    \"Useful\" means:\n\n    - Improves understanding of new cryptographic primitives relevant to blockchain performance or security\n    - Enhances scalability: distributed systems, P2P networking, consensus mechanisms\n    - Advances in zero knowledge, MPC, PQC that could impact future L1/L2 chains\n    - DeFi modeling, AMMs, MEV, risk models, liquidity dynamics\n    - Smart contract security, attack vectors, economic incentives\n    - Token economics, mechanism design for decentralized systems\n    - Quantum threats to blockchain or cryptography\n    - Any breakthrough that meaningfully improves decentralization, scalability, privacy, or composability\n\n    Output instructions:\n\n    - Output each JSON object in JSON Lines format (one line per paper).\n\n    {\n        \"title\": title of the paper (in Japanese),\n        \"summary\": A concise summary of the paper (in Japanese),\n        \"impact_level\": \"Highest|High|Medium|Low|Lowest\",\n        \"why_matters\": An array (JSON array) containing 2\u20134 bullet points explaining why this paper matters for Web3 investment\n    }\n\n    - Do not output anything except valid JSON object in JSON Lines.\n    - \"title\", \"summary\", \"why_matters\" text in the output must be written in Japanese.\n\n    Paper:\n    title: Efficient Public Verification of Private ML via Regularization\n    summary: Training with differential privacy (DP) provides a guarantee to members in a dataset that they cannot be identified by users of the released model. However, those data providers, and, in general, the public, lack methods to efficiently verify that models trained on their data satisfy DP guarantees. The amount of compute needed to verify DP guarantees for current algorithms scales with the amount of compute required to train the model. In this paper we design the first DP algorithm with near optimal privacy-utility trade-offs but whose DP guarantees can be verified cheaper than training. We focus on DP stochastic convex optimization (DP-SCO), where optimal privacy-utility trade-offs are known. Here we show we can obtain tight privacy-utility trade-offs by privately minimizing a series of regularized objectives and only using the standard DP composition bound. Crucially, this method can be verified with much less compute than training. This leads to the first known DP-SCO algorithm with near optimal privacy-utility whose DP verification scales better than training cost, significantly reducing verification costs on large datasets.\n    link: https://arxiv.org/abs/2512.04008v1\n    "}}
{"custom_id": "2512.03927v1", "method": "POST", "url": "/v1/responses", "body": {"model": "gpt-5-mini", "input": "You are a specialist research analyst in Web3, DeFi, cryptography, and distributed systems.\n\n    Your task:\n    From the paper below (Title + Summary + Link), evaluate how useful each paper is for understanding investment opportunities or technological advantages within the Web3 / crypto / DeFi ecosystem.\n    Rate each paper on a five-level scale: Highest / High / Medium / Low / Lowest.\n\n    \"Useful\" means:\n\n    - Improves understanding of new cryptographic primitives relevant to blockchain performance or security\n    - Enhances scalability: distributed systems, P2P networking, consensus mechanisms\n    - Advances in zero knowledge, MPC, PQC that could impact future L1/L2 chains\n    - DeFi modeling, AMMs, MEV, risk models, liquidity dynamics\n    - Smart contract security, attack vectors, economic incentives\n    - Token economics, mechanism design for decentralized systems\n    - Quantum threats to blockchain or cryptography\n    - Any breakthrough that meaningfully improves decentralization, scalability, privacy, or composability\n\n    Output instructions:\n\n    - Output each JSON object in JSON Lines format (one line per paper).\n\n    {\n        \"title\": title of the paper (in Japanese),\n        \"summary\": A concise summary of the paper (in Japanese),\n        \"impact_level\": \"Highest|High|Medium|Low|Lowest\",\n        \"why_matters\": An array (JSON array) containing 2\u20134 bullet points explaining why this paper matters for Web3 investment\n    }\n\n    - Do not output anything except valid JSON object in JSON Lines.\n    - \"title\", \"summary\", \"why_matters\" text in the output must be written in Japanese.\n\n    Paper:\n    title: OD-MoE: On-Demand Expert Loading for Cacheless Edge-Distributed MoE Inference\n    summary: Mixture-of-Experts (MoE), while offering significant advantages as a Large Language Model (LLM) architecture, faces substantial challenges when deployed on low-cost edge devices with tight memory constraints. Expert offloading mitigates this issue by storing expert parameters in CPU memory and caching a subset of popular experts in GPU memory. Although this approach improves GPU memory utilization by caching only the likely-used experts, the GPU memory reserved for expert caching is underutilized compared with dense LLMs. This paper presents OD-MoE, a distributed MoE inference framework that obviates the need for expert caches via fully on-demand expert loading. OD-MoE is built upon two key mechanisms: 1) parallelizing expert loading and expert computation across distributed edge nodes, and 2) an ultra-accurate emulative predictor that forecasts expert activations multiple layers ahead while expert computation is ongoing. With these innovations, OD-MoE dynamically loads each target expert to one of the distributed nodes just-in-time before its activation and promptly evicts it afterward, freeing GPU memory for subsequent experts. We comprehensively benchmark OD-MoE against state-of-the-art MoE offloading systems on a ten-node testbed. Experimental results show that: 1) OD-MoE achieves 99.94% expert activation prediction accuracy, substantially surpassing all existing methods; and 2) OD-MoE delivers approximately 75% of the decoding speed of a fully GPU-cached MoE deployment while using only 1/3 of the GPU memory. More importantly, by eliminating the need for expert caches, OD-MoE enables MoE inference on edge nodes with less-than-1GB GPU memory, paving the way for practical MoE deployment of low-cost IoT devices at the edge in the LLM era.\n    link: https://arxiv.org/abs/2512.03927v1\n    "}}
{"custom_id": "2408.05235v2", "method": "POST", "url": "/v1/responses", "body": {"model": "gpt-5-mini", "input": "You are a specialist research analyst in Web3, DeFi, cryptography, and distributed systems.\n\n    Your task:\n    From the paper below (Title + Summary + Link), evaluate how useful each paper is for understanding investment opportunities or technological advantages within the Web3 / crypto / DeFi ecosystem.\n    Rate each paper on a five-level scale: Highest / High / Medium / Low / Lowest.\n\n    \"Useful\" means:\n\n    - Improves understanding of new cryptographic primitives relevant to blockchain performance or security\n    - Enhances scalability: distributed systems, P2P networking, consensus mechanisms\n    - Advances in zero knowledge, MPC, PQC that could impact future L1/L2 chains\n    - DeFi modeling, AMMs, MEV, risk models, liquidity dynamics\n    - Smart contract security, attack vectors, economic incentives\n    - Token economics, mechanism design for decentralized systems\n    - Quantum threats to blockchain or cryptography\n    - Any breakthrough that meaningfully improves decentralization, scalability, privacy, or composability\n\n    Output instructions:\n\n    - Output each JSON object in JSON Lines format (one line per paper).\n\n    {\n        \"title\": title of the paper (in Japanese),\n        \"summary\": A concise summary of the paper (in Japanese),\n        \"impact_level\": \"Highest|High|Medium|Low|Lowest\",\n        \"why_matters\": An array (JSON array) containing 2\u20134 bullet points explaining why this paper matters for Web3 investment\n    }\n\n    - Do not output anything except valid JSON object in JSON Lines.\n    - \"title\", \"summary\", \"why_matters\" text in the output must be written in Japanese.\n\n    Paper:\n    title: SLO-aware GPU Frequency Scaling for Energy Efficient LLM Inference Serving\n    summary: As Large Language Models (LLMs) gain traction, their reliance on power-hungry GPUs places ever-increasing energy demands, raising environmental and monetary concerns. Inference dominates LLM workloads, presenting a critical challenge for providers: minimizing energy costs under Service-Level Objectives (SLOs) that ensure optimal user experience. In this paper, we present \\textit{throttLL'eM}, a framework that reduces energy consumption while meeting SLOs through the use of instance and GPU frequency scaling. \\textit{throttLL'eM} features mechanisms that project future KV cache usage and batch size. Leveraging a Machine-Learning (ML) model that receives these projections as inputs, \\textit{throttLL'eM} manages performance at the iteration level to satisfy SLOs with reduced frequencies and instance sizes. We show that the proposed ML model achieves $R^2$ scores greater than 0.97 and miss-predicts performance by less than 1 iteration per second on average. Experimental results on LLM inference traces show that \\textit{throttLL'eM} achieves up to 43.8\\% lower energy consumption and an energy efficiency improvement of at least $1.71\\times$ under SLOs, when compared to NVIDIA's Triton server.\n    link: https://arxiv.org/abs/2408.05235v2\n    "}}
{"custom_id": "2512.03914v1", "method": "POST", "url": "/v1/responses", "body": {"model": "gpt-5-mini", "input": "You are a specialist research analyst in Web3, DeFi, cryptography, and distributed systems.\n\n    Your task:\n    From the paper below (Title + Summary + Link), evaluate how useful each paper is for understanding investment opportunities or technological advantages within the Web3 / crypto / DeFi ecosystem.\n    Rate each paper on a five-level scale: Highest / High / Medium / Low / Lowest.\n\n    \"Useful\" means:\n\n    - Improves understanding of new cryptographic primitives relevant to blockchain performance or security\n    - Enhances scalability: distributed systems, P2P networking, consensus mechanisms\n    - Advances in zero knowledge, MPC, PQC that could impact future L1/L2 chains\n    - DeFi modeling, AMMs, MEV, risk models, liquidity dynamics\n    - Smart contract security, attack vectors, economic incentives\n    - Token economics, mechanism design for decentralized systems\n    - Quantum threats to blockchain or cryptography\n    - Any breakthrough that meaningfully improves decentralization, scalability, privacy, or composability\n\n    Output instructions:\n\n    - Output each JSON object in JSON Lines format (one line per paper).\n\n    {\n        \"title\": title of the paper (in Japanese),\n        \"summary\": A concise summary of the paper (in Japanese),\n        \"impact_level\": \"Highest|High|Medium|Low|Lowest\",\n        \"why_matters\": An array (JSON array) containing 2\u20134 bullet points explaining why this paper matters for Web3 investment\n    }\n\n    - Do not output anything except valid JSON object in JSON Lines.\n    - \"title\", \"summary\", \"why_matters\" text in the output must be written in Japanese.\n\n    Paper:\n    title: Integrating High Performance In-Memory Data Streaming and In-Situ Visualization in Hybrid MPI+OpenMP PIC MC Simulations Towards Exascale\n    summary: Efficient simulation of complex plasma dynamics is crucial for advancing fusion energy research. Particle-in-Cell (PIC) Monte Carlo (MC) simulations provide insights into plasma behavior, including turbulence and confinement, which are essential for optimizing fusion reactor performance. Transitioning to exascale simulations introduces significant challenges, with traditional file input/output (I/O) inefficiencies remaining a key bottleneck. This work advances BIT1, an electrostatic PIC MC code, by improving the particle mover with OpenMP task-based parallelism, integrating the openPMD streaming API, and enabling in-memory data streaming with ADIOS2's Sustainable Staging Transport (SST) engine to enhance I/O performance, computational efficiency, and system storage utilization. We employ profiling tools such as gprof, perf, IPM and Darshan, which provide insights into computation, communication, and I/O operations. We implement time-dependent data checkpointing with the openPMD API enabling seamless data movement and in-situ visualization for real-time analysis without interrupting the simulation. We demonstrate improvements in simulation runtime, data accessibility and real-time insights by comparing traditional file I/O with the ADIOS2 BP4 and SST backends. The proposed hybrid BIT1 openPMD SST enhancement introduces a new paradigm for real-time scientific discovery in plasma simulations, enabling faster insights and more efficient use of exascale computing resources.\n    link: https://arxiv.org/abs/2512.03914v1\n    "}}
{"custom_id": "2212.07356v4", "method": "POST", "url": "/v1/responses", "body": {"model": "gpt-5-mini", "input": "You are a specialist research analyst in Web3, DeFi, cryptography, and distributed systems.\n\n    Your task:\n    From the paper below (Title + Summary + Link), evaluate how useful each paper is for understanding investment opportunities or technological advantages within the Web3 / crypto / DeFi ecosystem.\n    Rate each paper on a five-level scale: Highest / High / Medium / Low / Lowest.\n\n    \"Useful\" means:\n\n    - Improves understanding of new cryptographic primitives relevant to blockchain performance or security\n    - Enhances scalability: distributed systems, P2P networking, consensus mechanisms\n    - Advances in zero knowledge, MPC, PQC that could impact future L1/L2 chains\n    - DeFi modeling, AMMs, MEV, risk models, liquidity dynamics\n    - Smart contract security, attack vectors, economic incentives\n    - Token economics, mechanism design for decentralized systems\n    - Quantum threats to blockchain or cryptography\n    - Any breakthrough that meaningfully improves decentralization, scalability, privacy, or composability\n\n    Output instructions:\n\n    - Output each JSON object in JSON Lines format (one line per paper).\n\n    {\n        \"title\": title of the paper (in Japanese),\n        \"summary\": A concise summary of the paper (in Japanese),\n        \"impact_level\": \"Highest|High|Medium|Low|Lowest\",\n        \"why_matters\": An array (JSON array) containing 2\u20134 bullet points explaining why this paper matters for Web3 investment\n    }\n\n    - Do not output anything except valid JSON object in JSON Lines.\n    - \"title\", \"summary\", \"why_matters\" text in the output must be written in Japanese.\n\n    Paper:\n    title: Scheduling and Aggregation Design for Asynchronous Federated Learning over Wireless Networks\n    summary: Federated Learning (FL) is a collaborative machine learning (ML) framework that combines on-device training and server-based aggregation to train a common ML model among distributed agents. In this work, we propose an asynchronous FL design with periodic aggregation to tackle the straggler issue in FL systems. Considering limited wireless communication resources, we investigate the effect of different scheduling policies and aggregation designs on the convergence performance. Driven by the importance of reducing the bias and variance of the aggregated model updates, we propose a scheduling policy that jointly considers the channel quality and training data representation of user devices. The effectiveness of our channel-aware data-importance-based scheduling policy, compared with state-of-the-art methods proposed for synchronous FL, is validated through simulations. Moreover, we show that an ``age-aware'' aggregation weighting design can significantly improve the learning performance in an asynchronous FL setting.\n    link: https://arxiv.org/abs/2212.07356v4\n    "}}
{"custom_id": "2504.03111v3", "method": "POST", "url": "/v1/responses", "body": {"model": "gpt-5-mini", "input": "You are a specialist research analyst in Web3, DeFi, cryptography, and distributed systems.\n\n    Your task:\n    From the paper below (Title + Summary + Link), evaluate how useful each paper is for understanding investment opportunities or technological advantages within the Web3 / crypto / DeFi ecosystem.\n    Rate each paper on a five-level scale: Highest / High / Medium / Low / Lowest.\n\n    \"Useful\" means:\n\n    - Improves understanding of new cryptographic primitives relevant to blockchain performance or security\n    - Enhances scalability: distributed systems, P2P networking, consensus mechanisms\n    - Advances in zero knowledge, MPC, PQC that could impact future L1/L2 chains\n    - DeFi modeling, AMMs, MEV, risk models, liquidity dynamics\n    - Smart contract security, attack vectors, economic incentives\n    - Token economics, mechanism design for decentralized systems\n    - Quantum threats to blockchain or cryptography\n    - Any breakthrough that meaningfully improves decentralization, scalability, privacy, or composability\n\n    Output instructions:\n\n    - Output each JSON object in JSON Lines format (one line per paper).\n\n    {\n        \"title\": title of the paper (in Japanese),\n        \"summary\": A concise summary of the paper (in Japanese),\n        \"impact_level\": \"Highest|High|Medium|Low|Lowest\",\n        \"why_matters\": An array (JSON array) containing 2\u20134 bullet points explaining why this paper matters for Web3 investment\n    }\n\n    - Do not output anything except valid JSON object in JSON Lines.\n    - \"title\", \"summary\", \"why_matters\" text in the output must be written in Japanese.\n\n    Paper:\n    title: Les Dissonances: Cross-Tool Harvesting and Polluting in Pool-of-Tools Empowered LLM Agents\n    summary: Large Language Model (LLM) agents are autonomous systems powered by LLMs, capable of reasoning and planning to solve problems by leveraging a set of tools. However, the integration of multi-tool capabilities in LLM agents introduces challenges in securely managing tools, ensuring their compatibility, handling dependency relationships, and protecting control flows within LLM agent workflows. In this paper, we present the first systematic security analysis of task control flows in multi-tool-enabled LLM agents. We identify a novel threat, Cross-Tool Harvesting and Polluting (XTHP), which includes multiple attack vectors to first hijack the normal control flows of agent tasks, and then collect and pollute confidential or private information within LLM agent systems. To understand the impact of this threat, we developed Chord, a dynamic scanning tool designed to automatically detect real-world agent tools susceptible to XTHP attacks. Our evaluation of 66 real-world tools from the repositories of two major LLM agent development frameworks, LangChain and LlamaIndex, revealed a significant security concern: 75% are vulnerable to XTHP attacks, highlighting the prevalence of this threat.\n    link: https://arxiv.org/abs/2504.03111v3\n    "}}
{"custom_id": "2512.03898v1", "method": "POST", "url": "/v1/responses", "body": {"model": "gpt-5-mini", "input": "You are a specialist research analyst in Web3, DeFi, cryptography, and distributed systems.\n\n    Your task:\n    From the paper below (Title + Summary + Link), evaluate how useful each paper is for understanding investment opportunities or technological advantages within the Web3 / crypto / DeFi ecosystem.\n    Rate each paper on a five-level scale: Highest / High / Medium / Low / Lowest.\n\n    \"Useful\" means:\n\n    - Improves understanding of new cryptographic primitives relevant to blockchain performance or security\n    - Enhances scalability: distributed systems, P2P networking, consensus mechanisms\n    - Advances in zero knowledge, MPC, PQC that could impact future L1/L2 chains\n    - DeFi modeling, AMMs, MEV, risk models, liquidity dynamics\n    - Smart contract security, attack vectors, economic incentives\n    - Token economics, mechanism design for decentralized systems\n    - Quantum threats to blockchain or cryptography\n    - Any breakthrough that meaningfully improves decentralization, scalability, privacy, or composability\n\n    Output instructions:\n\n    - Output each JSON object in JSON Lines format (one line per paper).\n\n    {\n        \"title\": title of the paper (in Japanese),\n        \"summary\": A concise summary of the paper (in Japanese),\n        \"impact_level\": \"Highest|High|Medium|Low|Lowest\",\n        \"why_matters\": An array (JSON array) containing 2\u20134 bullet points explaining why this paper matters for Web3 investment\n    }\n\n    - Do not output anything except valid JSON object in JSON Lines.\n    - \"title\", \"summary\", \"why_matters\" text in the output must be written in Japanese.\n\n    Paper:\n    title: Polylogarithmic-Depth Quantum Algorithm for Simulating the Extended Hubbard Model on a Two-Dimensional Lattice Using the Fast Multipole Method\n    summary: The extended Hubbard model on a two-dimensional lattice captures key physical phenomena, but is challenging to simulate due to the presence of long-range interactions. In this work, we present an efficient quantum algorithm for simulating the time evolution of this model. Our approach, inspired by the fast multipole method, approximates pairwise interactions by interactions between hierarchical levels of coarse-graining boxes. We discuss how to leverage recent advances in two-dimensional neutral atom quantum computing, supporting non-local operations such as long-range gates and shuttling. The resulting circuit depth for a single Trotter step scales polylogarithmically with system size.\n    link: https://arxiv.org/abs/2512.03898v1\n    "}}
{"custom_id": "2512.03868v1", "method": "POST", "url": "/v1/responses", "body": {"model": "gpt-5-mini", "input": "You are a specialist research analyst in Web3, DeFi, cryptography, and distributed systems.\n\n    Your task:\n    From the paper below (Title + Summary + Link), evaluate how useful each paper is for understanding investment opportunities or technological advantages within the Web3 / crypto / DeFi ecosystem.\n    Rate each paper on a five-level scale: Highest / High / Medium / Low / Lowest.\n\n    \"Useful\" means:\n\n    - Improves understanding of new cryptographic primitives relevant to blockchain performance or security\n    - Enhances scalability: distributed systems, P2P networking, consensus mechanisms\n    - Advances in zero knowledge, MPC, PQC that could impact future L1/L2 chains\n    - DeFi modeling, AMMs, MEV, risk models, liquidity dynamics\n    - Smart contract security, attack vectors, economic incentives\n    - Token economics, mechanism design for decentralized systems\n    - Quantum threats to blockchain or cryptography\n    - Any breakthrough that meaningfully improves decentralization, scalability, privacy, or composability\n\n    Output instructions:\n\n    - Output each JSON object in JSON Lines format (one line per paper).\n\n    {\n        \"title\": title of the paper (in Japanese),\n        \"summary\": A concise summary of the paper (in Japanese),\n        \"impact_level\": \"Highest|High|Medium|Low|Lowest\",\n        \"why_matters\": An array (JSON array) containing 2\u20134 bullet points explaining why this paper matters for Web3 investment\n    }\n\n    - Do not output anything except valid JSON object in JSON Lines.\n    - \"title\", \"summary\", \"why_matters\" text in the output must be written in Japanese.\n\n    Paper:\n    title: A Comprehensive Study on the Impact of Vulnerable Dependencies on Open-Source Software\n    summary: Open-source libraries are widely used by software developers to speed up the development of products, however, they can introduce security vulnerabilities, leading to incidents like Log4Shell. With the expanding usage of open-source libraries, it becomes even more imperative to comprehend and address these dependency vulnerabilities. The use of Software Composition Analysis (SCA) tools does greatly help here as they provide a deep insight on what dependencies are used in a project, enhancing the security and integrity in the software supply chain. In order to learn how wide spread vulnerabilities are and how quickly they are being fixed, we conducted a study on over 1k open-source software projects with about 50k releases comprising several languages such as Java, Python, Rust, Go, Ruby, PHP, and JavaScript. Our objective is to investigate the severity, persistence, and distribution of these vulnerabilities, as well as their correlation with project metrics such as team and contributors size, activity and release cycles. In order to perform such analysis, we crawled over 1k projects from github including their version history ranging from 2013 to 2023 using VODA, our SCA tool. Using our approach, we can provide information such as library versions, dependency depth, and known vulnerabilities, and how they evolved over the software development cycle. Being larger and more diverse than datasets used in earlier works and studies, ours provides better insights and generalizability of the gained results. The data collected answers several research questions about the dependency depth and the average time a vulnerability persists. Among other findings, we observed that for most programming languages, vulnerable dependencies are transitive, and a critical vulnerability persists in average for over a year before being fixed.\n    link: https://arxiv.org/abs/2512.03868v1\n    "}}
{"custom_id": "2510.21963v2", "method": "POST", "url": "/v1/responses", "body": {"model": "gpt-5-mini", "input": "You are a specialist research analyst in Web3, DeFi, cryptography, and distributed systems.\n\n    Your task:\n    From the paper below (Title + Summary + Link), evaluate how useful each paper is for understanding investment opportunities or technological advantages within the Web3 / crypto / DeFi ecosystem.\n    Rate each paper on a five-level scale: Highest / High / Medium / Low / Lowest.\n\n    \"Useful\" means:\n\n    - Improves understanding of new cryptographic primitives relevant to blockchain performance or security\n    - Enhances scalability: distributed systems, P2P networking, consensus mechanisms\n    - Advances in zero knowledge, MPC, PQC that could impact future L1/L2 chains\n    - DeFi modeling, AMMs, MEV, risk models, liquidity dynamics\n    - Smart contract security, attack vectors, economic incentives\n    - Token economics, mechanism design for decentralized systems\n    - Quantum threats to blockchain or cryptography\n    - Any breakthrough that meaningfully improves decentralization, scalability, privacy, or composability\n\n    Output instructions:\n\n    - Output each JSON object in JSON Lines format (one line per paper).\n\n    {\n        \"title\": title of the paper (in Japanese),\n        \"summary\": A concise summary of the paper (in Japanese),\n        \"impact_level\": \"Highest|High|Medium|Low|Lowest\",\n        \"why_matters\": An array (JSON array) containing 2\u20134 bullet points explaining why this paper matters for Web3 investment\n    }\n\n    - Do not output anything except valid JSON object in JSON Lines.\n    - \"title\", \"summary\", \"why_matters\" text in the output must be written in Japanese.\n\n    Paper:\n    title: Nonlinear magnetization dynamics as a route to nonreciprocal phases, spin superfluidity, and analogue gravity\n    summary: The identification of platforms with independently tunable nonlinearity and non-Hermiticity promises a quantitative route to far-from-equilibrium universality across many-body systems. Here we show that a conventional ferromagnetic multilayer realizes this paradigm: balancing a dc drive against Gilbert damping stabilizes a chiral spin-superfluid limit cycle that spontaneously breaks spacetime-translation symmetry. The resulting superflow is intrinsically nonreciprocal: long-wavelength magnons of opposite chirality acquire asymmetric dispersions and propagate direction-selectively, realizing a spin-superfluid diode. This asymmetry is flow-borne - it reflects broken Galilean invariance and requires neither structural asymmetry nor finely tuned gain-loss balance. Linearized dynamics in the comoving superfluid frame are intrinsically pseudo-Hermitian and, in the long-wavelength sector, can be mapped to a (1+1)D wave equation on curved spacetime. Spatial modulation of the drive enables the generation of sonic horizons that parametrically squeeze magnons and produce Hawking-like particle-hole emission. Our results establish a tabletop route from nonlinear dissipative-driven magnetization dynamics to nonreciprocal transport, nonequilibrium phase transitions, and analogue-gravity kinematics.\n    link: https://arxiv.org/abs/2510.21963v2\n    "}}
{"custom_id": "2512.03825v1", "method": "POST", "url": "/v1/responses", "body": {"model": "gpt-5-mini", "input": "You are a specialist research analyst in Web3, DeFi, cryptography, and distributed systems.\n\n    Your task:\n    From the paper below (Title + Summary + Link), evaluate how useful each paper is for understanding investment opportunities or technological advantages within the Web3 / crypto / DeFi ecosystem.\n    Rate each paper on a five-level scale: Highest / High / Medium / Low / Lowest.\n\n    \"Useful\" means:\n\n    - Improves understanding of new cryptographic primitives relevant to blockchain performance or security\n    - Enhances scalability: distributed systems, P2P networking, consensus mechanisms\n    - Advances in zero knowledge, MPC, PQC that could impact future L1/L2 chains\n    - DeFi modeling, AMMs, MEV, risk models, liquidity dynamics\n    - Smart contract security, attack vectors, economic incentives\n    - Token economics, mechanism design for decentralized systems\n    - Quantum threats to blockchain or cryptography\n    - Any breakthrough that meaningfully improves decentralization, scalability, privacy, or composability\n\n    Output instructions:\n\n    - Output each JSON object in JSON Lines format (one line per paper).\n\n    {\n        \"title\": title of the paper (in Japanese),\n        \"summary\": A concise summary of the paper (in Japanese),\n        \"impact_level\": \"Highest|High|Medium|Low|Lowest\",\n        \"why_matters\": An array (JSON array) containing 2\u20134 bullet points explaining why this paper matters for Web3 investment\n    }\n\n    - Do not output anything except valid JSON object in JSON Lines.\n    - \"title\", \"summary\", \"why_matters\" text in the output must be written in Japanese.\n\n    Paper:\n    title: Acceleration of Parallel Tempering for Markov Chain Monte Carlo methods\n    summary: Markov Chain Monte Carlo methods are algorithms used to sample probability distributions, commonly used to sample the Boltzmann distribution of physical/chemical models (e.g., protein folding, Ising model, etc.). This allows us to study their properties by sampling the most probable states of those systems. However, the sampling capabilities of these methods are not sufficiently accurate when handling complex configuration spaces. This has resulted in the development of new techniques that improve sampling accuracy, usually at the expense of increasing the computational cost. One of such techniques is Parallel Tempering which improves accuracy by running several replicas which periodically exchange their states. Computationally, this imposes a significant slow-down, which can be counteracted by means of parallelization. These schemes enable MCMC/PT techniques to be run more effectively and allow larger models to be studied. In this work, we present a parallel implementation of Metropolis-Hastings with Parallel Tempering, using OpenMP and CUDA for the parallelization in modern CPUs and GPUs, respectively. The results show a maximum speed-up of 52x using OpenMP with 48 cores, and of 986x speed-up with the CUDA version. Furthermore, the results serve as a basic benchmark to compare a future quantum implementation of the same algorithm.\n    link: https://arxiv.org/abs/2512.03825v1\n    "}}
{"custom_id": "2506.11254v2", "method": "POST", "url": "/v1/responses", "body": {"model": "gpt-5-mini", "input": "You are a specialist research analyst in Web3, DeFi, cryptography, and distributed systems.\n\n    Your task:\n    From the paper below (Title + Summary + Link), evaluate how useful each paper is for understanding investment opportunities or technological advantages within the Web3 / crypto / DeFi ecosystem.\n    Rate each paper on a five-level scale: Highest / High / Medium / Low / Lowest.\n\n    \"Useful\" means:\n\n    - Improves understanding of new cryptographic primitives relevant to blockchain performance or security\n    - Enhances scalability: distributed systems, P2P networking, consensus mechanisms\n    - Advances in zero knowledge, MPC, PQC that could impact future L1/L2 chains\n    - DeFi modeling, AMMs, MEV, risk models, liquidity dynamics\n    - Smart contract security, attack vectors, economic incentives\n    - Token economics, mechanism design for decentralized systems\n    - Quantum threats to blockchain or cryptography\n    - Any breakthrough that meaningfully improves decentralization, scalability, privacy, or composability\n\n    Output instructions:\n\n    - Output each JSON object in JSON Lines format (one line per paper).\n\n    {\n        \"title\": title of the paper (in Japanese),\n        \"summary\": A concise summary of the paper (in Japanese),\n        \"impact_level\": \"Highest|High|Medium|Low|Lowest\",\n        \"why_matters\": An array (JSON array) containing 2\u20134 bullet points explaining why this paper matters for Web3 investment\n    }\n\n    - Do not output anything except valid JSON object in JSON Lines.\n    - \"title\", \"summary\", \"why_matters\" text in the output must be written in Japanese.\n\n    Paper:\n    title: Acquisition of Delocalized Information via Classical and Quantum Carriers\n    summary: We investigate the information-theoretic power of spatial superposition by analyzing tasks in which information is locally encoded at multiple distant sites and must be acquired by a single information carrier, such as a particle. Within an operational framework, we systematically compare the statistical correlations that can be generated in such tasks using classical particles, quantum particles in spatial superposition, and more general \"second-order interference\" resources. We bound classical strategies via convex polytopes and present a study of their symmetry, demonstrating that the vertices are inherently connected to K-juntas as defined in the classical theory of Boolean functions, while their facet inequalities are in one-to-one correspondence with oracle games. We then analyze the violation of the \"fingerprinting inequality\" achievable by the use of one quantum particle, and we study the dependence of this violation on the dimension d of the particle's internal degree of freedom. In particular, we show that the case of d = 2 can achieve a higher violation of the inequality than the previously investigated case of d = 1. We also provide analytic and numerical evidence that this violation cannot be further increased for larger d > 2. Finally, we find that both quantum and any other (generalized) second-order interference models exhibit the same asymptotic scaling in violating the fingerprinting inequality. Our results thereby further articulate quantum interference and spatial superposition as a resource for information processing.\n    link: https://arxiv.org/abs/2506.11254v2\n    "}}
{"custom_id": "2512.03816v1", "method": "POST", "url": "/v1/responses", "body": {"model": "gpt-5-mini", "input": "You are a specialist research analyst in Web3, DeFi, cryptography, and distributed systems.\n\n    Your task:\n    From the paper below (Title + Summary + Link), evaluate how useful each paper is for understanding investment opportunities or technological advantages within the Web3 / crypto / DeFi ecosystem.\n    Rate each paper on a five-level scale: Highest / High / Medium / Low / Lowest.\n\n    \"Useful\" means:\n\n    - Improves understanding of new cryptographic primitives relevant to blockchain performance or security\n    - Enhances scalability: distributed systems, P2P networking, consensus mechanisms\n    - Advances in zero knowledge, MPC, PQC that could impact future L1/L2 chains\n    - DeFi modeling, AMMs, MEV, risk models, liquidity dynamics\n    - Smart contract security, attack vectors, economic incentives\n    - Token economics, mechanism design for decentralized systems\n    - Quantum threats to blockchain or cryptography\n    - Any breakthrough that meaningfully improves decentralization, scalability, privacy, or composability\n\n    Output instructions:\n\n    - Output each JSON object in JSON Lines format (one line per paper).\n\n    {\n        \"title\": title of the paper (in Japanese),\n        \"summary\": A concise summary of the paper (in Japanese),\n        \"impact_level\": \"Highest|High|Medium|Low|Lowest\",\n        \"why_matters\": An array (JSON array) containing 2\u20134 bullet points explaining why this paper matters for Web3 investment\n    }\n\n    - Do not output anything except valid JSON object in JSON Lines.\n    - \"title\", \"summary\", \"why_matters\" text in the output must be written in Japanese.\n\n    Paper:\n    title: Log Probability Tracking of LLM APIs\n    summary: When using an LLM through an API provider, users expect the served model to remain consistent over time, a property crucial for the reliability of downstream applications and the reproducibility of research. Existing audit methods are too costly to apply at regular time intervals to the wide range of available LLM APIs. This means that model updates are left largely unmonitored in practice. In this work, we show that while LLM log probabilities (logprobs) are usually non-deterministic, they can still be used as the basis for cost-effective continuous monitoring of LLM APIs. We apply a simple statistical test based on the average value of each token logprob, requesting only a single token of output. This is enough to detect changes as small as one step of fine-tuning, making this approach more sensitive than existing methods while being 1,000x cheaper. We introduce the TinyChange benchmark as a way to measure the sensitivity of audit methods in the context of small, realistic model changes.\n    link: https://arxiv.org/abs/2512.03816v1\n    "}}
{"custom_id": "2407.14938v5", "method": "POST", "url": "/v1/responses", "body": {"model": "gpt-5-mini", "input": "You are a specialist research analyst in Web3, DeFi, cryptography, and distributed systems.\n\n    Your task:\n    From the paper below (Title + Summary + Link), evaluate how useful each paper is for understanding investment opportunities or technological advantages within the Web3 / crypto / DeFi ecosystem.\n    Rate each paper on a five-level scale: Highest / High / Medium / Low / Lowest.\n\n    \"Useful\" means:\n\n    - Improves understanding of new cryptographic primitives relevant to blockchain performance or security\n    - Enhances scalability: distributed systems, P2P networking, consensus mechanisms\n    - Advances in zero knowledge, MPC, PQC that could impact future L1/L2 chains\n    - DeFi modeling, AMMs, MEV, risk models, liquidity dynamics\n    - Smart contract security, attack vectors, economic incentives\n    - Token economics, mechanism design for decentralized systems\n    - Quantum threats to blockchain or cryptography\n    - Any breakthrough that meaningfully improves decentralization, scalability, privacy, or composability\n\n    Output instructions:\n\n    - Output each JSON object in JSON Lines format (one line per paper).\n\n    {\n        \"title\": title of the paper (in Japanese),\n        \"summary\": A concise summary of the paper (in Japanese),\n        \"impact_level\": \"Highest|High|Medium|Low|Lowest\",\n        \"why_matters\": An array (JSON array) containing 2\u20134 bullet points explaining why this paper matters for Web3 investment\n    }\n\n    - Do not output anything except valid JSON object in JSON Lines.\n    - \"title\", \"summary\", \"why_matters\" text in the output must be written in Japanese.\n\n    Paper:\n    title: Exercising the CCPA Opt-out Right on Android: Legally Mandated but Practically Challenging\n    summary: The business model of many mobile apps is based on generating revenue from sharing user data with ad networks and other companies to deliver personalized ads. The California Consumer Privacy Act (CCPA) gives California residents a right to opt out of the selling and sharing of their personal information. In two experiments we evaluate to which extent popular apps on the Android platform enable California residents to exercise their CCPA opt-out right. In our first experiment -- manually exercising the opt-out right via app-level UIs for a set of 100 apps -- we find that only 48 apps implement the legally mandated setting, which suggests that CCPA opt-out right non-compliance is a broader issue on the platform. In our second experiment -- automatically exercising the opt-out right at the platform-level by sending Global Privacy Control (GPC) signals -- we find for an app dataset of $1,811$ apps that GPC is largely ineffective. While we estimate with 95% confidence that 62%--81% of apps in our app dataset must respect the CCPA's opt-out right, many apps do not do so. Disabling apps' access to the AdID, which is not intended for exercising the CCPA opt-out right but could have practical effect in this regard, does not lead to a different result. For example, when sending GPC signals and disabling apps' access to the AdID, 338 apps still had the ccpa status of the ad network Vungle set to opted in while only 26 had set it to opted out. Overall, our results suggest a compliance gap as California residents have no effective way of exercising their CCPA opt-out right on the Android platform; neither at the app- nor at the platform-level. We think that re-purposing the Android AdID setting as an opt-out right setting with legal meaning could resolve this compliance gap under the CCPA and other laws and improve users' privacy on the platform overall.\n    link: https://arxiv.org/abs/2407.14938v5\n    "}}
{"custom_id": "2512.03792v1", "method": "POST", "url": "/v1/responses", "body": {"model": "gpt-5-mini", "input": "You are a specialist research analyst in Web3, DeFi, cryptography, and distributed systems.\n\n    Your task:\n    From the paper below (Title + Summary + Link), evaluate how useful each paper is for understanding investment opportunities or technological advantages within the Web3 / crypto / DeFi ecosystem.\n    Rate each paper on a five-level scale: Highest / High / Medium / Low / Lowest.\n\n    \"Useful\" means:\n\n    - Improves understanding of new cryptographic primitives relevant to blockchain performance or security\n    - Enhances scalability: distributed systems, P2P networking, consensus mechanisms\n    - Advances in zero knowledge, MPC, PQC that could impact future L1/L2 chains\n    - DeFi modeling, AMMs, MEV, risk models, liquidity dynamics\n    - Smart contract security, attack vectors, economic incentives\n    - Token economics, mechanism design for decentralized systems\n    - Quantum threats to blockchain or cryptography\n    - Any breakthrough that meaningfully improves decentralization, scalability, privacy, or composability\n\n    Output instructions:\n\n    - Output each JSON object in JSON Lines format (one line per paper).\n\n    {\n        \"title\": title of the paper (in Japanese),\n        \"summary\": A concise summary of the paper (in Japanese),\n        \"impact_level\": \"Highest|High|Medium|Low|Lowest\",\n        \"why_matters\": An array (JSON array) containing 2\u20134 bullet points explaining why this paper matters for Web3 investment\n    }\n\n    - Do not output anything except valid JSON object in JSON Lines.\n    - \"title\", \"summary\", \"why_matters\" text in the output must be written in Japanese.\n\n    Paper:\n    title: Unfolding Challenges in Securing and Regulating Unmanned Air Vehicles\n    summary: Unmanned Aerial Vehicles (UAVs) or drones are being introduced in a wide range of commercial applications. This has also made them prime targets of attackers who compromise their fundamental security properties, including confidentiality, integrity, and availability. As researchers discover novel threat vectors in UAVs, the government and industry are increasingly concerned about their limited ability to secure and regulate UAVs and their usage. With the aim of unfolding a path for a large-scale commercial UAV network deployment, we conduct a comprehensive state-of-the-art study and examine the prevailing security challenges. Unlike the prior art, we focus on uncovering the research gaps that must be addressed to enforce security policy regulations in civilian off-the-shelf drone systems. To that end, we first examine the known security threats to UAVs based on their impact and effectiveness. We then analyze existing countermeasures to prevent, detect, and respond to these threats in terms of security and performance overhead. We further outline the future research directions for securing UAVs. Finally, we establish the fundamental requirements and highlight critical research challenges in introducing a regulatory entity to achieve a secure and regulated UAV network.\n    link: https://arxiv.org/abs/2512.03792v1\n    "}}
{"custom_id": "2512.03791v1", "method": "POST", "url": "/v1/responses", "body": {"model": "gpt-5-mini", "input": "You are a specialist research analyst in Web3, DeFi, cryptography, and distributed systems.\n\n    Your task:\n    From the paper below (Title + Summary + Link), evaluate how useful each paper is for understanding investment opportunities or technological advantages within the Web3 / crypto / DeFi ecosystem.\n    Rate each paper on a five-level scale: Highest / High / Medium / Low / Lowest.\n\n    \"Useful\" means:\n\n    - Improves understanding of new cryptographic primitives relevant to blockchain performance or security\n    - Enhances scalability: distributed systems, P2P networking, consensus mechanisms\n    - Advances in zero knowledge, MPC, PQC that could impact future L1/L2 chains\n    - DeFi modeling, AMMs, MEV, risk models, liquidity dynamics\n    - Smart contract security, attack vectors, economic incentives\n    - Token economics, mechanism design for decentralized systems\n    - Quantum threats to blockchain or cryptography\n    - Any breakthrough that meaningfully improves decentralization, scalability, privacy, or composability\n\n    Output instructions:\n\n    - Output each JSON object in JSON Lines format (one line per paper).\n\n    {\n        \"title\": title of the paper (in Japanese),\n        \"summary\": A concise summary of the paper (in Japanese),\n        \"impact_level\": \"Highest|High|Medium|Low|Lowest\",\n        \"why_matters\": An array (JSON array) containing 2\u20134 bullet points explaining why this paper matters for Web3 investment\n    }\n\n    - Do not output anything except valid JSON object in JSON Lines.\n    - \"title\", \"summary\", \"why_matters\" text in the output must be written in Japanese.\n\n    Paper:\n    title: CCN: Decentralized Cross-Chain Channel Networks Supporting Secure and Privacy-Preserving Multi-Hop Interactions\n    summary: Cross-chain technology enables interoperability among otherwise isolated blockchains, supporting interactions across heterogeneous networks. Similar to how multi-hop communication became fundamental in the evolution of the Internet, the demand for multi-hop cross-chain interactions is gaining increasing attention. However, this growing demand introduces new security and privacy challenges. On the security side, multi-hop interactions depend on the availability of multiple participating nodes. If any node becomes temporarily offline during execution, the protocol may fail to complete correctly, leading to settlement failure or fund loss. On the privacy side, the need for on-chain transparency to validate intermediate states may unintentionally leak linkable information, compromising the unlinkability of user interactions. In this paper, we propose the Cross-Chain Channel Network (CCN), a decentralized network designed to support secure and privacy-preserving multi-hop cross-chain transactions. Through experimental evaluation, we identify two critical types of offline failures, referred to as active and passive offline cases, which have not been adequately addressed by existing solutions. To mitigate these issues, we introduce R-HTLC, a core protocol within CCN. R-HTLC incorporates an hourglass mechanism and a multi-path refund strategy to ensure settlement correctness even when some nodes go offline during execution. Importantly, CCN addresses not only the correctness under offline conditions but also maintains unlinkability in such adversarial settings. To overcome this, CCN leverages zero-knowledge proofs and off-chain coordination, ensuring that interaction relationships remain indistinguishable even when certain nodes are temporarily offline.\n    link: https://arxiv.org/abs/2512.03791v1\n    "}}
{"custom_id": "2512.03775v1", "method": "POST", "url": "/v1/responses", "body": {"model": "gpt-5-mini", "input": "You are a specialist research analyst in Web3, DeFi, cryptography, and distributed systems.\n\n    Your task:\n    From the paper below (Title + Summary + Link), evaluate how useful each paper is for understanding investment opportunities or technological advantages within the Web3 / crypto / DeFi ecosystem.\n    Rate each paper on a five-level scale: Highest / High / Medium / Low / Lowest.\n\n    \"Useful\" means:\n\n    - Improves understanding of new cryptographic primitives relevant to blockchain performance or security\n    - Enhances scalability: distributed systems, P2P networking, consensus mechanisms\n    - Advances in zero knowledge, MPC, PQC that could impact future L1/L2 chains\n    - DeFi modeling, AMMs, MEV, risk models, liquidity dynamics\n    - Smart contract security, attack vectors, economic incentives\n    - Token economics, mechanism design for decentralized systems\n    - Quantum threats to blockchain or cryptography\n    - Any breakthrough that meaningfully improves decentralization, scalability, privacy, or composability\n\n    Output instructions:\n\n    - Output each JSON object in JSON Lines format (one line per paper).\n\n    {\n        \"title\": title of the paper (in Japanese),\n        \"summary\": A concise summary of the paper (in Japanese),\n        \"impact_level\": \"Highest|High|Medium|Low|Lowest\",\n        \"why_matters\": An array (JSON array) containing 2\u20134 bullet points explaining why this paper matters for Web3 investment\n    }\n\n    - Do not output anything except valid JSON object in JSON Lines.\n    - \"title\", \"summary\", \"why_matters\" text in the output must be written in Japanese.\n\n    Paper:\n    title: \"MCP Does Not Stand for Misuse Cryptography Protocol\": Uncovering Cryptographic Misuse in Model Context Protocol at Scale\n    summary: The Model Context Protocol (MCP) is rapidly emerging as the middleware for LLM-based applications, offering a standardized interface for tool integration. However, its built-in security mechanisms are minimal: while schemas and declarations prevent malformed requests, MCP provides no guarantees of authenticity or confidentiality, forcing developers to implement cryptography themselves. Such ad hoc practices are historically prone to misuse, and within MCP they threaten sensitive data and services. We present MICRYSCOPE, the first domain-specific framework for detecting cryptographic misuses in MCP implementations. MICRYSCOPE combines three key innovations: a cross-language intermediate representation that normalizes cryptographic APIs across diverse ecosystems, a hybrid dependency analysis that uncovers explicit and implicit function relationships (including insecure runtime compositions orchestrated by LLMs) and a taint-based misuse detector that tracks sensitive data flows and flags violations of established cryptographic rules. Applying MICRYSCOPE to 9,403 MCP servers, we identified 720 with cryptographic logic, of which 19.7% exhibited misuses. These flaws are concentrated in certain markets (e.g., Smithery Registry with 42% insecure servers), languages (Python at 34% misuse rate), and categories (Developer Tools and Data Science & ML accounting for over 50% of all misuses). Case studies reveal real-world consequences, including leaked API keys, insecure DES/ECB tools, and MD5-based authentication bypasses. Our study establishes the first ecosystem-wide view of cryptographic misuse in MCP and provides both tools and insights to strengthen the security foundations of this rapidly growing protocol.\n    link: https://arxiv.org/abs/2512.03775v1\n    "}}
{"custom_id": "2512.03771v1", "method": "POST", "url": "/v1/responses", "body": {"model": "gpt-5-mini", "input": "You are a specialist research analyst in Web3, DeFi, cryptography, and distributed systems.\n\n    Your task:\n    From the paper below (Title + Summary + Link), evaluate how useful each paper is for understanding investment opportunities or technological advantages within the Web3 / crypto / DeFi ecosystem.\n    Rate each paper on a five-level scale: Highest / High / Medium / Low / Lowest.\n\n    \"Useful\" means:\n\n    - Improves understanding of new cryptographic primitives relevant to blockchain performance or security\n    - Enhances scalability: distributed systems, P2P networking, consensus mechanisms\n    - Advances in zero knowledge, MPC, PQC that could impact future L1/L2 chains\n    - DeFi modeling, AMMs, MEV, risk models, liquidity dynamics\n    - Smart contract security, attack vectors, economic incentives\n    - Token economics, mechanism design for decentralized systems\n    - Quantum threats to blockchain or cryptography\n    - Any breakthrough that meaningfully improves decentralization, scalability, privacy, or composability\n\n    Output instructions:\n\n    - Output each JSON object in JSON Lines format (one line per paper).\n\n    {\n        \"title\": title of the paper (in Japanese),\n        \"summary\": A concise summary of the paper (in Japanese),\n        \"impact_level\": \"Highest|High|Medium|Low|Lowest\",\n        \"why_matters\": An array (JSON array) containing 2\u20134 bullet points explaining why this paper matters for Web3 investment\n    }\n\n    - Do not output anything except valid JSON object in JSON Lines.\n    - \"title\", \"summary\", \"why_matters\" text in the output must be written in Japanese.\n\n    Paper:\n    title: In-Context Representation Hijacking\n    summary: We introduce \\textbf{Doublespeak}, a simple \\emph{in-context representation hijacking} attack against large language models (LLMs). The attack works by systematically replacing a harmful keyword (e.g., \\textit{bomb}) with a benign token (e.g., \\textit{carrot}) across multiple in-context examples, provided a prefix to a harmful request. We demonstrate that this substitution leads to the internal representation of the benign token converging toward that of the harmful one, effectively embedding the harmful semantics under a euphemism. As a result, superficially innocuous prompts (e.g., ``How to build a carrot?'') are internally interpreted as disallowed instructions (e.g., ``How to build a bomb?''), thereby bypassing the model's safety alignment. We use interpretability tools to show that this semantic overwrite emerges layer by layer, with benign meanings in early layers converging into harmful semantics in later ones. Doublespeak is optimization-free, broadly transferable across model families, and achieves strong success rates on closed-source and open-source systems, reaching 74\\% ASR on Llama-3.3-70B-Instruct with a single-sentence context override. Our findings highlight a new attack surface in the latent space of LLMs, revealing that current alignment strategies are insufficient and should instead operate at the representation level.\n    link: https://arxiv.org/abs/2512.03771v1\n    "}}
{"custom_id": "2512.03770v1", "method": "POST", "url": "/v1/responses", "body": {"model": "gpt-5-mini", "input": "You are a specialist research analyst in Web3, DeFi, cryptography, and distributed systems.\n\n    Your task:\n    From the paper below (Title + Summary + Link), evaluate how useful each paper is for understanding investment opportunities or technological advantages within the Web3 / crypto / DeFi ecosystem.\n    Rate each paper on a five-level scale: Highest / High / Medium / Low / Lowest.\n\n    \"Useful\" means:\n\n    - Improves understanding of new cryptographic primitives relevant to blockchain performance or security\n    - Enhances scalability: distributed systems, P2P networking, consensus mechanisms\n    - Advances in zero knowledge, MPC, PQC that could impact future L1/L2 chains\n    - DeFi modeling, AMMs, MEV, risk models, liquidity dynamics\n    - Smart contract security, attack vectors, economic incentives\n    - Token economics, mechanism design for decentralized systems\n    - Quantum threats to blockchain or cryptography\n    - Any breakthrough that meaningfully improves decentralization, scalability, privacy, or composability\n\n    Output instructions:\n\n    - Output each JSON object in JSON Lines format (one line per paper).\n\n    {\n        \"title\": title of the paper (in Japanese),\n        \"summary\": A concise summary of the paper (in Japanese),\n        \"impact_level\": \"Highest|High|Medium|Low|Lowest\",\n        \"why_matters\": An array (JSON array) containing 2\u20134 bullet points explaining why this paper matters for Web3 investment\n    }\n\n    - Do not output anything except valid JSON object in JSON Lines.\n    - \"title\", \"summary\", \"why_matters\" text in the output must be written in Japanese.\n\n    Paper:\n    title: Quantum Simulations of Opinion Dynamics\n    summary: Quantum computing offers powerful new approaches for modeling complex social phenomena. Here, we propose and demonstrate quantum simulations of opinion dynamics, leveraging quantum superposition, measurement-induced state collapse, and entanglement to model realistic psychological and social processes. Specifically, we develop quantum models of opinion dynamics, solving exactly and simulating on IBM Quantum hardware. Our results, based on quantum devices and validated with practical quantum circuits, illustrate how quantum effects can enhance understanding of consensus formation, polarization, and collective decision-making. These findings pave the way for further exploration into quantum-enhanced social modeling, highlighting the potential of near-term quantum computers for simulating collective behavior in complex systems.\n    link: https://arxiv.org/abs/2512.03770v1\n    "}}
{"custom_id": "2512.03765v1", "method": "POST", "url": "/v1/responses", "body": {"model": "gpt-5-mini", "input": "You are a specialist research analyst in Web3, DeFi, cryptography, and distributed systems.\n\n    Your task:\n    From the paper below (Title + Summary + Link), evaluate how useful each paper is for understanding investment opportunities or technological advantages within the Web3 / crypto / DeFi ecosystem.\n    Rate each paper on a five-level scale: Highest / High / Medium / Low / Lowest.\n\n    \"Useful\" means:\n\n    - Improves understanding of new cryptographic primitives relevant to blockchain performance or security\n    - Enhances scalability: distributed systems, P2P networking, consensus mechanisms\n    - Advances in zero knowledge, MPC, PQC that could impact future L1/L2 chains\n    - DeFi modeling, AMMs, MEV, risk models, liquidity dynamics\n    - Smart contract security, attack vectors, economic incentives\n    - Token economics, mechanism design for decentralized systems\n    - Quantum threats to blockchain or cryptography\n    - Any breakthrough that meaningfully improves decentralization, scalability, privacy, or composability\n\n    Output instructions:\n\n    - Output each JSON object in JSON Lines format (one line per paper).\n\n    {\n        \"title\": title of the paper (in Japanese),\n        \"summary\": A concise summary of the paper (in Japanese),\n        \"impact_level\": \"Highest|High|Medium|Low|Lowest\",\n        \"why_matters\": An array (JSON array) containing 2\u20134 bullet points explaining why this paper matters for Web3 investment\n    }\n\n    - Do not output anything except valid JSON object in JSON Lines.\n    - \"title\", \"summary\", \"why_matters\" text in the output must be written in Japanese.\n\n    Paper:\n    title: The Treasury Proof Ledger: A Cryptographic Framework for Accountable Bitcoin Treasuries\n    summary: Public companies and institutional investors that hold Bitcoin face increasing pressure to show solvency, manage risk, and satisfy regulatory expectations without exposing internal wallet structures or trading strategies. This paper introduces the Treasury Proof Ledger (TPL), a Bitcoin-anchored logging framework for multi-domain Bitcoin treasuries that treats on-chain and off-chain exposures as a conserved state machine with an explicit fee sink. A TPL instance records proof-of-reserves snapshots, proof-of-transit receipts for movements between domains, and policy metadata, and it supports restricted views based on stakeholder permissions. We define an idealised TPL model, represent Bitcoin treasuries as multi-domain exposure vectors, and give deployment-level security notions including exposure soundness, policy completeness, non-equivocation, and privacy-compatible policy views. We then outline how practical, restricted forms of these guarantees can be achieved by combining standard proof-of-reserves and proof-of-transit techniques with hash-based commitments anchored on Bitcoin. The results are existence-type statements: they show which guarantees are achievable once economic and governance assumptions are set, without claiming that any current system already provides them. A stylised corporate-treasury example illustrates how TPL could support responsible transparency policies and future cross-institution checks consistent with Bitcoin's fixed monetary supply.\n    link: https://arxiv.org/abs/2512.03765v1\n    "}}
{"custom_id": "2512.00833v2", "method": "POST", "url": "/v1/responses", "body": {"model": "gpt-5-mini", "input": "You are a specialist research analyst in Web3, DeFi, cryptography, and distributed systems.\n\n    Your task:\n    From the paper below (Title + Summary + Link), evaluate how useful each paper is for understanding investment opportunities or technological advantages within the Web3 / crypto / DeFi ecosystem.\n    Rate each paper on a five-level scale: Highest / High / Medium / Low / Lowest.\n\n    \"Useful\" means:\n\n    - Improves understanding of new cryptographic primitives relevant to blockchain performance or security\n    - Enhances scalability: distributed systems, P2P networking, consensus mechanisms\n    - Advances in zero knowledge, MPC, PQC that could impact future L1/L2 chains\n    - DeFi modeling, AMMs, MEV, risk models, liquidity dynamics\n    - Smart contract security, attack vectors, economic incentives\n    - Token economics, mechanism design for decentralized systems\n    - Quantum threats to blockchain or cryptography\n    - Any breakthrough that meaningfully improves decentralization, scalability, privacy, or composability\n\n    Output instructions:\n\n    - Output each JSON object in JSON Lines format (one line per paper).\n\n    {\n        \"title\": title of the paper (in Japanese),\n        \"summary\": A concise summary of the paper (in Japanese),\n        \"impact_level\": \"Highest|High|Medium|Low|Lowest\",\n        \"why_matters\": An array (JSON array) containing 2\u20134 bullet points explaining why this paper matters for Web3 investment\n    }\n\n    - Do not output anything except valid JSON object in JSON Lines.\n    - \"title\", \"summary\", \"why_matters\" text in the output must be written in Japanese.\n\n    Paper:\n    title: Logic Encryption: This Time for Real\n    summary: Modern circuits face various threats like reverse engineering, theft of intellectual property (IP), side-channel attacks, etc. Here, we present a novel approach for IP protection based on logic encryption (LE). Unlike established schemes for logic locking, our work obfuscates the circuit's structure and functionality by encoding and encrypting the logic itself. We devise an end-to-end method for practical LE implementation based on standard cryptographic algorithms, key-bit randomization, simple circuit design techniques, and system-level synthesis operations, all in a correct-by-construction manner. Our extensive analysis demonstrates the remarkable efficacy of our scheme, outperforming prior art against a range of oracle-less attacks covering crucial threat vectors, all with lower design overheads. We provide a full open-source release.\n    link: https://arxiv.org/abs/2512.00833v2\n    "}}
{"custom_id": "2512.03758v1", "method": "POST", "url": "/v1/responses", "body": {"model": "gpt-5-mini", "input": "You are a specialist research analyst in Web3, DeFi, cryptography, and distributed systems.\n\n    Your task:\n    From the paper below (Title + Summary + Link), evaluate how useful each paper is for understanding investment opportunities or technological advantages within the Web3 / crypto / DeFi ecosystem.\n    Rate each paper on a five-level scale: Highest / High / Medium / Low / Lowest.\n\n    \"Useful\" means:\n\n    - Improves understanding of new cryptographic primitives relevant to blockchain performance or security\n    - Enhances scalability: distributed systems, P2P networking, consensus mechanisms\n    - Advances in zero knowledge, MPC, PQC that could impact future L1/L2 chains\n    - DeFi modeling, AMMs, MEV, risk models, liquidity dynamics\n    - Smart contract security, attack vectors, economic incentives\n    - Token economics, mechanism design for decentralized systems\n    - Quantum threats to blockchain or cryptography\n    - Any breakthrough that meaningfully improves decentralization, scalability, privacy, or composability\n\n    Output instructions:\n\n    - Output each JSON object in JSON Lines format (one line per paper).\n\n    {\n        \"title\": title of the paper (in Japanese),\n        \"summary\": A concise summary of the paper (in Japanese),\n        \"impact_level\": \"Highest|High|Medium|Low|Lowest\",\n        \"why_matters\": An array (JSON array) containing 2\u20134 bullet points explaining why this paper matters for Web3 investment\n    }\n\n    - Do not output anything except valid JSON object in JSON Lines.\n    - \"title\", \"summary\", \"why_matters\" text in the output must be written in Japanese.\n\n    Paper:\n    title: An end-to-end quantum algorithm for nonlinear fluid dynamics with bounded quantum advantage\n    summary: Computational fluid dynamics (CFD) is a cornerstone of classical scientific computing, and there is growing interest in whether quantum computers can accelerate such simulations. To date, the existing proposals for fault-tolerant quantum algorithms for CFD have almost exclusively been based on the Carleman embedding method, used to encode nonlinearities on a quantum computer. In this work, we begin by showing that these proposals suffer from a range of severe bottlenecks that negate conjectured quantum advantages: lack of convergence of the Carleman method, prohibitive time-stepping requirements, unfavorable condition number scaling, and inefficient data extraction. With these roadblocks clearly identified, we develop a novel algorithm for the incompressible lattice Boltzmann equation that circumvents these obstacles, and then provide a detailed analysis of our algorithm, including all potential sources of algorithmic complexity, as well as gate count estimates. We find that for an end-to-end problem, a modest quantum advantage may be preserved for selected observables in the high-error-tolerance regime. We lower bound the Reynolds number scaling of our quantum algorithm in dimension $D$ at Kolmogorov microscale resolution with $O(\\mathrm{Re}^{\\frac{3}{4}(1+\\frac{D}{2})} \\times q_M)$, where $q_M$ is a multiplicative overhead for data extraction with $q_M = O(\\mathrm{Re}^{\\frac{3}{8}})$ for the drag force. This upper bounds the scaling improvement over classical algorithms by $O(\\mathrm{Re}^{\\frac{3D}{8}})$. However, our numerical investigations suggest a lower speedup, with a scaling estimate of $O(\\mathrm{Re}^{1.936} \\times q_M)$ for $D=2$. Our results give robust evidence that small, but nontrivial, quantum advantages can be achieved in the context of CFD, and motivate the need for additional rigorous end-to-end quantum algorithm development.\n    link: https://arxiv.org/abs/2512.03758v1\n    "}}
{"custom_id": "2506.24066v2", "method": "POST", "url": "/v1/responses", "body": {"model": "gpt-5-mini", "input": "You are a specialist research analyst in Web3, DeFi, cryptography, and distributed systems.\n\n    Your task:\n    From the paper below (Title + Summary + Link), evaluate how useful each paper is for understanding investment opportunities or technological advantages within the Web3 / crypto / DeFi ecosystem.\n    Rate each paper on a five-level scale: Highest / High / Medium / Low / Lowest.\n\n    \"Useful\" means:\n\n    - Improves understanding of new cryptographic primitives relevant to blockchain performance or security\n    - Enhances scalability: distributed systems, P2P networking, consensus mechanisms\n    - Advances in zero knowledge, MPC, PQC that could impact future L1/L2 chains\n    - DeFi modeling, AMMs, MEV, risk models, liquidity dynamics\n    - Smart contract security, attack vectors, economic incentives\n    - Token economics, mechanism design for decentralized systems\n    - Quantum threats to blockchain or cryptography\n    - Any breakthrough that meaningfully improves decentralization, scalability, privacy, or composability\n\n    Output instructions:\n\n    - Output each JSON object in JSON Lines format (one line per paper).\n\n    {\n        \"title\": title of the paper (in Japanese),\n        \"summary\": A concise summary of the paper (in Japanese),\n        \"impact_level\": \"Highest|High|Medium|Low|Lowest\",\n        \"why_matters\": An array (JSON array) containing 2\u20134 bullet points explaining why this paper matters for Web3 investment\n    }\n\n    - Do not output anything except valid JSON object in JSON Lines.\n    - \"title\", \"summary\", \"why_matters\" text in the output must be written in Japanese.\n\n    Paper:\n    title: Quantum state transfer and periodicity in discrete-time quantum walks under non--Markovian dephasing noise\n    summary: In quantum communication, quantum state transfer from one location to another in a quantum network plays a prominent role, where the impact of noise could be crucial. The idea of state transfer can be fruitfully associated with quantum walk on graphs. We investigate the consequences of non-Markovian quantum noises on periodicity and state transfer induced by a discrete-time quantum walk on graphs, governed by the Grover coin operator. Different bipartite graphs, such as the path graph, cycle graph, star graph, and complete bipartite graph, present periodicity and state transfer in a discrete-time quantum walk depending on the topology of the graph. We investigate the effect of quantum non-Markovian dephasing noises, particularly quantum non-Markovian Random Telegraph Noise (RTN) and modified non-Markovian Ornstein-Uhlenbeck Noise (OUN) on state transfer and periodicity. We demonstrate how the RTN and OUN noises allow state transfer and periodicity for a finite number of steps in a quantum walk. Our investigation brings out the feasibility of state transfer in a noisy environment.\n    link: https://arxiv.org/abs/2506.24066v2\n    "}}
{"custom_id": "2512.03748v1", "method": "POST", "url": "/v1/responses", "body": {"model": "gpt-5-mini", "input": "You are a specialist research analyst in Web3, DeFi, cryptography, and distributed systems.\n\n    Your task:\n    From the paper below (Title + Summary + Link), evaluate how useful each paper is for understanding investment opportunities or technological advantages within the Web3 / crypto / DeFi ecosystem.\n    Rate each paper on a five-level scale: Highest / High / Medium / Low / Lowest.\n\n    \"Useful\" means:\n\n    - Improves understanding of new cryptographic primitives relevant to blockchain performance or security\n    - Enhances scalability: distributed systems, P2P networking, consensus mechanisms\n    - Advances in zero knowledge, MPC, PQC that could impact future L1/L2 chains\n    - DeFi modeling, AMMs, MEV, risk models, liquidity dynamics\n    - Smart contract security, attack vectors, economic incentives\n    - Token economics, mechanism design for decentralized systems\n    - Quantum threats to blockchain or cryptography\n    - Any breakthrough that meaningfully improves decentralization, scalability, privacy, or composability\n\n    Output instructions:\n\n    - Output each JSON object in JSON Lines format (one line per paper).\n\n    {\n        \"title\": title of the paper (in Japanese),\n        \"summary\": A concise summary of the paper (in Japanese),\n        \"impact_level\": \"Highest|High|Medium|Low|Lowest\",\n        \"why_matters\": An array (JSON array) containing 2\u20134 bullet points explaining why this paper matters for Web3 investment\n    }\n\n    - Do not output anything except valid JSON object in JSON Lines.\n    - \"title\", \"summary\", \"why_matters\" text in the output must be written in Japanese.\n\n    Paper:\n    title: Widefield Quantum Sensor for Vector Magnetic Field Imaging of Micromagnetic Structures\n    summary: Many spintronic, magnetic-memory, and neuromorphic devices rely on spatially varying magnetic fields. Quantitatively imaging these fields with full vector information over extended areas remains a major challenge. Existing probes either offer nanoscale resolution at the cost of slow scanning, or widefield imaging with limited vector sensitivity or material constraints. Quantum sensing with nitrogen-vacancy (NV) centers in diamond promises to bridge this gap, but a practical camera-based vector magnetometry implementation on relevant microstructures has not been demonstrated. Here we adapt a commercial widefield microscope to implement a camera-compatible pulsed optically detected magnetic resonance protocol to reconstruct stray-field vectors from microscale devices. By resolving the Zeeman shifts of the four NV orientations, we reconstruct the stray-field vector generated by microfabricated permalloy structures that host multiple stable remanent states. Our implementation achieves a spatial resolution of $\\approx 0.52 ~\u03bc\\mathrm{m}$ across an $83~\u03bc\\mathrm{m} \\times 83~\u03bc\\mathrm{m}$ field of view and a peak sensitivity of $ (828 \\pm 142)~\\mathrm{nT\\,Hz^{-1}}$, with acquisition times of only a few minutes. These results establish pulsed widefield NV magnetometry on standard microscopes as a practical and scalable tool for routine vector-resolved imaging of complex magnetic devices.\n    link: https://arxiv.org/abs/2512.03748v1\n    "}}
{"custom_id": "2506.13689v5", "method": "POST", "url": "/v1/responses", "body": {"model": "gpt-5-mini", "input": "You are a specialist research analyst in Web3, DeFi, cryptography, and distributed systems.\n\n    Your task:\n    From the paper below (Title + Summary + Link), evaluate how useful each paper is for understanding investment opportunities or technological advantages within the Web3 / crypto / DeFi ecosystem.\n    Rate each paper on a five-level scale: Highest / High / Medium / Low / Lowest.\n\n    \"Useful\" means:\n\n    - Improves understanding of new cryptographic primitives relevant to blockchain performance or security\n    - Enhances scalability: distributed systems, P2P networking, consensus mechanisms\n    - Advances in zero knowledge, MPC, PQC that could impact future L1/L2 chains\n    - DeFi modeling, AMMs, MEV, risk models, liquidity dynamics\n    - Smart contract security, attack vectors, economic incentives\n    - Token economics, mechanism design for decentralized systems\n    - Quantum threats to blockchain or cryptography\n    - Any breakthrough that meaningfully improves decentralization, scalability, privacy, or composability\n\n    Output instructions:\n\n    - Output each JSON object in JSON Lines format (one line per paper).\n\n    {\n        \"title\": title of the paper (in Japanese),\n        \"summary\": A concise summary of the paper (in Japanese),\n        \"impact_level\": \"Highest|High|Medium|Low|Lowest\",\n        \"why_matters\": An array (JSON array) containing 2\u20134 bullet points explaining why this paper matters for Web3 investment\n    }\n\n    - Do not output anything except valid JSON object in JSON Lines.\n    - \"title\", \"summary\", \"why_matters\" text in the output must be written in Japanese.\n\n    Paper:\n    title: Purely quantum memory in closed systems observed via imperfect measurements\n    summary: The detection and quantification of non-Markovianity, a.k.a. memory, in quantum systems is a central problem in the theory of open quantum systems. There memory is as a result of the interaction between the system and its environment. Little is known, however, about memory effects induced by imperfect measurements on closed systems, where an entanglement with the environment is not possible. We investigate the emergence and characteristics of memory in closed systems observed via imperfect stroboscopic quantum measurements yielding coarse-grained outcomes. We consider ideal and two kinds of imperfect measurements: von Neumann measurements--the analogue of classical lumping--which destroy any coherence in the system, and genuinely quantum-lumping L\u00fcders measurements preserving certain quantum correlations. Whereas the conditions for Markov dynamics under von Neumann lumping are the same as for classical dynamics, quantum-lumping requires stronger conditions, i.e. the absence of any detectable coherence. We introduce the concept of purely quantum memory having no classical counterpart. We illustrate our results with a quantum walk on a lattice and discuss their implications for dissipative dynamics and decoherence effects induced by more realistic measurements.\n    link: https://arxiv.org/abs/2506.13689v5\n    "}}
{"custom_id": "2512.03722v1", "method": "POST", "url": "/v1/responses", "body": {"model": "gpt-5-mini", "input": "You are a specialist research analyst in Web3, DeFi, cryptography, and distributed systems.\n\n    Your task:\n    From the paper below (Title + Summary + Link), evaluate how useful each paper is for understanding investment opportunities or technological advantages within the Web3 / crypto / DeFi ecosystem.\n    Rate each paper on a five-level scale: Highest / High / Medium / Low / Lowest.\n\n    \"Useful\" means:\n\n    - Improves understanding of new cryptographic primitives relevant to blockchain performance or security\n    - Enhances scalability: distributed systems, P2P networking, consensus mechanisms\n    - Advances in zero knowledge, MPC, PQC that could impact future L1/L2 chains\n    - DeFi modeling, AMMs, MEV, risk models, liquidity dynamics\n    - Smart contract security, attack vectors, economic incentives\n    - Token economics, mechanism design for decentralized systems\n    - Quantum threats to blockchain or cryptography\n    - Any breakthrough that meaningfully improves decentralization, scalability, privacy, or composability\n\n    Output instructions:\n\n    - Output each JSON object in JSON Lines format (one line per paper).\n\n    {\n        \"title\": title of the paper (in Japanese),\n        \"summary\": A concise summary of the paper (in Japanese),\n        \"impact_level\": \"Highest|High|Medium|Low|Lowest\",\n        \"why_matters\": An array (JSON array) containing 2\u20134 bullet points explaining why this paper matters for Web3 investment\n    }\n\n    - Do not output anything except valid JSON object in JSON Lines.\n    - \"title\", \"summary\", \"why_matters\" text in the output must be written in Japanese.\n\n    Paper:\n    title: Tutorial on Large Language Model-Enhanced Reinforcement Learning for Wireless Networks\n    summary: Reinforcement Learning (RL) has shown remarkable success in enabling adaptive and data-driven optimization for various applications in wireless networks. However, classical RL suffers from limitations in generalization, learning feedback, interpretability, and sample efficiency in dynamic wireless environments. Large Language Models (LLMs) have emerged as a transformative Artificial Intelligence (AI) paradigm with exceptional capabilities in knowledge generalization, contextual reasoning, and interactive generation, which have demonstrated strong potential to enhance classical RL. This paper serves as a comprehensive tutorial on LLM-enhanced RL for wireless networks. We propose a taxonomy to categorize the roles of LLMs into four critical functions: state perceiver, reward designer, decision-maker, and generator. Then, we review existing studies exploring how each role of LLMs enhances different stages of the RL pipeline. Moreover, we provide a series of case studies to illustrate how to design and apply LLM-enhanced RL in low-altitude economy networking, vehicular networks, and space-air-ground integrated networks. Finally, we conclude with a discussion on potential future directions for LLM-enhanced RL and offer insights into its future development in wireless networks.\n    link: https://arxiv.org/abs/2512.03722v1\n    "}}
{"custom_id": "2512.03720v1", "method": "POST", "url": "/v1/responses", "body": {"model": "gpt-5-mini", "input": "You are a specialist research analyst in Web3, DeFi, cryptography, and distributed systems.\n\n    Your task:\n    From the paper below (Title + Summary + Link), evaluate how useful each paper is for understanding investment opportunities or technological advantages within the Web3 / crypto / DeFi ecosystem.\n    Rate each paper on a five-level scale: Highest / High / Medium / Low / Lowest.\n\n    \"Useful\" means:\n\n    - Improves understanding of new cryptographic primitives relevant to blockchain performance or security\n    - Enhances scalability: distributed systems, P2P networking, consensus mechanisms\n    - Advances in zero knowledge, MPC, PQC that could impact future L1/L2 chains\n    - DeFi modeling, AMMs, MEV, risk models, liquidity dynamics\n    - Smart contract security, attack vectors, economic incentives\n    - Token economics, mechanism design for decentralized systems\n    - Quantum threats to blockchain or cryptography\n    - Any breakthrough that meaningfully improves decentralization, scalability, privacy, or composability\n\n    Output instructions:\n\n    - Output each JSON object in JSON Lines format (one line per paper).\n\n    {\n        \"title\": title of the paper (in Japanese),\n        \"summary\": A concise summary of the paper (in Japanese),\n        \"impact_level\": \"Highest|High|Medium|Low|Lowest\",\n        \"why_matters\": An array (JSON array) containing 2\u20134 bullet points explaining why this paper matters for Web3 investment\n    }\n\n    - Do not output anything except valid JSON object in JSON Lines.\n    - \"title\", \"summary\", \"why_matters\" text in the output must be written in Japanese.\n\n    Paper:\n    title: Context-Aware Hierarchical Learning: A Two-Step Paradigm towards Safer LLMs\n    summary: Large Language Models (LLMs) have emerged as powerful tools for diverse applications. However, their uniform token processing paradigm introduces critical vulnerabilities in instruction handling, particularly when exposed to adversarial scenarios. In this work, we identify and propose a novel class of vulnerabilities, termed Tool-Completion Attack (TCA), which exploits function-calling mechanisms to subvert model behavior. To evaluate LLM robustness against such threats, we introduce the Tool-Completion benchmark, a comprehensive security assessment framework, which reveals that even state-of-the-art models remain susceptible to TCA, with surprisingly high attack success rates. To address these vulnerabilities, we introduce Context-Aware Hierarchical Learning (CAHL), a sophisticated mechanism that dynamically balances semantic comprehension with role-specific instruction constraints. CAHL leverages the contextual correlations between different instruction segments to establish a robust, context-aware instruction hierarchy. Extensive experiments demonstrate that CAHL significantly enhances LLM robustness against both conventional attacks and the proposed TCA, exhibiting strong generalization capabilities in zero-shot evaluations while still preserving model performance on generic tasks. Our code is available at https://github.com/S2AILab/CAHL.\n    link: https://arxiv.org/abs/2512.03720v1\n    "}}
{"custom_id": "2512.03717v1", "method": "POST", "url": "/v1/responses", "body": {"model": "gpt-5-mini", "input": "You are a specialist research analyst in Web3, DeFi, cryptography, and distributed systems.\n\n    Your task:\n    From the paper below (Title + Summary + Link), evaluate how useful each paper is for understanding investment opportunities or technological advantages within the Web3 / crypto / DeFi ecosystem.\n    Rate each paper on a five-level scale: Highest / High / Medium / Low / Lowest.\n\n    \"Useful\" means:\n\n    - Improves understanding of new cryptographic primitives relevant to blockchain performance or security\n    - Enhances scalability: distributed systems, P2P networking, consensus mechanisms\n    - Advances in zero knowledge, MPC, PQC that could impact future L1/L2 chains\n    - DeFi modeling, AMMs, MEV, risk models, liquidity dynamics\n    - Smart contract security, attack vectors, economic incentives\n    - Token economics, mechanism design for decentralized systems\n    - Quantum threats to blockchain or cryptography\n    - Any breakthrough that meaningfully improves decentralization, scalability, privacy, or composability\n\n    Output instructions:\n\n    - Output each JSON object in JSON Lines format (one line per paper).\n\n    {\n        \"title\": title of the paper (in Japanese),\n        \"summary\": A concise summary of the paper (in Japanese),\n        \"impact_level\": \"Highest|High|Medium|Low|Lowest\",\n        \"why_matters\": An array (JSON array) containing 2\u20134 bullet points explaining why this paper matters for Web3 investment\n    }\n\n    - Do not output anything except valid JSON object in JSON Lines.\n    - \"title\", \"summary\", \"why_matters\" text in the output must be written in Japanese.\n\n    Paper:\n    title: Geometrical structure of the Wigner flow information quantifiers and hyperbolic stability in the phase-space framework\n    summary: Quantifiers of stationarity, classicality, purity and vorticity are derived from phase-space differential geometrical structures within the Weyl-Wigner framework, after which they are related to the hyperbolic stability of classical and quantum-modified Hamiltonian (non-linear) equations of motion. By examining the equilibrium regime produced by such an autonomous system of ordinary differential equations, a correspondence between Wigner flow properties and hyperbolic stability boundaries in the phase-space is identified. Explicit analytical expressions for equilibrium-stability parameters are obtained for quantum Gaussian ensembles, wherein information quantifiers driven by Wigner currents are identified. Illustrated by an application to a Harper-like system, the results provide a self-contained analysis for identifying the influence of quantum fluctuations associated to the emergence of phase-space vorticity in order to quantify equilibrium and stability properties of Hamiltonian non-linear dynamics.\n    link: https://arxiv.org/abs/2512.03717v1\n    "}}
{"custom_id": "2512.03697v1", "method": "POST", "url": "/v1/responses", "body": {"model": "gpt-5-mini", "input": "You are a specialist research analyst in Web3, DeFi, cryptography, and distributed systems.\n\n    Your task:\n    From the paper below (Title + Summary + Link), evaluate how useful each paper is for understanding investment opportunities or technological advantages within the Web3 / crypto / DeFi ecosystem.\n    Rate each paper on a five-level scale: Highest / High / Medium / Low / Lowest.\n\n    \"Useful\" means:\n\n    - Improves understanding of new cryptographic primitives relevant to blockchain performance or security\n    - Enhances scalability: distributed systems, P2P networking, consensus mechanisms\n    - Advances in zero knowledge, MPC, PQC that could impact future L1/L2 chains\n    - DeFi modeling, AMMs, MEV, risk models, liquidity dynamics\n    - Smart contract security, attack vectors, economic incentives\n    - Token economics, mechanism design for decentralized systems\n    - Quantum threats to blockchain or cryptography\n    - Any breakthrough that meaningfully improves decentralization, scalability, privacy, or composability\n\n    Output instructions:\n\n    - Output each JSON object in JSON Lines format (one line per paper).\n\n    {\n        \"title\": title of the paper (in Japanese),\n        \"summary\": A concise summary of the paper (in Japanese),\n        \"impact_level\": \"Highest|High|Medium|Low|Lowest\",\n        \"why_matters\": An array (JSON array) containing 2\u20134 bullet points explaining why this paper matters for Web3 investment\n    }\n\n    - Do not output anything except valid JSON object in JSON Lines.\n    - \"title\", \"summary\", \"why_matters\" text in the output must be written in Japanese.\n\n    Paper:\n    title: On the Challenges of Energy-Efficiency Analysis in HPC Systems: Evaluating Synthetic Benchmarks and Gromacs\n    summary: This paper discusses the challenges encountered when analyzing the energy efficiency of synthetic benchmarks and the Gromacs package on the Fritz and Alex HPC clusters. Experiments were conducted using MPI parallelism on full sockets of Intel Ice Lake and Sapphire Rapids CPUs, as well as Nvidia A40 and A100 GPUs. The metrics and measurements obtained with the Likwid and Nvidia profiling tools are presented, along with the results. The challenges and pitfalls encountered during experimentation and analysis are revealed and discussed. Best practices for future energy efficiency analysis studies are suggested.\n    link: https://arxiv.org/abs/2512.03697v1\n    "}}
{"custom_id": "2512.03685v1", "method": "POST", "url": "/v1/responses", "body": {"model": "gpt-5-mini", "input": "You are a specialist research analyst in Web3, DeFi, cryptography, and distributed systems.\n\n    Your task:\n    From the paper below (Title + Summary + Link), evaluate how useful each paper is for understanding investment opportunities or technological advantages within the Web3 / crypto / DeFi ecosystem.\n    Rate each paper on a five-level scale: Highest / High / Medium / Low / Lowest.\n\n    \"Useful\" means:\n\n    - Improves understanding of new cryptographic primitives relevant to blockchain performance or security\n    - Enhances scalability: distributed systems, P2P networking, consensus mechanisms\n    - Advances in zero knowledge, MPC, PQC that could impact future L1/L2 chains\n    - DeFi modeling, AMMs, MEV, risk models, liquidity dynamics\n    - Smart contract security, attack vectors, economic incentives\n    - Token economics, mechanism design for decentralized systems\n    - Quantum threats to blockchain or cryptography\n    - Any breakthrough that meaningfully improves decentralization, scalability, privacy, or composability\n\n    Output instructions:\n\n    - Output each JSON object in JSON Lines format (one line per paper).\n\n    {\n        \"title\": title of the paper (in Japanese),\n        \"summary\": A concise summary of the paper (in Japanese),\n        \"impact_level\": \"Highest|High|Medium|Low|Lowest\",\n        \"why_matters\": An array (JSON array) containing 2\u20134 bullet points explaining why this paper matters for Web3 investment\n    }\n\n    - Do not output anything except valid JSON object in JSON Lines.\n    - \"title\", \"summary\", \"why_matters\" text in the output must be written in Japanese.\n\n    Paper:\n    title: Distributed Quantum Computing with Fan-Out Operations and Qudits: the Case of Distributed Global Gates (a Preliminary Study)\n    summary: Much recent work on distributed quantum computing have focused on the use of entangled pairs and distributed two qubit gates. But there has also been work on efficient schemes for achieving multipartite entanglement between nodes in a single shot, removing the need to generate multipartite entangled states using many entangled pairs. This paper looks at how multipartite entanglement resources (e.g., GHZ states) can be useful for distributed fan-out operations; we also consider the use of qudits of dimension four for distributed quantum circuit compression. In particular, we consider how such fan-out operations and qudits can be used to implement circuits which are challenging for distributed quantum computation, involving pairwise qubit interactions, i.e., what has been called global gates (a.k.a. global M\u00f8lmer-S\u00f8rensen gates). Such gates have been explored to possibly yield more efficient computations via reduced circuit depth, and can be carried out efficiently in some types of quantum hardware (e.g., trapped-ion quantum computers); we consider this as an exploration of an ``extreme'' case for distribution given the global qubit-qubit interactions. We also conclude with some implications for future work on quantum circuit compilation and quantum data centre design.\n    link: https://arxiv.org/abs/2512.03685v1\n    "}}
{"custom_id": "2512.03681v1", "method": "POST", "url": "/v1/responses", "body": {"model": "gpt-5-mini", "input": "You are a specialist research analyst in Web3, DeFi, cryptography, and distributed systems.\n\n    Your task:\n    From the paper below (Title + Summary + Link), evaluate how useful each paper is for understanding investment opportunities or technological advantages within the Web3 / crypto / DeFi ecosystem.\n    Rate each paper on a five-level scale: Highest / High / Medium / Low / Lowest.\n\n    \"Useful\" means:\n\n    - Improves understanding of new cryptographic primitives relevant to blockchain performance or security\n    - Enhances scalability: distributed systems, P2P networking, consensus mechanisms\n    - Advances in zero knowledge, MPC, PQC that could impact future L1/L2 chains\n    - DeFi modeling, AMMs, MEV, risk models, liquidity dynamics\n    - Smart contract security, attack vectors, economic incentives\n    - Token economics, mechanism design for decentralized systems\n    - Quantum threats to blockchain or cryptography\n    - Any breakthrough that meaningfully improves decentralization, scalability, privacy, or composability\n\n    Output instructions:\n\n    - Output each JSON object in JSON Lines format (one line per paper).\n\n    {\n        \"title\": title of the paper (in Japanese),\n        \"summary\": A concise summary of the paper (in Japanese),\n        \"impact_level\": \"Highest|High|Medium|Low|Lowest\",\n        \"why_matters\": An array (JSON array) containing 2\u20134 bullet points explaining why this paper matters for Web3 investment\n    }\n\n    - Do not output anything except valid JSON object in JSON Lines.\n    - \"title\", \"summary\", \"why_matters\" text in the output must be written in Japanese.\n\n    Paper:\n    title: Direct Equivalence between Dynamics of Quantum Walks and Coupled Classical Oscillators\n    summary: Continuous time quantum walks on exponentially large, sparse graphs form a powerful paradigm for quantum computing: On the one hand, they can be efficiently simulated on a quantum computer. On the other hand, they are themselves BQP-complete, providing an alternative framework for thinking about quantum computing -- a perspective which has indeed led to a number of novel algorithms and oracle problems. Recently, simulating the dynamics of a system of harmonic oscillators (that is, masses and springs) was set forth as another BQP-complete problem defined on exponentially large, sparse graphs. In this work, we establish a direct and transparent mapping between these two classes of problems. As compared to linking the two classes of problems via their BQP-completeness, our mapping has several desirable features: It is transparent, in that it respects the structure of the problem, including the geometry of the underlying graph, initialization, read-out, and efficient oracle access, resulting in low overhead in terms of both space and time; it allows to map also between restricted subsets of instances of both problems which are not BQP-complete; it provides a recipe to directly translate any quantum algorithm designed in the quantum walk paradigm to harmonic oscillators (and vice versa); and finally, it provides an alternative, transparent way to prove BQP-completeness of the harmonic oscillator problem by mapping it to BQP-completeness construction for the quantum walk problem (or vice versa).\n    link: https://arxiv.org/abs/2512.03681v1\n    "}}
{"custom_id": "2512.03669v1", "method": "POST", "url": "/v1/responses", "body": {"model": "gpt-5-mini", "input": "You are a specialist research analyst in Web3, DeFi, cryptography, and distributed systems.\n\n    Your task:\n    From the paper below (Title + Summary + Link), evaluate how useful each paper is for understanding investment opportunities or technological advantages within the Web3 / crypto / DeFi ecosystem.\n    Rate each paper on a five-level scale: Highest / High / Medium / Low / Lowest.\n\n    \"Useful\" means:\n\n    - Improves understanding of new cryptographic primitives relevant to blockchain performance or security\n    - Enhances scalability: distributed systems, P2P networking, consensus mechanisms\n    - Advances in zero knowledge, MPC, PQC that could impact future L1/L2 chains\n    - DeFi modeling, AMMs, MEV, risk models, liquidity dynamics\n    - Smart contract security, attack vectors, economic incentives\n    - Token economics, mechanism design for decentralized systems\n    - Quantum threats to blockchain or cryptography\n    - Any breakthrough that meaningfully improves decentralization, scalability, privacy, or composability\n\n    Output instructions:\n\n    - Output each JSON object in JSON Lines format (one line per paper).\n\n    {\n        \"title\": title of the paper (in Japanese),\n        \"summary\": A concise summary of the paper (in Japanese),\n        \"impact_level\": \"Highest|High|Medium|Low|Lowest\",\n        \"why_matters\": An array (JSON array) containing 2\u20134 bullet points explaining why this paper matters for Web3 investment\n    }\n\n    - Do not output anything except valid JSON object in JSON Lines.\n    - \"title\", \"summary\", \"why_matters\" text in the output must be written in Japanese.\n\n    Paper:\n    title: Towards Privacy-Preserving Range Queries with Secure Learned Spatial Index over Encrypted Data\n    summary: With the growing reliance on cloud services for large-scale data management, preserving the security and privacy of outsourced datasets has become increasingly critical. While encrypting data and queries can prevent direct content exposure, recent research reveals that adversaries can still infer sensitive information via access pattern and search path analysis. However, existing solutions that offer strong access pattern privacy often incur substantial performance overhead. In this paper, we propose a novel privacy-preserving range query scheme over encrypted datasets, offering strong security guarantees while maintaining high efficiency. To achieve this, we develop secure learned spatial index (SLS-INDEX), a secure learned index that integrates the Paillier cryptosystem with a hierarchical prediction architecture and noise-injected buckets, enabling data-aware query acceleration in the encrypted domain. To further obfuscate query execution paths, SLS-INDEXbased Range Queries (SLRQ) employs a permutation-based secure bucket prediction protocol. Additionally, we introduce a secure point extraction protocol that generates candidate results to reduce the overhead of secure computation. We provide formal security analysis under realistic leakage functions and implement a prototype to evaluate its practical performance. Extensive experiments on both real-world and synthetic datasets demonstrate that SLRQ significantly outperforms existing solutions in query efficiency while ensuring dataset, query, result, and access pattern privacy.\n    link: https://arxiv.org/abs/2512.03669v1\n    "}}
{"custom_id": "2512.02822v2", "method": "POST", "url": "/v1/responses", "body": {"model": "gpt-5-mini", "input": "You are a specialist research analyst in Web3, DeFi, cryptography, and distributed systems.\n\n    Your task:\n    From the paper below (Title + Summary + Link), evaluate how useful each paper is for understanding investment opportunities or technological advantages within the Web3 / crypto / DeFi ecosystem.\n    Rate each paper on a five-level scale: Highest / High / Medium / Low / Lowest.\n\n    \"Useful\" means:\n\n    - Improves understanding of new cryptographic primitives relevant to blockchain performance or security\n    - Enhances scalability: distributed systems, P2P networking, consensus mechanisms\n    - Advances in zero knowledge, MPC, PQC that could impact future L1/L2 chains\n    - DeFi modeling, AMMs, MEV, risk models, liquidity dynamics\n    - Smart contract security, attack vectors, economic incentives\n    - Token economics, mechanism design for decentralized systems\n    - Quantum threats to blockchain or cryptography\n    - Any breakthrough that meaningfully improves decentralization, scalability, privacy, or composability\n\n    Output instructions:\n\n    - Output each JSON object in JSON Lines format (one line per paper).\n\n    {\n        \"title\": title of the paper (in Japanese),\n        \"summary\": A concise summary of the paper (in Japanese),\n        \"impact_level\": \"Highest|High|Medium|Low|Lowest\",\n        \"why_matters\": An array (JSON array) containing 2\u20134 bullet points explaining why this paper matters for Web3 investment\n    }\n\n    - Do not output anything except valid JSON object in JSON Lines.\n    - \"title\", \"summary\", \"why_matters\" text in the output must be written in Japanese.\n\n    Paper:\n    title: Decryption Through Polynomial Ambiguity: Noise-Enhanced High-Memory Convolutional Codes for Post-Quantum Cryptography\n    summary: We present a novel approach to post-quantum cryptography that employs directed-graph decryption of noise-enhanced high-memory convolutional codes. The proposed construction generates random-like generator matrices that effectively conceal algebraic structure and resist known structural attacks. Security is further reinforced by the deliberate injection of strong noise during decryption, arising from polynomial division: while legitimate recipients retain polynomial-time decoding, adversaries face exponential-time complexity. As a result, the scheme achieves cryptanalytic security margins surpassing those of Classic McEliece by factors exceeding 2^(200). Beyond its enhanced security, the method offers greater design flexibility, supporting arbitrary plaintext lengths with linear-time decryption and uniform per-bit computational cost, enabling seamless scalability to long messages. Practical deployment is facilitated by parallel arrays of directed-graph decoders, which identify the correct plaintext through polynomial ambiguity while allowing efficient hardware and software implementations. Altogether, the scheme represents a compelling candidate for robust, scalable, and quantum-resistant public-key cryptography.\n    link: https://arxiv.org/abs/2512.02822v2\n    "}}
{"custom_id": "2512.03644v1", "method": "POST", "url": "/v1/responses", "body": {"model": "gpt-5-mini", "input": "You are a specialist research analyst in Web3, DeFi, cryptography, and distributed systems.\n\n    Your task:\n    From the paper below (Title + Summary + Link), evaluate how useful each paper is for understanding investment opportunities or technological advantages within the Web3 / crypto / DeFi ecosystem.\n    Rate each paper on a five-level scale: Highest / High / Medium / Low / Lowest.\n\n    \"Useful\" means:\n\n    - Improves understanding of new cryptographic primitives relevant to blockchain performance or security\n    - Enhances scalability: distributed systems, P2P networking, consensus mechanisms\n    - Advances in zero knowledge, MPC, PQC that could impact future L1/L2 chains\n    - DeFi modeling, AMMs, MEV, risk models, liquidity dynamics\n    - Smart contract security, attack vectors, economic incentives\n    - Token economics, mechanism design for decentralized systems\n    - Quantum threats to blockchain or cryptography\n    - Any breakthrough that meaningfully improves decentralization, scalability, privacy, or composability\n\n    Output instructions:\n\n    - Output each JSON object in JSON Lines format (one line per paper).\n\n    {\n        \"title\": title of the paper (in Japanese),\n        \"summary\": A concise summary of the paper (in Japanese),\n        \"impact_level\": \"Highest|High|Medium|Low|Lowest\",\n        \"why_matters\": An array (JSON array) containing 2\u20134 bullet points explaining why this paper matters for Web3 investment\n    }\n\n    - Do not output anything except valid JSON object in JSON Lines.\n    - \"title\", \"summary\", \"why_matters\" text in the output must be written in Japanese.\n\n    Paper:\n    title: FFTrainer: Fast Failover in Large-Language Model Training with Almost-Free State Management\n    summary: Recent developments in large language models (LLMs) have introduced new requirements for efficient and robust training. As LLM clusters scale, node failures, lengthy recoveries, and bulky checkpoints erode efficiency. Infrequent asynchronous checkpoints trigger costly rollbacks, yet higher frequencies add prohibitive overhead. To address these challenges, we propose FFTrainer, a system designed for robust LLM training. FFTrainer leverages surplus network capacity to quickly save and load states, thereby preventing rollbacks and accelerating recovery. Compared with prior checkpointing approaches, FFTrainer reduces recovery time by up to 98% and mitigates GPU utilization loss by up to 68% without hindering normal training.\n    link: https://arxiv.org/abs/2512.03644v1\n    "}}
{"custom_id": "2512.03641v1", "method": "POST", "url": "/v1/responses", "body": {"model": "gpt-5-mini", "input": "You are a specialist research analyst in Web3, DeFi, cryptography, and distributed systems.\n\n    Your task:\n    From the paper below (Title + Summary + Link), evaluate how useful each paper is for understanding investment opportunities or technological advantages within the Web3 / crypto / DeFi ecosystem.\n    Rate each paper on a five-level scale: Highest / High / Medium / Low / Lowest.\n\n    \"Useful\" means:\n\n    - Improves understanding of new cryptographic primitives relevant to blockchain performance or security\n    - Enhances scalability: distributed systems, P2P networking, consensus mechanisms\n    - Advances in zero knowledge, MPC, PQC that could impact future L1/L2 chains\n    - DeFi modeling, AMMs, MEV, risk models, liquidity dynamics\n    - Smart contract security, attack vectors, economic incentives\n    - Token economics, mechanism design for decentralized systems\n    - Quantum threats to blockchain or cryptography\n    - Any breakthrough that meaningfully improves decentralization, scalability, privacy, or composability\n\n    Output instructions:\n\n    - Output each JSON object in JSON Lines format (one line per paper).\n\n    {\n        \"title\": title of the paper (in Japanese),\n        \"summary\": A concise summary of the paper (in Japanese),\n        \"impact_level\": \"Highest|High|Medium|Low|Lowest\",\n        \"why_matters\": An array (JSON array) containing 2\u20134 bullet points explaining why this paper matters for Web3 investment\n    }\n\n    - Do not output anything except valid JSON object in JSON Lines.\n    - \"title\", \"summary\", \"why_matters\" text in the output must be written in Japanese.\n\n    Paper:\n    title: A Descriptive Model for Modelling Attacker Decision-Making in Cyber-Deception\n    summary: Cyber-deception is an increasingly important defensive strategy, shaping adversarial decision making through controlled misinformation, uncertainty, and misdirection. Although game-theoretic, Bayesian, Markov decision process, and reinforcement learning models offer insight into deceptive interactions, they typically assume an attacker has already chosen to engage. Such approaches overlook cognitive and perceptual factors that influence an attacker's initial decision to engage or withdraw. This paper presents a descriptive model that incorporates the psychological and strategic elements shaping this decision. The model defines five components, belief (B), scepticism (S), deception fidelity (D), reconnaissance (R), and experience (E), which interact to capture how adversaries interpret deceptive cues and assess whether continued engagement is worthwhile. The framework provides a structured method for analysing engagement decisions in cyber-deception scenarios. A series of experiments has been designed to evaluate this model through Capture the Flag activities incorporating varying levels of deception, supported by behavioural and biometric observations. These experiments have not yet been conducted, and no experimental findings are presented in this paper. These experiments will combine behavioural observations with biometric indicators to produce a multidimensional view of adversarial responses. Findings will improve understanding of the factors influencing engagement decisions and refine the model's relevance to real-world cyber-deception settings. By addressing the gap in existing models that presume engagement, this work supports more cognitively realistic and strategically effective cyber-deception practices.\n    link: https://arxiv.org/abs/2512.03641v1\n    "}}
{"custom_id": "2512.03620v1", "method": "POST", "url": "/v1/responses", "body": {"model": "gpt-5-mini", "input": "You are a specialist research analyst in Web3, DeFi, cryptography, and distributed systems.\n\n    Your task:\n    From the paper below (Title + Summary + Link), evaluate how useful each paper is for understanding investment opportunities or technological advantages within the Web3 / crypto / DeFi ecosystem.\n    Rate each paper on a five-level scale: Highest / High / Medium / Low / Lowest.\n\n    \"Useful\" means:\n\n    - Improves understanding of new cryptographic primitives relevant to blockchain performance or security\n    - Enhances scalability: distributed systems, P2P networking, consensus mechanisms\n    - Advances in zero knowledge, MPC, PQC that could impact future L1/L2 chains\n    - DeFi modeling, AMMs, MEV, risk models, liquidity dynamics\n    - Smart contract security, attack vectors, economic incentives\n    - Token economics, mechanism design for decentralized systems\n    - Quantum threats to blockchain or cryptography\n    - Any breakthrough that meaningfully improves decentralization, scalability, privacy, or composability\n\n    Output instructions:\n\n    - Output each JSON object in JSON Lines format (one line per paper).\n\n    {\n        \"title\": title of the paper (in Japanese),\n        \"summary\": A concise summary of the paper (in Japanese),\n        \"impact_level\": \"Highest|High|Medium|Low|Lowest\",\n        \"why_matters\": An array (JSON array) containing 2\u20134 bullet points explaining why this paper matters for Web3 investment\n    }\n\n    - Do not output anything except valid JSON object in JSON Lines.\n    - \"title\", \"summary\", \"why_matters\" text in the output must be written in Japanese.\n\n    Paper:\n    title: SELF: A Robust Singular Value and Eigenvalue Approach for LLM Fingerprinting\n    summary: The protection of Intellectual Property (IP) in Large Language Models (LLMs) represents a critical challenge in contemporary AI research. While fingerprinting techniques have emerged as a fundamental mechanism for detecting unauthorized model usage, existing methods -- whether behavior-based or structural -- suffer from vulnerabilities such as false claim attacks or susceptible to weight manipulations. To overcome these limitations, we propose SELF, a novel intrinsic weight-based fingerprinting scheme that eliminates dependency on input and inherently resists false claims. SELF achieves robust IP protection through two key innovations: 1) unique, scalable and transformation-invariant fingerprint extraction via singular value and eigenvalue decomposition of LLM attention weights, and 2) effective neural network-based fingerprint similarity comparison based on few-shot learning and data augmentation. Experimental results demonstrate SELF maintains high IP infringement detection accuracy while showing strong robustness against various downstream modifications, including quantization, pruning, and fine-tuning attacks. Our code is available at https://github.com/HanxiuZhang/SELF_v2.\n    link: https://arxiv.org/abs/2512.03620v1\n    "}}
{"custom_id": "2507.04093v2", "method": "POST", "url": "/v1/responses", "body": {"model": "gpt-5-mini", "input": "You are a specialist research analyst in Web3, DeFi, cryptography, and distributed systems.\n\n    Your task:\n    From the paper below (Title + Summary + Link), evaluate how useful each paper is for understanding investment opportunities or technological advantages within the Web3 / crypto / DeFi ecosystem.\n    Rate each paper on a five-level scale: Highest / High / Medium / Low / Lowest.\n\n    \"Useful\" means:\n\n    - Improves understanding of new cryptographic primitives relevant to blockchain performance or security\n    - Enhances scalability: distributed systems, P2P networking, consensus mechanisms\n    - Advances in zero knowledge, MPC, PQC that could impact future L1/L2 chains\n    - DeFi modeling, AMMs, MEV, risk models, liquidity dynamics\n    - Smart contract security, attack vectors, economic incentives\n    - Token economics, mechanism design for decentralized systems\n    - Quantum threats to blockchain or cryptography\n    - Any breakthrough that meaningfully improves decentralization, scalability, privacy, or composability\n\n    Output instructions:\n\n    - Output each JSON object in JSON Lines format (one line per paper).\n\n    {\n        \"title\": title of the paper (in Japanese),\n        \"summary\": A concise summary of the paper (in Japanese),\n        \"impact_level\": \"Highest|High|Medium|Low|Lowest\",\n        \"why_matters\": An array (JSON array) containing 2\u20134 bullet points explaining why this paper matters for Web3 investment\n    }\n\n    - Do not output anything except valid JSON object in JSON Lines.\n    - \"title\", \"summary\", \"why_matters\" text in the output must be written in Japanese.\n\n    Paper:\n    title: Dynamic Asset Pricing with \u03b1-MEU Model\n    summary: We study a dynamic asset pricing problem in which a representative agent is ambiguous about the aggregate endowment growth rate and trades a risky stock, human capital, and a risk-free asset to maximize her preference value of consumption represented by the \u03b1-maxmin expected utility model. This preference model is known to be dynamically inconsistent, so we consider intra-personal equilibrium strategies for the representative agent and define the market equilibrium as the one in which the strategy that clears the market is an intra-personal equilibrium. We prove the existence and uniqueness of the market equilibrium and show that the asset prices in the equilibrium are the same as in the case when the agent does not perceive any ambiguity but believes in a particular probabilistic model of the endowment process. We show that with reasonable parameter values, the more ambiguity the agent perceives or the more ambiguity-averse she is, the lower the risk-free rate, the higher the stock price, the higher the stock risk premium, and the lower the stock volatility.\n    link: https://arxiv.org/abs/2507.04093v2\n    "}}
{"custom_id": "2505.15644v2", "method": "POST", "url": "/v1/responses", "body": {"model": "gpt-5-mini", "input": "You are a specialist research analyst in Web3, DeFi, cryptography, and distributed systems.\n\n    Your task:\n    From the paper below (Title + Summary + Link), evaluate how useful each paper is for understanding investment opportunities or technological advantages within the Web3 / crypto / DeFi ecosystem.\n    Rate each paper on a five-level scale: Highest / High / Medium / Low / Lowest.\n\n    \"Useful\" means:\n\n    - Improves understanding of new cryptographic primitives relevant to blockchain performance or security\n    - Enhances scalability: distributed systems, P2P networking, consensus mechanisms\n    - Advances in zero knowledge, MPC, PQC that could impact future L1/L2 chains\n    - DeFi modeling, AMMs, MEV, risk models, liquidity dynamics\n    - Smart contract security, attack vectors, economic incentives\n    - Token economics, mechanism design for decentralized systems\n    - Quantum threats to blockchain or cryptography\n    - Any breakthrough that meaningfully improves decentralization, scalability, privacy, or composability\n\n    Output instructions:\n\n    - Output each JSON object in JSON Lines format (one line per paper).\n\n    {\n        \"title\": title of the paper (in Japanese),\n        \"summary\": A concise summary of the paper (in Japanese),\n        \"impact_level\": \"Highest|High|Medium|Low|Lowest\",\n        \"why_matters\": An array (JSON array) containing 2\u20134 bullet points explaining why this paper matters for Web3 investment\n    }\n\n    - Do not output anything except valid JSON object in JSON Lines.\n    - \"title\", \"summary\", \"why_matters\" text in the output must be written in Japanese.\n\n    Paper:\n    title: Can VLMs Detect and Localize Fine-Grained AI-Edited Images?\n    summary: Fine-grained detection and localization of localized image edits is crucial for assessing content authenticity, especially as modern diffusion models and image editors can produce highly realistic manipulations. However, this problem faces three key challenges: (1) most AIGC detectors produce only a global real-or-fake label without indicating where edits occur; (2) traditional computer vision methods for edit localization typically rely on costly pixel-level annotations; and (3) there is no large-scale, modern benchmark specifically targeting edited-image detection. To address these gaps, we develop an automated data-generation pipeline and construct FragFake, a large-scale benchmark of AI-edited images spanning multiple source datasets, diverse editing models, and several common edit types. Building on FragFake, we are the first to systematically study vision language models (VLMs) for edited-image classification and edited-region localization. Our experiments show that pretrained VLMs, including GPT4o, perform poorly on this task, whereas fine-tuned models such as Qwen2.5-VL achieve high accuracy and substantially higher object precision across all settings. We further explore GRPO-based RLVR training, which yields modest metric gains while improving the interpretability of model outputs. Ablation and transfer analyses reveal how data balancing, training size, LoRA rank, and training domain affect performance, and highlight both the potential and the limitations of cross-editor and cross-dataset generalization. We anticipate that this work will establish a solid foundation to facilitate and inspire subsequent research endeavors in the domain of multimodal content authenticity.\n    link: https://arxiv.org/abs/2505.15644v2\n    "}}
{"custom_id": "2512.03581v1", "method": "POST", "url": "/v1/responses", "body": {"model": "gpt-5-mini", "input": "You are a specialist research analyst in Web3, DeFi, cryptography, and distributed systems.\n\n    Your task:\n    From the paper below (Title + Summary + Link), evaluate how useful each paper is for understanding investment opportunities or technological advantages within the Web3 / crypto / DeFi ecosystem.\n    Rate each paper on a five-level scale: Highest / High / Medium / Low / Lowest.\n\n    \"Useful\" means:\n\n    - Improves understanding of new cryptographic primitives relevant to blockchain performance or security\n    - Enhances scalability: distributed systems, P2P networking, consensus mechanisms\n    - Advances in zero knowledge, MPC, PQC that could impact future L1/L2 chains\n    - DeFi modeling, AMMs, MEV, risk models, liquidity dynamics\n    - Smart contract security, attack vectors, economic incentives\n    - Token economics, mechanism design for decentralized systems\n    - Quantum threats to blockchain or cryptography\n    - Any breakthrough that meaningfully improves decentralization, scalability, privacy, or composability\n\n    Output instructions:\n\n    - Output each JSON object in JSON Lines format (one line per paper).\n\n    {\n        \"title\": title of the paper (in Japanese),\n        \"summary\": A concise summary of the paper (in Japanese),\n        \"impact_level\": \"Highest|High|Medium|Low|Lowest\",\n        \"why_matters\": An array (JSON array) containing 2\u20134 bullet points explaining why this paper matters for Web3 investment\n    }\n\n    - Do not output anything except valid JSON object in JSON Lines.\n    - \"title\", \"summary\", \"why_matters\" text in the output must be written in Japanese.\n\n    Paper:\n    title: Quantum Hash Function Based on Spectral Properties of Graphs and Discrete Walker Dynamics\n    summary: We present Quantum Graph Hash (QGH-256), a novel quantum spectral hashing algorithm that generates high-entropy fingerprints from message-induced graphs. Each input message is mapped to a weighted graph via a discrete random walk on an n X n toroidal grid, where the walk dynamics determine the edge weights. Quantum Phase Estimation (QPE) is then used to extract the phase spectrum of the graph Laplacian. Unlike standard QPE settings, the phase estimation is performed with respect to a superposition state (a uniform superposition over all node basis states) rather than an eigenvector, ensuring that all eigencomponents contribute to the resulting spectrum. This yields spectral features that distinguish even co-spectral but non-isomorphic message-induced graphs. The final spectral fingerprint is converted into a 256-bit digest, producing a compact representation of the input. As the fingerprint encodes both spectral and dynamical properties of the message-induced graph, the resulting hash exhibits strong sensitivity to input perturbations and provides a structurally rich foundation for post-quantum hashing. To demonstrate the feasibility of the approach, we implement QGH-256 on a 4 X 4 toroidal grid, chosen empirically: smaller grids exhibit collisions, whereas larger grids significantly increase execution time. The entire pipeline is implemented in Qiskit, and we use a seeded statevector simulator to obtain stable, noise-free results.\n    link: https://arxiv.org/abs/2512.03581v1\n    "}}
{"custom_id": "2512.03580v1", "method": "POST", "url": "/v1/responses", "body": {"model": "gpt-5-mini", "input": "You are a specialist research analyst in Web3, DeFi, cryptography, and distributed systems.\n\n    Your task:\n    From the paper below (Title + Summary + Link), evaluate how useful each paper is for understanding investment opportunities or technological advantages within the Web3 / crypto / DeFi ecosystem.\n    Rate each paper on a five-level scale: Highest / High / Medium / Low / Lowest.\n\n    \"Useful\" means:\n\n    - Improves understanding of new cryptographic primitives relevant to blockchain performance or security\n    - Enhances scalability: distributed systems, P2P networking, consensus mechanisms\n    - Advances in zero knowledge, MPC, PQC that could impact future L1/L2 chains\n    - DeFi modeling, AMMs, MEV, risk models, liquidity dynamics\n    - Smart contract security, attack vectors, economic incentives\n    - Token economics, mechanism design for decentralized systems\n    - Quantum threats to blockchain or cryptography\n    - Any breakthrough that meaningfully improves decentralization, scalability, privacy, or composability\n\n    Output instructions:\n\n    - Output each JSON object in JSON Lines format (one line per paper).\n\n    {\n        \"title\": title of the paper (in Japanese),\n        \"summary\": A concise summary of the paper (in Japanese),\n        \"impact_level\": \"Highest|High|Medium|Low|Lowest\",\n        \"why_matters\": An array (JSON array) containing 2\u20134 bullet points explaining why this paper matters for Web3 investment\n    }\n\n    - Do not output anything except valid JSON object in JSON Lines.\n    - \"title\", \"summary\", \"why_matters\" text in the output must be written in Japanese.\n\n    Paper:\n    title: Dynamic Optical Test for Bot Identification (DOT-BI): A simple check to identify bots in surveys and online processes\n    summary: We propose the Dynamic Optical Test for Bot Identification (DOT-BI): a quick and easy method that uses human perception of motion to differentiate between human respondents and automated systems in surveys and online processes. In DOT-BI, a 'hidden' number is displayed with the same random black-and-white pixel texture as its background. Only the difference in motion and scale between the number and the background makes the number perceptible to humans across frames, while frame-by-frame algorithmic processing yields no meaningful signal. We conducted two preliminary assessments. Firstly, state-of-the-art, video-capable, multimodal models (GPT-5-Thinking and Gemini 2.5 Pro) fail to extract the correct value, even when given explicit instructions about the mechanism. Secondly, in an online survey (n=182), 99.5% (181/182) of participants solved the task, with an average end-to-end completion time of 10.7 seconds; a supervised lab study (n=39) found no negative effects on perceived ease-of-use or completion time relative to a control. We release code to generate tests and 100+ pre-rendered variants to facilitate adoption in surveys and online processes.\n    link: https://arxiv.org/abs/2512.03580v1\n    "}}
{"custom_id": "2512.03570v1", "method": "POST", "url": "/v1/responses", "body": {"model": "gpt-5-mini", "input": "You are a specialist research analyst in Web3, DeFi, cryptography, and distributed systems.\n\n    Your task:\n    From the paper below (Title + Summary + Link), evaluate how useful each paper is for understanding investment opportunities or technological advantages within the Web3 / crypto / DeFi ecosystem.\n    Rate each paper on a five-level scale: Highest / High / Medium / Low / Lowest.\n\n    \"Useful\" means:\n\n    - Improves understanding of new cryptographic primitives relevant to blockchain performance or security\n    - Enhances scalability: distributed systems, P2P networking, consensus mechanisms\n    - Advances in zero knowledge, MPC, PQC that could impact future L1/L2 chains\n    - DeFi modeling, AMMs, MEV, risk models, liquidity dynamics\n    - Smart contract security, attack vectors, economic incentives\n    - Token economics, mechanism design for decentralized systems\n    - Quantum threats to blockchain or cryptography\n    - Any breakthrough that meaningfully improves decentralization, scalability, privacy, or composability\n\n    Output instructions:\n\n    - Output each JSON object in JSON Lines format (one line per paper).\n\n    {\n        \"title\": title of the paper (in Japanese),\n        \"summary\": A concise summary of the paper (in Japanese),\n        \"impact_level\": \"Highest|High|Medium|Low|Lowest\",\n        \"why_matters\": An array (JSON array) containing 2\u20134 bullet points explaining why this paper matters for Web3 investment\n    }\n\n    - Do not output anything except valid JSON object in JSON Lines.\n    - \"title\", \"summary\", \"why_matters\" text in the output must be written in Japanese.\n\n    Paper:\n    title: Machine Learning to Predict Slot Usage in TSCH Wireless Sensor Networks\n    summary: Wireless sensor networks (WSNs) are employed across a wide range of industrial applications where ultra-low power consumption is a critical prerequisite. At the same time, these systems must maintain a certain level of determinism to ensure reliable and predictable operation. In this view, time slotted channel hopping (TSCH) is a communication technology that meets both conditions, making it an attractive option for its usage in industrial WSNs. This work proposes the use of machine learning to learn the traffic pattern generated in networks based on the TSCH protocol, in order to turn nodes into a deep sleep state when no transmission is planned and thus to improve the energy efficiency of the WSN. The ability of machine learning models to make good predictions at different network levels in a typical tree network topology was analyzed in depth, showing how their capabilities degrade while approaching the root of the tree. The application of these models on simulated data based on an accurate modeling of wireless sensor nodes indicates that the investigated algorithms can be suitably used to further and substantially reduce the power consumption of a TSCH network.\n    link: https://arxiv.org/abs/2512.03570v1\n    "}}
{"custom_id": "2512.03569v1", "method": "POST", "url": "/v1/responses", "body": {"model": "gpt-5-mini", "input": "You are a specialist research analyst in Web3, DeFi, cryptography, and distributed systems.\n\n    Your task:\n    From the paper below (Title + Summary + Link), evaluate how useful each paper is for understanding investment opportunities or technological advantages within the Web3 / crypto / DeFi ecosystem.\n    Rate each paper on a five-level scale: Highest / High / Medium / Low / Lowest.\n\n    \"Useful\" means:\n\n    - Improves understanding of new cryptographic primitives relevant to blockchain performance or security\n    - Enhances scalability: distributed systems, P2P networking, consensus mechanisms\n    - Advances in zero knowledge, MPC, PQC that could impact future L1/L2 chains\n    - DeFi modeling, AMMs, MEV, risk models, liquidity dynamics\n    - Smart contract security, attack vectors, economic incentives\n    - Token economics, mechanism design for decentralized systems\n    - Quantum threats to blockchain or cryptography\n    - Any breakthrough that meaningfully improves decentralization, scalability, privacy, or composability\n\n    Output instructions:\n\n    - Output each JSON object in JSON Lines format (one line per paper).\n\n    {\n        \"title\": title of the paper (in Japanese),\n        \"summary\": A concise summary of the paper (in Japanese),\n        \"impact_level\": \"Highest|High|Medium|Low|Lowest\",\n        \"why_matters\": An array (JSON array) containing 2\u20134 bullet points explaining why this paper matters for Web3 investment\n    }\n\n    - Do not output anything except valid JSON object in JSON Lines.\n    - \"title\", \"summary\", \"why_matters\" text in the output must be written in Japanese.\n\n    Paper:\n    title: Performance Evaluation of Parallel Wi-Fi Redundancy with Deferral Techniques\n    summary: Wireless communication is increasingly used in industrial environments, since it supports mobility of interconnected devices. Among the transmission technologies operating in unlicensed bands available to this purpose, Wi-Fi is certainly one of the most interesting, because of its high performance and the relatively low deployment costs. Unfortunately, its dependability is often deemed unsuitable for real-time control systems. In this paper, the use of parallel redundancy is evaluated from a quantitative viewpoint, by considering a number of performance indices that are relevant for soft real-time applications. Analysis is carried out on a large dataset acquired from a real setup, to provide realistic insights on the advantages this kind of approaches can provide. As will be seen, deferred parallel redundancy provides clear advantages in terms of the worst-case transmission latency, at limited costs concerning the amount of consumed spectrum. Hence, it can be practically exploited every time a wireless connection is included in a control loop.\n    link: https://arxiv.org/abs/2512.03569v1\n    "}}
{"custom_id": "2507.11168v2", "method": "POST", "url": "/v1/responses", "body": {"model": "gpt-5-mini", "input": "You are a specialist research analyst in Web3, DeFi, cryptography, and distributed systems.\n\n    Your task:\n    From the paper below (Title + Summary + Link), evaluate how useful each paper is for understanding investment opportunities or technological advantages within the Web3 / crypto / DeFi ecosystem.\n    Rate each paper on a five-level scale: Highest / High / Medium / Low / Lowest.\n\n    \"Useful\" means:\n\n    - Improves understanding of new cryptographic primitives relevant to blockchain performance or security\n    - Enhances scalability: distributed systems, P2P networking, consensus mechanisms\n    - Advances in zero knowledge, MPC, PQC that could impact future L1/L2 chains\n    - DeFi modeling, AMMs, MEV, risk models, liquidity dynamics\n    - Smart contract security, attack vectors, economic incentives\n    - Token economics, mechanism design for decentralized systems\n    - Quantum threats to blockchain or cryptography\n    - Any breakthrough that meaningfully improves decentralization, scalability, privacy, or composability\n\n    Output instructions:\n\n    - Output each JSON object in JSON Lines format (one line per paper).\n\n    {\n        \"title\": title of the paper (in Japanese),\n        \"summary\": A concise summary of the paper (in Japanese),\n        \"impact_level\": \"Highest|High|Medium|Low|Lowest\",\n        \"why_matters\": An array (JSON array) containing 2\u20134 bullet points explaining why this paper matters for Web3 investment\n    }\n\n    - Do not output anything except valid JSON object in JSON Lines.\n    - \"title\", \"summary\", \"why_matters\" text in the output must be written in Japanese.\n\n    Paper:\n    title: Improving Wi-Fi Network Performance Prediction with Deep Learning Models\n    summary: The increasing need for robustness, reliability, and determinism in wireless networks for industrial and mission-critical applications is the driver for the growth of new innovative methods. The study presented in this work makes use of machine learning techniques to predict channel quality in a Wi-Fi network in terms of the frame delivery ratio. Predictions can be used proactively to adjust communication parameters at runtime and optimize network operations for industrial applications. Methods including convolutional neural networks and long short-term memory were analyzed on datasets acquired from a real Wi-Fi setup across multiple channels. The models were compared in terms of prediction accuracy and computational complexity. Results show that the frame delivery ratio can be reliably predicted, and convolutional neural networks, although slightly less effective than other models, are more efficient in terms of CPU usage and memory consumption. This enhances the model's usability on embedded and industrial systems.\n    link: https://arxiv.org/abs/2507.11168v2\n    "}}
{"custom_id": "2512.03565v1", "method": "POST", "url": "/v1/responses", "body": {"model": "gpt-5-mini", "input": "You are a specialist research analyst in Web3, DeFi, cryptography, and distributed systems.\n\n    Your task:\n    From the paper below (Title + Summary + Link), evaluate how useful each paper is for understanding investment opportunities or technological advantages within the Web3 / crypto / DeFi ecosystem.\n    Rate each paper on a five-level scale: Highest / High / Medium / Low / Lowest.\n\n    \"Useful\" means:\n\n    - Improves understanding of new cryptographic primitives relevant to blockchain performance or security\n    - Enhances scalability: distributed systems, P2P networking, consensus mechanisms\n    - Advances in zero knowledge, MPC, PQC that could impact future L1/L2 chains\n    - DeFi modeling, AMMs, MEV, risk models, liquidity dynamics\n    - Smart contract security, attack vectors, economic incentives\n    - Token economics, mechanism design for decentralized systems\n    - Quantum threats to blockchain or cryptography\n    - Any breakthrough that meaningfully improves decentralization, scalability, privacy, or composability\n\n    Output instructions:\n\n    - Output each JSON object in JSON Lines format (one line per paper).\n\n    {\n        \"title\": title of the paper (in Japanese),\n        \"summary\": A concise summary of the paper (in Japanese),\n        \"impact_level\": \"Highest|High|Medium|Low|Lowest\",\n        \"why_matters\": An array (JSON array) containing 2\u20134 bullet points explaining why this paper matters for Web3 investment\n    }\n\n    - Do not output anything except valid JSON object in JSON Lines.\n    - \"title\", \"summary\", \"why_matters\" text in the output must be written in Japanese.\n\n    Paper:\n    title: Tuning of Vectorization Parameters for Molecular Dynamics Simulations in AutoPas\n    summary: Molecular Dynamics simulations can help scientists to gather valuable insights for physical processes on an atomic scale. This work explores various techniques for SIMD vectorization to improve the pairwise force calculation between molecules in the scope of the particle simulation library AutoPas. The focus lies on the order in which particle values are loaded into vector registers to achieve the most optimal performance regarding execution time or energy consumption.\n  As previous work indicates that the optimal MD algorithm can change during runtime, this paper investigates simulation-specific parameters like particle density and the impact of the neighbor identification algorithms, which distinguishes this work from related projects. Furthermore, AutoPas' dynamic tuning mechanism is extended to choose the optimal vectorization order during runtime.\n  The benchmarks show that considering different particle interaction orders during runtime can lead to a considerable performance improvement for the force calculation compared to AutoPas' previous approach.\n    link: https://arxiv.org/abs/2512.03565v1\n    "}}
{"custom_id": "2512.03564v1", "method": "POST", "url": "/v1/responses", "body": {"model": "gpt-5-mini", "input": "You are a specialist research analyst in Web3, DeFi, cryptography, and distributed systems.\n\n    Your task:\n    From the paper below (Title + Summary + Link), evaluate how useful each paper is for understanding investment opportunities or technological advantages within the Web3 / crypto / DeFi ecosystem.\n    Rate each paper on a five-level scale: Highest / High / Medium / Low / Lowest.\n\n    \"Useful\" means:\n\n    - Improves understanding of new cryptographic primitives relevant to blockchain performance or security\n    - Enhances scalability: distributed systems, P2P networking, consensus mechanisms\n    - Advances in zero knowledge, MPC, PQC that could impact future L1/L2 chains\n    - DeFi modeling, AMMs, MEV, risk models, liquidity dynamics\n    - Smart contract security, attack vectors, economic incentives\n    - Token economics, mechanism design for decentralized systems\n    - Quantum threats to blockchain or cryptography\n    - Any breakthrough that meaningfully improves decentralization, scalability, privacy, or composability\n\n    Output instructions:\n\n    - Output each JSON object in JSON Lines format (one line per paper).\n\n    {\n        \"title\": title of the paper (in Japanese),\n        \"summary\": A concise summary of the paper (in Japanese),\n        \"impact_level\": \"Highest|High|Medium|Low|Lowest\",\n        \"why_matters\": An array (JSON array) containing 2\u20134 bullet points explaining why this paper matters for Web3 investment\n    }\n\n    - Do not output anything except valid JSON object in JSON Lines.\n    - \"title\", \"summary\", \"why_matters\" text in the output must be written in Japanese.\n\n    Paper:\n    title: Towards Irreversible Machine Unlearning for Diffusion Models\n    summary: Diffusion models are renowned for their state-of-the-art performance in generating synthetic images. However, concerns related to safety, privacy, and copyright highlight the need for machine unlearning, which can make diffusion models forget specific training data and prevent the generation of sensitive or unwanted content. Current machine unlearning methods for diffusion models are primarily designed for conditional diffusion models and focus on unlearning specific data classes or features. Among these methods, finetuning-based machine unlearning methods are recognized for their efficiency and effectiveness, which update the parameters of pre-trained diffusion models by minimizing carefully designed loss functions. However, in this paper, we propose a novel attack named Diffusion Model Relearning Attack (DiMRA), which can reverse the finetuning-based machine unlearning methods, posing a significant vulnerability of this kind of technique. Without prior knowledge of the unlearning elements, DiMRA optimizes the unlearned diffusion model on an auxiliary dataset to reverse the unlearning, enabling the model to regenerate previously unlearned elements. To mitigate this vulnerability, we propose a novel machine unlearning method for diffusion models, termed as Diffusion Model Unlearning by Memorization (DiMUM). Unlike traditional methods that focus on forgetting, DiMUM memorizes alternative data or features to replace targeted unlearning data or features in order to prevent generating such elements. In our experiments, we demonstrate the effectiveness of DiMRA in reversing state-of-the-art finetuning-based machine unlearning methods for diffusion models, highlighting the need for more robust solutions. We extensively evaluate DiMUM, demonstrating its superior ability to preserve the generative performance of diffusion models while enhancing robustness against DiMRA.\n    link: https://arxiv.org/abs/2512.03564v1\n    "}}
{"custom_id": "2512.03551v1", "method": "POST", "url": "/v1/responses", "body": {"model": "gpt-5-mini", "input": "You are a specialist research analyst in Web3, DeFi, cryptography, and distributed systems.\n\n    Your task:\n    From the paper below (Title + Summary + Link), evaluate how useful each paper is for understanding investment opportunities or technological advantages within the Web3 / crypto / DeFi ecosystem.\n    Rate each paper on a five-level scale: Highest / High / Medium / Low / Lowest.\n\n    \"Useful\" means:\n\n    - Improves understanding of new cryptographic primitives relevant to blockchain performance or security\n    - Enhances scalability: distributed systems, P2P networking, consensus mechanisms\n    - Advances in zero knowledge, MPC, PQC that could impact future L1/L2 chains\n    - DeFi modeling, AMMs, MEV, risk models, liquidity dynamics\n    - Smart contract security, attack vectors, economic incentives\n    - Token economics, mechanism design for decentralized systems\n    - Quantum threats to blockchain or cryptography\n    - Any breakthrough that meaningfully improves decentralization, scalability, privacy, or composability\n\n    Output instructions:\n\n    - Output each JSON object in JSON Lines format (one line per paper).\n\n    {\n        \"title\": title of the paper (in Japanese),\n        \"summary\": A concise summary of the paper (in Japanese),\n        \"impact_level\": \"Highest|High|Medium|Low|Lowest\",\n        \"why_matters\": An array (JSON array) containing 2\u20134 bullet points explaining why this paper matters for Web3 investment\n    }\n\n    - Do not output anything except valid JSON object in JSON Lines.\n    - \"title\", \"summary\", \"why_matters\" text in the output must be written in Japanese.\n\n    Paper:\n    title: A User Centric Group Authentication Scheme for Secure Communication\n    summary: Group Authentication Schemes (GAS) are methodologies developed to verify the membership of multiple users simultaneously. These schemes enable the concurrent authentication of several users while eliminating the need for a certification authority. Numerous GAS methods have been explored in the literature, and they can be classified into three distinct generations based on their foundational mathematical principles. First-generation GASs rely on polynomial interpolation and the multiplicative subgroup of a finite field. Second-generation GASs also employ polynomial interpolation, but they distinguish themselves by incorporating elliptic curves over finite fields. While third-generation GASs present a promising solution for scalable environments, they demonstrate a limitation in certain applications. Such applications typically require the identification of users participating in the authentication process. In the third-generation GAS, users are able to verify their credentials while maintaining anonymity. However, there are various applications where the identification of participating users is necessary. In this study, we propose an improved version of third-generation GAS, utilizing inner product spaces and polynomial interpolation to resolve this limitation. We address the issue of preventing malicious actions by legitimate group members. The current third-generation scheme allows members to share group credentials, which can jeopardize group confidentiality. Our proposed scheme mitigates this risk by eliminating the ability of individual users to distribute credentials. However, a potential limitation of our scheme is its reliance on a central authority for authentication in certain scenarios.\n    link: https://arxiv.org/abs/2512.03551v1\n    "}}
{"custom_id": "2507.01513v2", "method": "POST", "url": "/v1/responses", "body": {"model": "gpt-5-mini", "input": "You are a specialist research analyst in Web3, DeFi, cryptography, and distributed systems.\n\n    Your task:\n    From the paper below (Title + Summary + Link), evaluate how useful each paper is for understanding investment opportunities or technological advantages within the Web3 / crypto / DeFi ecosystem.\n    Rate each paper on a five-level scale: Highest / High / Medium / Low / Lowest.\n\n    \"Useful\" means:\n\n    - Improves understanding of new cryptographic primitives relevant to blockchain performance or security\n    - Enhances scalability: distributed systems, P2P networking, consensus mechanisms\n    - Advances in zero knowledge, MPC, PQC that could impact future L1/L2 chains\n    - DeFi modeling, AMMs, MEV, risk models, liquidity dynamics\n    - Smart contract security, attack vectors, economic incentives\n    - Token economics, mechanism design for decentralized systems\n    - Quantum threats to blockchain or cryptography\n    - Any breakthrough that meaningfully improves decentralization, scalability, privacy, or composability\n\n    Output instructions:\n\n    - Output each JSON object in JSON Lines format (one line per paper).\n\n    {\n        \"title\": title of the paper (in Japanese),\n        \"summary\": A concise summary of the paper (in Japanese),\n        \"impact_level\": \"Highest|High|Medium|Low|Lowest\",\n        \"why_matters\": An array (JSON array) containing 2\u20134 bullet points explaining why this paper matters for Web3 investment\n    }\n\n    - Do not output anything except valid JSON object in JSON Lines.\n    - \"title\", \"summary\", \"why_matters\" text in the output must be written in Japanese.\n\n    Paper:\n    title: SafePTR: Token-Level Jailbreak Defense in Multimodal LLMs via Prune-then-Restore Mechanism\n    summary: By incorporating visual inputs, Multimodal Large Language Models (MLLMs) extend LLMs to support visual reasoning. However, this integration also introduces new vulnerabilities, making MLLMs susceptible to multimodal jailbreak attacks and hindering their safe deployment.Existing defense methods, including Image-to-Text Translation, Safe Prompting, and Multimodal Safety Tuning, attempt to address this by aligning multimodal inputs with LLMs' built-in safeguards.Yet, they fall short in uncovering root causes of multimodal vulnerabilities, particularly how harmful multimodal tokens trigger jailbreak in MLLMs? Consequently, they remain vulnerable to text-driven multimodal jailbreaks, often exhibiting overdefensive behaviors and imposing heavy training overhead.To bridge this gap, we present an comprehensive analysis of where, how and which harmful multimodal tokens bypass safeguards in MLLMs. Surprisingly, we find that less than 1% tokens in early-middle layers are responsible for inducing unsafe behaviors, highlighting the potential of precisely removing a small subset of harmful tokens, without requiring safety tuning, can still effectively improve safety against jailbreaks. Motivated by this, we propose Safe Prune-then-Restore (SafePTR), an training-free defense framework that selectively prunes harmful tokens at vulnerable layers while restoring benign features at subsequent layers.Without incurring additional computational overhead, SafePTR significantly enhances the safety of MLLMs while preserving efficiency. Extensive evaluations across three MLLMs and five benchmarks demonstrate SafePTR's state-of-the-art performance in mitigating jailbreak risks without compromising utility.\n    link: https://arxiv.org/abs/2507.01513v2\n    "}}
{"custom_id": "2512.03536v1", "method": "POST", "url": "/v1/responses", "body": {"model": "gpt-5-mini", "input": "You are a specialist research analyst in Web3, DeFi, cryptography, and distributed systems.\n\n    Your task:\n    From the paper below (Title + Summary + Link), evaluate how useful each paper is for understanding investment opportunities or technological advantages within the Web3 / crypto / DeFi ecosystem.\n    Rate each paper on a five-level scale: Highest / High / Medium / Low / Lowest.\n\n    \"Useful\" means:\n\n    - Improves understanding of new cryptographic primitives relevant to blockchain performance or security\n    - Enhances scalability: distributed systems, P2P networking, consensus mechanisms\n    - Advances in zero knowledge, MPC, PQC that could impact future L1/L2 chains\n    - DeFi modeling, AMMs, MEV, risk models, liquidity dynamics\n    - Smart contract security, attack vectors, economic incentives\n    - Token economics, mechanism design for decentralized systems\n    - Quantum threats to blockchain or cryptography\n    - Any breakthrough that meaningfully improves decentralization, scalability, privacy, or composability\n\n    Output instructions:\n\n    - Output each JSON object in JSON Lines format (one line per paper).\n\n    {\n        \"title\": title of the paper (in Japanese),\n        \"summary\": A concise summary of the paper (in Japanese),\n        \"impact_level\": \"Highest|High|Medium|Low|Lowest\",\n        \"why_matters\": An array (JSON array) containing 2\u20134 bullet points explaining why this paper matters for Web3 investment\n    }\n\n    - Do not output anything except valid JSON object in JSON Lines.\n    - \"title\", \"summary\", \"why_matters\" text in the output must be written in Japanese.\n\n    Paper:\n    title: Mobility Induced Sensitivity of UAV based Nodes to Jamming in Private 5G Airfield Networks An Experimental Study\n    summary: This work presents an experimental performance evaluation of a private 5G airfield network under controlled directional SDR jamming attacks targeting UAV-based UE nodes. Using a QualiPoc Android UE, mounted as a payload on a quadcopter UAV, we conducted a series of experiments to evaluate signal degradation, handover performance, and ser-vice stability in the presence of constant directional jamming. The conducted experiments aimed to examine the effects of varying travel speeds, altitudes, and moving patterns of a UAV-based UE to record and analyze the key physical-layer and network-layer metrics such as CQI, MCS, RSRP, SINR, BLER, Net PDSCH Throughput and RLF. The re-sults of this work describe the link stability and signal degradation dependencies, caused by the level of mobility of the UAV-based UE nodes during autonomous and automatic operation in private 5G Airfield networks\n    link: https://arxiv.org/abs/2512.03536v1\n    "}}
{"custom_id": "2512.03526v1", "method": "POST", "url": "/v1/responses", "body": {"model": "gpt-5-mini", "input": "You are a specialist research analyst in Web3, DeFi, cryptography, and distributed systems.\n\n    Your task:\n    From the paper below (Title + Summary + Link), evaluate how useful each paper is for understanding investment opportunities or technological advantages within the Web3 / crypto / DeFi ecosystem.\n    Rate each paper on a five-level scale: Highest / High / Medium / Low / Lowest.\n\n    \"Useful\" means:\n\n    - Improves understanding of new cryptographic primitives relevant to blockchain performance or security\n    - Enhances scalability: distributed systems, P2P networking, consensus mechanisms\n    - Advances in zero knowledge, MPC, PQC that could impact future L1/L2 chains\n    - DeFi modeling, AMMs, MEV, risk models, liquidity dynamics\n    - Smart contract security, attack vectors, economic incentives\n    - Token economics, mechanism design for decentralized systems\n    - Quantum threats to blockchain or cryptography\n    - Any breakthrough that meaningfully improves decentralization, scalability, privacy, or composability\n\n    Output instructions:\n\n    - Output each JSON object in JSON Lines format (one line per paper).\n\n    {\n        \"title\": title of the paper (in Japanese),\n        \"summary\": A concise summary of the paper (in Japanese),\n        \"impact_level\": \"Highest|High|Medium|Low|Lowest\",\n        \"why_matters\": An array (JSON array) containing 2\u20134 bullet points explaining why this paper matters for Web3 investment\n    }\n\n    - Do not output anything except valid JSON object in JSON Lines.\n    - \"title\", \"summary\", \"why_matters\" text in the output must be written in Japanese.\n\n    Paper:\n    title: Stretched Exponential Scaling of Parity-Restricted Energy Gaps in a Random Transverse-Field Ising Model\n    summary: The success of a quantum annealing algorithm requires a polynomial scaling of the energy gap. Recently it was shown that a two-dimensional transverse-field Ising model on a square lattice with nearest-neighbor $\\pm J$ random coupling has a polynomial energy gap in the symmetric subspace of the parity operator [Nature 631, 749-754 (2024)], indicating the efficient preparation of its ground states by quantum annealing. However, it is not clear if this result can be generalized to other spin glass models with continuous or biased randomness. Here we prove that under general independent and identical distributions (i.i.d.) of the exchange energies, the energy gap of a one-dimensional random transverse-field Ising model follows a stretched exponential scaling even in the parity-restricted subspace. We discuss the implication of this result to quantum annealing problems.\n    link: https://arxiv.org/abs/2512.03526v1\n    "}}
{"custom_id": "2512.03487v1", "method": "POST", "url": "/v1/responses", "body": {"model": "gpt-5-mini", "input": "You are a specialist research analyst in Web3, DeFi, cryptography, and distributed systems.\n\n    Your task:\n    From the paper below (Title + Summary + Link), evaluate how useful each paper is for understanding investment opportunities or technological advantages within the Web3 / crypto / DeFi ecosystem.\n    Rate each paper on a five-level scale: Highest / High / Medium / Low / Lowest.\n\n    \"Useful\" means:\n\n    - Improves understanding of new cryptographic primitives relevant to blockchain performance or security\n    - Enhances scalability: distributed systems, P2P networking, consensus mechanisms\n    - Advances in zero knowledge, MPC, PQC that could impact future L1/L2 chains\n    - DeFi modeling, AMMs, MEV, risk models, liquidity dynamics\n    - Smart contract security, attack vectors, economic incentives\n    - Token economics, mechanism design for decentralized systems\n    - Quantum threats to blockchain or cryptography\n    - Any breakthrough that meaningfully improves decentralization, scalability, privacy, or composability\n\n    Output instructions:\n\n    - Output each JSON object in JSON Lines format (one line per paper).\n\n    {\n        \"title\": title of the paper (in Japanese),\n        \"summary\": A concise summary of the paper (in Japanese),\n        \"impact_level\": \"Highest|High|Medium|Low|Lowest\",\n        \"why_matters\": An array (JSON array) containing 2\u20134 bullet points explaining why this paper matters for Web3 investment\n    }\n\n    - Do not output anything except valid JSON object in JSON Lines.\n    - \"title\", \"summary\", \"why_matters\" text in the output must be written in Japanese.\n\n    Paper:\n    title: Double-Edge-Assisted Computation Offloading and Resource Allocation for Space-Air-Marine Integrated Networks\n    summary: In this paper, we propose a double-edge-assisted computation offloading and resource allocation scheme tailored for space-air-marine integrated networks (SAMINs). Specifically, we consider a scenario where both unmanned aerial vehicles (UAVs) and a low earth orbit (LEO) satellite are equipped with edge servers, providing computing services for maritime autonomous surface ships (MASSs). Partial computation workloads of MASSs can be offloaded to both UAVs and the LEO satellite, concurrently, for processing via a multi-access approach. To minimize the energy consumption of SAMINs under latency constraints, we formulate an optimization problem and propose energy efficient algorithms to jointly optimize offloading mode, offloading volume, and computing resource allocation of the LEO satellite and the UAVs, respectively. We further exploit an alternating optimization (AO) method and a layered approach to decompose the original problem to attain the optimal solutions. Finally, we conduct simulations to validate the effectiveness and efficiency of the proposed scheme in comparison with benchmark algorithms.\n    link: https://arxiv.org/abs/2512.03487v1\n    "}}
{"custom_id": "2410.19062v2", "method": "POST", "url": "/v1/responses", "body": {"model": "gpt-5-mini", "input": "You are a specialist research analyst in Web3, DeFi, cryptography, and distributed systems.\n\n    Your task:\n    From the paper below (Title + Summary + Link), evaluate how useful each paper is for understanding investment opportunities or technological advantages within the Web3 / crypto / DeFi ecosystem.\n    Rate each paper on a five-level scale: Highest / High / Medium / Low / Lowest.\n\n    \"Useful\" means:\n\n    - Improves understanding of new cryptographic primitives relevant to blockchain performance or security\n    - Enhances scalability: distributed systems, P2P networking, consensus mechanisms\n    - Advances in zero knowledge, MPC, PQC that could impact future L1/L2 chains\n    - DeFi modeling, AMMs, MEV, risk models, liquidity dynamics\n    - Smart contract security, attack vectors, economic incentives\n    - Token economics, mechanism design for decentralized systems\n    - Quantum threats to blockchain or cryptography\n    - Any breakthrough that meaningfully improves decentralization, scalability, privacy, or composability\n\n    Output instructions:\n\n    - Output each JSON object in JSON Lines format (one line per paper).\n\n    {\n        \"title\": title of the paper (in Japanese),\n        \"summary\": A concise summary of the paper (in Japanese),\n        \"impact_level\": \"Highest|High|Medium|Low|Lowest\",\n        \"why_matters\": An array (JSON array) containing 2\u20134 bullet points explaining why this paper matters for Web3 investment\n    }\n\n    - Do not output anything except valid JSON object in JSON Lines.\n    - \"title\", \"summary\", \"why_matters\" text in the output must be written in Japanese.\n\n    Paper:\n    title: Oracle Separations for the Quantum-Classical Polynomial Hierarchy\n    summary: We study the quantum-classical polynomial hierarchy, QCPH, which is the class of languages solvable by a constant number of alternating classical quantifiers followed by a quantum verifier. Our main result is that QCPH is infinite relative to a random oracle (previously, this was not even known relative to any oracle). We further prove that higher levels of PH are not contained in lower levels of QCPH relative to a random oracle; this is a strengthening of the somewhat recent result that PH is infinite relative to a random oracle (Rossman, Servedio, and Tan 2016).\n  The oracle separation requires lower bounding a certain type of low-depth alternating circuit with some quantum gates. To establish this, we give a new switching lemma for quantum algorithms which may be of independent interest. Our lemma says that for any $d$, if we apply a random restriction to a function $f$ with quantum query complexity $\\mathrm{Q}(f)\\le n^{1/3}$, the restricted function becomes exponentially close (in terms of $d$) to a depth-$d$ decision tree. Our switching lemma works even in a \"worst-case\" sense, in that only the indices to be restricted are random; the values they are restricted to are chosen adversarially. Moreover, the switching lemma also works for polynomial degree in place of quantum query complexity.\n    link: https://arxiv.org/abs/2410.19062v2\n    "}}
{"custom_id": "2512.03465v1", "method": "POST", "url": "/v1/responses", "body": {"model": "gpt-5-mini", "input": "You are a specialist research analyst in Web3, DeFi, cryptography, and distributed systems.\n\n    Your task:\n    From the paper below (Title + Summary + Link), evaluate how useful each paper is for understanding investment opportunities or technological advantages within the Web3 / crypto / DeFi ecosystem.\n    Rate each paper on a five-level scale: Highest / High / Medium / Low / Lowest.\n\n    \"Useful\" means:\n\n    - Improves understanding of new cryptographic primitives relevant to blockchain performance or security\n    - Enhances scalability: distributed systems, P2P networking, consensus mechanisms\n    - Advances in zero knowledge, MPC, PQC that could impact future L1/L2 chains\n    - DeFi modeling, AMMs, MEV, risk models, liquidity dynamics\n    - Smart contract security, attack vectors, economic incentives\n    - Token economics, mechanism design for decentralized systems\n    - Quantum threats to blockchain or cryptography\n    - Any breakthrough that meaningfully improves decentralization, scalability, privacy, or composability\n\n    Output instructions:\n\n    - Output each JSON object in JSON Lines format (one line per paper).\n\n    {\n        \"title\": title of the paper (in Japanese),\n        \"summary\": A concise summary of the paper (in Japanese),\n        \"impact_level\": \"Highest|High|Medium|Low|Lowest\",\n        \"why_matters\": An array (JSON array) containing 2\u20134 bullet points explaining why this paper matters for Web3 investment\n    }\n\n    - Do not output anything except valid JSON object in JSON Lines.\n    - \"title\", \"summary\", \"why_matters\" text in the output must be written in Japanese.\n\n    Paper:\n    title: Tuning for TraceTarnish: Techniques, Trends, and Testing Tangible Traits\n    summary: In this study, we more rigorously evaluated our attack script $\\textit{TraceTarnish}$, which leverages adversarial stylometry principles to anonymize the authorship of text-based messages. To ensure the efficacy and utility of our attack, we sourced, processed, and analyzed Reddit comments--comments that were later alchemized into $\\textit{TraceTarnish}$ data--to gain valuable insights. The transformed $\\textit{TraceTarnish}$ data was then further augmented by $\\textit{StyloMetrix}$ to manufacture stylometric features--features that were culled using the Information Gain criterion, leaving only the most informative, predictive, and discriminative ones. Our results found that function words and function word types ($L\\_FUNC\\_A$ $\\&$ $L\\_FUNC\\_T$); content words and content word types ($L\\_CONT\\_A$ $\\&$ $L\\_CONT\\_T$); and the Type-Token Ratio ($ST\\_TYPE\\_TOKEN\\_RATIO\\_LEMMAS$) yielded significant Information-Gain readings. The identified stylometric cues--function-word frequencies, content-word distributions, and the Type-Token Ratio--serve as reliable indicators of compromise (IoCs), revealing when a text has been deliberately altered to mask its true author. Similarly, these features could function as forensic beacons, alerting defenders to the presence of an adversarial stylometry attack; granted, in the absence of the original message, this signal may go largely unnoticed, as it appears to depend on a pre- and post-transformation comparison. \"In trying to erase a trace, you often imprint a larger one.\" Armed with this understanding, we framed $\\textit{TraceTarnish}$'s operations and outputs around these five isolated features, using them to conceptualize and implement enhancements that further strengthen the attack.\n    link: https://arxiv.org/abs/2512.03465v1\n    "}}
{"custom_id": "2512.03461v1", "method": "POST", "url": "/v1/responses", "body": {"model": "gpt-5-mini", "input": "You are a specialist research analyst in Web3, DeFi, cryptography, and distributed systems.\n\n    Your task:\n    From the paper below (Title + Summary + Link), evaluate how useful each paper is for understanding investment opportunities or technological advantages within the Web3 / crypto / DeFi ecosystem.\n    Rate each paper on a five-level scale: Highest / High / Medium / Low / Lowest.\n\n    \"Useful\" means:\n\n    - Improves understanding of new cryptographic primitives relevant to blockchain performance or security\n    - Enhances scalability: distributed systems, P2P networking, consensus mechanisms\n    - Advances in zero knowledge, MPC, PQC that could impact future L1/L2 chains\n    - DeFi modeling, AMMs, MEV, risk models, liquidity dynamics\n    - Smart contract security, attack vectors, economic incentives\n    - Token economics, mechanism design for decentralized systems\n    - Quantum threats to blockchain or cryptography\n    - Any breakthrough that meaningfully improves decentralization, scalability, privacy, or composability\n\n    Output instructions:\n\n    - Output each JSON object in JSON Lines format (one line per paper).\n\n    {\n        \"title\": title of the paper (in Japanese),\n        \"summary\": A concise summary of the paper (in Japanese),\n        \"impact_level\": \"Highest|High|Medium|Low|Lowest\",\n        \"why_matters\": An array (JSON array) containing 2\u20134 bullet points explaining why this paper matters for Web3 investment\n    }\n\n    - Do not output anything except valid JSON object in JSON Lines.\n    - \"title\", \"summary\", \"why_matters\" text in the output must be written in Japanese.\n\n    Paper:\n    title: In-Situ Encryption of Single-Transistor Nonvolatile Memories without Density Loss\n    summary: Non-volatile memories (NVMs) offer negligible leakage power consumption, high integration density, and data retention, but their non-volatility also raises the risk of data exposure. Conventional encryption techniques such as the Advanced Encryption Standard (AES) incur large area overheads and performance penalties, motivating lightweight XOR-based in-situ encryption schemes with low area and power requirements. This work proposes an ultra-dense single-transistor encrypted cell using ferroelectric FET (FeFET) devices, which, to our knowledge, is the first to eliminate the two-memory-devices-per-encrypted-cell requirement in XOR-based schemes, enabling encrypted memory arrays to maintain the same number of storage devices as unencrypted arrays. The key idea is an in-memory single-FeFET XOR scheme, where the ciphertext is encoded in the device threshold voltage and leverages the direction-dependent current flow of the FeFET for single-cycle decryption; eliminating complementary bit storage also removes the need for two write cycles, allowing faster encryption. We extend the approach to multi-level-cell (MLC) FeFETs to store multiple bits per transistor. We validate the proposed idea through both simulation and experimental evaluations. Our analysis on a 128x128-bit array shows 2x higher encryption/decryption throughput than prior FeFET work and 45.2x/14.12x improvement over AES, while application-level evaluations using neural-network benchmarks demonstrate average latency reductions of 50% and 95% compared to prior FeFET-based and AES-based schemes, respectively.\n    link: https://arxiv.org/abs/2512.03461v1\n    "}}
{"custom_id": "2512.03432v1", "method": "POST", "url": "/v1/responses", "body": {"model": "gpt-5-mini", "input": "You are a specialist research analyst in Web3, DeFi, cryptography, and distributed systems.\n\n    Your task:\n    From the paper below (Title + Summary + Link), evaluate how useful each paper is for understanding investment opportunities or technological advantages within the Web3 / crypto / DeFi ecosystem.\n    Rate each paper on a five-level scale: Highest / High / Medium / Low / Lowest.\n\n    \"Useful\" means:\n\n    - Improves understanding of new cryptographic primitives relevant to blockchain performance or security\n    - Enhances scalability: distributed systems, P2P networking, consensus mechanisms\n    - Advances in zero knowledge, MPC, PQC that could impact future L1/L2 chains\n    - DeFi modeling, AMMs, MEV, risk models, liquidity dynamics\n    - Smart contract security, attack vectors, economic incentives\n    - Token economics, mechanism design for decentralized systems\n    - Quantum threats to blockchain or cryptography\n    - Any breakthrough that meaningfully improves decentralization, scalability, privacy, or composability\n\n    Output instructions:\n\n    - Output each JSON object in JSON Lines format (one line per paper).\n\n    {\n        \"title\": title of the paper (in Japanese),\n        \"summary\": A concise summary of the paper (in Japanese),\n        \"impact_level\": \"Highest|High|Medium|Low|Lowest\",\n        \"why_matters\": An array (JSON array) containing 2\u20134 bullet points explaining why this paper matters for Web3 investment\n    }\n\n    - Do not output anything except valid JSON object in JSON Lines.\n    - \"title\", \"summary\", \"why_matters\" text in the output must be written in Japanese.\n\n    Paper:\n    title: Classification of totally real number fields via their zeta function, regulator, and log unit lattice\n    summary: In this paper, assuming the weak Schanuel Conjecture (WSC), we prove that for any collection of pairwise non-arithmetically equivalent totally real number fields, the residues at $s=1$ of their Dedekind zeta functions form a linearly independent set over the field of algebraic numbers. As a corollary, we obtain that, under WSC, two totally real number fields have the same regulator if and only if they have the same class number and Dedekind zeta function. We also prove that, under WSC, the isometry and similarity classes of the log unit lattice of a real Galois number field of degree $[K:\\Q]\\geq 4$, characterize the isomorphism class of said field. All of our results follow from establishing that, under WSC, any Gram matrix of the log unit lattice of a real Galois number field yields a generic point of certain closed irreducible $\\Q$-subvariety of the space of symmetric matrices of appropriate size.\n    link: https://arxiv.org/abs/2512.03432v1\n    "}}
{"custom_id": "2512.02318v2", "method": "POST", "url": "/v1/responses", "body": {"model": "gpt-5-mini", "input": "You are a specialist research analyst in Web3, DeFi, cryptography, and distributed systems.\n\n    Your task:\n    From the paper below (Title + Summary + Link), evaluate how useful each paper is for understanding investment opportunities or technological advantages within the Web3 / crypto / DeFi ecosystem.\n    Rate each paper on a five-level scale: Highest / High / Medium / Low / Lowest.\n\n    \"Useful\" means:\n\n    - Improves understanding of new cryptographic primitives relevant to blockchain performance or security\n    - Enhances scalability: distributed systems, P2P networking, consensus mechanisms\n    - Advances in zero knowledge, MPC, PQC that could impact future L1/L2 chains\n    - DeFi modeling, AMMs, MEV, risk models, liquidity dynamics\n    - Smart contract security, attack vectors, economic incentives\n    - Token economics, mechanism design for decentralized systems\n    - Quantum threats to blockchain or cryptography\n    - Any breakthrough that meaningfully improves decentralization, scalability, privacy, or composability\n\n    Output instructions:\n\n    - Output each JSON object in JSON Lines format (one line per paper).\n\n    {\n        \"title\": title of the paper (in Japanese),\n        \"summary\": A concise summary of the paper (in Japanese),\n        \"impact_level\": \"Highest|High|Medium|Low|Lowest\",\n        \"why_matters\": An array (JSON array) containing 2\u20134 bullet points explaining why this paper matters for Web3 investment\n    }\n\n    - Do not output anything except valid JSON object in JSON Lines.\n    - \"title\", \"summary\", \"why_matters\" text in the output must be written in Japanese.\n\n    Paper:\n    title: COGNITION: From Evaluation to Defense against Multimodal LLM CAPTCHA Solvers\n    summary: This paper studies how multimodal large language models (MLLMs) undermine the security guarantees of visual CAPTCHA. We identify the attack surface where an adversary can cheaply automate CAPTCHA solving using off-the-shelf models. We evaluate 7 leading commercial and open-source MLLMs across 18 real-world CAPTCHA task types, measuring single-shot accuracy, success under limited retries, end-to-end latency, and per-solve cost. We further analyze the impact of task-specific prompt engineering and few-shot demonstrations on solver effectiveness. We reveal that MLLMs can reliably solve recognition-oriented and low-interaction CAPTCHA tasks at human-like cost and latency, whereas tasks requiring fine-grained localization, multi-step spatial reasoning, or cross-frame consistency remain significantly harder for current models. By examining the reasoning traces of such MLLMs, we investigate the underlying mechanisms of why models succeed/fail on specific CAPTCHA puzzles and use these insights to derive defense-oriented guidelines for selecting and strengthening CAPTCHA tasks. We conclude by discussing implications for platform operators deploying CAPTCHA as part of their abuse-mitigation pipeline.Code Availability (https://anonymous.4open.science/r/Captcha-465E/).\n    link: https://arxiv.org/abs/2512.02318v2\n    "}}
{"custom_id": "2512.03420v1", "method": "POST", "url": "/v1/responses", "body": {"model": "gpt-5-mini", "input": "You are a specialist research analyst in Web3, DeFi, cryptography, and distributed systems.\n\n    Your task:\n    From the paper below (Title + Summary + Link), evaluate how useful each paper is for understanding investment opportunities or technological advantages within the Web3 / crypto / DeFi ecosystem.\n    Rate each paper on a five-level scale: Highest / High / Medium / Low / Lowest.\n\n    \"Useful\" means:\n\n    - Improves understanding of new cryptographic primitives relevant to blockchain performance or security\n    - Enhances scalability: distributed systems, P2P networking, consensus mechanisms\n    - Advances in zero knowledge, MPC, PQC that could impact future L1/L2 chains\n    - DeFi modeling, AMMs, MEV, risk models, liquidity dynamics\n    - Smart contract security, attack vectors, economic incentives\n    - Token economics, mechanism design for decentralized systems\n    - Quantum threats to blockchain or cryptography\n    - Any breakthrough that meaningfully improves decentralization, scalability, privacy, or composability\n\n    Output instructions:\n\n    - Output each JSON object in JSON Lines format (one line per paper).\n\n    {\n        \"title\": title of the paper (in Japanese),\n        \"summary\": A concise summary of the paper (in Japanese),\n        \"impact_level\": \"Highest|High|Medium|Low|Lowest\",\n        \"why_matters\": An array (JSON array) containing 2\u20134 bullet points explaining why this paper matters for Web3 investment\n    }\n\n    - Do not output anything except valid JSON object in JSON Lines.\n    - \"title\", \"summary\", \"why_matters\" text in the output must be written in Japanese.\n\n    Paper:\n    title: HarnessAgent: Scaling Automatic Fuzzing Harness Construction with Tool-Augmented LLM Pipelines\n    summary: Large language model (LLM)-based techniques have achieved notable progress in generating harnesses for program fuzzing. However, applying them to arbitrary functions (especially internal functions) \\textit{at scale} remains challenging due to the requirement of sophisticated contextual information, such as specification, dependencies, and usage examples. State-of-the-art methods heavily rely on static or incomplete context provisioning, causing failure of generating functional harnesses. Furthermore, LLMs tend to exploit harness validation metrics, producing plausible yet logically useless code. % Therefore, harness generation across large and diverse projects continues to face challenges in reliable compilation, robust code retrieval, and comprehensive validation.\n  To address these challenges, we present HarnessAgent, a tool-augmented agentic framework that achieves fully automated, scalable harness construction over hundreds of OSS-Fuzz targets. HarnessAgent introduces three key innovations: 1) a rule-based strategy to identify and minimize various compilation errors; 2) a hybrid tool pool for precise and robust symbol source code retrieval; and 3) an enhanced harness validation pipeline that detects fake definitions. We evaluate HarnessAgent on 243 target functions from OSS-Fuzz projects (65 C projects and 178 C++ projects). It improves the three-shot success rate by approximately 20\\% compared to state-of-the-art techniques, reaching 87\\% for C and 81\\% for C++. Our one-hour fuzzing results show that more than 75\\% of the harnesses generated by HarnessAgent increase the target function coverage, surpassing the baselines by over 10\\%. In addition, the hybrid tool-pool system of HarnessAgent achieves a response rate of over 90\\% for source code retrieval, outperforming Fuzz Introspector by more than 30\\%.\n    link: https://arxiv.org/abs/2512.03420v1\n    "}}
{"custom_id": "2508.12295v2", "method": "POST", "url": "/v1/responses", "body": {"model": "gpt-5-mini", "input": "You are a specialist research analyst in Web3, DeFi, cryptography, and distributed systems.\n\n    Your task:\n    From the paper below (Title + Summary + Link), evaluate how useful each paper is for understanding investment opportunities or technological advantages within the Web3 / crypto / DeFi ecosystem.\n    Rate each paper on a five-level scale: Highest / High / Medium / Low / Lowest.\n\n    \"Useful\" means:\n\n    - Improves understanding of new cryptographic primitives relevant to blockchain performance or security\n    - Enhances scalability: distributed systems, P2P networking, consensus mechanisms\n    - Advances in zero knowledge, MPC, PQC that could impact future L1/L2 chains\n    - DeFi modeling, AMMs, MEV, risk models, liquidity dynamics\n    - Smart contract security, attack vectors, economic incentives\n    - Token economics, mechanism design for decentralized systems\n    - Quantum threats to blockchain or cryptography\n    - Any breakthrough that meaningfully improves decentralization, scalability, privacy, or composability\n\n    Output instructions:\n\n    - Output each JSON object in JSON Lines format (one line per paper).\n\n    {\n        \"title\": title of the paper (in Japanese),\n        \"summary\": A concise summary of the paper (in Japanese),\n        \"impact_level\": \"Highest|High|Medium|Low|Lowest\",\n        \"why_matters\": An array (JSON array) containing 2\u20134 bullet points explaining why this paper matters for Web3 investment\n    }\n\n    - Do not output anything except valid JSON object in JSON Lines.\n    - \"title\", \"summary\", \"why_matters\" text in the output must be written in Japanese.\n\n    Paper:\n    title: Resonant dynamics of spin cluster in a periodically driven one-dimensional Rydberg lattice\n    summary: Rydberg lattice under facilitation conditions can feature kinetic constraints, leading to ballistic and nonergodic behavior at different detuning intensities. Here, we demonstrate that a resonant driving field can achieve effects similar to those under facilitation conditions. We focus on the relaxation dynamics of spin clusters in a periodically driven Rydberg spin lattice. Through an effective Hamiltonian for the domain walls of the spin cluster, it is shown that when the driving frequency is resonant with the Rydberg interaction, the spin cluster exhibits ballistic expansion with half the spreading rate compared to the case of facilitation conditions. However, near the resonant point, the spin cluster displays confinement behavior of the Bloch-like oscillations. These results demonstrate the rich dynamic behaviors in the driven Rydberg spin lattices and may find applications in quantum state manipulation.\n    link: https://arxiv.org/abs/2508.12295v2\n    "}}
{"custom_id": "2505.08032v2", "method": "POST", "url": "/v1/responses", "body": {"model": "gpt-5-mini", "input": "You are a specialist research analyst in Web3, DeFi, cryptography, and distributed systems.\n\n    Your task:\n    From the paper below (Title + Summary + Link), evaluate how useful each paper is for understanding investment opportunities or technological advantages within the Web3 / crypto / DeFi ecosystem.\n    Rate each paper on a five-level scale: Highest / High / Medium / Low / Lowest.\n\n    \"Useful\" means:\n\n    - Improves understanding of new cryptographic primitives relevant to blockchain performance or security\n    - Enhances scalability: distributed systems, P2P networking, consensus mechanisms\n    - Advances in zero knowledge, MPC, PQC that could impact future L1/L2 chains\n    - DeFi modeling, AMMs, MEV, risk models, liquidity dynamics\n    - Smart contract security, attack vectors, economic incentives\n    - Token economics, mechanism design for decentralized systems\n    - Quantum threats to blockchain or cryptography\n    - Any breakthrough that meaningfully improves decentralization, scalability, privacy, or composability\n\n    Output instructions:\n\n    - Output each JSON object in JSON Lines format (one line per paper).\n\n    {\n        \"title\": title of the paper (in Japanese),\n        \"summary\": A concise summary of the paper (in Japanese),\n        \"impact_level\": \"Highest|High|Medium|Low|Lowest\",\n        \"why_matters\": An array (JSON array) containing 2\u20134 bullet points explaining why this paper matters for Web3 investment\n    }\n\n    - Do not output anything except valid JSON object in JSON Lines.\n    - \"title\", \"summary\", \"why_matters\" text in the output must be written in Japanese.\n\n    Paper:\n    title: Online Learning-based Adaptive Beam Switching for 6G Networks: Enhancing Efficiency and Resilience\n    summary: Adaptive beam switching is essential for mission-critical military and commercial 6G networks but faces major challenges from high carrier frequencies, user mobility, and frequent blockages. While existing machine learning (ML) solutions often focus on maximizing instantaneous throughput, this can lead to unstable policies with high signaling overhead. This paper presents an online Deep Reinforcement Learning (DRL) framework designed to learn an operationally stable policy. By equipping the DRL agent with an enhanced state representation that includes blockage history, and a stability-centric reward function, we enable it to prioritize long-term link quality over transient gains. Validated in a challenging 100-user scenario using the Sionna library, our agent achieves throughput comparable to a reactive Multi-Armed Bandit (MAB) baseline. Specifically, our proposed framework improves link stability by approximately 43% compared to a vanilla DRL approach, achieving operational reliability competitive with MAB while maintaining high data rates. This work demonstrates that by reframing the optimization goal towards operational stability, DRL can deliver efficient, reliable, and real-time beam management solutions for next-generation mission-critical networks.\n    link: https://arxiv.org/abs/2505.08032v2\n    "}}
{"custom_id": "2512.03416v1", "method": "POST", "url": "/v1/responses", "body": {"model": "gpt-5-mini", "input": "You are a specialist research analyst in Web3, DeFi, cryptography, and distributed systems.\n\n    Your task:\n    From the paper below (Title + Summary + Link), evaluate how useful each paper is for understanding investment opportunities or technological advantages within the Web3 / crypto / DeFi ecosystem.\n    Rate each paper on a five-level scale: Highest / High / Medium / Low / Lowest.\n\n    \"Useful\" means:\n\n    - Improves understanding of new cryptographic primitives relevant to blockchain performance or security\n    - Enhances scalability: distributed systems, P2P networking, consensus mechanisms\n    - Advances in zero knowledge, MPC, PQC that could impact future L1/L2 chains\n    - DeFi modeling, AMMs, MEV, risk models, liquidity dynamics\n    - Smart contract security, attack vectors, economic incentives\n    - Token economics, mechanism design for decentralized systems\n    - Quantum threats to blockchain or cryptography\n    - Any breakthrough that meaningfully improves decentralization, scalability, privacy, or composability\n\n    Output instructions:\n\n    - Output each JSON object in JSON Lines format (one line per paper).\n\n    {\n        \"title\": title of the paper (in Japanese),\n        \"summary\": A concise summary of the paper (in Japanese),\n        \"impact_level\": \"Highest|High|Medium|Low|Lowest\",\n        \"why_matters\": An array (JSON array) containing 2\u20134 bullet points explaining why this paper matters for Web3 investment\n    }\n\n    - Do not output anything except valid JSON object in JSON Lines.\n    - \"title\", \"summary\", \"why_matters\" text in the output must be written in Japanese.\n\n    Paper:\n    title: TokenScale: Timely and Accurate Autoscaling for Disaggregated LLM Serving with Token Velocity\n    summary: The architectural shift to prefill/decode (PD) disaggregation in LLM serving improves resource utilization but struggles with the bursty nature of modern workloads. Existing autoscaling policies, often retrofitted from monolithic systems like those in AIBrix and DistServe, rely on lagging indicators such as GPU utilization or coarse-grained request counts. This results in slow reactions to load spikes, leading to significant Time-to First-Token (TTFT) and Time-Per-Output-Token (TPOT) SLO violations and costly over-provisioning. We introduce TokenScale, an autoscaling framework that resolves this performance mismatch through two innovations. First, we propose Token Velocity, a novel metric that unifies the prefill, network, and decode stages by quantifying their rate of work. As a leading indicator of system backpressure, it enables proactive scaling. Second, Convertible Decoders allow decoder GPUs to dynamically execute prefill tasks during traffic spikes, creating a rapid-response buffer that absorbs bursts and eliminates the initialization latency of new prefillers. Our evaluation on a GPU cluster with production traces shows TokenScale improves SLO attainment from 50-88% to 80-96% and reduces costs by 4-14% over state-of-the-art systems, including DistServe, BlitzScale, and AIBrix. By uniting a predictive metric with a flexible system design, TokenScale significantly boosts the performance and efficiency of disaggregated LLM serving infrastructure.\n    link: https://arxiv.org/abs/2512.03416v1\n    "}}
{"custom_id": "2504.19525v2", "method": "POST", "url": "/v1/responses", "body": {"model": "gpt-5-mini", "input": "You are a specialist research analyst in Web3, DeFi, cryptography, and distributed systems.\n\n    Your task:\n    From the paper below (Title + Summary + Link), evaluate how useful each paper is for understanding investment opportunities or technological advantages within the Web3 / crypto / DeFi ecosystem.\n    Rate each paper on a five-level scale: Highest / High / Medium / Low / Lowest.\n\n    \"Useful\" means:\n\n    - Improves understanding of new cryptographic primitives relevant to blockchain performance or security\n    - Enhances scalability: distributed systems, P2P networking, consensus mechanisms\n    - Advances in zero knowledge, MPC, PQC that could impact future L1/L2 chains\n    - DeFi modeling, AMMs, MEV, risk models, liquidity dynamics\n    - Smart contract security, attack vectors, economic incentives\n    - Token economics, mechanism design for decentralized systems\n    - Quantum threats to blockchain or cryptography\n    - Any breakthrough that meaningfully improves decentralization, scalability, privacy, or composability\n\n    Output instructions:\n\n    - Output each JSON object in JSON Lines format (one line per paper).\n\n    {\n        \"title\": title of the paper (in Japanese),\n        \"summary\": A concise summary of the paper (in Japanese),\n        \"impact_level\": \"Highest|High|Medium|Low|Lowest\",\n        \"why_matters\": An array (JSON array) containing 2\u20134 bullet points explaining why this paper matters for Web3 investment\n    }\n\n    - Do not output anything except valid JSON object in JSON Lines.\n    - \"title\", \"summary\", \"why_matters\" text in the output must be written in Japanese.\n\n    Paper:\n    title: Spin-Depairing-Induced Exceptional Fermionic Superfluidity\n    summary: We investigate the non-Hermitian (NH) attractive Hubbard model with spin depairing, which is a spin-resolved asymmetric hopping that nonreciprocally operates spins in the opposite direction. We find that spin depairing stabilizes a superfluid state unique to the NH system. This phase is characterized not only by a finite order parameter, but also by the emergence of exceptional points (EPs) in the momentum space - a feature that starkly contrasts with previously discussed NH fermionic superfluidity, where EPs are absent within the superfluid state and emerge only at the onset of the superfluid breakdown. We uncover the rich mechanism underlying this ``exceptional fermionic superfluidity'' by analyzing the interplay between EPs and the effective density of states of the complex energy dispersion. Furthermore, we reveal that the exceptional superfluid state breaks down induced by strong spin depairing on the cubic lattice, while it remains robust on the square lattice.\n    link: https://arxiv.org/abs/2504.19525v2\n    "}}
{"custom_id": "2508.09442v2", "method": "POST", "url": "/v1/responses", "body": {"model": "gpt-5-mini", "input": "You are a specialist research analyst in Web3, DeFi, cryptography, and distributed systems.\n\n    Your task:\n    From the paper below (Title + Summary + Link), evaluate how useful each paper is for understanding investment opportunities or technological advantages within the Web3 / crypto / DeFi ecosystem.\n    Rate each paper on a five-level scale: Highest / High / Medium / Low / Lowest.\n\n    \"Useful\" means:\n\n    - Improves understanding of new cryptographic primitives relevant to blockchain performance or security\n    - Enhances scalability: distributed systems, P2P networking, consensus mechanisms\n    - Advances in zero knowledge, MPC, PQC that could impact future L1/L2 chains\n    - DeFi modeling, AMMs, MEV, risk models, liquidity dynamics\n    - Smart contract security, attack vectors, economic incentives\n    - Token economics, mechanism design for decentralized systems\n    - Quantum threats to blockchain or cryptography\n    - Any breakthrough that meaningfully improves decentralization, scalability, privacy, or composability\n\n    Output instructions:\n\n    - Output each JSON object in JSON Lines format (one line per paper).\n\n    {\n        \"title\": title of the paper (in Japanese),\n        \"summary\": A concise summary of the paper (in Japanese),\n        \"impact_level\": \"Highest|High|Medium|Low|Lowest\",\n        \"why_matters\": An array (JSON array) containing 2\u20134 bullet points explaining why this paper matters for Web3 investment\n    }\n\n    - Do not output anything except valid JSON object in JSON Lines.\n    - \"title\", \"summary\", \"why_matters\" text in the output must be written in Japanese.\n\n    Paper:\n    title: Shadow in the Cache: Unveiling and Mitigating Privacy Risks of KV-cache in LLM Inference\n    summary: The Key-Value (KV) cache, which stores intermediate attention computations (Key and Value pairs) to avoid redundant calculations, is a fundamental mechanism for accelerating Large Language Model (LLM) inference. However, this efficiency optimization introduces significant yet underexplored privacy risks. This paper provides the first comprehensive analysis of these vulnerabilities, demonstrating that an attacker can reconstruct sensitive user inputs directly from the KV-cache. We design and implement three distinct attack vectors: a direct Inversion Attack, a more broadly applicable and potent Collision Attack, and a semantic-based Injection Attack. These methods demonstrate the practicality and severity of KV-cache privacy leakage issues. To mitigate this, we propose KV-Cloak, a novel, lightweight, and efficient defense mechanism. KV-Cloak uses a reversible matrix-based obfuscation scheme, combined with operator fusion, to secure the KV-cache. Our extensive experiments show that KV-Cloak effectively thwarts all proposed attacks, reducing reconstruction quality to random noise. Crucially, it achieves this robust security with virtually no degradation in model accuracy and minimal performance overhead, offering a practical solution for trustworthy LLM deployment.\n    link: https://arxiv.org/abs/2508.09442v2\n    "}}
{"custom_id": "2512.03368v1", "method": "POST", "url": "/v1/responses", "body": {"model": "gpt-5-mini", "input": "You are a specialist research analyst in Web3, DeFi, cryptography, and distributed systems.\n\n    Your task:\n    From the paper below (Title + Summary + Link), evaluate how useful each paper is for understanding investment opportunities or technological advantages within the Web3 / crypto / DeFi ecosystem.\n    Rate each paper on a five-level scale: Highest / High / Medium / Low / Lowest.\n\n    \"Useful\" means:\n\n    - Improves understanding of new cryptographic primitives relevant to blockchain performance or security\n    - Enhances scalability: distributed systems, P2P networking, consensus mechanisms\n    - Advances in zero knowledge, MPC, PQC that could impact future L1/L2 chains\n    - DeFi modeling, AMMs, MEV, risk models, liquidity dynamics\n    - Smart contract security, attack vectors, economic incentives\n    - Token economics, mechanism design for decentralized systems\n    - Quantum threats to blockchain or cryptography\n    - Any breakthrough that meaningfully improves decentralization, scalability, privacy, or composability\n\n    Output instructions:\n\n    - Output each JSON object in JSON Lines format (one line per paper).\n\n    {\n        \"title\": title of the paper (in Japanese),\n        \"summary\": A concise summary of the paper (in Japanese),\n        \"impact_level\": \"Highest|High|Medium|Low|Lowest\",\n        \"why_matters\": An array (JSON array) containing 2\u20134 bullet points explaining why this paper matters for Web3 investment\n    }\n\n    - Do not output anything except valid JSON object in JSON Lines.\n    - \"title\", \"summary\", \"why_matters\" text in the output must be written in Japanese.\n\n    Paper:\n    title: Short-Range Modulated Electron Lattice and d-Wave Superconductivity in Cuprates: A Phenomenological Ginzburg-Landau Framework\n    summary: We develop a phenomenological Ginzburg-Landau (GL) framework for high-$T_c$ cuprates in which a short-range modulation of the electronic charge density couples to a $d$-wave superconducting condensate. The resulting modulated electron lattice (MEL) state is distinct from long-range static charge density wave order: it is short range, partially phase coherent, and linked to superconducting coherence. A preferred wave vector $q^{\\ast} \\approx 0.3$ reciprocal lattice units along the Cu-O bond direction emerges from the interplay between a momentum-dependent susceptibility and bond-stretching phonons, consistent with neutron and x-ray data on YBa$_2$Cu$_3$O$_{7-\u03b4}$ and related cuprates. The GL free energy contains coupled $d$-wave superconducting and charge sectors with parameters constrained by optimally doped YBa$_2$Cu$_3$O$_{7-\u03b4}$. We identify an MEL enhancement window in doping, temperature, MEL correlation length, and disorder where a coherence linked modulation enhances the superfluid stiffness. Classical Monte Carlo simulations yield an in-plane stiffness enhancement of order ten percent, which we treat as a qualitative prediction to be tested by self-consistent Bogoliubov de Gennes calculations. The MEL framework yields falsifiable experimental signatures. For scanning tunneling spectroscopy in Bi-based cuprates we highlight two predictions: the Fourier-transformed local density of states should exhibit a $q^{\\ast} \\approx 0.3$ peak whose spectral weight sharpens as superconducting phase coherence develops below $T_c$, in contrast to static charge scenarios, and the local gap magnitude $\u0394(r)$ should correlate positively with the local MEL amplitude. The framework implies correlations between MEL correlation length, superfluid stiffness, disorder, and vortex pinning, and organizes cuprate observations into testable STM/STS predictions.\n    link: https://arxiv.org/abs/2512.03368v1\n    "}}
{"custom_id": "2512.03361v1", "method": "POST", "url": "/v1/responses", "body": {"model": "gpt-5-mini", "input": "You are a specialist research analyst in Web3, DeFi, cryptography, and distributed systems.\n\n    Your task:\n    From the paper below (Title + Summary + Link), evaluate how useful each paper is for understanding investment opportunities or technological advantages within the Web3 / crypto / DeFi ecosystem.\n    Rate each paper on a five-level scale: Highest / High / Medium / Low / Lowest.\n\n    \"Useful\" means:\n\n    - Improves understanding of new cryptographic primitives relevant to blockchain performance or security\n    - Enhances scalability: distributed systems, P2P networking, consensus mechanisms\n    - Advances in zero knowledge, MPC, PQC that could impact future L1/L2 chains\n    - DeFi modeling, AMMs, MEV, risk models, liquidity dynamics\n    - Smart contract security, attack vectors, economic incentives\n    - Token economics, mechanism design for decentralized systems\n    - Quantum threats to blockchain or cryptography\n    - Any breakthrough that meaningfully improves decentralization, scalability, privacy, or composability\n\n    Output instructions:\n\n    - Output each JSON object in JSON Lines format (one line per paper).\n\n    {\n        \"title\": title of the paper (in Japanese),\n        \"summary\": A concise summary of the paper (in Japanese),\n        \"impact_level\": \"Highest|High|Medium|Low|Lowest\",\n        \"why_matters\": An array (JSON array) containing 2\u20134 bullet points explaining why this paper matters for Web3 investment\n    }\n\n    - Do not output anything except valid JSON object in JSON Lines.\n    - \"title\", \"summary\", \"why_matters\" text in the output must be written in Japanese.\n\n    Paper:\n    title: Rethinking Security in Semantic Communication: Latent Manipulation as a New Threat\n    summary: Deep learning-based semantic communication (SemCom) has emerged as a promising paradigm for next-generation wireless networks, offering superior transmission efficiency by extracting and conveying task-relevant semantic latent representations rather than raw data. However, the openness of the wireless medium and the intrinsic vulnerability of semantic latent representations expose such systems to previously unrecognized security risks. In this paper, we uncover a fundamental latent-space vulnerability that enables Man-in-the-Middle (MitM) attacker to covertly manipulate the transmitted semantics while preserving the statistical properties of the transmitted latent representations. We first present a Diffusion-based Re-encoding Attack (DiR), wherein the attacker employs a diffusion model to synthesize an attacker-designed semantic variant, and re-encodes it into a valid latent representation compatible with the SemCom decoder. Beyond this model-dependent pathway, we further propose a model-agnostic and training-free Test-Time Adaptation Latent Manipulation attack (TTA-LM), in which the attacker perturbs and steers the intercepted latent representation toward an attacker-specified semantic target by leveraging the gradient of a target loss function. In contrast to diffusion-based manipulation, TTA-LM does not rely on any generative model and does not impose modality-specific or task-specific assumptions, thereby enabling efficient and broadly applicable latent-space tampering across diverse SemCom architectures. Extensive experiments on representative semantic communication architectures demonstrate that both attacks can significantly alter the decoded semantics while preserving natural latent-space distributions, making the attacks covert and difficult to detect.\n    link: https://arxiv.org/abs/2512.03361v1\n    "}}
{"custom_id": "2512.03358v1", "method": "POST", "url": "/v1/responses", "body": {"model": "gpt-5-mini", "input": "You are a specialist research analyst in Web3, DeFi, cryptography, and distributed systems.\n\n    Your task:\n    From the paper below (Title + Summary + Link), evaluate how useful each paper is for understanding investment opportunities or technological advantages within the Web3 / crypto / DeFi ecosystem.\n    Rate each paper on a five-level scale: Highest / High / Medium / Low / Lowest.\n\n    \"Useful\" means:\n\n    - Improves understanding of new cryptographic primitives relevant to blockchain performance or security\n    - Enhances scalability: distributed systems, P2P networking, consensus mechanisms\n    - Advances in zero knowledge, MPC, PQC that could impact future L1/L2 chains\n    - DeFi modeling, AMMs, MEV, risk models, liquidity dynamics\n    - Smart contract security, attack vectors, economic incentives\n    - Token economics, mechanism design for decentralized systems\n    - Quantum threats to blockchain or cryptography\n    - Any breakthrough that meaningfully improves decentralization, scalability, privacy, or composability\n\n    Output instructions:\n\n    - Output each JSON object in JSON Lines format (one line per paper).\n\n    {\n        \"title\": title of the paper (in Japanese),\n        \"summary\": A concise summary of the paper (in Japanese),\n        \"impact_level\": \"Highest|High|Medium|Low|Lowest\",\n        \"why_matters\": An array (JSON array) containing 2\u20134 bullet points explaining why this paper matters for Web3 investment\n    }\n\n    - Do not output anything except valid JSON object in JSON Lines.\n    - \"title\", \"summary\", \"why_matters\" text in the output must be written in Japanese.\n\n    Paper:\n    title: Scaling Trust in Quantum Federated Learning: A Multi-Protocol Privacy Design\n    summary: Quantum Federated Learning (QFL) promises to revolutionize distributed machine learning by combining the computational power of quantum devices with collaborative model training. Yet, privacy of both data and models remains a critical challenge. In this work, we propose a privacy-preserving QFL framework where a network of $n$ quantum devices trains local models and transmits them to a central server under a multi-layered privacy protocol. Our design leverages Singular Value Decomposition (SVD), Quantum Key Distribution (QKD), and Analytic Quantum Gradient Descent (AQGD) to secure data preparation, model sharing, and training stages. Through theoretical analysis and experiments on contemporary quantum platforms and datasets, we demonstrate that the framework robustly safeguards data and model confidentiality while maintaining training efficiency.\n    link: https://arxiv.org/abs/2512.03358v1\n    "}}
{"custom_id": "2512.03356v1", "method": "POST", "url": "/v1/responses", "body": {"model": "gpt-5-mini", "input": "You are a specialist research analyst in Web3, DeFi, cryptography, and distributed systems.\n\n    Your task:\n    From the paper below (Title + Summary + Link), evaluate how useful each paper is for understanding investment opportunities or technological advantages within the Web3 / crypto / DeFi ecosystem.\n    Rate each paper on a five-level scale: Highest / High / Medium / Low / Lowest.\n\n    \"Useful\" means:\n\n    - Improves understanding of new cryptographic primitives relevant to blockchain performance or security\n    - Enhances scalability: distributed systems, P2P networking, consensus mechanisms\n    - Advances in zero knowledge, MPC, PQC that could impact future L1/L2 chains\n    - DeFi modeling, AMMs, MEV, risk models, liquidity dynamics\n    - Smart contract security, attack vectors, economic incentives\n    - Token economics, mechanism design for decentralized systems\n    - Quantum threats to blockchain or cryptography\n    - Any breakthrough that meaningfully improves decentralization, scalability, privacy, or composability\n\n    Output instructions:\n\n    - Output each JSON object in JSON Lines format (one line per paper).\n\n    {\n        \"title\": title of the paper (in Japanese),\n        \"summary\": A concise summary of the paper (in Japanese),\n        \"impact_level\": \"Highest|High|Medium|Low|Lowest\",\n        \"why_matters\": An array (JSON array) containing 2\u20134 bullet points explaining why this paper matters for Web3 investment\n    }\n\n    - Do not output anything except valid JSON object in JSON Lines.\n    - \"title\", \"summary\", \"why_matters\" text in the output must be written in Japanese.\n\n    Paper:\n    title: Immunity memory-based jailbreak detection: multi-agent adaptive guard for large language models\n    summary: Large language models (LLMs) have become foundational in AI systems, yet they remain vulnerable to adversarial jailbreak attacks. These attacks involve carefully crafted prompts that bypass safety guardrails and induce models to produce harmful content. Detecting such malicious input queries is therefore critical for maintaining LLM safety. Existing methods for jailbreak detection typically involve fine-tuning LLMs as static safety LLMs using fixed training datasets. However, these methods incur substantial computational costs when updating model parameters to improve robustness, especially in the face of novel jailbreak attacks. Inspired by immunological memory mechanisms, we propose the Multi-Agent Adaptive Guard (MAAG) framework for jailbreak detection. The core idea is to equip guard with memory capabilities: upon encountering novel jailbreak attacks, the system memorizes attack patterns, enabling it to rapidly and accurately identify similar threats in future encounters. Specifically, MAAG first extracts activation values from input prompts and compares them to historical activations stored in a memory bank for quick preliminary detection. A defense agent then simulates responses based on these detection results, and an auxiliary agent supervises the simulation process to provide secondary filtering of the detection outcomes. Extensive experiments across five open-source models demonstrate that MAAG significantly outperforms state-of-the-art (SOTA) methods, achieving 98% detection accuracy and a 96% F1-score across a diverse range of attack scenarios.\n    link: https://arxiv.org/abs/2512.03356v1\n    "}}
{"custom_id": "2512.03351v1", "method": "POST", "url": "/v1/responses", "body": {"model": "gpt-5-mini", "input": "You are a specialist research analyst in Web3, DeFi, cryptography, and distributed systems.\n\n    Your task:\n    From the paper below (Title + Summary + Link), evaluate how useful each paper is for understanding investment opportunities or technological advantages within the Web3 / crypto / DeFi ecosystem.\n    Rate each paper on a five-level scale: Highest / High / Medium / Low / Lowest.\n\n    \"Useful\" means:\n\n    - Improves understanding of new cryptographic primitives relevant to blockchain performance or security\n    - Enhances scalability: distributed systems, P2P networking, consensus mechanisms\n    - Advances in zero knowledge, MPC, PQC that could impact future L1/L2 chains\n    - DeFi modeling, AMMs, MEV, risk models, liquidity dynamics\n    - Smart contract security, attack vectors, economic incentives\n    - Token economics, mechanism design for decentralized systems\n    - Quantum threats to blockchain or cryptography\n    - Any breakthrough that meaningfully improves decentralization, scalability, privacy, or composability\n\n    Output instructions:\n\n    - Output each JSON object in JSON Lines format (one line per paper).\n\n    {\n        \"title\": title of the paper (in Japanese),\n        \"summary\": A concise summary of the paper (in Japanese),\n        \"impact_level\": \"Highest|High|Medium|Low|Lowest\",\n        \"why_matters\": An array (JSON array) containing 2\u20134 bullet points explaining why this paper matters for Web3 investment\n    }\n\n    - Do not output anything except valid JSON object in JSON Lines.\n    - \"title\", \"summary\", \"why_matters\" text in the output must be written in Japanese.\n\n    Paper:\n    title: Empirical assessment of the perception of graphical threat model acceptability\n    summary: Threat modeling (TM) is an important aspect of risk analysis and secure software engineering. Graphical threat models are a recommended tool to analyze and communicate threat information. However, the comparison of different graphical threat models, and the acceptability of these threat models for an audience with a limited technical background, is not well understood, despite these users making up a sizable portion of the cybersecurity industry. We seek to compare the acceptability of three general, graphical threat models, Attack-Defense Trees (ADTs), Attack Graphs (AGs), and CORAS, for users with a limited technical background. We conducted a laboratory study with 38 bachelor students who completed tasks with the three threat models across three different scenarios assigned using a Latin square design. Threat model submissions were qualitatively analyzed, and participants filled out a perception questionnaire based on the Method Evaluation Model (MEM). We find that both ADTs and CORAS are broadly acceptable for a wide range of scenarios, and both could be applied successfully by users with a limited technical background; further, we also find that the lack of a specific tool for AGs may have impacted the perceived usefulness of AGs. We can recommend that users with a limited technical background use ADTs or CORAS as a general graphical TM method. Further research on the acceptability of AGs to such an audience and the effect of a dedicated TM tool support is needed.\n    link: https://arxiv.org/abs/2512.03351v1\n    "}}
{"custom_id": "2512.03338v1", "method": "POST", "url": "/v1/responses", "body": {"model": "gpt-5-mini", "input": "You are a specialist research analyst in Web3, DeFi, cryptography, and distributed systems.\n\n    Your task:\n    From the paper below (Title + Summary + Link), evaluate how useful each paper is for understanding investment opportunities or technological advantages within the Web3 / crypto / DeFi ecosystem.\n    Rate each paper on a five-level scale: Highest / High / Medium / Low / Lowest.\n\n    \"Useful\" means:\n\n    - Improves understanding of new cryptographic primitives relevant to blockchain performance or security\n    - Enhances scalability: distributed systems, P2P networking, consensus mechanisms\n    - Advances in zero knowledge, MPC, PQC that could impact future L1/L2 chains\n    - DeFi modeling, AMMs, MEV, risk models, liquidity dynamics\n    - Smart contract security, attack vectors, economic incentives\n    - Token economics, mechanism design for decentralized systems\n    - Quantum threats to blockchain or cryptography\n    - Any breakthrough that meaningfully improves decentralization, scalability, privacy, or composability\n\n    Output instructions:\n\n    - Output each JSON object in JSON Lines format (one line per paper).\n\n    {\n        \"title\": title of the paper (in Japanese),\n        \"summary\": A concise summary of the paper (in Japanese),\n        \"impact_level\": \"Highest|High|Medium|Low|Lowest\",\n        \"why_matters\": An array (JSON array) containing 2\u20134 bullet points explaining why this paper matters for Web3 investment\n    }\n\n    - Do not output anything except valid JSON object in JSON Lines.\n    - \"title\", \"summary\", \"why_matters\" text in the output must be written in Japanese.\n\n    Paper:\n    title: Structure theorems for the heart of LCA\n    summary: Cohomology theories with values in LCA (locally compact abelian) groups suffer from the problem that the latter do not form an abelian category. However, the category LCA has a canonical abelian category envelope, the heart of a suitable t-structure. It adds formal cokernel objects. We show the surprising result that these abstract cokernels can also be interpreted as Hausdorff topological abelian groups, at least up to lattice isogenies. These need not be locally compact.\n    link: https://arxiv.org/abs/2512.03338v1\n    "}}
{"custom_id": "2503.03428v2", "method": "POST", "url": "/v1/responses", "body": {"model": "gpt-5-mini", "input": "You are a specialist research analyst in Web3, DeFi, cryptography, and distributed systems.\n\n    Your task:\n    From the paper below (Title + Summary + Link), evaluate how useful each paper is for understanding investment opportunities or technological advantages within the Web3 / crypto / DeFi ecosystem.\n    Rate each paper on a five-level scale: Highest / High / Medium / Low / Lowest.\n\n    \"Useful\" means:\n\n    - Improves understanding of new cryptographic primitives relevant to blockchain performance or security\n    - Enhances scalability: distributed systems, P2P networking, consensus mechanisms\n    - Advances in zero knowledge, MPC, PQC that could impact future L1/L2 chains\n    - DeFi modeling, AMMs, MEV, risk models, liquidity dynamics\n    - Smart contract security, attack vectors, economic incentives\n    - Token economics, mechanism design for decentralized systems\n    - Quantum threats to blockchain or cryptography\n    - Any breakthrough that meaningfully improves decentralization, scalability, privacy, or composability\n\n    Output instructions:\n\n    - Output each JSON object in JSON Lines format (one line per paper).\n\n    {\n        \"title\": title of the paper (in Japanese),\n        \"summary\": A concise summary of the paper (in Japanese),\n        \"impact_level\": \"Highest|High|Medium|Low|Lowest\",\n        \"why_matters\": An array (JSON array) containing 2\u20134 bullet points explaining why this paper matters for Web3 investment\n    }\n\n    - Do not output anything except valid JSON object in JSON Lines.\n    - \"title\", \"summary\", \"why_matters\" text in the output must be written in Japanese.\n\n    Paper:\n    title: Privacy is All You Need: Revolutionizing Wearable Health Data with Advanced PETs\n    summary: In a world where data is the new currency, wearable health devices offer unprecedented insights into daily life, continuously monitoring vital signs and metrics. However, this convenience raises privacy concerns, as these devices collect sensitive data that can be misused or breached. Traditional measures often fail due to real-time data processing needs and limited device power. Users also lack awareness and control over data sharing and usage. We propose a Privacy-Enhancing Technology (PET) framework for wearable devices, integrating federated learning, lightweight cryptographic methods, and selectively deployed blockchain technology. The blockchain acts as a secure ledger triggered only upon data transfer requests, granting users real-time notifications and control. By dismantling data monopolies, this approach returns data sovereignty to individuals. Through real-world applications like secure medical data sharing, privacy-preserving fitness tracking, and continuous health monitoring, our framework reduces privacy risks by up to 70 percent while preserving data utility and performance. This innovation sets a new benchmark for wearable privacy and can scale to broader IoT ecosystems, including smart homes and industry. As data continues to shape our digital landscape, our research underscores the critical need to maintain privacy and user control at the forefront of technological progress.\n    link: https://arxiv.org/abs/2503.03428v2\n    "}}
{"custom_id": "2512.01353v2", "method": "POST", "url": "/v1/responses", "body": {"model": "gpt-5-mini", "input": "You are a specialist research analyst in Web3, DeFi, cryptography, and distributed systems.\n\n    Your task:\n    From the paper below (Title + Summary + Link), evaluate how useful each paper is for understanding investment opportunities or technological advantages within the Web3 / crypto / DeFi ecosystem.\n    Rate each paper on a five-level scale: Highest / High / Medium / Low / Lowest.\n\n    \"Useful\" means:\n\n    - Improves understanding of new cryptographic primitives relevant to blockchain performance or security\n    - Enhances scalability: distributed systems, P2P networking, consensus mechanisms\n    - Advances in zero knowledge, MPC, PQC that could impact future L1/L2 chains\n    - DeFi modeling, AMMs, MEV, risk models, liquidity dynamics\n    - Smart contract security, attack vectors, economic incentives\n    - Token economics, mechanism design for decentralized systems\n    - Quantum threats to blockchain or cryptography\n    - Any breakthrough that meaningfully improves decentralization, scalability, privacy, or composability\n\n    Output instructions:\n\n    - Output each JSON object in JSON Lines format (one line per paper).\n\n    {\n        \"title\": title of the paper (in Japanese),\n        \"summary\": A concise summary of the paper (in Japanese),\n        \"impact_level\": \"Highest|High|Medium|Low|Lowest\",\n        \"why_matters\": An array (JSON array) containing 2\u20134 bullet points explaining why this paper matters for Web3 investment\n    }\n\n    - Do not output anything except valid JSON object in JSON Lines.\n    - \"title\", \"summary\", \"why_matters\" text in the output must be written in Japanese.\n\n    Paper:\n    title: The Trojan Knowledge: Bypassing Commercial LLM Guardrails via Harmless Prompt Weaving and Adaptive Tree Search\n    summary: Large language models (LLMs) remain vulnerable to jailbreak attacks that bypass safety guardrails to elicit harmful outputs. Existing approaches overwhelmingly operate within the prompt-optimization paradigm: whether through traditional algorithmic search or recent agent-based workflows, the resulting prompts typically retain malicious semantic signals that modern guardrails are primed to detect. In contrast, we identify a deeper, largely overlooked vulnerability stemming from the highly interconnected nature of an LLM's internal knowledge. This structure allows harmful objectives to be realized by weaving together sequences of benign sub-queries, each of which individually evades detection. To exploit this loophole, we introduce the Correlated Knowledge Attack Agent (CKA-Agent), a dynamic framework that reframes jailbreaking as an adaptive, tree-structured exploration of the target model's knowledge base. The CKA-Agent issues locally innocuous queries, uses model responses to guide exploration across multiple paths, and ultimately assembles the aggregated information to achieve the original harmful objective. Evaluated across state-of-the-art commercial LLMs (Gemini2.5-Flash/Pro, GPT-oss-120B, Claude-Haiku-4.5), CKA-Agent consistently achieves over 95% success rates even against strong guardrails, underscoring the severity of this vulnerability and the urgent need for defenses against such knowledge-decomposition attacks. Our codes are available at https://github.com/Graph-COM/CKA-Agent.\n    link: https://arxiv.org/abs/2512.01353v2\n    "}}
{"custom_id": "2512.03310v1", "method": "POST", "url": "/v1/responses", "body": {"model": "gpt-5-mini", "input": "You are a specialist research analyst in Web3, DeFi, cryptography, and distributed systems.\n\n    Your task:\n    From the paper below (Title + Summary + Link), evaluate how useful each paper is for understanding investment opportunities or technological advantages within the Web3 / crypto / DeFi ecosystem.\n    Rate each paper on a five-level scale: Highest / High / Medium / Low / Lowest.\n\n    \"Useful\" means:\n\n    - Improves understanding of new cryptographic primitives relevant to blockchain performance or security\n    - Enhances scalability: distributed systems, P2P networking, consensus mechanisms\n    - Advances in zero knowledge, MPC, PQC that could impact future L1/L2 chains\n    - DeFi modeling, AMMs, MEV, risk models, liquidity dynamics\n    - Smart contract security, attack vectors, economic incentives\n    - Token economics, mechanism design for decentralized systems\n    - Quantum threats to blockchain or cryptography\n    - Any breakthrough that meaningfully improves decentralization, scalability, privacy, or composability\n\n    Output instructions:\n\n    - Output each JSON object in JSON Lines format (one line per paper).\n\n    {\n        \"title\": title of the paper (in Japanese),\n        \"summary\": A concise summary of the paper (in Japanese),\n        \"impact_level\": \"Highest|High|Medium|Low|Lowest\",\n        \"why_matters\": An array (JSON array) containing 2\u20134 bullet points explaining why this paper matters for Web3 investment\n    }\n\n    - Do not output anything except valid JSON object in JSON Lines.\n    - \"title\", \"summary\", \"why_matters\" text in the output must be written in Japanese.\n\n    Paper:\n    title: Randomized Masked Finetuning: An Efficient Way to Mitigate Memorization of PIIs in LLMs\n    summary: The current literature on memorization in Natural Language Models, especially Large Language Models (LLMs), poses severe security and privacy risks, as models tend to memorize personally identifying information (PIIs) from training data. We introduce Randomized Masked Fine-Tuning (RMFT), a novel privacy-preserving fine-tuning technique that reduces PII memorization while minimizing performance impact. Using the Enron Email Dataset, we demonstrate that RMFT achieves an 80.81% reduction in Total Extraction Rate and 80.17% reduction in Seen Extraction Rate compared to baseline fine-tuning, outperforming deduplication methods while maintaining only a 5.73% increase in perplexity. We present MaxTER, a Pareto-optimal evaluation framework for assessing privacy-utility tradeoffs, and show the performance of RMFT vs Deduplication by Area Under The Response Curve (AURC) metric.\n    link: https://arxiv.org/abs/2512.03310v1\n    "}}
{"custom_id": "2512.03287v1", "method": "POST", "url": "/v1/responses", "body": {"model": "gpt-5-mini", "input": "You are a specialist research analyst in Web3, DeFi, cryptography, and distributed systems.\n\n    Your task:\n    From the paper below (Title + Summary + Link), evaluate how useful each paper is for understanding investment opportunities or technological advantages within the Web3 / crypto / DeFi ecosystem.\n    Rate each paper on a five-level scale: Highest / High / Medium / Low / Lowest.\n\n    \"Useful\" means:\n\n    - Improves understanding of new cryptographic primitives relevant to blockchain performance or security\n    - Enhances scalability: distributed systems, P2P networking, consensus mechanisms\n    - Advances in zero knowledge, MPC, PQC that could impact future L1/L2 chains\n    - DeFi modeling, AMMs, MEV, risk models, liquidity dynamics\n    - Smart contract security, attack vectors, economic incentives\n    - Token economics, mechanism design for decentralized systems\n    - Quantum threats to blockchain or cryptography\n    - Any breakthrough that meaningfully improves decentralization, scalability, privacy, or composability\n\n    Output instructions:\n\n    - Output each JSON object in JSON Lines format (one line per paper).\n\n    {\n        \"title\": title of the paper (in Japanese),\n        \"summary\": A concise summary of the paper (in Japanese),\n        \"impact_level\": \"Highest|High|Medium|Low|Lowest\",\n        \"why_matters\": An array (JSON array) containing 2\u20134 bullet points explaining why this paper matters for Web3 investment\n    }\n\n    - Do not output anything except valid JSON object in JSON Lines.\n    - \"title\", \"summary\", \"why_matters\" text in the output must be written in Japanese.\n\n    Paper:\n    title: Multi-Frequency Federated Learning for Human Activity Recognition Using Head-Worn Sensors\n    summary: Human Activity Recognition (HAR) benefits various application domains, including health and elderly care. Traditional HAR involves constructing pipelines reliant on centralized user data, which can pose privacy concerns as they necessitate the uploading of user data to a centralized server. This work proposes multi-frequency Federated Learning (FL) to enable: (1) privacy-aware ML; (2) joint ML model learning across devices with varying sampling frequency. We focus on head-worn devices (e.g., earbuds and smart glasses), a relatively unexplored domain compared to traditional smartwatch- or smartphone-based HAR. Results have shown improvements on two datasets against frequency-specific approaches, indicating a promising future in the multi-frequency FL-HAR task. The proposed network's implementation is publicly available for further research and development.\n    link: https://arxiv.org/abs/2512.03287v1\n    "}}
{"custom_id": "2506.00821v2", "method": "POST", "url": "/v1/responses", "body": {"model": "gpt-5-mini", "input": "You are a specialist research analyst in Web3, DeFi, cryptography, and distributed systems.\n\n    Your task:\n    From the paper below (Title + Summary + Link), evaluate how useful each paper is for understanding investment opportunities or technological advantages within the Web3 / crypto / DeFi ecosystem.\n    Rate each paper on a five-level scale: Highest / High / Medium / Low / Lowest.\n\n    \"Useful\" means:\n\n    - Improves understanding of new cryptographic primitives relevant to blockchain performance or security\n    - Enhances scalability: distributed systems, P2P networking, consensus mechanisms\n    - Advances in zero knowledge, MPC, PQC that could impact future L1/L2 chains\n    - DeFi modeling, AMMs, MEV, risk models, liquidity dynamics\n    - Smart contract security, attack vectors, economic incentives\n    - Token economics, mechanism design for decentralized systems\n    - Quantum threats to blockchain or cryptography\n    - Any breakthrough that meaningfully improves decentralization, scalability, privacy, or composability\n\n    Output instructions:\n\n    - Output each JSON object in JSON Lines format (one line per paper).\n\n    {\n        \"title\": title of the paper (in Japanese),\n        \"summary\": A concise summary of the paper (in Japanese),\n        \"impact_level\": \"Highest|High|Medium|Low|Lowest\",\n        \"why_matters\": An array (JSON array) containing 2\u20134 bullet points explaining why this paper matters for Web3 investment\n    }\n\n    - Do not output anything except valid JSON object in JSON Lines.\n    - \"title\", \"summary\", \"why_matters\" text in the output must be written in Japanese.\n\n    Paper:\n    title: SafeGenes: Evaluating the Adversarial Robustness of Genomic Foundation Models\n    summary: Genomic Foundation Models (GFMs), such as Evolutionary Scale Modeling (ESM), have demonstrated significant success in variant effect prediction. However, their adversarial robustness remains largely unexplored. To address this gap, we propose SafeGenes: a framework for Secure analysis of genomic foundation models, leveraging adversarial attacks to evaluate robustness against both engineered near-identical adversarial Genes and embedding-space manipulations. In this study, we assess the adversarial vulnerabilities of GFMs using two approaches: the Fast Gradient Sign Method (FGSM) and a soft prompt attack. FGSM introduces minimal perturbations to input sequences, while the soft prompt attack optimizes continuous embeddings to manipulate model predictions without modifying the input tokens. By combining these techniques, SafeGenes provides a comprehensive assessment of GFM susceptibility to adversarial manipulation. Targeted soft prompt attacks induced severe degradation in MLM-based shallow architectures such as ProteinBERT, while still producing substantial failure modes even in high-capacity foundation models such as ESM1b and ESM1v. These findings expose critical vulnerabilities in current foundation models, opening new research directions toward improving their security and robustness in high-stakes genomic applications such as variant effect prediction.\n    link: https://arxiv.org/abs/2506.00821v2\n    "}}
{"custom_id": "2505.05559v2", "method": "POST", "url": "/v1/responses", "body": {"model": "gpt-5-mini", "input": "You are a specialist research analyst in Web3, DeFi, cryptography, and distributed systems.\n\n    Your task:\n    From the paper below (Title + Summary + Link), evaluate how useful each paper is for understanding investment opportunities or technological advantages within the Web3 / crypto / DeFi ecosystem.\n    Rate each paper on a five-level scale: Highest / High / Medium / Low / Lowest.\n\n    \"Useful\" means:\n\n    - Improves understanding of new cryptographic primitives relevant to blockchain performance or security\n    - Enhances scalability: distributed systems, P2P networking, consensus mechanisms\n    - Advances in zero knowledge, MPC, PQC that could impact future L1/L2 chains\n    - DeFi modeling, AMMs, MEV, risk models, liquidity dynamics\n    - Smart contract security, attack vectors, economic incentives\n    - Token economics, mechanism design for decentralized systems\n    - Quantum threats to blockchain or cryptography\n    - Any breakthrough that meaningfully improves decentralization, scalability, privacy, or composability\n\n    Output instructions:\n\n    - Output each JSON object in JSON Lines format (one line per paper).\n\n    {\n        \"title\": title of the paper (in Japanese),\n        \"summary\": A concise summary of the paper (in Japanese),\n        \"impact_level\": \"Highest|High|Medium|Low|Lowest\",\n        \"why_matters\": An array (JSON array) containing 2\u20134 bullet points explaining why this paper matters for Web3 investment\n    }\n\n    - Do not output anything except valid JSON object in JSON Lines.\n    - \"title\", \"summary\", \"why_matters\" text in the output must be written in Japanese.\n\n    Paper:\n    title: A Circuit-QED Lattice System with Flexible Connectivity and Gapped Flat Bands for Photon-Mediated Spin Models\n    summary: Quantum spin models are ubiquitous in solid-state physics, but classical simulation of them remains extremely challenging. Experimental testbed systems with a variety of spin-spin interactions and measurement channels are therefore needed. One promising potential route to such testbeds is provided by microwave-photon-mediated interactions between superconducting qubits, where native strong light-matter coupling enables significant interactions even for virtual-photon-mediated processes. In this approach, the spin-model connectivity is set by the photonic mode structure, rather than the spatial structure of the qubit. Lattices of coplanar-waveguide (CPW) resonators have been demonstrated to allow extremely flexible connectivities and can therefore host a huge variety of photon-mediated spin models. However, large-scale CPW lattices with non-trivial band structures have never before been successfully combined with superconducting qubits. Here we present the first such device featuring a quasi-1D CPW lattice with multiple transmon qubits. We demonstrate that superconducting-qubit readout and diagnostic techniques can be generalized to this highly multimode environment and observe the effective qubit-qubit interaction mediated by the bands of the resonator lattice. This device completes the toolkit needed to realize CPW lattices with qubits in one or two Euclidean dimensions, or negatively-curved hyperbolic space, and paves the way to driven-dissipative spin models with a large variety of connectivities.\n    link: https://arxiv.org/abs/2505.05559v2\n    "}}
{"custom_id": "2509.07506v2", "method": "POST", "url": "/v1/responses", "body": {"model": "gpt-5-mini", "input": "You are a specialist research analyst in Web3, DeFi, cryptography, and distributed systems.\n\n    Your task:\n    From the paper below (Title + Summary + Link), evaluate how useful each paper is for understanding investment opportunities or technological advantages within the Web3 / crypto / DeFi ecosystem.\n    Rate each paper on a five-level scale: Highest / High / Medium / Low / Lowest.\n\n    \"Useful\" means:\n\n    - Improves understanding of new cryptographic primitives relevant to blockchain performance or security\n    - Enhances scalability: distributed systems, P2P networking, consensus mechanisms\n    - Advances in zero knowledge, MPC, PQC that could impact future L1/L2 chains\n    - DeFi modeling, AMMs, MEV, risk models, liquidity dynamics\n    - Smart contract security, attack vectors, economic incentives\n    - Token economics, mechanism design for decentralized systems\n    - Quantum threats to blockchain or cryptography\n    - Any breakthrough that meaningfully improves decentralization, scalability, privacy, or composability\n\n    Output instructions:\n\n    - Output each JSON object in JSON Lines format (one line per paper).\n\n    {\n        \"title\": title of the paper (in Japanese),\n        \"summary\": A concise summary of the paper (in Japanese),\n        \"impact_level\": \"Highest|High|Medium|Low|Lowest\",\n        \"why_matters\": An array (JSON array) containing 2\u20134 bullet points explaining why this paper matters for Web3 investment\n    }\n\n    - Do not output anything except valid JSON object in JSON Lines.\n    - \"title\", \"summary\", \"why_matters\" text in the output must be written in Japanese.\n\n    Paper:\n    title: Astra: A Multi-Agent System for GPU Kernel Performance Optimization\n    summary: GPU kernel optimization has long been a central challenge at the intersection of high-performance computing and machine learning. Efficient kernels are crucial for accelerating large language model (LLM) training and serving, yet attaining high performance typically requires extensive manual tuning. Compiler-based systems reduce some of this burden, but still demand substantial manual design and engineering effort. Recently, researchers have explored using LLMs for GPU kernel generation, though prior work has largely focused on translating high-level PyTorch modules into CUDA code. In this work, we introduce Astra, the first LLM-based multi-agent system for GPU kernel optimization. Unlike previous approaches, Astra starts from existing CUDA implementations extracted from SGLang, a widely deployed framework for serving LLMs, rather than treating PyTorch modules as the specification. Within Astra, specialized LLM agents collaborate through iterative code generation, testing, profiling, and planning to produce kernels that are both correct and high-performance. On kernels from SGLang, Astra achieves an average speedup of 1.32x using zero-shot prompting with OpenAI o4-mini. A detailed case study further demonstrates that LLMs can autonomously apply loop transformations, optimize memory access patterns, exploit CUDA intrinsics, and leverage fast math operations to yield substantial performance gains. Our work highlights multi-agent LLM systems as a promising new paradigm for GPU kernel optimization. Our code is publicly available at https://github.com/Anjiang-Wei/Astra.\n    link: https://arxiv.org/abs/2509.07506v2\n    "}}
{"custom_id": "2512.03238v1", "method": "POST", "url": "/v1/responses", "body": {"model": "gpt-5-mini", "input": "You are a specialist research analyst in Web3, DeFi, cryptography, and distributed systems.\n\n    Your task:\n    From the paper below (Title + Summary + Link), evaluate how useful each paper is for understanding investment opportunities or technological advantages within the Web3 / crypto / DeFi ecosystem.\n    Rate each paper on a five-level scale: Highest / High / Medium / Low / Lowest.\n\n    \"Useful\" means:\n\n    - Improves understanding of new cryptographic primitives relevant to blockchain performance or security\n    - Enhances scalability: distributed systems, P2P networking, consensus mechanisms\n    - Advances in zero knowledge, MPC, PQC that could impact future L1/L2 chains\n    - DeFi modeling, AMMs, MEV, risk models, liquidity dynamics\n    - Smart contract security, attack vectors, economic incentives\n    - Token economics, mechanism design for decentralized systems\n    - Quantum threats to blockchain or cryptography\n    - Any breakthrough that meaningfully improves decentralization, scalability, privacy, or composability\n\n    Output instructions:\n\n    - Output each JSON object in JSON Lines format (one line per paper).\n\n    {\n        \"title\": title of the paper (in Japanese),\n        \"summary\": A concise summary of the paper (in Japanese),\n        \"impact_level\": \"Highest|High|Medium|Low|Lowest\",\n        \"why_matters\": An array (JSON array) containing 2\u20134 bullet points explaining why this paper matters for Web3 investment\n    }\n\n    - Do not output anything except valid JSON object in JSON Lines.\n    - \"title\", \"summary\", \"why_matters\" text in the output must be written in Japanese.\n\n    Paper:\n    title: How to DP-fy Your Data: A Practical Guide to Generating Synthetic Data With Differential Privacy\n    summary: High quality data is needed to unlock the full potential of AI for end users. However finding new sources of such data is getting harder: most publicly-available human generated data will soon have been used. Additionally, publicly available data often is not representative of users of a particular system -- for example, a research speech dataset of contractors interacting with an AI assistant will likely be more homogeneous, well articulated and self-censored than real world commands that end users will issue. Therefore unlocking high-quality data grounded in real user interactions is of vital interest. However, the direct use of user data comes with significant privacy risks. Differential Privacy (DP) is a well established framework for reasoning about and limiting information leakage, and is a gold standard for protecting user privacy. The focus of this work, \\emph{Differentially Private Synthetic data}, refers to synthetic data that preserves the overall trends of source data,, while providing strong privacy guarantees to individuals that contributed to the source dataset. DP synthetic data can unlock the value of datasets that have previously been inaccessible due to privacy concerns and can replace the use of sensitive datasets that previously have only had rudimentary protections like ad-hoc rule-based anonymization.\n  In this paper we explore the full suite of techniques surrounding DP synthetic data, the types of privacy protections they offer and the state-of-the-art for various modalities (image, tabular, text and decentralized). We outline all the components needed in a system that generates DP synthetic data, from sensitive data handling and preparation, to tracking the use and empirical privacy testing. We hope that work will result in increased adoption of DP synthetic data, spur additional research and increase trust in DP synthetic data approaches.\n    link: https://arxiv.org/abs/2512.03238v1\n    "}}
{"custom_id": "2506.19881v2", "method": "POST", "url": "/v1/responses", "body": {"model": "gpt-5-mini", "input": "You are a specialist research analyst in Web3, DeFi, cryptography, and distributed systems.\n\n    Your task:\n    From the paper below (Title + Summary + Link), evaluate how useful each paper is for understanding investment opportunities or technological advantages within the Web3 / crypto / DeFi ecosystem.\n    Rate each paper on a five-level scale: Highest / High / Medium / Low / Lowest.\n\n    \"Useful\" means:\n\n    - Improves understanding of new cryptographic primitives relevant to blockchain performance or security\n    - Enhances scalability: distributed systems, P2P networking, consensus mechanisms\n    - Advances in zero knowledge, MPC, PQC that could impact future L1/L2 chains\n    - DeFi modeling, AMMs, MEV, risk models, liquidity dynamics\n    - Smart contract security, attack vectors, economic incentives\n    - Token economics, mechanism design for decentralized systems\n    - Quantum threats to blockchain or cryptography\n    - Any breakthrough that meaningfully improves decentralization, scalability, privacy, or composability\n\n    Output instructions:\n\n    - Output each JSON object in JSON Lines format (one line per paper).\n\n    {\n        \"title\": title of the paper (in Japanese),\n        \"summary\": A concise summary of the paper (in Japanese),\n        \"impact_level\": \"Highest|High|Medium|Low|Lowest\",\n        \"why_matters\": An array (JSON array) containing 2\u20134 bullet points explaining why this paper matters for Web3 investment\n    }\n\n    - Do not output anything except valid JSON object in JSON Lines.\n    - \"title\", \"summary\", \"why_matters\" text in the output must be written in Japanese.\n\n    Paper:\n    title: Blameless Users in a Clean Room: Defining Copyright Protection for Generative Models\n    summary: Are there any conditions under which a generative model's outputs are guaranteed not to infringe the copyrights of its training data? This is the question of \"provable copyright protection\" first posed by Vyas, Kakade, and Barak (ICML 2023). They define near access-freeness (NAF) and propose it as sufficient for protection. This paper revisits the question and establishes new foundations for provable copyright protection -- foundations that are firmer both technically and legally. First, we show that NAF alone does not prevent infringement. In fact, NAF models can enable verbatim copying, a blatant failure of copy protection that we dub being tainted. Then, we introduce our blameless copy protection framework for defining meaningful guarantees, and instantiate it with clean-room copy protection. Clean-room copy protection allows a user to control their risk of copying by behaving in a way that is unlikely to copy in a counterfactual clean-room setting. Finally, we formalize a common intuition about differential privacy and copyright by proving that DP implies clean-room copy protection when the dataset is golden, a copyright deduplication requirement.\n    link: https://arxiv.org/abs/2506.19881v2\n    "}}
{"custom_id": "2509.24932v3", "method": "POST", "url": "/v1/responses", "body": {"model": "gpt-5-mini", "input": "You are a specialist research analyst in Web3, DeFi, cryptography, and distributed systems.\n\n    Your task:\n    From the paper below (Title + Summary + Link), evaluate how useful each paper is for understanding investment opportunities or technological advantages within the Web3 / crypto / DeFi ecosystem.\n    Rate each paper on a five-level scale: Highest / High / Medium / Low / Lowest.\n\n    \"Useful\" means:\n\n    - Improves understanding of new cryptographic primitives relevant to blockchain performance or security\n    - Enhances scalability: distributed systems, P2P networking, consensus mechanisms\n    - Advances in zero knowledge, MPC, PQC that could impact future L1/L2 chains\n    - DeFi modeling, AMMs, MEV, risk models, liquidity dynamics\n    - Smart contract security, attack vectors, economic incentives\n    - Token economics, mechanism design for decentralized systems\n    - Quantum threats to blockchain or cryptography\n    - Any breakthrough that meaningfully improves decentralization, scalability, privacy, or composability\n\n    Output instructions:\n\n    - Output each JSON object in JSON Lines format (one line per paper).\n\n    {\n        \"title\": title of the paper (in Japanese),\n        \"summary\": A concise summary of the paper (in Japanese),\n        \"impact_level\": \"Highest|High|Medium|Low|Lowest\",\n        \"why_matters\": An array (JSON array) containing 2\u20134 bullet points explaining why this paper matters for Web3 investment\n    }\n\n    - Do not output anything except valid JSON object in JSON Lines.\n    - \"title\", \"summary\", \"why_matters\" text in the output must be written in Japanese.\n\n    Paper:\n    title: Graph Theory Meets Federated Learning over Satellite Constellations: Spanning Aggregations, Network Formation, and Performance Optimization\n    summary: In this work, we introduce Fed-Span: \\textit{\\underline{fed}erated learning with \\underline{span}ning aggregation over low Earth orbit (LEO) satellite constellations}. Fed-Span aims to address critical challenges inherent to distributed learning in dynamic satellite networks, including intermittent satellite connectivity, heterogeneous computational capabilities of satellites, and time-varying satellites' datasets. At its core, Fed-Span leverages minimum spanning tree (MST) and minimum spanning forest (MSF) topologies to introduce spanning model aggregation and dispatching processes for distributed learning. To formalize Fed-Span, we offer a fresh perspective on MST/MSF topologies by formulating them through a set of continuous constraint representations (CCRs), thereby integrating these topologies into a distributed learning framework for satellite networks. Using these CCRs, we obtain the energy consumption and latency of operations in Fed-Span. Moreover, we derive novel convergence bounds for Fed-Span, accommodating its key system characteristics and degrees of freedom (i.e., tunable parameters). Finally, we propose a comprehensive optimization problem that jointly minimizes model prediction loss, energy consumption, and latency of {Fed-Span}. We unveil that this problem is NP-hard and develop a systematic approach to transform it into a geometric programming formulation, solved via successive convex optimization with performance guarantees. Through evaluations on real-world datasets, we demonstrate that Fed-Span outperforms existing methods, with faster model convergence, greater energy efficiency, and reduced latency.\n    link: https://arxiv.org/abs/2509.24932v3\n    "}}
{"custom_id": "2512.03211v1", "method": "POST", "url": "/v1/responses", "body": {"model": "gpt-5-mini", "input": "You are a specialist research analyst in Web3, DeFi, cryptography, and distributed systems.\n\n    Your task:\n    From the paper below (Title + Summary + Link), evaluate how useful each paper is for understanding investment opportunities or technological advantages within the Web3 / crypto / DeFi ecosystem.\n    Rate each paper on a five-level scale: Highest / High / Medium / Low / Lowest.\n\n    \"Useful\" means:\n\n    - Improves understanding of new cryptographic primitives relevant to blockchain performance or security\n    - Enhances scalability: distributed systems, P2P networking, consensus mechanisms\n    - Advances in zero knowledge, MPC, PQC that could impact future L1/L2 chains\n    - DeFi modeling, AMMs, MEV, risk models, liquidity dynamics\n    - Smart contract security, attack vectors, economic incentives\n    - Token economics, mechanism design for decentralized systems\n    - Quantum threats to blockchain or cryptography\n    - Any breakthrough that meaningfully improves decentralization, scalability, privacy, or composability\n\n    Output instructions:\n\n    - Output each JSON object in JSON Lines format (one line per paper).\n\n    {\n        \"title\": title of the paper (in Japanese),\n        \"summary\": A concise summary of the paper (in Japanese),\n        \"impact_level\": \"Highest|High|Medium|Low|Lowest\",\n        \"why_matters\": An array (JSON array) containing 2\u20134 bullet points explaining why this paper matters for Web3 investment\n    }\n\n    - Do not output anything except valid JSON object in JSON Lines.\n    - \"title\", \"summary\", \"why_matters\" text in the output must be written in Japanese.\n\n    Paper:\n    title: A Multi-Agent, Policy-Gradient approach to Network Routing\n    summary: Network routing is a distributed decision problem which naturally admits numerical performance measures, such as the average time for a packet to travel from source to destination. OLPOMDP, a policy-gradient reinforcement learning algorithm, was successfully applied to simulated network routing under a number of network models. Multiple distributed agents (routers) learned co-operative behavior without explicit inter-agent communication, and they avoided behavior which was individually desirable, but detrimental to the group's overall performance. Furthermore, shaping the reward signal by explicitly penalizing certain patterns of sub-optimal behavior was found to dramatically improve the convergence rate.\n    link: https://arxiv.org/abs/2512.03211v1\n    "}}
{"custom_id": "2512.03207v1", "method": "POST", "url": "/v1/responses", "body": {"model": "gpt-5-mini", "input": "You are a specialist research analyst in Web3, DeFi, cryptography, and distributed systems.\n\n    Your task:\n    From the paper below (Title + Summary + Link), evaluate how useful each paper is for understanding investment opportunities or technological advantages within the Web3 / crypto / DeFi ecosystem.\n    Rate each paper on a five-level scale: Highest / High / Medium / Low / Lowest.\n\n    \"Useful\" means:\n\n    - Improves understanding of new cryptographic primitives relevant to blockchain performance or security\n    - Enhances scalability: distributed systems, P2P networking, consensus mechanisms\n    - Advances in zero knowledge, MPC, PQC that could impact future L1/L2 chains\n    - DeFi modeling, AMMs, MEV, risk models, liquidity dynamics\n    - Smart contract security, attack vectors, economic incentives\n    - Token economics, mechanism design for decentralized systems\n    - Quantum threats to blockchain or cryptography\n    - Any breakthrough that meaningfully improves decentralization, scalability, privacy, or composability\n\n    Output instructions:\n\n    - Output each JSON object in JSON Lines format (one line per paper).\n\n    {\n        \"title\": title of the paper (in Japanese),\n        \"summary\": A concise summary of the paper (in Japanese),\n        \"impact_level\": \"Highest|High|Medium|Low|Lowest\",\n        \"why_matters\": An array (JSON array) containing 2\u20134 bullet points explaining why this paper matters for Web3 investment\n    }\n\n    - Do not output anything except valid JSON object in JSON Lines.\n    - \"title\", \"summary\", \"why_matters\" text in the output must be written in Japanese.\n\n    Paper:\n    title: Technical Report: The Need for a (Research) Sandstorm through the Privacy Sandbox\n    summary: The Privacy Sandbox, launched in 2019, is a series of proposals from Google to reduce ``cross-site and cross-app tracking while helping to keep online content and services free for all''. Over the years, Google implemented, experimented, and deprecated some of these APIs into their own products (Chrome, Android, etc.) which raised concerns about the potential of these mechanisms to fundamentally disrupt the advertising, mobile, and web ecosystems. As a result, it is paramount for researchers to understand the consequences that these new technologies, and future ones, will have on billions of users if and when deployed. In this report, we outline our call for privacy, security, usability, and utility evaluations of these APIs, our efforts materialized through the creation and operation of Privacy Sandstorm (https://privacysandstorm.github.io); a research portal to systematically gather resources (overview, analyses, artifacts, etc.) about such proposals. We find that our inventory provides a better visibility and broader perspective on the research findings in that space than what Google lets show through official channels.\n    link: https://arxiv.org/abs/2512.03207v1\n    "}}
{"custom_id": "2512.03193v1", "method": "POST", "url": "/v1/responses", "body": {"model": "gpt-5-mini", "input": "You are a specialist research analyst in Web3, DeFi, cryptography, and distributed systems.\n\n    Your task:\n    From the paper below (Title + Summary + Link), evaluate how useful each paper is for understanding investment opportunities or technological advantages within the Web3 / crypto / DeFi ecosystem.\n    Rate each paper on a five-level scale: Highest / High / Medium / Low / Lowest.\n\n    \"Useful\" means:\n\n    - Improves understanding of new cryptographic primitives relevant to blockchain performance or security\n    - Enhances scalability: distributed systems, P2P networking, consensus mechanisms\n    - Advances in zero knowledge, MPC, PQC that could impact future L1/L2 chains\n    - DeFi modeling, AMMs, MEV, risk models, liquidity dynamics\n    - Smart contract security, attack vectors, economic incentives\n    - Token economics, mechanism design for decentralized systems\n    - Quantum threats to blockchain or cryptography\n    - Any breakthrough that meaningfully improves decentralization, scalability, privacy, or composability\n\n    Output instructions:\n\n    - Output each JSON object in JSON Lines format (one line per paper).\n\n    {\n        \"title\": title of the paper (in Japanese),\n        \"summary\": A concise summary of the paper (in Japanese),\n        \"impact_level\": \"Highest|High|Medium|Low|Lowest\",\n        \"why_matters\": An array (JSON array) containing 2\u20134 bullet points explaining why this paper matters for Web3 investment\n    }\n\n    - Do not output anything except valid JSON object in JSON Lines.\n    - \"title\", \"summary\", \"why_matters\" text in the output must be written in Japanese.\n\n    Paper:\n    title: In Situ Quantum Analog Pulse Characterization via Structured Signal Processing\n    summary: Analog quantum simulators can directly emulate time-dependent Hamiltonian dynamics, enabling the exploration of diverse physical phenomena such as phase transitions, quench dynamics, and non-equilibrium processes. Realizing accurate analog simulations requires high-fidelity time-dependent pulse control, yet existing calibration schemes are tailored to digital gate characterization and cannot be readily extended to learn continuous pulse trajectories. We present a characterization algorithm for in situ learning of pulse trajectories by extending the Quantum Signal Processing (QSP) framework to analyze time-dependent pulses. By combining QSP with a logical-level analog-digital mapping paradigm, our method reconstructs a smooth pulse directly from queries of the time-ordered propagator, without requiring mid-circuit measurements or additional evolution. Unlike conventional Trotterization-based methods, our approach avoids unscalable performance degradation arising from accumulated local truncation errors as the logical-level segmentation increases. Through rigorous theoretical analysis and extensive numerical simulations, we demonstrate that our method achieves high accuracy with strong efficiency and robustness against SPAM as well as depolarizing errors, providing a lightweight and optimal validation protocol for analog quantum simulators capable of detecting major hardware faults.\n    link: https://arxiv.org/abs/2512.03193v1\n    "}}
{"custom_id": "2512.01115v2", "method": "POST", "url": "/v1/responses", "body": {"model": "gpt-5-mini", "input": "You are a specialist research analyst in Web3, DeFi, cryptography, and distributed systems.\n\n    Your task:\n    From the paper below (Title + Summary + Link), evaluate how useful each paper is for understanding investment opportunities or technological advantages within the Web3 / crypto / DeFi ecosystem.\n    Rate each paper on a five-level scale: Highest / High / Medium / Low / Lowest.\n\n    \"Useful\" means:\n\n    - Improves understanding of new cryptographic primitives relevant to blockchain performance or security\n    - Enhances scalability: distributed systems, P2P networking, consensus mechanisms\n    - Advances in zero knowledge, MPC, PQC that could impact future L1/L2 chains\n    - DeFi modeling, AMMs, MEV, risk models, liquidity dynamics\n    - Smart contract security, attack vectors, economic incentives\n    - Token economics, mechanism design for decentralized systems\n    - Quantum threats to blockchain or cryptography\n    - Any breakthrough that meaningfully improves decentralization, scalability, privacy, or composability\n\n    Output instructions:\n\n    - Output each JSON object in JSON Lines format (one line per paper).\n\n    {\n        \"title\": title of the paper (in Japanese),\n        \"summary\": A concise summary of the paper (in Japanese),\n        \"impact_level\": \"Highest|High|Medium|Low|Lowest\",\n        \"why_matters\": An array (JSON array) containing 2\u20134 bullet points explaining why this paper matters for Web3 investment\n    }\n\n    - Do not output anything except valid JSON object in JSON Lines.\n    - \"title\", \"summary\", \"why_matters\" text in the output must be written in Japanese.\n\n    Paper:\n    title: Sliced R\u00e9nyi Pufferfish Privacy: Directional Additive Noise Mechanism and Private Learning with Gradient Clipping\n    summary: We study privatization mechanism design and privacy accounting in the Pufferfish family, addressing two practical gaps of Renyi Pufferfish Privacy (RPP): high-dimensional optimal transport (OT) calibration and the absence of a general, mechanism-agnostic composition rule for iterative learning. We introduce Sliced Renyi Pufferfish Privacy (SRPP), which replaces high-dimensional comparisons by directional ones over a set of unit vectors, enabling geometry-aware and tractable guarantees. To calibrate noise without high-dimensional OT, we propose sliced Wasserstein mechanisms that compute per-direction (1-D) sensitivities, yielding closed-form, statistically stable, and anisotropic calibrations. We further define SRPP Envelope (SRPE) as computable upper bounds that are tightly implementable by these sliced Wasserstein mechanisms. For iterative deep learning algorithms, we develop a decompose-then-compose SRPP-SGD scheme with gradient clipping based on a History-Uniform Cap (HUC), a pathwise bound on one-step directional changes that is uniform over optimization history, and a mean-square variant (ms-HUC) that leverages subsampling randomness to obtain on-average SRPP guarantees with improved utility. The resulting HUC and ms-HUC accountants aggregate per-iteration, per-direction Renyi costs and integrate naturally with moments-accountant style analyses. Finally, when multiple mechanisms are trained and privatized independently under a common slicing geometry, our analysis yields graceful additive composition in both worst-case and mean-square regimes. Our experiments indicate that the proposed SRPP-based methods achieve favorable privacy-utility trade-offs in both static and iterative settings.\n    link: https://arxiv.org/abs/2512.01115v2\n    "}}
{"custom_id": "2510.22664v3", "method": "POST", "url": "/v1/responses", "body": {"model": "gpt-5-mini", "input": "You are a specialist research analyst in Web3, DeFi, cryptography, and distributed systems.\n\n    Your task:\n    From the paper below (Title + Summary + Link), evaluate how useful each paper is for understanding investment opportunities or technological advantages within the Web3 / crypto / DeFi ecosystem.\n    Rate each paper on a five-level scale: Highest / High / Medium / Low / Lowest.\n\n    \"Useful\" means:\n\n    - Improves understanding of new cryptographic primitives relevant to blockchain performance or security\n    - Enhances scalability: distributed systems, P2P networking, consensus mechanisms\n    - Advances in zero knowledge, MPC, PQC that could impact future L1/L2 chains\n    - DeFi modeling, AMMs, MEV, risk models, liquidity dynamics\n    - Smart contract security, attack vectors, economic incentives\n    - Token economics, mechanism design for decentralized systems\n    - Quantum threats to blockchain or cryptography\n    - Any breakthrough that meaningfully improves decentralization, scalability, privacy, or composability\n\n    Output instructions:\n\n    - Output each JSON object in JSON Lines format (one line per paper).\n\n    {\n        \"title\": title of the paper (in Japanese),\n        \"summary\": A concise summary of the paper (in Japanese),\n        \"impact_level\": \"Highest|High|Medium|Low|Lowest\",\n        \"why_matters\": An array (JSON array) containing 2\u20134 bullet points explaining why this paper matters for Web3 investment\n    }\n\n    - Do not output anything except valid JSON object in JSON Lines.\n    - \"title\", \"summary\", \"why_matters\" text in the output must be written in Japanese.\n\n    Paper:\n    title: The Gravitational Aspect of Information: The Physical Reality of Asymmetric \"Distance\"\n    summary: We show that when a Brownian bridge is physically constrained to satisfy a canonical condition, its time evolution exactly coincides with an m-geodesic on the statistical manifold of Gaussian distributions. This identification provides a direct physical realization of a geometric concept in information geometry. It implies that purely random processes evolve along informationally straight trajectories, analogous to geodesics in general relativity. Our findings suggest that the asymmetry of informational ``distance\" (divergence) plays a fundamental physical role, offering a concrete step toward an equivalence principle for information.\n    link: https://arxiv.org/abs/2510.22664v3\n    "}}
