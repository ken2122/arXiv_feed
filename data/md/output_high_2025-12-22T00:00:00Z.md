# 低ラウンドKeccak/SHA-3事前画像攻撃の量子資源解析：Qiskitモデリングによる古典2^{57.8}から量子2^{28.9}へ
https://arxiv.org/abs/2512.14759v1

## institutions
- Guilan University
- Iran University of Science and Technology

## summary
本論文はGroverのアルゴリズムを用いた3ラウンドKeccak-256（SHA-3）事前画像攻撃のハードウェア志向な量子解析を行う。Qiskitベースの回路合成により、3ラウンドKeccak量子オラクルは可逆化のためのアンコンピュートを含め約9,600個のToffoliゲート、論理量子ビット約3,200（状態1,600＋補助1,600）、全2量子ビットゲート約7.47×10^{13}、量子誤り訂正を考慮すると物理量子ビット約320万が必要と推定される。理論上の時間複雑度は古典T_cl=2^{57.8}から量子T_qu=2^{28.9}へ短縮されるが、物理ビット数・回路深さ・誤り蓄積といった実装オーバーヘッドが極めて大きく、実行時間はマシン仮定により43日〜2,365年以上と幅があり、いずれにせよ現実的な攻撃実行は不可であると結論づける。したがってSHA-3に対する事前画像攻撃は近〜中期的には量子コンピュータによって脅かされないと示す。

## impact_level: High

## why_matters
- SHA-3（Keccak）に対する量子事前画像攻撃が現実的でないことを具体的資源見積もりで示し、プロトコル運営者や投資家が今すぐ大規模なポスト量子移行を急ぐ必要性を緩和する判断材料を提供する。
- 量子脅威モデルをハードウェア志向で定量化しており、L1/L2やブリッジ、スマートコントラクトで利用されるハッシュ関数の長期安全性評価とロードマップ策定に直接応用できる。
- 量子攻撃の「理論的高速化」と実装上のオーバーヘッド（物理量子ビット、回路深さ、誤り訂正）を明確に区別する手法は、投資判断やリスク評価における現実的な脅威評価の基準を提供する。
- 論文の定量的データ（必要な量子ビット数・ゲート数・実行時間幅）は、将来の量子耐性暗号導入のタイムライン設計やコスト見積もりに有用で、プロジェクトの資本配分やセキュリティ投資判断に寄与する。

## categories
quant-ph, cs.CR

# エージェント向けゼロ知識監査：モデルコンテキストプロトコルによるプライバシー保護型通信検証
https://arxiv.org/abs/2512.14737v1

## institutions


## summary
既存のエージェント間通信は、課金・コンプライアンス・説明責任を満たすための検証可能な監査記録を提供しつつ通信の機密性を保つことが困難である。本論文はゼロ知識証明をModel Context Protocol（MCP）と組み合わせ、メッセージ内容を明かさずに通信が所定の形式やルールに従っていることを検証する枠組みを提案する。軽量ネットワークと互換性を保ちつつ非同期の監査検証を提供し、相互監査（片方は内容品質、もう一方は利用メトリクスを検証）を可能にする。安全性目標を形式化し、Circomベースの実装で実用性（低遅延かつ効率的な検証）を示した点が特徴で、通信プライバシーとデータ真正性を同時に達成する初の実用的システムとしている。

## impact_level: High

## why_matters
- プライバシー保護された監査は、オラクルやデータプロバイダ、オフチェーンリレーなどWeb3インフラでの信頼最小化と商用コンプライアンス（課金・KYC型検証等）を両立させるために直接応用可能。
- Circom実装による実装性の証明は、L2ブリッジ、ステートチャネル、分散オフチェーンエージェント（ガバナンス執行や自動化された戦略）への統合可能性を示しており、実用的なプロダクト導入の道筋を作る。
- 内容開示を伴わない検証により、監査や証跡がビジネス機密やユーザープライバシーを損なうことなく提供できるため、規制対応型DeFiや機関向けサービスの広がりを促進する可能性が高い。
- 暗号学的には新しい基礎プリミティブの提案ではないが、既存のゼロ知識技術を通信プロトコル（MCP）に組み込み非同期相互監査を実現した点は、Web3プロトコル設計における実用的な技術的優位性を示す（投資判断での技術リスク低減に寄与）。

## categories
cs.CR, cs.AI

# 一般化周期分解によるショアの量子アルゴリズムの実用的信頼性向上：理論と大規模実証
https://arxiv.org/abs/2512.11004v1

## institutions
- National Taiwan Normal University
- Taipei Municipal University of Education

## summary
本論文は、ショアの因数分解アルゴリズムに対する「一般化周期分解」手法を提案する。量子位相推定で得られる周期に対する厳密条件を緩和し、得られた周期の任意の約数を系統的に利用することで、各量子実行から得られる有効性を大幅に拡張する。2〜8桁の整数を対象に100万件以上の古典シミュレーションで実証し、7桁で99.998%超、8桁で99.999%超の成功率を示した。多項式時間性は維持され、不要な再試行を減らすことで量子資源の効率化にも寄与し、特にNISQ世代の量子器での量子暗号解析への適用可能性が示唆される。

## impact_level: High

## why_matters
- 量子暗号破りの実効性に直接関わる改良であり、ブロックチェーンで使われる離散対数／因数分解ベースの鍵（例：ECDSA, RSA）に対する脅威評価の再検討を促す。
- 実機やNISQ環境での成功率向上と資源削減は、量子技術が実運用レベルで暗号を破る閾値を下げる可能性があるため、ポスト量子暗号への移行計画（投資・設計・保険評価）に影響を与える。
- Web3インフラ（ウォレット、カストディ、L1プロトコル）のリスクモデリングとロードマップ策定にとって重要な入力となり、ポスト量子対応や量子耐性サービスへの投資機会を示唆する。

## categories
quant-ph, cs.CR

# ZK-APEX：実行可能な証明を用いたゼロ知識近似パーソナライズド消去
https://arxiv.org/abs/2512.09953v1

## institutions
- Imperial College London
- LASIGE, Universidade de Lisboa

## summary
個別にパーソナライズされたエッジ上モデルから特定データの影響を除去（機械的消去）し、その実行をプロバイダが検証できるようにする手法。プロバイダ側はスパースマスキング、クライアント側は小規模な補償更新（Group OBS）を行い、ブロック単位の経験的フィッシャー行列で曲率を考慮した低負荷の更新を設計する。Halo2ベースのゼロ知識証明と組み合わせることで、個人データやパラメータを明かさずに正しい消去変換が行われたことを検証可能にする。ViT分類でほぼ元の個別化精度を回復し、OPT125Mでは約70%を回復。再学習による検証より10^7倍高速な証明生成（ViTで約2時間）、メモリ<1GB、証明サイズ≈400MBといった実用的な初実装を示す。

## impact_level: High

## why_matters
- ゼロ知識証明を機械学習の『消去（unlearning）』に実用的に適用した初のフレームワークで、分散学習やエッジ上の個別モデルに対する信頼性検証を可能にするため、分散AI市場やオンチェーン外部データ供給の信頼担保につながる。
- Halo2などの現行ZKスタックを用いた具体的実装であり、ZKを用いた複雑な状態変換（モデル更新・削除）の証明が現実的であることを示しているため、将来のL1/L2上の検証付きAIサービスやオラクル、コンプライアンス証明への応用可能性が高い。
- 現状の証明サイズ（≈400MB）や生成時間（数時間）といった制約は残るが、再学習不要の近似手法により検査コストを桁違いに削減しており、投資観点では『分散AI＋ZK』を謳うプロジェクトの技術的優位性評価や、プライバシー準拠サービスの事業化ポテンシャル評価に直接役立つ。

## categories
cs.CR, cs.AI, cs.LG

# Llamaベースのソースコード脆弱性検出：プロンプトエンジニアリング vs ファインチューニング
https://arxiv.org/abs/2512.09006v1

## institutions
- University of Mons

## summary
本研究は、オープンソースのLlama-3.1（8B）を用いてソースコード脆弱性検出（CVD）を評価し、プロンプト設計と各種ファインチューニング手法を比較している。著者は新たなファインチューニング手法「Double Fine-tuning」を提案し、Test-TimeファインチューニングやRAG（Retrieval Augmented Generation）を含む設定を検証。BigVul／PrimeVulから抽出したコードで実験し、プロンプトのみでは性能が不十分である一方、ファインチューニング（特にDouble tuning）とRAGによる例選択が有効であることを示した。実装は公開されているが、スマートコントラクト固有データへの適用や一般化性については今後の課題が残る。

## impact_level: High

## why_matters
- スマートコントラクト／DeFiプロトコルの自動監査に直接応用可能：LLMベースの脆弱性検出が実用化すれば監査コスト削減、バグ発見の高速化、保険やデューデリジェンスの精度向上を通じて投資リスクを低減できる。
- 低コストで導入可能な実装パス：Llama-3.1 8Bのような中規模オープンモデルで効果を示しており、セキュリティツールやオーディットSaaSプロバイダが比較的容易に商用化できる可能性がある（競争優位の源泉）。
- 技術的示唆が投資判断に有用：Double Fine-tuningやTest-Time適応、RAGの有効性は、プロダクト差別化や技術的独自性を持つスタートアップの評価指標になり得る。
- 限定事項と注意点：実験は一般コードデータセット中心で、Solidity/EVM固有の脆弱性や悪意ある対抗入力への堅牢性評価は不十分。投資や導入判断ではドメイン適合性と誤検出率の検証が必須。

## categories
cs.SE, cs.AI, cs.CR

# 信頼できる分散型AIのための技術的ポリシーブループリント
https://arxiv.org/abs/2512.11878v1

## institutions


## summary
分散型AI（フェデレーテッドラーニング等）向けに、ガバナンス要件をポリシー-as-codeとして定義し、ポリシーの検証と執行を分離するアーキテクチャを提案する。Policy EngineがID・署名・支払い・信頼ハードウェアの証拠を検証して能力パッケージ（capability packages）を発行し、Asset Guardians（データ/モデル/計算ガーディアン）がその能力パッケージに基づいてアクセスや実行を行う。これによりガバナンスの進化がAIインフラの再構成を伴わずに可能となり、透明性・検証可能性・可搬性が向上する。

## impact_level: High

## why_matters
- 分散データ・モデル市場の相互運用性を高め、データやモデルのアクセス権をトークン化・能力パッケージ化して販売・ライセンスする新たなビジネスモデルを生むため、Web3のマーケットプレイス／収益化機会に直結する。
- 検証（オンチェーン／オフチェーンの証拠収集）と執行（ガーディアンによるアクセス制御）を明確に分離する設計は、スマートコントラクト+オフチェーンガバナンスの実装を容易にし、ミドルウェア・認証・アテステーション（TEE／DID）分野への投資機会を創出する。
- ポリシーをコード化することで監査性とアップグレード可能性が向上し、規制対応や企業導入の障壁を下げるため、機関投資家や規制志向のプロジェクトにとって価値が高い。
- 暗号的証明、署名、ハードウェア・アテステーション、支払い証跡などと親和性があり、ZK／MPCや信頼できる実行環境と組み合わせれば、プライバシー重視のL1/L2やクロスチェーンAI利用ケースで差別化できる技術基盤を提供する。

## categories
cs.CY, cs.CR

# データを開示せずにAIへ販売する：同型暗号による安全なデータ評価と共有
https://arxiv.org/abs/2512.06033v1

## institutions
- University of Texas at Dallas

## summary
本論文は、買い手がデータの有用性を検証するために生データを開示する必要があるという情報の逆説（Arrowの情報の逆説）を解決するため、Trustworthy Influence Protocol（TIP）を提案する。TIPは同型暗号と勾配ベースのインフルエンス関数を組み合わせ、買い手のモデルに対する各データ点の効用スコアを暗号化されたまま正確に算出可能にする。LLM向けのスケーラビリティを確保するために低ランク勾配射影を用い、BERTやGPT-2で平文基準とほぼ同等の精度を保ちながら計算負荷を低減している。医療や生成AIのシミュレーションでは、暗号化された評価信号が臨床的有用性と高相関を示し、事前学習コーパスで少数のテキストが性能を牽引する一方で多数が性能を劣化させるという重厚尾分布を明らかにした。これにより、フラットレート課金ではなく実力主義的なデータ経済の技術的基盤を提示する。

## impact_level: High

## why_matters
- プライバシー保護されたデータ評価はWeb3上のデータマーケットプレイスやデータNFTの実現に直結し、データ所有者が秘匿性を維持しつつ収益化できる新たなビジネスモデルを支える。
- 同型暗号を用いた暗号化下での評価信号は、検証可能な価格発見やエスクロー支払いと組み合わせれば、スマートコントラクトベースの取引・インセンティブ設計に組み込めるため、DeFi的な流動性・報酬メカニズム構築に有用。
- LLM対応の低ランク勾配射影によるスケーラビリティ改善と、実証された重厚尾なデータ価値分布は、希少な高価値データ資産の発掘／キュレーションに投資機会を示唆し、データ収集・取引戦略の差別化を可能にする。
- ただし同型暗号の計算コスト、オフチェーンでの処理や監査可能性の課題は残り、ブロックチェーン上での即時実装には追加の設計（例：軽量証明、オラクル連携）が必要である。

## categories
cs.CR, econ.GN

# 透明な事業者間決済のためのブロックチェーン基盤監査トレイルモデル
https://arxiv.org/abs/2512.09938v1

## institutions


## summary
本論文は、通信事業者および金融サービスにおける長期化した和解サイクル、高コスト、リアルタイム透明性不足といった課題に対し、分散台帳、スマートコントラクト自動化、暗号的検証を組み合わせたブロックチェーン連携の監査トレイルモデルを提案する。実証評価では取引手数料を87％削減、和解時間を120日から3分へ圧縮、監査トレイル整合性100％を報告し、手動介入を92％削減、決済紛争を88％削減したと主張する。さらに12,000TPSのスケーラビリティ、相互運用性、各国の規制適合性に対応可能とし、市場導入率と産業投資の急拡大を示唆している。

## impact_level: High

## why_matters
- 大幅なコスト削減と和解時間短縮は企業向けブロックチェーン導入を現実的にし、決済インフラやミドルウェア提供者への投資機会を創出する。
- スマートコントラクトによる自動化と改ざん不可能な監査トレイルは規制対応と透明性を強化し、金融機関・通信事業者のデジタル決済移行を促進する。
- 高いTPSと相互運用性の主張は高頻度決済やL2／クロスチェーン統合との親和性を示唆するが、基盤技術の新規性は限定的であり、実装・統合の成否が投資リスクを左右する。
- 想定される市場規模（年92億USD級）と導入実績の見込みは、決済トークン、決済ゲートウェイ、企業向けブロックチェーンサービスへの資本流入を正当化する。

## categories
cs.CR, cs.CY

# 数学・暗号学的視点からの隠れ部分群問題（HSP）に関するサーベイ
https://arxiv.org/abs/2512.02087v1

## institutions
- University of Trento
- Politecnico of Torino

## summary
本論文は隠れ部分群問題（HSP）を数学的および暗号学的観点から整理した総説である。アベリアン群の場合についてはKitaevのアルゴリズムなどを通じてHSPが効率的に量子解法を持つこと、これが因数分解や離散対数、順序探索といった古典的公的鍵暗号の脆弱性に直結する点を解説する。非アベリアン群については一般解法が未確立であり、二面体群（最短ベクトル問題）、対称群（グラフ同型）、半直積構成（符号等価問題）など関連する群と問題の関係を述べ、フーリエ測定やブラックボックス手法といった主要手法を紹介する。暗号学者向けに必要な数学的素地を提示しつつ、量子攻撃の適用範囲とポスト量子候補の位置づけを明確化する意図がある。

## impact_level: High

## why_matters
- 量子アルゴリズムが破る暗号（因数分解・離散対数など）をHSPフレームワークで整理しており、ブロックチェーン鍵管理やL1/L2プロトコルの量子耐性リスク評価に直接役立つ。
- 非アベリアンHSPと格子問題・符号問題などの関連を整理しているため、ポスト量子暗号の実用性・安全性の見積もりや投資判断（どのPQスキームが実用的か）に有用な知見を与える。
- 量子攻撃の現状と限界（どのクラスの問題がまだ安全か）を明確化するため、プロトコル設計者や運用者が移行ロードマップやソフトフォークの優先度を決める際の根拠として使える。
- 理論寄りの総説で新しい実装技術を直接示すわけではないが、暗号脅威モデリング・長期的なリスク管理・ポートフォリオ配分（量子耐性プロジェクトへの投資）において戦略的価値が高い。

## categories
cs.CR

# LLMBugScannerによる大規模言語モデルベースのスマートコントラクト監査
https://arxiv.org/abs/2512.02069v1

## institutions
- Georgia Institute of Technology

## summary
本論文はLLMBugScannerというフレームワークを提案する。複数の大規模言語モデル（LLM）を対象に、ドメイン知識適応（一般的なコード意味論と命令指向の脆弱性推論を補完するデータでの微調整）とパラメータ効率の良いチューニングを行い、さらにアンサンブル推論と合意ベースの衝突解決を導入して脆弱性検出の頑健性と汎化性能を高める。多数の公開LLM上での実験により、単一の事前学習/微調整モデルと比べて一貫した精度改善と費用対効果の向上を示している。

## impact_level: High

## why_matters
- スマートコントラクト監査の自動化により監査コストと時間を大幅に削減でき、プロジェクトのローンチ速度や投資前のリスク評価を改善するため直接的に資本効率に寄与する。
- アンサンブル＋ドメイン適応は多様なコントラクト構造や脆弱性タイプへの汎化性を高めるため、CI/CD統合やオンチェーン監視ツールへの実装によって実運用でのセキュリティ向上が期待できる。
- 実用的な限界（誤検知・見逃し、敵対的コードやモデルの誇張表現）は残るため、人的監査やバグバウンティと組み合わせた運用設計が必要であり、投資判断では自動診断の出力を過信しないリスク管理が重要である。

## categories
cs.CR, cs.AI

# オラクルの選択からオラクル・ロックインへ：ブロックチェーン・オラクル供給者選定に関する探索的研究
https://arxiv.org/abs/2512.03088v1

## institutions


## summary
Web3アプリにとってデータは不可欠であり、適切なオラクル選定は成功の鍵となる。本研究は、学術的に未解明だったクライアント側のオラクル選定理由を埋めるため、プロトコル幹部や代表者から得たデータ（DeFi時価総額の55％超をカバー）を解析した。主な知見は、スマートコントラクトの不変性が技術的依存を増幅しオラクルのロックインを招く点、そしてサードパーティの実用的解が存在する場合は多くのプロトコルが内製よりもアウトソースを好む点である。

## impact_level: High

## why_matters
- プロトコル依存性とスマートコントラクトの不変性がオラクル供給者のロックインを生むことを実証しており、オラクル集中化・交換コストに関する投資リスク評価に直結する。
- アウトソース志向が強いことは、オラクル事業者に対する収益機会と同時に集中化リスク（単一障害点・攻撃対象）の存在を示し、インフラ投資や保険・ヘッジ商品の需要を示唆する。
- プロトコルが切り替え困難である実態は、可搬性・モジュール化を提供する新しいオラクル標準や差別化技術（データ可検証性、分散化メカニズム、ガバナンス切替手続き）への需要を裏付け、技術投資案件の発掘に有用。
- 実データに基づく意思決定要因の整理は、オラクルやデータインフラに関する規制・競争リスク評価、及びDeFiプロトコルのリスク管理・設計改善（アップグレード戦略やデータ冗長化）に直接役立つ。

## categories
cs.CR, cs.CY, econ.GN

# コード脆弱性検出における検索拡張型few-shotプロンプティングとファインチューニングの比較
https://arxiv.org/abs/2512.04106v1

## institutions
- American University of Beirut

## summary
本研究は、大規模言語モデル（LLM）を用いたコード脆弱性検出において、(1) ランダム選択のfew-shotプロンプティング、(2) 検索（retrieval）で類似事例を取得して用いる検索拡張型few-shotプロンプティング、(3) 取得例に基づくラベリング（モデル推論を行わない）を比較した。Gemini-1.5-Flashを用いた評価では、検索拡張プロンプトが一貫して最良の結果を示し、20ショットでF1=74.05%、部分一致精度=83.90%を達成した。これはゼロショットや標準few-shot、ファインチューニング済みGemini（F1=59.31%）より優れる一方、ファインチューニングしたCodeBERT（F1=91.22%）には及ばなかった。検索拡張は学習コスト・運用コストを抑えつつ堅実な性能を提供する点が強調される。

## impact_level: High

## why_matters
- スマートコントラクト／DeFiコード監査のコスト効率化：検索拡張型few-shotは高精度の検出を比較的低コストで実現でき、オンチェーン／オフチェーンの自動脆弱性スキャンやCIパイプラインに導入しやすい。
- 事業化・投資機会の観点：専用のファインチューニングが不要なため、スタートアップやセキュリティツール事業者が迅速にサービスを立ち上げられ、脆弱性検出SaaSやバグバウンティ支援ビジネスの参入障壁を下げる。
- リスク軽減と資本保全：DeFiプロトコルやL1/L2実装に対する早期検出能力の向上は、契約損失やハッキングによる資金流出リスクを低減し、投資判断や保険・監査市場にプラスに働く。
- 限界と実装トレードオフ：最高性能はファインチューニング済みモデルが有するため、ミッションクリティカル（高価値）コードには追加学習投資が依然として有効。導入時は検出カバレッジと運用コストのトレードオフを評価する必要あり。

## categories
cs.SE, cs.AI, cs.CL, cs.CR

